from flask import Flask, render_template, request, jsonify, redirect, url_for, session, flash, abort, send_from_directory, Response
from collections import deque, defaultdict
# from flask_wtf.csrf import CSRFProtect, generate_csrf, validate_csrf as wtf_validate_csrf
import errno
import os
import sys
import json
import sqlite3
import random
import re
import logging
import uuid
import requests
import urllib.request
import urllib.error
import time
import base64
from io import BytesIO
import imghdr
from datetime import datetime, timedelta
from email.utils import parsedate_to_datetime
from functools import wraps
from markupsafe import escape
import secrets
from werkzeug.utils import secure_filename
from werkzeug.security import generate_password_hash, check_password_hash
from hashlib import sha256
from redis_cache import (
    cache,
    cache_result,
    invalidate_user_cache,
    invalidate_community_cache,
    invalidate_message_cache,
    community_feed_user_cache_key,
    COMMUNITY_CACHE_TTL,
    user_parent_dashboard_cache_key,
    user_community_tree_cache_key,
)
from itsdangerous import URLSafeTimedSerializer, BadSignature, SignatureExpired
from urllib.parse import urlencode, urljoin, quote_plus
from typing import Optional, Dict, Any, List, Iterable, Tuple, Set, Sequence
from concurrent.futures import ThreadPoolExecutor
from encryption_endpoints import register_encryption_endpoints
from signal_endpoints import register_signal_endpoints
from backend import init_app
from backend.services.database import USE_MYSQL, get_db_connection, get_sql_placeholder
from backend.services.community import (
    fetch_community_names,
    get_community_ancestors,
    get_community_basic,
    get_descendant_community_ids,
    get_parent_chain_ids,
    is_community_admin,
    is_community_owner,
)
from backend.services.notifications import (
    check_single_event_notifications,
    check_single_poll_notifications,
    create_notification,
    send_push_to_user,
)
from backend.services.native_push import (
    DEFAULT_APNS_ENVIRONMENT,
    associate_install_tokens_with_user,
    register_native_push_token,
    unregister_native_push_token,
)
from backend.services.media import (
    DEFAULT_ALLOWED_EXTENSIONS,
    allowed_file,
    get_public_upload_url,
    load_upload_bytes,
    normalize_upload_reference,
    optimize_image,
    resolve_upload_abspath,
    save_uploaded_file,
)
from backend.services.tasks import (
    ensure_tasks_table as ensure_tasks_table_service,
    is_community_admin_or_owner as service_is_community_admin_or_owner,
)
from backend.services.reactions import (
    get_post_reaction_summary,
    get_reply_reaction_summary,
)
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("Warning: PIL not available, image optimization disabled")

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
    print("‚úÖ OpenAI package imported successfully")
except ImportError as e:
    OPENAI_AVAILABLE = False
    print(f"‚ùå OpenAI not available: {e}")
    print("   Run: pip install openai")

# Initialize Flask app
app = Flask(__name__, template_folder='templates')
init_app(app)

# Initialize Firebase Cloud Messaging
print("üî• ATTEMPTING FIREBASE INITIALIZATION...")  # This WILL show in logs
try:
    from backend.services.firebase_notifications import initialize_firebase
    print("üî• Firebase module imported")
    result = initialize_firebase()
    print(f"üî• initialize_firebase() returned: {result}")
    if result:
        app.logger.info("‚úÖ Firebase Cloud Messaging initialized")
        print("‚úÖ Firebase Cloud Messaging initialized")
    else:
        app.logger.warning("‚ö†Ô∏è  Firebase not initialized - check FIREBASE_CREDENTIALS env var")
        print("‚ö†Ô∏è  Firebase not initialized - check FIREBASE_CREDENTIALS env var")
except Exception as e:
    app.logger.warning(f"‚ö†Ô∏è  Firebase initialization skipped: {e}")
    print(f"‚ö†Ô∏è  Firebase initialization skipped: {e}")
    import traceback
    traceback.print_exc()

MISSING_UPLOAD_CACHE = deque(maxlen=200)

COUNTRY_CACHE_TTL = 60 * 60 * 24  # 24 hours
CITY_CACHE_TTL = 60 * 60 * 24
COUNTRY_CACHE: Dict[str, Any] = {'timestamp': 0, 'data': []}
CITY_CACHE: Dict[str, Dict[str, Any]] = {}
FALLBACK_COUNTRIES = [
    {'name': 'United States', 'iso2': 'US'},
    {'name': 'United Kingdom', 'iso2': 'GB'},
    {'name': 'Canada', 'iso2': 'CA'},
    {'name': 'Australia', 'iso2': 'AU'},
    {'name': 'Germany', 'iso2': 'DE'},
    {'name': 'France', 'iso2': 'FR'},
    {'name': 'Brazil', 'iso2': 'BR'},
    {'name': 'India', 'iso2': 'IN'},
    {'name': 'Japan', 'iso2': 'JP'},
    {'name': 'Spain', 'iso2': 'ES'},
]
FALLBACK_CITY_MAP: Dict[str, List[str]] = {
    'united states': ['New York', 'Los Angeles', 'Chicago', 'San Francisco', 'Seattle', 'Austin', 'Boston', 'Miami'],
    'united kingdom': ['London', 'Manchester', 'Birmingham', 'Leeds', 'Glasgow', 'Edinburgh'],
    'canada': ['Toronto', 'Vancouver', 'Montreal', 'Calgary', 'Ottawa', 'Edmonton'],
    'australia': ['Sydney', 'Melbourne', 'Brisbane', 'Perth', 'Adelaide', 'Canberra'],
    'germany': ['Berlin', 'Munich', 'Hamburg', 'Frankfurt', 'Cologne', 'Stuttgart'],
    'france': ['Paris', 'Lyon', 'Marseille', 'Toulouse', 'Nice', 'Bordeaux'],
    'brazil': ['S√£o Paulo', 'Rio de Janeiro', 'Bras√≠lia', 'Salvador', 'Fortaleza', 'Curitiba'],
    'india': ['Mumbai', 'Delhi', 'Bengaluru', 'Hyderabad', 'Chennai', 'Kolkata'],
    'japan': ['Tokyo', 'Osaka', 'Kyoto', 'Yokohama', 'Nagoya', 'Sapporo'],
    'spain': ['Madrid', 'Barcelona', 'Valencia', 'Seville', 'Bilbao', 'Granada'],
    'italy': ['Rome', 'Milan', 'Florence', 'Venice', 'Turin', 'Naples'],
    'mexico': ['Mexico City', 'Guadalajara', 'Monterrey', 'Canc√∫n', 'Tijuana', 'Puebla'],
    'china': ['Beijing', 'Shanghai', 'Shenzhen', 'Guangzhou', 'Chengdu', 'Hong Kong'],
    'south korea': ['Seoul', 'Busan', 'Incheon', 'Daegu', 'Daejeon', 'Gwangju'],
    'russia': ['Moscow', 'Saint Petersburg', 'Novosibirsk', 'Yekaterinburg', 'Kazan', 'Sochi'],
    'netherlands': ['Amsterdam', 'Rotterdam', 'The Hague', 'Utrecht', 'Eindhoven', 'Maastricht'],
    'switzerland': ['Zurich', 'Geneva', 'Basel', 'Bern', 'Lausanne', 'Lucerne'],
    'south africa': ['Johannesburg', 'Cape Town', 'Durban', 'Pretoria', 'Port Elizabeth', 'Bloemfontein'],
    'united arab emirates': ['Dubai', 'Abu Dhabi', 'Sharjah', 'Al Ain', 'Ajman'],
    'turkey': ['Istanbul', 'Ankara', 'Izmir', 'Antalya', 'Bursa', 'Gaziantep'],
    'portugal': ['Lisbon', 'Porto', 'Faro', 'Coimbra', 'Braga', 'Funchal'],
    'ireland': ['Dublin', 'Cork', 'Galway', 'Limerick', 'Waterford'],
    'norway': ['Oslo', 'Bergen', 'Trondheim', 'Stavanger', 'Troms√∏'],
    'denmark': ['Copenhagen', 'Aarhus', 'Odense', 'Aalborg'],
    'sweden': ['Stockholm', 'Gothenburg', 'Malm√∂', 'Uppsala'],
    'belgium': ['Brussels', 'Antwerp', 'Ghent', 'Bruges', 'Leuven'],
    'new zealand': ['Auckland', 'Wellington', 'Christchurch', 'Queenstown', 'Hamilton'],
    'singapore': ['Singapore'],
    'saudi arabia': ['Riyadh', 'Jeddah', 'Mecca', 'Medina', 'Dammam'],
    'thailand': ['Bangkok', 'Chiang Mai', 'Phuket', 'Pattaya', 'Krabi'],
    'indonesia': ['Jakarta', 'Bali', 'Surabaya', 'Bandung', 'Yogyakarta'],
    'argentina': ['Buenos Aires', 'C√≥rdoba', 'Rosario', 'Mendoza', 'Bariloche'],
    'colombia': ['Bogot√°', 'Medell√≠n', 'Cartagena', 'Cali', 'Barranquilla'],
    'chile': ['Santiago', 'Valpara√≠so', 'Vi√±a del Mar', 'Concepci√≥n'],
    'peru': ['Lima', 'Cusco', 'Arequipa', 'Trujillo'],
    'egypt': ['Cairo', 'Alexandria', 'Giza', 'Luxor', 'Sharm El-Sheikh'],
    'nigeria': ['Lagos', 'Abuja', 'Port Harcourt', 'Ibadan', 'Kano'],
    'ghana': ['Accra', 'Kumasi', 'Takoradi', 'Tamale'],
    'kenya': ['Nairobi', 'Mombasa', 'Kisumu'],
    'philippines': ['Manila', 'Cebu', 'Davao City', 'Quezon City', 'Taguig'],
    'vietnam': ['Hanoi', 'Ho Chi Minh City', 'Da Nang', 'Hoi An'],
    'malaysia': ['Kuala Lumpur', 'George Town', 'Johor Bahru', 'Kota Kinabalu'],
    'austria': ['Vienna', 'Salzburg', 'Innsbruck', 'Graz', 'Linz'],
    'czech republic': ['Prague', 'Brno', 'Ostrava', 'Plzen'],
    'poland': ['Warsaw', 'Krak√≥w', 'Gda≈Ñsk', 'Wroc≈Çaw', 'Pozna≈Ñ'],
    'hungary': ['Budapest', 'Debrecen', 'Szeged', 'P√©cs'],
    'greece': ['Athens', 'Thessaloniki', 'Heraklion', 'Patras', 'Santorini'],
    'romania': ['Bucharest', 'Cluj-Napoca', 'Brasov', 'Timisoara'],
    'croatia': ['Zagreb', 'Split', 'Dubrovnik', 'Zadar'],
    'israel': ['Tel Aviv', 'Jerusalem', 'Haifa', 'Eilat'],
    'finland': ['Helsinki', 'Espoo', 'Tampere', 'Turku'],
    'iceland': ['Reykjavik', 'Akureyri'],
    'dominican republic': ['Santo Domingo', 'Punta Cana', 'Santiago De Los Caballeros'],
    'costa rica': ['San Jos√©', 'Liberia', 'Alajuela'],
}

STORY_IMAGE_EXTENSIONS = {'jpg', 'jpeg', 'png', 'gif', 'webp'}
STORY_VIDEO_EXTENSIONS = {'mp4', 'mov', 'm4v', 'webm', 'avi'}
STORY_ALLOWED_EXTENSIONS = STORY_IMAGE_EXTENSIONS | STORY_VIDEO_EXTENSIONS
STORY_DEFAULT_LIFESPAN_HOURS = 24
STORY_MAX_CAPTION_LENGTH = 2000

# Authentication decorators (defined early so they are in scope for route decorators)
def login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'username' not in session:
            try:
                logger.info("No username in session, redirecting to login")
            except Exception:
                pass
            return redirect(url_for('auth.login'))
        return f(*args, **kwargs)
    return decorated_function

def business_login_required(f):
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'business_id' not in session:
            return redirect(url_for('business_login'))
        return f(*args, **kwargs)
    return decorated_function

def handle_broken_pipe(f):
    """
    Decorator to gracefully handle broken pipe errors.
    
    These occur when the client disconnects before the server finishes 
    sending the response. Common on mobile apps when requests are cancelled.
    """
    @wraps(f)
    def decorated_function(*args, **kwargs):
        try:
            return f(*args, **kwargs)
        except (BrokenPipeError, ConnectionResetError):
            # Client disconnected - this is normal behavior
            return '', 499  # 499 = Client Closed Request
        except OSError as e:
            # Check for EPIPE (broken pipe) or ECONNRESET
            if e.errno in (errno.EPIPE, errno.ECONNRESET, errno.ENOTCONN):
                return '', 499
            raise  # Re-raise other OS errors
        except IOError as e:
            # Also catch IOError for write errors
            if 'write error' in str(e).lower() or 'broken pipe' in str(e).lower():
                return '', 499
            raise
    return decorated_function

# Add caching headers for static files (especially images)
@app.after_request
def add_cache_headers(response):
    """Add aggressive caching headers for static files to improve performance"""
    # Check if this is a static file request
    if request.path.startswith('/static/'):
        # Images get long cache time (7 days)
        if any(request.path.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.ico']):
            response.headers['Cache-Control'] = 'public, max-age=604800, immutable'  # 7 days
            response.headers['Expires'] = (datetime.now() + timedelta(days=7)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        # CSS and JS get medium cache time (1 day) with immutable flag
        # Vite's filename hashing (index-B1Wbmng4.js) ensures new builds get new files
        # The hash changes on every build, so aggressive caching is safe
        elif any(request.path.endswith(ext) for ext in ['.css', '.js']):
            response.headers['Cache-Control'] = 'public, max-age=86400, immutable'  # 1 day
            response.headers['Expires'] = (datetime.now() + timedelta(days=1)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        # Other static files get short cache time (1 hour)
        else:
            response.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour
    
    # Cache uploaded media files (videos, images) - iOS WKWebView respects these headers
    if request.path.startswith('/uploads/'):
        # Videos get long cache time (30 days) - they don't change after upload
        if any(request.path.endswith(ext) for ext in ['.mp4', '.webm', '.mov', '.m4v', '.avi']):
            response.headers['Cache-Control'] = 'public, max-age=2592000, immutable'  # 30 days
            response.headers['Expires'] = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        # Images in uploads also get long cache time
        elif any(request.path.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']):
            response.headers['Cache-Control'] = 'public, max-age=2592000, immutable'  # 30 days
            response.headers['Expires'] = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        # Audio files
        elif any(request.path.endswith(ext) for ext in ['.mp3', '.m4a', '.wav', '.ogg', '.webm']):
            response.headers['Cache-Control'] = 'public, max-age=2592000, immutable'  # 30 days
            response.headers['Expires'] = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S GMT')
    
    # Add security headers while we're at it
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'SAMEORIGIN'
    
    return response

@app.after_request
def log_onboarding_redirects(response):
    try:
        if response.status_code in (301, 302) and '/onboarding' in (response.headers.get('Location') or ''):
            logger.warning(f"HTTP redirect to /onboarding: path={request.path}, referer={request.headers.get('Referer')}, ua={request.headers.get('User-Agent')}")
    except Exception:
        pass
    return response

# Custom template filters
@app.template_filter('nl2br')
def nl2br_filter(text):
    """Convert newlines to <br> tags"""
    if text is None:
        return ''
    return text.replace('\n', '<br>')

# Force reload to clear any cached routes - Updated 2025-08-21 16:50 - CLEAR CACHE

# Temporarily disable CSRF protection
# csrf = CSRFProtect(app)
# csrf.exempt(app)  # Disable CSRF protection globally

# File upload configuration
# Always use an absolute path based on this file's directory to avoid CWD issues under WSGI
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_FOLDER = os.path.join(BASE_DIR, 'static', 'uploads')
# Allow common image, video, and audio types
ALLOWED_EXTENSIONS = set(DEFAULT_ALLOWED_EXTENSIONS)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['ALLOWED_EXTENSIONS'] = ALLOWED_EXTENSIONS

IMAGINE_OUTPUT_SUBDIR = 'imagine'
IMAGINE_OUTPUT_DIR = os.path.join(app.config['UPLOAD_FOLDER'], IMAGINE_OUTPUT_SUBDIR)
os.makedirs(IMAGINE_OUTPUT_DIR, exist_ok=True)

RUNWAY_API_KEY = (os.environ.get('RUNWAY_API_KEY') or '').strip() or None
RUNWAY_MODEL_ID = os.environ.get('RUNWAY_MODEL_ID', 'gen4_turbo')
RUNWAY_API_URL = os.environ.get('RUNWAY_API_URL', 'https://api.dev.runwayml.com')
# Kling AI configuration for spicy video generation
KLING_SECRET_KEY = (os.environ.get('Kling_Secret_KEY') or os.environ.get('KLING_SECRET_KEY') or '').strip() or None
KLING_ACCESS_KEY = (os.environ.get('Kling_Access_KEY') or os.environ.get('KLING_ACCESS_KEY') or '').strip() or None
KLING_API_URL = 'https://api.klingai.com/v1'
KLING_TIMEOUT_SECONDS = int(os.environ.get('KLING_TIMEOUT_SECONDS', '600'))
KLING_POLL_INTERVAL_SECONDS = int(os.environ.get('KLING_POLL_INTERVAL_SECONDS', '10'))
PUBLIC_BASE_URL = (os.environ.get('PUBLIC_BASE_URL') or '').rstrip('/') or None
app.config['PUBLIC_BASE_URL'] = PUBLIC_BASE_URL
try:
    imagine_executor = ThreadPoolExecutor(max_workers=int(os.environ.get('IMAGINE_MAX_WORKERS', '2')))
except Exception:
    imagine_executor = ThreadPoolExecutor(max_workers=2)

IMAGINE_ALLOWED_STYLES = {'normal', 'fun', 'spicy'}
IMAGINE_STATUS_PENDING = 'pending'
IMAGINE_STATUS_PROCESSING = 'processing'
IMAGINE_STATUS_COMPLETED = 'completed'
IMAGINE_STATUS_ERROR = 'error'
IMAGINE_STATUS_AWAITING_OWNER = 'awaiting_owner'

RUNWAY_MODEL_RATIO_OPTIONS: Dict[str, Dict[str, Any]] = {
    'gen4_turbo': {
        'landscape': ['1280:720', '1104:832', '1584:672'],
        'portrait': ['720:1280', '832:1104'],
        'square': ['960:960']
    },
    'gen3a_turbo': {
        'landscape': ['1280:768'],
        'portrait': ['768:1280'],
        'square': ['1280:768']
    },
    'veo3.1': {
        'landscape': ['1280:720', '1920:1080'],
        'portrait': ['720:1280', '1080:1920'],
        'square': ['1280:720']
    },
    'veo3.1_fast': {
        'landscape': ['1280:720', '1920:1080'],
        'portrait': ['720:1280', '1080:1920'],
        'square': ['1280:720']
    },
    'veo3': {
        'landscape': ['1280:720', '1920:1080'],
        'portrait': ['720:1280', '1080:1920'],
        'square': ['1280:720']
    }
}

# Session configuration: persist login for 30 days
app.config['SESSION_COOKIE_HTTPONLY'] = True
app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
app.config['SESSION_COOKIE_PATH'] = '/'  # Ensure cookie is available for all paths
app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=30)
# For production with HTTPS - disabled for PythonAnywhere proxy compatibility
# PythonAnywhere proxy doesn't forward X-Forwarded-Proto properly, so Flask thinks it's HTTP
# Setting this to True prevents session cookies from being set
app.config['SESSION_COOKIE_SECURE'] = False  # Must be False for PythonAnywhere
# Cookie domain: ensure session persists across apex and www
try:
    explicit_domain = os.getenv('SESSION_COOKIE_DOMAIN')
    if explicit_domain:
        app.config['SESSION_COOKIE_DOMAIN'] = explicit_domain
    else:
        # If canonical host is provided and ends with c-point.co, scope cookie to .c-point.co
        ch = os.getenv('CANONICAL_HOST') or ''
        if ch.endswith('c-point.co'):
            app.config['SESSION_COOKIE_DOMAIN'] = '.c-point.co'
except Exception:
    pass
app.config['SESSION_COOKIE_NAME'] = 'cpoint_session'  # Changed to avoid conflicts with old cookies
app.config['PREFERRED_URL_SCHEME'] = 'https'


@app.route('/api/config/giphy_key', methods=['GET'])
def api_config_giphy_key():
    """Expose the Giphy API key for the frontend if available."""
    key = os.environ.get('GIPHY_API_KEY') or os.environ.get('VITE_GIPHY_API_KEY')
    if key:
        return jsonify({'success': True, 'key': key})
    return jsonify({'success': False, 'key': None})

# Email (Resend)
RESEND_API_KEY = os.getenv('RESEND_API_KEY')
EMAIL_FROM = os.getenv('EMAIL_FROM', 'C-Point <no-reply@c-point.co>')
VERIFICATION_TOKEN_SECRET = os.getenv('VERIFICATION_TOKEN_SECRET', app.secret_key or 'change-me')
VERIFICATION_TOKEN_SALT = 'email-verify'
VERIFICATION_TOKEN_MAX_AGE = int(os.getenv('VERIFICATION_TOKEN_MAX_AGE', '86400'))  # 24h default
PENDING_SIGNUP_TOKEN_SALT = 'pending-signup'

def _get_serializer():
    return URLSafeTimedSerializer(VERIFICATION_TOKEN_SECRET)

# Block unverified users from entering the app except for auth/static routes
@app.before_request
def _block_unverified_users():
    try:
        # Allow static and auth endpoints
        path = request.path or ''
        if path.startswith('/static') or path.startswith('/assets'):
            return None
        if path in ('/', '/welcome', '/login', '/login_password', '/signup', '/signup_react', '/verify_email', '/resend_verification', '/logout', '/verify_required', '/onboarding', '/resend_verification_pending'):
            return None
        # Allow login flow API endpoints (no auth required)
        if path in ('/api/check_pending_login', '/api/invitation/verify'):
            return None
        # Health and misc
        if path in ('/health', '/vite.svg', '/favicon.svg', '/manifest.webmanifest') or path.startswith('/icons/'):
            return None
        # API behavior: return JSON instead of HTML redirects to avoid client parse errors
        # Exception for public endpoints (no auth required)
        public_api_endpoints = ['/api/poll_notification_check', '/api/event_notification_check', '/api/email_verified_status', '/api/invitation/verify']
        if path.startswith('/api/') and path not in public_api_endpoints:
            username = session.get('username')
            if not username:
                return jsonify({'success': False, 'error': 'unauthenticated'}), 401
            with get_db_connection() as conn:
                c = conn.cursor()
                c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
                row = c.fetchone()
                verified = bool((row['email_verified'] if hasattr(row, 'keys') else row[0]) if row is not None else False)
            if not verified:
                return jsonify({'success': False, 'error': 'verify_required'}), 403
            return None
        # API that must remain accessible
        if path.startswith('/api/client_log'):
            return None
        # If not logged in, normal flow
        username = session.get('username')
        if not username:
            return None
        # Check email_verified
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
            row = c.fetchone()
            verified = bool((row['email_verified'] if hasattr(row, 'keys') else row[0]) if row is not None else False)
        if not verified:
            # Allow only verification related pages
            if path.startswith('/verify_email') or path == '/resend_verification' or path == '/resend_verification_pending':
                return None
            # Redirect to verification required page (React onboarding-friendly)
            return redirect(url_for('verify_required'))
    except Exception:
        return None

@app.route('/verify_required')
def verify_required():
    # Always serve the simple HTML page to avoid client-side routing confusion
    try:
        return render_template('verify_required.html')
    except Exception:
        return render_template('verify_required.html')

def generate_email_token(email: str) -> str:
    s = _get_serializer()
    return s.dumps({'email': email}, salt=VERIFICATION_TOKEN_SALT)

def verify_email_token(token: str):
    s = _get_serializer()
    try:
        data = s.loads(token, salt=VERIFICATION_TOKEN_SALT, max_age=VERIFICATION_TOKEN_MAX_AGE)
        return data.get('email')
    except SignatureExpired:
        return None
    except BadSignature:
        return None

def generate_pending_signup_token(pending_id: int, email: str) -> str:
    s = _get_serializer()
    return s.dumps({'pending_id': pending_id, 'email': email}, salt=PENDING_SIGNUP_TOKEN_SALT)

def verify_pending_signup_token(token: str):
    s = _get_serializer()
    try:
        data = s.loads(token, salt=PENDING_SIGNUP_TOKEN_SALT, max_age=VERIFICATION_TOKEN_MAX_AGE)
        pid = data.get('pending_id')
        email = data.get('email')
        if pid is None or not email:
            return None
        return {'pending_id': int(pid), 'email': email}
    except Exception:
        return None

def _build_verify_url(token: str) -> str:
    try:
        scheme = (CANONICAL_SCHEME or 'https')
    except Exception:
        scheme = 'https'
    try:
        host = CANONICAL_HOST or request.headers.get('Host') or ''
    except Exception:
        host = ''
    if not host:
        # Fallback to url_root parsing
        try:
            from urllib.parse import urlparse
            p = urlparse(request.url_root)
            host = p.netloc
            if p.scheme:
                scheme = p.scheme
        except Exception:
            pass
    return f"{scheme}://{host}/verify_email?token={token}"

def _send_email_via_resend(to_email: str, subject: str, html: str, text: str = None):
    if not RESEND_API_KEY:
        logger.error('RESEND_API_KEY not set; skipping email send')
        return False
    try:
        payload = {
            'from': EMAIL_FROM,
            'to': [to_email],
            'subject': subject,
            'html': html
        }
        if text:
            payload['text'] = text
        # Use requests to call Resend API (JSON body)
        r = requests.post(
            'https://api.resend.com/emails',
            headers={'Authorization': f'Bearer {RESEND_API_KEY}'},
            json=payload,
            timeout=15,
        )
        if r.status_code in (200, 201):
            logger.info('Resend email queued successfully')
            return True
        try:
            logger.error(f'Resend send failed: {r.status_code} {r.text}')
        except Exception:
            logger.error(f'Resend send failed with status {r.status_code}')
        return False
    except Exception as e:
        logger.error(f'Resend send exception: {e}')
        return False

def ensure_password_reset_table(c):
    try:
        if USE_MYSQL:
            c.execute('''CREATE TABLE IF NOT EXISTS password_reset_tokens (
                          id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          email VARCHAR(191) NOT NULL,
                          token VARCHAR(191) NOT NULL UNIQUE,
                          created_at TEXT NOT NULL,
                          used TINYINT(1) DEFAULT 0
                        )''')
        else:
            c.execute('''CREATE TABLE IF NOT EXISTS password_reset_tokens (
                          id INTEGER PRIMARY KEY AUTOINCREMENT,
                          username VARCHAR(191) NOT NULL,
                          email TEXT NOT NULL,
                          token TEXT NOT NULL UNIQUE,
                          created_at TEXT NOT NULL,
                          used INTEGER DEFAULT 0,
                          FOREIGN KEY (username) REFERENCES users (username)
                        )''')
    except Exception as e:
        logger.error(f"Failed ensuring password_reset_tokens table: {e}")

def ensure_pending_signups_table(c):
    try:
        if USE_MYSQL:
            c.execute('''CREATE TABLE IF NOT EXISTS pending_signups (
                          id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191),
                          email VARCHAR(191) NOT NULL UNIQUE,
                          password TEXT NOT NULL,
                          first_name TEXT,
                          last_name TEXT,
                          mobile TEXT,
                          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                          verification_sent_at TEXT
                        )''')
        else:
            c.execute('''CREATE TABLE IF NOT EXISTS pending_signups (
                          id INTEGER PRIMARY KEY AUTOINCREMENT,
                          username TEXT,
                          email TEXT NOT NULL UNIQUE,
                          password TEXT NOT NULL,
                          first_name TEXT,
                          last_name TEXT,
                          mobile TEXT,
                          created_at TEXT DEFAULT (datetime('now')),
                          verification_sent_at TEXT
                        )''')
    except Exception as e:
        logger.warning(f"Could not ensure pending_signups table: {e}")

def ensure_community_invitations_table(c):
    """Create table for community email invitations"""
    try:
        if USE_MYSQL:
            c.execute('''CREATE TABLE IF NOT EXISTS community_invitations (
                          id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          invited_email VARCHAR(191) NOT NULL,
                          invited_by_username VARCHAR(191) NOT NULL,
                          invited_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                          token VARCHAR(191) NOT NULL UNIQUE,
                          used TINYINT(1) DEFAULT 0,
                          used_at TIMESTAMP NULL,
                          include_nested_ids TEXT,
                          include_parent_ids TEXT,
                          INDEX idx_community_id (community_id),
                          INDEX idx_invited_email (invited_email),
                          INDEX idx_token (token),
                          FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE
                        )''')
        else:
            c.execute('''CREATE TABLE IF NOT EXISTS community_invitations (
                          id INTEGER PRIMARY KEY AUTOINCREMENT,
                          community_id INTEGER NOT NULL,
                          invited_email TEXT NOT NULL,
                          invited_by_username VARCHAR(191) NOT NULL,
                          invited_at TEXT DEFAULT (datetime('now')),
                          token TEXT NOT NULL UNIQUE,
                          used INTEGER DEFAULT 0,
                          used_at TEXT,
                          include_nested_ids TEXT,
                          include_parent_ids TEXT,
                          FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                          FOREIGN KEY (invited_by_username) REFERENCES users(username) ON DELETE CASCADE
                        )''')

        try:
            c.execute("ALTER TABLE community_invitations ADD COLUMN include_nested_ids TEXT")
        except Exception:
            pass
        try:
            c.execute("ALTER TABLE community_invitations ADD COLUMN include_parent_ids TEXT")
        except Exception:
            pass
    except Exception as e:
        logger.warning(f"Could not ensure community_invitations table: {e}")

def ensure_post_views_table(c):
    """Ensure the post_views table exists for tracking unique post views."""
    try:
        if USE_MYSQL:
            c.execute('''CREATE TABLE IF NOT EXISTS post_views (
                          id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          post_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          viewed_at DATETIME NOT NULL,
                          UNIQUE(post_id, username),
                          FOREIGN KEY (post_id) REFERENCES posts(id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE
                        )''')
        else:
            c.execute('''CREATE TABLE IF NOT EXISTS post_views (
                          id INTEGER PRIMARY KEY AUTOINCREMENT,
                          post_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          viewed_at TEXT NOT NULL,
                          UNIQUE(post_id, username),
                          FOREIGN KEY (post_id) REFERENCES posts(id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE
                        )''')
    except Exception as e:
        logger.warning(f"Could not ensure post_views table: {e}")

def _count_post_views_excluding_admin(c, post_id: int) -> Optional[int]:
    """Return the number of views for a post ignoring admin activity."""
    try:
        post_ph = get_sql_placeholder()
        admin_ph = get_sql_placeholder()
        c.execute(
            f"SELECT COUNT(*) as cnt FROM post_views WHERE post_id = {post_ph} AND LOWER(username) <> LOWER({admin_ph})",
            (post_id, 'admin'),
        )
        row = c.fetchone()
        count = row['cnt'] if hasattr(row, 'keys') else (row[0] if row else 0)
        return int(count or 0)
    except Exception as count_err:
        logger.warning(f"Failed counting post views for post {post_id}: {count_err}")
        return None


def upsert_post_view(c, post_id: int, username: Optional[str]) -> Optional[int]:
    """Ensure a unique view record for username/post_id, excluding the admin user."""
    ensure_post_views_table(c)
    if not username:
        return _count_post_views_excluding_admin(c, post_id)

    if username.lower() == 'admin':
        try:
            post_ph = get_sql_placeholder()
            admin_ph = get_sql_placeholder()
            c.execute(
                f"DELETE FROM post_views WHERE post_id = {post_ph} AND LOWER(username) = LOWER({admin_ph})",
                (post_id, 'admin'),
            )
        except Exception as cleanup_err:
            logger.warning(f"Failed cleaning admin views for post {post_id}: {cleanup_err}")
        return _count_post_views_excluding_admin(c, post_id)

    now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    try:
        if USE_MYSQL:
            c.execute("INSERT IGNORE INTO post_views (post_id, username, viewed_at) VALUES (%s,%s,%s)", (post_id, username, now_str))
        else:
            c.execute("INSERT OR IGNORE INTO post_views (post_id, username, viewed_at) VALUES (?,?,?)", (post_id, username, now_str))
    except Exception as insert_err:
        logger.warning(f"Failed inserting post_view for post {post_id} and user {username}: {insert_err}")
    return _count_post_views_excluding_admin(c, post_id)


def ensure_story_tables(c):
    """Ensure community_stories, views, and reactions tables exist. Returns True if successful."""
    try:
        # First check if tables already exist
        if USE_MYSQL:
            c.execute("SHOW TABLES LIKE 'community_stories'")
            if c.fetchone():
                return True  # Tables already exist
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_stories (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    community_id INT NOT NULL,
                    username VARCHAR(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                    media_path VARCHAR(512) NOT NULL,
                    media_type VARCHAR(16) NOT NULL,
                    caption TEXT,
                    duration_seconds INT,
                    status VARCHAR(32) NOT NULL DEFAULT 'active',
                    created_at DATETIME NOT NULL,
                    expires_at DATETIME NOT NULL,
                    view_count INT NOT NULL DEFAULT 0,
                    last_viewed_at DATETIME,
                    text_overlays JSON,
                    location_data JSON,
                    INDEX idx_cs_comm_expires (community_id, expires_at),
                    INDEX idx_cs_user_created (username, created_at),
                    CONSTRAINT fk_cs_community FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                    CONSTRAINT fk_cs_user FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
                """
            )
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_story_views (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    story_id INT NOT NULL,
                    username VARCHAR(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                    viewed_at DATETIME NOT NULL,
                    UNIQUE KEY uniq_story_viewer (story_id, username),
                    INDEX idx_csv_story (story_id),
                    INDEX idx_csv_user (username),
                    CONSTRAINT fk_csv_story FOREIGN KEY (story_id) REFERENCES community_stories(id) ON DELETE CASCADE,
                    CONSTRAINT fk_csv_user FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
                """
            )
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_story_reactions (
                    id INT AUTO_INCREMENT PRIMARY KEY,
                    story_id INT NOT NULL,
                    username VARCHAR(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                    reaction VARCHAR(16) NOT NULL,
                    created_at DATETIME NOT NULL,
                    UNIQUE KEY uniq_story_reaction (story_id, username),
                    INDEX idx_csr_story (story_id),
                    INDEX idx_csr_reaction (reaction),
                    CONSTRAINT fk_csr_story FOREIGN KEY (story_id) REFERENCES community_stories(id) ON DELETE CASCADE,
                    CONSTRAINT fk_csr_user FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE
                ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
                """
            )
        else:
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_stories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    community_id INTEGER NOT NULL,
                    username TEXT NOT NULL,
                    media_path TEXT NOT NULL,
                    media_type TEXT NOT NULL,
                    caption TEXT,
                    duration_seconds INTEGER,
                    status TEXT NOT NULL DEFAULT 'active',
                    created_at TEXT NOT NULL,
                    expires_at TEXT NOT NULL,
                    view_count INTEGER NOT NULL DEFAULT 0,
                    last_viewed_at TEXT,
                    text_overlays TEXT,
                    location_data TEXT
                )
                """
            )
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_story_views (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    story_id INTEGER NOT NULL,
                    username TEXT NOT NULL,
                    viewed_at TEXT NOT NULL
                )
                """
            )
            c.execute("CREATE INDEX IF NOT EXISTS idx_cs_comm_expires ON community_stories (community_id, expires_at)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_cs_user_created ON community_stories (username, created_at)")
            c.execute("CREATE UNIQUE INDEX IF NOT EXISTS uniq_story_viewer ON community_story_views (story_id, username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_csv_user ON community_story_views (username)")
            c.execute(
                """
                CREATE TABLE IF NOT EXISTS community_story_reactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    story_id INTEGER NOT NULL,
                    username TEXT NOT NULL,
                    reaction TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
                """
            )
            c.execute("CREATE UNIQUE INDEX IF NOT EXISTS uniq_story_reaction ON community_story_reactions (story_id, username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_csr_story ON community_story_reactions (story_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_csr_reaction ON community_story_reactions (reaction)")
        return True
    except Exception as e:
        logger.error(f"Could not ensure community story tables: {e}")
        return False


STORY_ALLOWED_REACTIONS: Set[str] = {"‚ù§Ô∏è", "üî•", "üëè", "üòÇ", "üòÆ", "üëç"}


def normalize_story_reaction(value: Optional[str]) -> Optional[str]:
    if not value:
        return None
    token = str(value).strip()
    return token if token in STORY_ALLOWED_REACTIONS else None


def fetch_story_reaction_maps(
    c,
    story_ids: Sequence[int],
    username: Optional[str] = None,
) -> Tuple[Dict[int, Dict[str, int]], Dict[int, Optional[str]]]:
    if not story_ids:
        return {}, {}
    ensure_story_tables(c)
    ph = get_sql_placeholder()
    placeholders = ",".join([ph] * len(story_ids))

    reaction_counts: Dict[int, Dict[str, int]] = {}
    user_reactions: Dict[int, Optional[str]] = {}

    try:
        c.execute(
            f"""
            SELECT story_id, reaction, COUNT(*) as cnt
            FROM community_story_reactions
            WHERE story_id IN ({placeholders})
            GROUP BY story_id, reaction
            """,
            tuple(story_ids),
        )
        rows = c.fetchall() or []
        for row in rows:
            story_id = row["story_id"] if hasattr(row, "keys") else row[0]
            reaction = row["reaction"] if hasattr(row, "keys") else row[1]
            count = row["cnt"] if hasattr(row, "keys") else (row[2] if len(row) > 2 else 0)
            if story_id is None or reaction is None:
                continue
            reaction_counts.setdefault(int(story_id), {})[reaction] = int(count or 0)
    except Exception as err:
        logger.warning(f"Failed to aggregate story reactions: {err}")

    if username:
        try:
            params = list(story_ids) + [username]
            c.execute(
                f"""
                SELECT story_id, reaction
                FROM community_story_reactions
                WHERE story_id IN ({placeholders}) AND LOWER(username) = LOWER({ph})
                """,
                tuple(params),
            )
            rows = c.fetchall() or []
            for row in rows:
                story_id = row["story_id"] if hasattr(row, "keys") else row[0]
                reaction = row["reaction"] if hasattr(row, "keys") else (row[1] if len(row) > 1 else None)
                if story_id is None:
                    continue
                user_reactions[int(story_id)] = reaction
        except Exception as err:
            logger.warning(f"Failed to fetch user story reactions: {err}")

    return reaction_counts, user_reactions


def user_has_story_access(c, username: Optional[str], community_id: int, creator_username: Optional[str] = None) -> bool:
    """Check if a user can interact with community-level ephemeral content (member or ancestor admin)."""
    if not username or not community_id:
        return False
    norm_username = str(username).strip().lower()
    if norm_username == 'admin':
        return True
    creator_norm = str(creator_username).strip().lower() if creator_username else None
    if creator_norm and norm_username == creator_norm:
        return True

    ph = get_sql_placeholder()
    try:
        c.execute(
            f"""
            SELECT 1
            FROM user_communities uc
            JOIN users u ON uc.user_id = u.id
            WHERE LOWER(u.username) = LOWER({ph}) AND uc.community_id = {ph}
            LIMIT 1
            """,
            (username, community_id),
        )
        if c.fetchone():
            return True
    except Exception as membership_err:
        logger.warning(f"story access membership check failed for community {community_id}: {membership_err}")

    try:
        parent_ids = get_parent_chain_ids(c, community_id)
    except Exception as parent_err:
        logger.warning(f"story access parent chain failed for community {community_id}: {parent_err}")
        parent_ids = []

    for parent_id in parent_ids:
        try:
            c.execute(
                f"""
                SELECT uc.role, c.creator_username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                JOIN communities c ON c.id = uc.community_id
                WHERE LOWER(u.username) = LOWER({ph}) AND uc.community_id = {ph}
                LIMIT 1
                """,
                (username, parent_id),
            )
            row = c.fetchone()
        except Exception as ancestor_err:
            logger.warning(f"story access ancestor check failed for {parent_id}: {ancestor_err}")
            row = None
        if not row:
            continue
        role = row["role"] if hasattr(row, "keys") else (row[0] if len(row) > 0 else None)
        creator = row["creator_username"] if hasattr(row, "keys") else (row[1] if len(row) > 1 else None)
        role_norm = (role or "").strip().lower()
        if role_norm in {"admin", "owner", "manager", "moderator"}:
            return True
        creator_parent_norm = (creator or "").strip().lower()
        if creator_parent_norm and creator_parent_norm == norm_username:
            return True
    return False


def record_story_view(c, story_id: int, username: str) -> Optional[int]:
    """Upsert a story view and return the latest total view count."""
    ensure_story_tables(c)
    now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    try:
        if USE_MYSQL:
            c.execute(
                """
                INSERT INTO community_story_views (story_id, username, viewed_at)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE viewed_at = VALUES(viewed_at)
                """,
                (story_id, username, now_str),
            )
        else:
            c.execute(
                "INSERT OR REPLACE INTO community_story_views (story_id, username, viewed_at) VALUES (?,?,?)",
                (story_id, username, now_str),
            )
    except Exception as view_err:
        logger.warning(f"Failed recording story view for {story_id}: {view_err}")

    try:
        ph = get_sql_placeholder()
        c.execute(f"SELECT COUNT(*) as cnt FROM community_story_views WHERE story_id = {ph}", (story_id,))
        row = c.fetchone()
        count = row["cnt"] if hasattr(row, "keys") else (row[0] if row else 0)
        c.execute(
            f"UPDATE community_stories SET view_count = {ph}, last_viewed_at = {ph} WHERE id = {ph}",
            (int(count or 0), now_str, story_id),
        )
        return int(count or 0)
    except Exception as agg_err:
        logger.warning(f"Failed updating story view count for {story_id}: {agg_err}")
        return None

# Optional: enforce canonical host (e.g., www.c-point.co) to prevent cookie splits
CANONICAL_HOST = os.getenv('CANONICAL_HOST')  # e.g., 'www.c-point.co'
CANONICAL_SCHEME = os.getenv('CANONICAL_SCHEME', 'https')

@app.before_request
def enforce_canonical_host():
    try:
        req_host = request.headers.get('Host', '').split(':')[0]
        req_scheme = request.headers.get('X-Forwarded-Proto') or request.scheme
        # Enforce host
        if CANONICAL_HOST and req_host and req_host != CANONICAL_HOST:
            target = f"{CANONICAL_SCHEME}://{CANONICAL_HOST}{request.full_path}"
            if target.endswith('?'):
                target = target[:-1]
            return redirect(target, code=301)
        # Enforce https if configured
        if CANONICAL_SCHEME == 'https' and req_scheme != 'https' and req_host:
            target = f"https://{req_host}{request.full_path}"
            if target.endswith('?'):
                target = target[:-1]
            return redirect(target, code=301)
    except Exception:
        # Never block request on redirect failure
        return None

# Create uploads directory if it doesn't exist
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# Load secret keys from environment variables
# IMPORTANT: Must be consistent across all workers/processes
# On PythonAnywhere, set this in your web app's environment variables
FLASK_SECRET_KEY = os.getenv('FLASK_SECRET_KEY')
if not FLASK_SECRET_KEY:
    # Use a hardcoded key as fallback (not ideal for production but ensures consistency)
    FLASK_SECRET_KEY = 'c-point-secret-key-2024-stable-across-workers'
    print("WARNING: Using hardcoded secret key - set FLASK_SECRET_KEY env var in production")
app.secret_key = FLASK_SECRET_KEY
DEFAULT_STRIPE_API_KEY = 'sk_test_your_stripe_key'
STRIPE_API_KEY = (os.getenv('STRIPE_API_KEY') or DEFAULT_STRIPE_API_KEY).strip()
STRIPE_PUBLISHABLE_KEY = (os.getenv('STRIPE_PUBLISHABLE_KEY') or '').strip()
STRIPE_PRICE_PREMIUM_MONTHLY = (os.getenv('STRIPE_PRICE_PREMIUM_MONTHLY') or '').strip()
STRIPE_PRICE_PREMIUM_YEARLY = (os.getenv('STRIPE_PRICE_PREMIUM_YEARLY') or '').strip()
STRIPE_PRICE_IDS = {
    'premium_monthly': STRIPE_PRICE_PREMIUM_MONTHLY,
    'premium_yearly': STRIPE_PRICE_PREMIUM_YEARLY,
}
XAI_API_KEY = os.getenv('XAI_API_KEY', 'xai-hFCxhRKITxZXsIQy5rRpRus49rxcgUPw4NECAunCgHU0BnWnbPE9Y594Nk5jba03t5FYl2wJkjcwyxRh')
X_CONSUMER_KEY = os.getenv('X_CONSUMER_KEY', 'cjB0MmRPRFRnOG9jcTA0UGRZV006MTpjaQ')
X_CONSUMER_SECRET = os.getenv('X_CONSUMER_SECRET', 'Wxo9qnpOaDIJ-9Aw_Bl_MDkor4uY24ephq9ZJFq6HwdH7o4-kB')
VAPID_PUBLIC_KEY = os.getenv('VAPID_PUBLIC_KEY', '')
VAPID_PRIVATE_KEY = os.getenv('VAPID_PRIVATE_KEY', '')
VAPID_SUBJECT = os.getenv('VAPID_SUBJECT', 'https://www.c-point.co')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', '')
TYPING_TTL_SECONDS = 5



# Logging setup
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)


def prefers_json_response() -> bool:
    """Determine if the current request prefers a JSON response."""
    try:
        if request.is_json:
            return True
    except RuntimeError:
        return False

    xhr = request.headers.get('X-Requested-With', '')
    if xhr and xhr.lower() == 'xmlhttprequest':
        return True

    try:
        accept = request.accept_mimetypes
        return accept['application/json'] >= accept['text/html']
    except Exception:
        return False


def serve_react_index() -> Optional[Response]:
    """Serve the built React single page app, if available."""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        index_path = os.path.join(dist_dir, 'index.html')
        if not os.path.exists(index_path):
            logger.warning("React build missing at %s", index_path)
            return None
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as exc:
        logger.error(f"Failed to serve React index: {exc}")
        return None


# Stripe setup (optional)
try:
    import stripe
    stripe.api_key = STRIPE_API_KEY
except ImportError:
    logger.warning("Stripe module not installed. Run 'pip install stripe'")
    stripe = None

# Import custom modules
try:
    from workouts import workouts as workout_data
except ImportError as e:
    logger.error(f"Failed to import custom modules: {e}")
    workout_data = {}

# OAuth setup for X
# oauth = OAuth(app)
# x_auth = oauth.remote_app(
#     'x',
#     consumer_key=X_CONSUMER_KEY,
#     consumer_secret=X_CONSUMER_SECRET,
#     request_token_params={'scope': 'users.read'},
#     base_url='https://api.x.com/2/',
#     request_token_url=None,
#     access_token_method='POST',
#     access_token_url='https://api.x.com/2/oauth2/token',
#     authorize_url='https://x.com/i/oauth2/authorize',
# )

# xAI API setup
XAI_API_URL = 'https://api.x.ai/v1/chat/completions'
DAILY_API_LIMIT = 10

MENTIONS_ENABLED = os.getenv('MENTIONS_ENABLED', 'false').lower() == 'true'

def normalize_id_list(raw) -> List[int]:
    """Normalize incoming payload (list or JSON string) into a unique list of ints preserving order."""
    result: List[int] = []
    if isinstance(raw, list):
        for value in raw:
            try:
                iv = int(value)
            except (TypeError, ValueError):
                continue
            if iv not in result:
                result.append(iv)
    elif isinstance(raw, str):
        stripped = raw.strip()
        if stripped:
            try:
                parsed = json.loads(stripped)
                if isinstance(parsed, list):
                    return normalize_id_list(parsed)
            except Exception:
                pass
    return result

class CommunityMembershipLimitError(Exception):
    """Raised when a free-plan community exceeds its member capacity."""
    pass


def normalize_subscription(value: Optional[str]) -> str:
    return str(value or '').strip().lower()


def fetch_user_subscription(cursor, username: Optional[str]) -> str:
    if not username:
        return ''
    placeholder = get_sql_placeholder()
    cursor.execute(f"SELECT subscription FROM users WHERE username = {placeholder}", (username,))
    row = cursor.fetchone()
    if not row:
        return ''
    if hasattr(row, 'keys'):
        return normalize_subscription(row.get('subscription'))
    return normalize_subscription(row[0] if isinstance(row, (list, tuple)) and row else row)


def is_free_subscription(subscription_value: str) -> bool:
    return subscription_value not in {'premium'}


def delete_community_records(cursor, community_id: int) -> None:
    """Remove a community and its direct associations."""
    placeholder = get_sql_placeholder()
    try:
        cursor.execute(
            f"DELETE FROM post_views WHERE post_id IN (SELECT id FROM posts WHERE community_id = {placeholder})",
            (community_id,),
        )
    except Exception as err:
        logger.warning(f"Failed deleting post_views for community {community_id}: {err}")

    try:
        cursor.execute(f"DELETE FROM posts WHERE community_id = {placeholder}", (community_id,))
    except Exception as err:
        logger.warning(f"Failed deleting posts for community {community_id}: {err}")

    try:
        cursor.execute(f"DELETE FROM user_communities WHERE community_id = {placeholder}", (community_id,))
    except Exception as err:
        logger.warning(f"Failed deleting user_communities for community {community_id}: {err}")

    try:
        cursor.execute(f"DELETE FROM communities WHERE id = {placeholder}", (community_id,))
    except Exception as err:
        logger.warning(f"Failed deleting community {community_id}: {err}")


def ensure_followers_table(cursor) -> None:
    """Ensure followers table exists for follow relationships."""
    try:
        if USE_MYSQL:
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS followers (
                    follower_username VARCHAR(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                    followed_username VARCHAR(150) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
                    created_at DATETIME NOT NULL,
                    status VARCHAR(16) NOT NULL DEFAULT 'pending',
                    accepted_at DATETIME NULL,
                    PRIMARY KEY (follower_username, followed_username),
                    CONSTRAINT fk_follow_follower FOREIGN KEY (follower_username) REFERENCES users(username) ON DELETE CASCADE,
                    CONSTRAINT fk_follow_followed FOREIGN KEY (followed_username) REFERENCES users(username) ON DELETE CASCADE
                ) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci
                """
            )
        else:
            cursor.execute(
                """
                CREATE TABLE IF NOT EXISTS followers (
                    follower_username TEXT NOT NULL,
                    followed_username TEXT NOT NULL,
                    created_at TEXT NOT NULL,
                    status TEXT NOT NULL DEFAULT 'pending',
                    accepted_at TEXT NULL,
                    PRIMARY KEY (follower_username, followed_username),
                    FOREIGN KEY (follower_username) REFERENCES users(username) ON DELETE CASCADE,
                    FOREIGN KEY (followed_username) REFERENCES users(username) ON DELETE CASCADE
                )
                """
            )
    except Exception as e:
        logger.warning(f"Could not ensure followers table: {e}")
    # Ensure newer columns exist for pending/accepted workflow
    try:
        if USE_MYSQL:
            cursor.execute("ALTER TABLE followers ADD COLUMN status VARCHAR(16) NOT NULL DEFAULT 'pending'")
        else:
            cursor.execute("ALTER TABLE followers ADD COLUMN status TEXT NOT NULL DEFAULT 'pending'")
    except Exception:
        pass
    try:
        if USE_MYSQL:
            cursor.execute("ALTER TABLE followers ADD COLUMN accepted_at DATETIME NULL")
        else:
            cursor.execute("ALTER TABLE followers ADD COLUMN accepted_at TEXT NULL")
    except Exception:
        pass
    try:
        if USE_MYSQL:
            cursor.execute("UPDATE followers SET status = 'accepted' WHERE status IS NULL OR status = ''")
        else:
            cursor.execute("UPDATE followers SET status = 'accepted' WHERE status IS NULL OR status = ''")
    except Exception as backfill_err:
        logger.warning(f"Could not backfill follower status: {backfill_err}")


def get_follow_summary(cursor, username: str) -> Dict[str, int]:
    """Return followers/following/request counts for a username."""
    ensure_followers_table(cursor)
    followers_count = 0
    following_count = 0
    requests_count = 0
    placeholder = get_sql_placeholder()
    try:
        cursor.execute(
            f"SELECT COUNT(*) FROM followers WHERE followed_username = {placeholder} AND status = 'accepted'",
            (username,),
        )
        row = cursor.fetchone()
        if row:
            followers_count = int(row[0] if not hasattr(row, 'keys') else list(row.values())[0] or 0)
    except Exception as e:
        logger.warning(f"Failed counting accepted followers for {username}: {e}")
    try:
        cursor.execute(
            f"SELECT COUNT(*) FROM followers WHERE follower_username = {placeholder} AND status = 'accepted'",
            (username,),
        )
        row = cursor.fetchone()
        if row:
            following_count = int(row[0] if not hasattr(row, 'keys') else list(row.values())[0] or 0)
    except Exception as e:
        logger.warning(f"Failed counting accepted following for {username}: {e}")
    try:
        cursor.execute(
            f"SELECT COUNT(*) FROM followers WHERE followed_username = {placeholder} AND status = 'pending'",
            (username,),
        )
        row = cursor.fetchone()
        if row:
            requests_count = int(row[0] if not hasattr(row, 'keys') else list(row.values())[0] or 0)
    except Exception as e:
        logger.warning(f"Failed counting follow requests for {username}: {e}")
    return {'followers': followers_count, 'following': following_count, 'requests': requests_count}


def get_follow_counts(cursor, username: str) -> Tuple[int, int]:
    """Return follower and following counts for a username."""
    summary = get_follow_summary(cursor, username)
    return summary['followers'], summary['following']


def ensure_free_parent_member_capacity(cursor, community_id: Optional[int], extra_members: int = 1) -> None:
    """Ensure a free-plan parent community has capacity for additional members."""
    if not community_id:
        return
    community_info = get_community_basic(cursor, community_id)
    if not community_info:
        return
    if community_info.get('parent_community_id'):
        # Only enforce on parent communities
        return
    creator_username = community_info.get('creator_username')
    if not creator_username or creator_username.lower() == 'admin':
        return
    subscription_value = fetch_user_subscription(cursor, creator_username)
    if not is_free_subscription(subscription_value):
        return
    placeholder = get_sql_placeholder()
    cursor.execute(f"SELECT COUNT(*) FROM user_communities WHERE community_id = {placeholder}", (community_id,))
    row = cursor.fetchone()
    current_count = 0
    if row:
        if hasattr(row, 'keys'):
            current_count = list(row.values())[0]
        else:
            current_count = row[0] if isinstance(row, (list, tuple)) and row else 0
    try:
        current_count = int(current_count or 0)
    except Exception:
        current_count = 0
    if current_count + extra_members > 100:
        raise CommunityMembershipLimitError('Free plan communities can have up to 100 members. Upgrade to add more members.')


def add_user_to_community(cursor, user_id: int, community_id: int, role: Optional[str] = 'member') -> None:
    """Insert a user into user_communities respecting free plan limits."""
    ensure_free_parent_member_capacity(cursor, community_id)
    joined_at_value = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    if role is None:
        if USE_MYSQL:
            cursor.execute(
                """
                INSERT INTO user_communities (user_id, community_id, joined_at)
                VALUES (%s, %s, %s)
                """,
                (user_id, community_id, joined_at_value),
            )
        else:
            cursor.execute(
                """
                INSERT INTO user_communities (user_id, community_id, joined_at)
                VALUES (?, ?, ?)
                """,
                (user_id, community_id, joined_at_value),
            )
    else:
        if USE_MYSQL:
            cursor.execute(
                """
                INSERT INTO user_communities (user_id, community_id, role, joined_at)
                VALUES (%s, %s, %s, %s)
                """,
                (user_id, community_id, role, joined_at_value),
            )
        else:
            cursor.execute(
                """
                INSERT INTO user_communities (user_id, community_id, role, joined_at)
                VALUES (?, ?, ?, ?)
                """,
                (user_id, community_id, role, joined_at_value),
            )

def get_scalar_result(row, column_index=0, column_name=None):
    """Helper to get a scalar value from a database row that could be dict or tuple"""
    if row is None:
        return None
    if hasattr(row, 'keys'):  # Dict-like result (MySQL with DictCursor)
        if column_name:
            return row.get(column_name)
        # If no column name provided, try to get first value
        values = list(row.values())
        return values[column_index] if values else None
    else:  # Tuple/list result (SQLite)
        return row[column_index] if len(row) > column_index else None


def get_cached_countries() -> List[Dict[str, Any]]:
    now = time.time()
    cached = COUNTRY_CACHE
    if cached['data'] and (now - cached['timestamp']) < COUNTRY_CACHE_TTL:
        return cached['data']
    url = 'https://countriesnow.space/api/v0.1/countries/iso'
    try:
        req = urllib.request.Request(url, headers={'Accept': 'application/json'})
        with urllib.request.urlopen(req, timeout=8) as resp:
            payload = json.loads(resp.read().decode('utf-8'))
        data = []
        for item in payload.get('data', []):
            name = item.get('name')
            iso2 = item.get('Iso2') or item.get('iso2')
            if name:
                data.append({'name': name, 'iso2': iso2})
        if data:
            COUNTRY_CACHE['data'] = sorted(data, key=lambda x: x['name'])
            COUNTRY_CACHE['timestamp'] = now
            return COUNTRY_CACHE['data']
    except Exception as e:
        logger.warning(f"Failed to fetch countries remotely: {e}")
    COUNTRY_CACHE['data'] = FALLBACK_COUNTRIES
    COUNTRY_CACHE['timestamp'] = now
    return COUNTRY_CACHE['data']


def get_cached_cities(country_name: str) -> List[str]:
    if not country_name:
        return []
    key = country_name.strip().lower()
    now = time.time()
    cached = CITY_CACHE.get(key)
    if cached and (now - cached['timestamp']) < CITY_CACHE_TTL:
        return cached['data']
    url = 'https://countriesnow.space/api/v0.1/countries/cities'
    payload = json.dumps({'country': country_name}).encode('utf-8')
    try:
        req = urllib.request.Request(
            url,
            data=payload,
            headers={'Content-Type': 'application/json', 'Accept': 'application/json'}
        )
        with urllib.request.urlopen(req, timeout=10) as resp:
            result = json.loads(resp.read().decode('utf-8'))
        data = result.get('data') or []
        if isinstance(data, list) and data:
            sorted_data = sorted(dict.fromkeys([str(city) for city in data]))
            filtered = filter_major_cities(country_name, sorted_data)
            CITY_CACHE[key] = {'data': filtered, 'timestamp': now}
            return filtered
    except Exception as e:
        logger.warning(f"Failed to fetch cities for {country_name}: {e}")
    fallback = filter_major_cities(country_name, FALLBACK_CITY_MAP.get(key, []))
    CITY_CACHE[key] = {'data': fallback, 'timestamp': now}
    return fallback


def filter_major_cities(country_name: str, incoming: List[str]) -> List[str]:
    key = country_name.strip().lower()
    override = FALLBACK_CITY_MAP.get(key)
    if override:
        return override
    unique: List[str] = []
    seen: set[str] = set()
    for name in incoming:
        if not name:
            continue
        cleaned = str(name).strip()
        if not cleaned:
            continue
        lowered = cleaned.lower()
        if lowered in seen:
            continue
        seen.add(lowered)
        unique.append(cleaned)
        if len(unique) >= 24:
            break
    return unique

def ensure_database_exists():
    """Ensure the database and all tables exist."""
    try:
        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'users.db')
        logger.info(f"Database path: {db_path}")
        
        # Connect to database (this will create it if it doesn't exist)
        conn = sqlite3.connect(db_path)
        c = conn.cursor()
        
        # Check if users table exists
        c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='users'")
        users_table_exists = c.fetchone() is not None
        
        if not users_table_exists:
            logger.info("Users table does not exist. Creating all tables...")
            init_db()
        else:
            logger.info("Users table exists. Checking for missing tables and columns...")
            # Always check for missing tables and columns
            add_missing_tables()
        
        conn.close()
        logger.info("Database check completed successfully")
        
    except Exception as e:
        logger.error(f"Error ensuring database exists: {e}")
        raise


def ensure_imagine_jobs_table():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            if USE_MYSQL:
                c.execute(
                    """
                    CREATE TABLE IF NOT EXISTS imagine_jobs (
                        id INT AUTO_INCREMENT PRIMARY KEY,
                        target_type VARCHAR(16) NOT NULL,
                        target_id BIGINT NOT NULL,
                        community_id BIGINT NULL,
                        status VARCHAR(32) NOT NULL,
                        style VARCHAR(16) NOT NULL,
                        runway_job_id VARCHAR(128) NULL,
                        result_path TEXT,
                        source_path TEXT,
                        error TEXT,
                        created_by VARCHAR(255) NOT NULL,
                        created_at DATETIME NOT NULL,
                        updated_at DATETIME NOT NULL,
                        is_owner TINYINT(1) NOT NULL DEFAULT 0,
                        auto_reply_id BIGINT NULL,
                        action VARCHAR(32) NULL
                    ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
                    """
                )
                c.execute("CREATE INDEX IF NOT EXISTS idx_imagine_jobs_status ON imagine_jobs (status)")
                c.execute("CREATE INDEX IF NOT EXISTS idx_imagine_jobs_created_by ON imagine_jobs (created_by)")
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN source_path TEXT")
                except Exception:
                    pass
                # Add source_type, audio_path, and provider columns for talking avatar feature
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN source_type VARCHAR(50) NULL")
                except Exception:
                    pass
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN audio_path VARCHAR(512) NULL")
                except Exception:
                    pass
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN provider VARCHAR(32) NULL")
                except Exception:
                    pass
                # Add progress column for tracking generation progress
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN progress INT DEFAULT 0")
                except Exception:
                    pass
            else:
                c.execute(
                    """
                    CREATE TABLE IF NOT EXISTS imagine_jobs (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        target_type TEXT NOT NULL,
                        target_id INTEGER NOT NULL,
                        community_id INTEGER,
                        status TEXT NOT NULL,
                        style TEXT NOT NULL,
                        runway_job_id TEXT,
                        result_path TEXT,
                        source_path TEXT,
                        error TEXT,
                        created_by TEXT NOT NULL,
                        created_at TEXT NOT NULL,
                        updated_at TEXT NOT NULL,
                        is_owner INTEGER NOT NULL DEFAULT 0,
                        auto_reply_id INTEGER,
                        action TEXT
                    )
                    """
                )
                c.execute("CREATE INDEX IF NOT EXISTS idx_imagine_jobs_status ON imagine_jobs (status)")
                c.execute("CREATE INDEX IF NOT EXISTS idx_imagine_jobs_created_by ON imagine_jobs (created_by)")
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN source_path TEXT")
                except Exception:
                    pass
                # Add source_type, audio_path, and provider columns for talking avatar feature
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN source_type TEXT")
                except Exception:
                    pass
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN audio_path TEXT")
                except Exception:
                    pass
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN provider TEXT")
                except Exception:
                    pass
                # Add progress column for tracking generation progress
                try:
                    c.execute("ALTER TABLE imagine_jobs ADD COLUMN progress INTEGER DEFAULT 0")
                except Exception:
                    pass
                conn.commit()
    except Exception as e:
        logger.error(f"Failed ensuring imagine_jobs table: {e}")


def ensure_reply_video_column():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                if USE_MYSQL:
                    c.execute("ALTER TABLE replies ADD COLUMN video_path TEXT")
                else:
                    c.execute("ALTER TABLE replies ADD COLUMN video_path TEXT")
                    conn.commit()
            except Exception:
                pass
    except Exception as e:
        logger.warning(f"Failed ensuring replies.video_path column: {e}")


ensure_imagine_jobs_table()
ensure_reply_video_column()


def ensure_community_allow_nsfw_imagine_column():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            column_name = 'allow_nsfw_imagine'
            if USE_MYSQL:
                try:
                    c.execute(f"SHOW COLUMNS FROM communities LIKE '{column_name}'")
                    exists = c.fetchone() is not None
                except Exception as e:
                    logger.warning(f"Failed checking {column_name} column on MySQL: {e}")
                    exists = False
                if not exists:
                    try:
                        c.execute(f"ALTER TABLE communities ADD COLUMN {column_name} TINYINT(1) DEFAULT 0")
                    except Exception as alter_err:
                        logger.warning(f"Failed adding {column_name} column to communities (likely already exists): {alter_err}")
            else:
                try:
                    c.execute("PRAGMA table_info(communities)")
                    rows = c.fetchall() or []
                    columns = []
                    for row in rows:
                        try:
                            # sqlite3.Row or tuple fallback
                            if hasattr(row, 'keys'):
                                columns.append(row.get('name'))
                            else:
                                columns.append(row[1])
                        except Exception:
                            continue
                    exists = column_name in {col for col in columns if col}
                except Exception as pragma_err:
                    logger.warning(f"Failed checking {column_name} column on SQLite: {pragma_err}")
                    exists = False
                if not exists:
                    try:
                        c.execute(f"ALTER TABLE communities ADD COLUMN {column_name} INTEGER DEFAULT 0")
                        conn.commit()
                    except Exception as alter_err:
                        logger.warning(f"Failed adding {column_name} column to communities (likely already exists): {alter_err}")
    except Exception as e:
        logger.warning(f"ensure_community_allow_nsfw_imagine_column error: {e}")


ensure_community_allow_nsfw_imagine_column()


def add_missing_tables():
    """Add any missing tables to existing database."""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Create messages table
            c.execute('''CREATE TABLE IF NOT EXISTS messages
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          sender VARCHAR(191) NOT NULL,
                          receiver VARCHAR(191) NOT NULL,
                          message TEXT NOT NULL,
                          timestamp TEXT NOT NULL,
                          is_read INTEGER DEFAULT 0,
                          FOREIGN KEY (sender) REFERENCES users(username),
                          FOREIGN KEY (receiver) REFERENCES users(username))''')
            
            # Create api_usage table if it doesn't exist
            c.execute('''CREATE TABLE IF NOT EXISTS api_usage
                         (username VARCHAR(191), date TEXT, count INTEGER,
                          PRIMARY KEY (username, date))''')
            
            # Create saved_data table if it doesn't exist
            c.execute('''CREATE TABLE IF NOT EXISTS saved_data
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT, username VARCHAR(191), type TEXT, data TEXT, timestamp TEXT)''')

            # Create key_posts table (user-starred posts within communities)
            c.execute('''CREATE TABLE IF NOT EXISTS key_posts
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          post_id INTEGER NOT NULL,
                          community_id INTEGER NOT NULL,
                          created_at TEXT NOT NULL,
                          FOREIGN KEY (post_id) REFERENCES posts(id),
                          FOREIGN KEY (community_id) REFERENCES communities(id),
                          UNIQUE(username, post_id))''')
            # Create community_key_posts table (admin/owner highlighted posts for the community)
            try:
                c.execute('''CREATE TABLE IF NOT EXISTS community_key_posts
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              community_id INTEGER NOT NULL,
                              post_id INTEGER NOT NULL,
                              created_at TEXT NOT NULL,
                              FOREIGN KEY (community_id) REFERENCES communities(id),
                              FOREIGN KEY (post_id) REFERENCES posts(id),
                              UNIQUE(community_id, post_id))''')
            except Exception as e:
                logger.warning(f"Could not ensure community_key_posts table: {e}")
            # Store web push subscriptions
            c.execute('''CREATE TABLE IF NOT EXISTS push_subscriptions
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          endpoint TEXT NOT NULL UNIQUE,
                          p256dh TEXT,
                          auth TEXT,
                          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')

            # Store native (APNs) push tokens
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS native_push_tokens
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              token VARCHAR(191) NOT NULL UNIQUE,
                              username VARCHAR(191),
                              install_id VARCHAR(191),
                              platform VARCHAR(50) NOT NULL DEFAULT 'ios',
                              environment VARCHAR(20) NOT NULL DEFAULT 'sandbox',
                              bundle_id VARCHAR(191) NOT NULL,
                              device_name VARCHAR(191),
                              last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                              is_active TINYINT(1) DEFAULT 1,
                              INDEX idx_native_push_user (username),
                              INDEX idx_native_push_install (install_id)
                             )''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS native_push_tokens
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              token TEXT NOT NULL UNIQUE,
                              username TEXT,
                              install_id TEXT,
                              platform TEXT NOT NULL DEFAULT 'ios',
                              environment TEXT NOT NULL DEFAULT 'sandbox',
                              bundle_id TEXT NOT NULL,
                              device_name TEXT,
                              last_seen TEXT DEFAULT (datetime('now')),
                              created_at TEXT DEFAULT (datetime('now')),
                              is_active INTEGER DEFAULT 1
                             )''')
                c.execute("CREATE INDEX IF NOT EXISTS idx_native_push_user ON native_push_tokens(username)")
                c.execute("CREATE INDEX IF NOT EXISTS idx_native_push_install ON native_push_tokens(install_id)")

            # Log of recently sent push notifications for de-duplication
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS push_send_log (
                                     id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                     username VARCHAR(191) NOT NULL,
                                     tag VARCHAR(191) NULL,
                                     title TEXT,
                                     body TEXT,
                                     url TEXT,
                                     sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                     INDEX idx_user_time (username, sent_at)
                                 )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS push_send_log (
                                     id INTEGER PRIMARY KEY AUTOINCREMENT,
                                     username VARCHAR(191) NOT NULL,
                                     tag TEXT,
                                     title TEXT,
                                     body TEXT,
                                     url TEXT,
                                     sent_at TEXT DEFAULT (datetime('now'))
                                 )''')
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure push_send_log table: {e}")

            # Track active chat presence (suppress chat push when recipient is in the thread)
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS active_chat_status (
                                     user VARCHAR(191) NOT NULL,
                                     peer VARCHAR(191) NOT NULL,
                                     updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                     PRIMARY KEY (user, peer)
                                 )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS active_chat_status (
                                     user TEXT NOT NULL,
                                     peer TEXT NOT NULL,
                                     updated_at TEXT DEFAULT (datetime('now')),
                                     PRIMARY KEY (user, peer)
                                 )''')
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure active_chat_status table: {e}")

            # Ensure pending_signups exists for email-first flow
            try:
                ensure_pending_signups_table(c)
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure pending_signups table: {e}")

            # Ensure community_invitations table exists for email invitations
            try:
                ensure_community_invitations_table(c)
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure community_invitations table: {e}")

            # Ensure post_views table exists for tracking unique views
            try:
                ensure_post_views_table(c)
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure post_views table: {e}")

            # Idempotency tokens for post creation (prevent duplicate posts)
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS recent_post_tokens (
                                     token VARCHAR(191) PRIMARY KEY,
                                     username VARCHAR(191) NOT NULL,
                                     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                     INDEX idx_rpt_user_time (username, created_at)
                                 )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS recent_post_tokens (
                                     token TEXT PRIMARY KEY,
                                     username VARCHAR(191) NOT NULL,
                                     created_at TEXT DEFAULT (datetime('now'))
                                 )''')
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure recent_post_tokens table: {e}")

            # Idempotency tokens for replies
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS recent_reply_tokens (
                                     token VARCHAR(191) PRIMARY KEY,
                                     username VARCHAR(191) NOT NULL,
                                     created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                     INDEX idx_rrt_user_time (username, created_at)
                                 )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS recent_reply_tokens (
                                     token TEXT PRIMARY KEY,
                                     username VARCHAR(191) NOT NULL,
                                     created_at TEXT DEFAULT (datetime('now'))
                                 )''')
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure recent_reply_tokens table: {e}")

            # Remember-me tokens for persistent login
            c.execute('''CREATE TABLE IF NOT EXISTS remember_tokens
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          token_hash TEXT NOT NULL,
                          created_at TEXT NOT NULL,
                          expires_at TEXT NOT NULL)''')
            
            # Add missing columns to communities table (MySQL/SQLite safe)
            columns_to_add = [
                ('description', 'TEXT'),
                ('location', 'TEXT'),
                ('background_path', 'TEXT'),
                ('template', 'TEXT'),
                ('background_color', 'TEXT'),
                ('text_color', 'TEXT'),
                ('accent_color', 'TEXT'),
                ('card_color', 'TEXT'),
                ('parent_community_id', 'INTEGER')
            ]

            for column_name, column_type in columns_to_add:
                try:
                    exists = False
                    try:
                        if USE_MYSQL:
                            c.execute("SHOW COLUMNS FROM communities LIKE ?", (column_name,))
                        else:
                            c.execute("PRAGMA table_info(communities)")
                            exists = any(r[1] == column_name if not hasattr(r, 'keys') else r['name'] == column_name for r in c.fetchall())
                            # Reset exists for MySQL path; below we set from fetchone
                            if not USE_MYSQL:
                                pass
                        if USE_MYSQL:
                            exists = c.fetchone() is not None
                    except Exception:
                        # Fallback: assume might not exist and try to add
                        exists = False

                    if not exists:
                        c.execute(f"ALTER TABLE communities ADD COLUMN {column_name} {column_type}")
                        logger.info(f"Added column {column_name} to communities table")
                    else:
                        logger.info(f"Column {column_name} already exists in communities table")
                except Exception as e:
                    # Ignore duplicate/exists errors; log others but continue
                    msg = str(e)
                    if 'duplicate column' in msg.lower() or '1060' in msg:
                        logger.info(f"Column {column_name} already present (detected by error)")
                    else:
                        logger.warning(f"Could not ensure column {column_name} on communities: {e}")
            
            # Ensure parent_reply_id exists on replies (MySQL/SQLite safe)
            try:
                exists = False
                if USE_MYSQL:
                    try:
                        c.execute("SHOW COLUMNS FROM replies LIKE 'parent_reply_id'")
                        exists = c.fetchone() is not None
                    except Exception:
                        exists = False
                else:
                    try:
                        c.execute("PRAGMA table_info(replies)")
                        exists = any(r[1] == 'parent_reply_id' if not hasattr(r,'keys') else r['name']=='parent_reply_id' for r in c.fetchall())
                    except Exception:
                        exists = False

                if not exists:
                    c.execute("ALTER TABLE replies ADD COLUMN parent_reply_id INTEGER")
                    logger.info("Added column parent_reply_id to replies table")
                else:
                    logger.info("Column parent_reply_id already exists in replies table")
            except Exception as e:
                msg = str(e)
                if 'duplicate column' in msg.lower() or '1060' in msg:
                    logger.info("Column parent_reply_id already present (detected by error)")
                else:
                    logger.warning(f"Could not ensure parent_reply_id on replies: {e}")

            # Ensure messages table has is_read column
            try:
                c.execute("SHOW COLUMNS FROM messages LIKE 'is_read'")
                if not c.fetchone():
                    c.execute("ALTER TABLE messages ADD COLUMN is_read INTEGER DEFAULT 0")
                    logger.info("Added is_read column to messages table")
            except Exception as e:
                logger.warning(f"Could not ensure is_read column on messages: {e}")
            
            # Ensure messages table has image_path column for photo messages
            try:
                c.execute("SHOW COLUMNS FROM messages LIKE 'image_path'")
                if not c.fetchone():
                    c.execute("ALTER TABLE messages ADD COLUMN image_path TEXT")
                    conn.commit()
                    logger.info("Added image_path column to messages table")
            except Exception as e:
                logger.warning(f"Could not ensure image_path column on messages: {e}")

            # Ensure messages table has video_path column for video messages
            try:
                exists = False
                try:
                    if USE_MYSQL:
                        c.execute("SHOW COLUMNS FROM messages LIKE 'video_path'")
                        exists = c.fetchone() is not None
                except Exception:
                    exists = False
                if not exists:
                    c.execute("ALTER TABLE messages ADD COLUMN video_path TEXT")
                    conn.commit()
                    logger.info("Added video_path column to messages table")
            except Exception as e:
                logger.warning(f"Could not ensure video_path column on messages: {e}")

            # Ensure messages table has audio columns for voice messages
            for col_name, col_type in [
                ('audio_path', 'TEXT'),
                ('audio_duration_seconds', 'INTEGER'),
                ('audio_mime', 'TEXT'),
            ]:
                try:
                    exists = False
                    try:
                        c.execute(f"SHOW COLUMNS FROM messages LIKE '{col_name}'")
                        exists = c.fetchone() is not None
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute(f"ALTER TABLE messages ADD COLUMN {col_name} {col_type}")
                        conn.commit()
                        logger.info(f"Added {col_name} column to messages table")
                except Exception as ae:
                    logger.warning(f"Could not ensure {col_name} column on messages: {ae}")
            
            # Ensure messages table has E2E encryption columns
            for col_name, col_type in [
                ('is_encrypted', 'INTEGER DEFAULT 0'),
                ('encrypted_body', 'TEXT'),
                ('encrypted_body_for_sender', 'TEXT'),
            ]:
                try:
                    exists = False
                    try:
                        c.execute(f"SHOW COLUMNS FROM messages LIKE '{col_name}'")
                        exists = c.fetchone() is not None
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute(f"ALTER TABLE messages ADD COLUMN {col_name} {col_type}")
                        conn.commit()
                        logger.info(f"Added {col_name} column to messages table for E2E encryption")
                except Exception as ae:
                    logger.warning(f"Could not ensure {col_name} column on messages: {ae}")

            # Typing status table for realtime UX
            c.execute('''CREATE TABLE IF NOT EXISTS typing_status (
                             id INTEGER PRIMARY KEY AUTO_INCREMENT,
                             user TEXT NOT NULL,
                             peer TEXT NOT NULL,
                             is_typing INTEGER DEFAULT 0,
                             updated_at TEXT NOT NULL,
                             UNIQUE(user, peer))''')
            
            # E2E Encryption tables
            logger.info("Creating encryption_keys table...")
            c.execute('''CREATE TABLE IF NOT EXISTS encryption_keys (
                             id INTEGER PRIMARY KEY AUTO_INCREMENT,
                             username VARCHAR(191) UNIQUE NOT NULL,
                             identity_key TEXT NOT NULL,
                             signed_prekey_id INTEGER NOT NULL,
                             signed_prekey_public TEXT NOT NULL,
                             signed_prekey_signature TEXT NOT NULL,
                             registration_id INTEGER NOT NULL,
                             created_at TEXT NOT NULL,
                             updated_at TEXT NOT NULL)''')
            
            logger.info("Creating encryption_prekeys table...")
            c.execute('''CREATE TABLE IF NOT EXISTS encryption_prekeys (
                             id INTEGER PRIMARY KEY AUTO_INCREMENT,
                             username VARCHAR(191) NOT NULL,
                             key_id INTEGER NOT NULL,
                             public_key TEXT NOT NULL,
                             used INTEGER DEFAULT 0,
                             created_at TEXT NOT NULL,
                             UNIQUE(username, key_id))''')
            
            logger.info("Creating encryption_backups table...")
            c.execute('''CREATE TABLE IF NOT EXISTS encryption_backups (
                             id INTEGER PRIMARY KEY AUTO_INCREMENT,
                             username VARCHAR(191) UNIQUE NOT NULL,
                             encrypted_backup TEXT NOT NULL,
                             salt TEXT NOT NULL,
                             created_at TEXT NOT NULL,
                             updated_at TEXT NOT NULL)''')

            # Ensure helpful indexes
            try:
                c.execute("CREATE INDEX IF NOT EXISTS idx_replies_post ON replies(post_id)")
                c.execute("CREATE INDEX IF NOT EXISTS idx_replies_parent ON replies(parent_reply_id)")
            except Exception as e:
                logger.warning(f"Could not create replies indexes: {e}")

            # Ensure professional info columns exist on users (MySQL-compatible)
            try:
                # For MySQL, use SHOW COLUMNS to check
                for col, coltype in [
                    ('role','TEXT'), ('company','TEXT'), ('industry','TEXT'), ('degree','TEXT'),
                    ('school','TEXT'), ('skills','TEXT'), ('linkedin','TEXT'), ('experience','INTEGER'),
                    ('professional_about','TEXT'), ('professional_interests','TEXT')
                ]:
                    try:
                        c.execute(f"SHOW COLUMNS FROM users LIKE '{col}'")
                        if not c.fetchone():
                            c.execute(f"ALTER TABLE users ADD COLUMN {col} {coltype}")
                            logger.info(f"Added users.{col}")
                    except Exception as ce:
                        # Fallback attempt for SQLite (ignore if exists)
                        try:
                            c.execute(f"ALTER TABLE users ADD COLUMN {col} {coltype}")
                            logger.info(f"Added users.{col} (sqlite fallback)")
                        except Exception as ce2:
                            logger.warning(f"Could not ensure users.{col}: {ce2}")
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure professional columns on users: {e}")

            # Ensure professional_share_community_id column exists on users (controls visibility)
            try:
                exists = False
                try:
                    if USE_MYSQL:
                        c.execute("SHOW COLUMNS FROM users LIKE 'professional_share_community_id'")
                        exists = c.fetchone() is not None
                    else:
                        c.execute("PRAGMA table_info(users)")
                        exists = any(r[1] == 'professional_share_community_id' if not hasattr(r, 'keys') else r['name'] == 'professional_share_community_id' for r in c.fetchall())
                except Exception:
                    exists = False
                if not exists:
                    c.execute("ALTER TABLE users ADD COLUMN professional_share_community_id INTEGER")
                    logger.info("Added users.professional_share_community_id")
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure users.professional_share_community_id: {e}")

            # Ensure personal info columns (country, city, age, gender) exist on users
            try:
                for col, coltype in [
                    ('country','TEXT'), ('city','TEXT'), ('age','INTEGER'), ('gender','TEXT'), ('mobile','TEXT'), ('date_of_birth','TEXT')
                ]:
                    exists = False
                    try:
                        if USE_MYSQL:
                            c.execute("SHOW COLUMNS FROM users LIKE ?", (col,))
                            exists = c.fetchone() is not None
                        else:
                            c.execute("PRAGMA table_info(users)")
                            exists = any(r[1] == col if not hasattr(r, 'keys') else r['name'] == col for r in c.fetchall())
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute(f"ALTER TABLE users ADD COLUMN {col} {coltype}")
                        logger.info(f"Added users.{col}")
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure personal columns on users: {e}")

            # Create product development tables if not present
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS product_posts (
                                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                    username VARCHAR(191) NOT NULL,
                                    section VARCHAR(32) NOT NULL,
                                    content TEXT NOT NULL,
                                    created_at TEXT NOT NULL
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_replies (
                                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                    post_id INTEGER NOT NULL,
                                    username VARCHAR(191) NOT NULL,
                                    content TEXT NOT NULL,
                                    created_at TEXT NOT NULL,
                                    FOREIGN KEY (post_id) REFERENCES product_posts(id) ON DELETE CASCADE
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_polls (
                                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                    username VARCHAR(191) NOT NULL,
                                    question TEXT NOT NULL,
                                    options_json TEXT NOT NULL,
                                    created_at TEXT NOT NULL
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_poll_votes (
                                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                    poll_id INTEGER NOT NULL,
                                    username VARCHAR(191) NOT NULL,
                                    option_index INTEGER NOT NULL,
                                    created_at TEXT NOT NULL,
                                    UNIQUE(poll_id, username),
                                    FOREIGN KEY (poll_id) REFERENCES product_polls(id) ON DELETE CASCADE
                                 )''')
                    # Ensure closed column exists on product_polls
                    try:
                        c.execute("SHOW COLUMNS FROM product_polls LIKE 'closed'")
                        exists = c.fetchone() is not None
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute("ALTER TABLE product_polls ADD COLUMN closed TINYINT(1) NOT NULL DEFAULT 0")
                    # Ensure allow_multiple column exists on product_polls
                    try:
                        c.execute("SHOW COLUMNS FROM product_polls LIKE 'allow_multiple'")
                        exists2 = c.fetchone() is not None
                    except Exception:
                        exists2 = False
                    if not exists2:
                        c.execute("ALTER TABLE product_polls ADD COLUMN allow_multiple TINYINT(1) NOT NULL DEFAULT 0")
                    # Ensure unique index allows multiple options (poll_id, username, option_index)
                    try:
                        c.execute("SHOW INDEX FROM product_poll_votes WHERE Non_unique=0")
                        idx_rows = c.fetchall() or []
                        # Map index name -> ordered column list
                        idx_cols = {}
                        for r in idx_rows:
                            key = r['Key_name'] if hasattr(r,'keys') else r[2]
                            col = r['Column_name'] if hasattr(r,'keys') else r[4]
                            seq = r['Seq_in_index'] if hasattr(r,'keys') else r[3]
                            idx_cols.setdefault(key, {})[int(seq)] = col
                        # Find 2-col unique on (poll_id, username)
                        to_drop = None
                        for name, cols_map in idx_cols.items():
                            ordered = [cols_map[k] for k in sorted(cols_map.keys())]
                            if ordered == ['poll_id','username']:
                                to_drop = name
                                break
                        if to_drop:
                            c.execute(f"ALTER TABLE product_poll_votes DROP INDEX {to_drop}")
                            conn.commit()
                    except Exception as eidx:
                        logger.warning(f"Could not adjust unique index for poll votes: {eidx}")
                    try:
                        # Create composite unique if not exists
                        c.execute("SHOW INDEX FROM product_poll_votes WHERE Key_name='ux_poll_user_option'")
                        exists_idx = c.fetchone() is not None
                        if not exists_idx:
                            c.execute("ALTER TABLE product_poll_votes ADD UNIQUE KEY ux_poll_user_option (poll_id, username, option_index)")
                    except Exception as e2:
                        logger.warning(f"Could not ensure composite unique for poll votes: {e2}")
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS product_posts (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    username VARCHAR(191) NOT NULL,
                                    section TEXT NOT NULL,
                                    content TEXT NOT NULL,
                                    created_at TEXT NOT NULL
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_replies (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    post_id INTEGER NOT NULL,
                                    username VARCHAR(191) NOT NULL,
                                    content TEXT NOT NULL,
                                    created_at TEXT NOT NULL,
                                    FOREIGN KEY (post_id) REFERENCES product_posts(id) ON DELETE CASCADE
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_polls (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    username VARCHAR(191) NOT NULL,
                                    question TEXT NOT NULL,
                                    options_json TEXT NOT NULL,
                                    created_at TEXT NOT NULL
                                 )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS product_poll_votes (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    poll_id INTEGER NOT NULL,
                                    username VARCHAR(191) NOT NULL,
                                    option_index INTEGER NOT NULL,
                                    created_at TEXT NOT NULL,
                                    UNIQUE(poll_id, username),
                                    FOREIGN KEY (poll_id) REFERENCES product_polls(id) ON DELETE CASCADE
                                 )''')
                    # Ensure closed column exists on product_polls
                    try:
                        c.execute("PRAGMA table_info(product_polls)")
                        cols = c.fetchall()
                        exists = any((r[1] if not hasattr(r,'keys') else r['name']) == 'closed' for r in cols)
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute("ALTER TABLE product_polls ADD COLUMN closed INTEGER NOT NULL DEFAULT 0")
                    # Ensure allow_multiple column exists on product_polls
                    try:
                        c.execute("PRAGMA table_info(product_polls)")
                        cols2 = c.fetchall()
                        exists2 = any((r[1] if not hasattr(r,'keys') else r['name']) == 'allow_multiple' for r in cols2)
                    except Exception:
                        exists2 = False
                    if not exists2:
                        c.execute("ALTER TABLE product_polls ADD COLUMN allow_multiple INTEGER NOT NULL DEFAULT 0")
                
                    # Ensure poll_notification_log table exists (track sent notifications)
                    try:
                        if USE_MYSQL:
                            c.execute("SHOW TABLES LIKE 'poll_notification_log'")
                            if not c.fetchone():
                                c.execute('''CREATE TABLE IF NOT EXISTS poll_notification_log (
                                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                    poll_id INTEGER NOT NULL,
                                    username VARCHAR(191) NOT NULL,
                                    notification_type VARCHAR(50) NOT NULL,
                                    sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                    UNIQUE KEY unique_poll_notif (poll_id, username, notification_type),
                                    FOREIGN KEY (poll_id) REFERENCES polls(id) ON DELETE CASCADE
                                )''')
                        else:
                            c.execute('''CREATE TABLE IF NOT EXISTS poll_notification_log (
                                id INTEGER PRIMARY KEY AUTOINCREMENT,
                                poll_id INTEGER NOT NULL,
                                username TEXT NOT NULL,
                                notification_type TEXT NOT NULL,
                                sent_at TEXT DEFAULT (datetime('now')),
                                UNIQUE(poll_id, username, notification_type),
                                FOREIGN KEY (poll_id) REFERENCES polls(id) ON DELETE CASCADE
                            )''')
                    except Exception as pnl_err:
                        logger.warning(f"Could not create poll_notification_log table: {pnl_err}")
                
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure product dev tables: {e}")

            # Ensure email verification columns exist on users
            try:
                for col, coltype in [
                    ('email_verified', 'INTEGER DEFAULT 0'),
                    ('email_verified_at', 'TEXT'),
                    ('email_verification_sent_at', 'TEXT')
                ]:
                    exists = False
                    try:
                        if USE_MYSQL:
                            c.execute("SHOW COLUMNS FROM users LIKE ?", (col,))
                            exists = c.fetchone() is not None
                        else:
                            c.execute("PRAGMA table_info(users)")
                            exists = any(r[1] == col if not hasattr(r, 'keys') else r['name'] == col for r in c.fetchall())
                    except Exception:
                        exists = False
                    if not exists:
                        c.execute(f"ALTER TABLE users ADD COLUMN {col} {coltype}")
                        logger.info(f"Added users.{col}")
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure email verification columns on users: {e}")

            # Ensure useful_links table exists (for Useful Links & Docs)
            try:
                if USE_MYSQL:
                    c.execute("SHOW TABLES LIKE 'useful_links'")
                    if not c.fetchone():
                        c.execute('''CREATE TABLE IF NOT EXISTS useful_links (
                                         id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                         community_id INTEGER NULL,
                                         username VARCHAR(191) NOT NULL,
                                         url TEXT NOT NULL,
                                         description TEXT,
                                         created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                         FOREIGN KEY (community_id) REFERENCES communities(id)
                                     )''')
                        conn.commit()
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS useful_links (
                                     id INTEGER PRIMARY KEY AUTOINCREMENT,
                                     community_id INTEGER NULL,
                                     username VARCHAR(191) NOT NULL,
                                     url TEXT NOT NULL,
                                     description TEXT,
                                     created_at TEXT DEFAULT (datetime('now'))
                                 )''')
                    conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure useful_links table: {e}")

            # Ensure useful_docs table exists (for PDF uploads)
            try:
                if USE_MYSQL:
                    c.execute("SHOW TABLES LIKE 'useful_docs'")
                    if not c.fetchone():
                        c.execute('''CREATE TABLE IF NOT EXISTS useful_docs (
                                         id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                         community_id INTEGER NULL,
                                         username VARCHAR(191) NOT NULL,
                                         file_path TEXT NOT NULL,
                                         description TEXT,
                                         created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                         FOREIGN KEY (community_id) REFERENCES communities(id)
                                     )''')
                        conn.commit()
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS useful_docs (
                                     id INTEGER PRIMARY KEY AUTOINCREMENT,
                                     community_id INTEGER NULL,
                                     username VARCHAR(191) NOT NULL,
                                     file_path TEXT NOT NULL,
                                     description TEXT,
                                     created_at TEXT DEFAULT (datetime('now'))
                                 )''')
                    conn.commit()
            except Exception as e:
                logger.warning(f"Could not ensure useful_docs table: {e}")

            conn.commit()
            logger.info("Missing tables and columns added successfully")
            
    except Exception as e:
        logger.error(f"Error adding missing tables: {e}")
        raise
def init_db():
    """Initialize the database with all required tables."""
    try:
        logger.info("Starting database initialization...")
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Create users table
            logger.info("Creating users table...")
            c.execute('''CREATE TABLE IF NOT EXISTS users
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) UNIQUE NOT NULL, email TEXT UNIQUE, subscription TEXT DEFAULT 'free',
                          password TEXT, first_name TEXT, last_name TEXT, age INTEGER, gender TEXT,
                          fitness_level TEXT, primary_goal TEXT, weight REAL, height REAL, blood_type TEXT,
                          muscle_mass REAL, bmi REAL, nutrition_goal TEXT, nutrition_restrictions TEXT,
                          created_at TEXT, is_admin BOOLEAN DEFAULT 0)''')
            
            # Add id column for MySQL compatibility if it doesn't exist
            try:
                c.execute("SELECT id FROM users LIMIT 1")
            except:
                logger.info("Adding id column to users table for MySQL compatibility...")
                c.execute("ALTER TABLE users ADD COLUMN id INTEGER PRIMARY KEY AUTO_INCREMENT FIRST")
                conn.commit()
            
            # Ensure user_communities table exists and has correct schema
            try:
                # Check if table exists
                c.execute("SHOW TABLES LIKE 'user_communities'")
                if not c.fetchone():
                    logger.info("Creating user_communities table...")
                    c.execute('''CREATE TABLE user_communities
                                 (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                  user_id INTEGER NOT NULL,
                                  community_id INTEGER NOT NULL,
                                  role TEXT,
                                  joined_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                  FOREIGN KEY (user_id) REFERENCES users(id),
                                  FOREIGN KEY (community_id) REFERENCES communities(id),
                                  UNIQUE(user_id, community_id))''')
                    conn.commit()
                    logger.info("Created user_communities table")

                    # Add role column if it doesn't exist (migration for existing installations)
                    try:
                        c.execute("SHOW COLUMNS FROM user_communities LIKE 'role'")
                        if not c.fetchone():
                            logger.info("Adding role column to user_communities table...")
                            # TEXT columns can't have default values in MySQL
                            c.execute("ALTER TABLE user_communities ADD COLUMN role TEXT")
                            c.execute("UPDATE user_communities SET role = 'member' WHERE role IS NULL")
                            conn.commit()
                            logger.info("Added role column to user_communities table")
                    except Exception as e:
                        logger.warning(f"Could not add role column: {e}")
                    
                else:
                    # Table exists, check if it has user_id column
                    c.execute("SHOW COLUMNS FROM user_communities LIKE 'user_id'")
                    if not c.fetchone():
                        logger.info("user_id column missing, recreating user_communities table...")
                        c.execute("DROP TABLE user_communities")
                        c.execute('''CREATE TABLE user_communities
                                     (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                      user_id INTEGER NOT NULL,
                                      community_id INTEGER NOT NULL,
                                      role TEXT,
                                      joined_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                      FOREIGN KEY (user_id) REFERENCES users(id),
                                      FOREIGN KEY (community_id) REFERENCES communities(id),
                                      UNIQUE(user_id, community_id))''')
                        conn.commit()
                        logger.info("Recreated user_communities table with correct schema")

                        # Add role column if it doesn't exist (migration for existing installations)
                        try:
                            c.execute("SHOW COLUMNS FROM user_communities LIKE 'role'")
                            if not c.fetchone():
                                logger.info("Adding role column to user_communities table...")
                                # TEXT columns can't have default values in MySQL
                                c.execute("ALTER TABLE user_communities ADD COLUMN role TEXT")
                                c.execute("UPDATE user_communities SET role = 'member' WHERE role IS NULL")
                                conn.commit()
                                logger.info("Added role column to user_communities table")
                        except Exception as e:
                            logger.warning(f"Could not add role column: {e}")
            except Exception as e:
                logger.error(f"Failed to ensure user_communities table: {e}")
            
            # Add missing columns to existing users table if they don't exist
            logger.info("Checking for missing columns...")
            columns_to_add = [
                ('email', 'TEXT'),
                ('first_name', 'TEXT'),
                ('last_name', 'TEXT'),
                ('age', 'INTEGER'),
                ('fitness_level', 'TEXT'),
                ('primary_goal', 'TEXT'),
                ('created_at', 'TEXT'),
                ('country', 'TEXT'),
                ('city', 'TEXT'),
                ('industry', 'TEXT'),
                ('role', 'TEXT'),
                ('company', 'TEXT'),
                ('degree', 'TEXT'),
                ('school', 'TEXT'),
                ('skills', 'TEXT'),
                ('linkedin', 'TEXT'),
                ('experience', 'INTEGER'),
                ('mobile', 'TEXT')
            ]
            
            for column_name, column_type in columns_to_add:
                try:
                    c.execute(f"ALTER TABLE users ADD COLUMN {column_name} {column_type}")
                    logger.info(f"Added column {column_name}")
                except sqlite3.OperationalError as e:
                    if "duplicate column name" in str(e):
                        logger.info(f"Column {column_name} already exists")
                    else:
                        logger.warning(f"Could not add column {column_name}: {e}")
            
            # Insert admin user
            logger.info("Inserting admin user...")
            c.execute("INSERT IGNORE INTO users (username, email, subscription, password, first_name, last_name, created_at) VALUES (?, ?, ?, ?, ?, ?, ?)",
                      ('admin', 'admin@cpoint.com', 'premium', '12345', 'Admin', 'User', datetime.now().strftime('%m.%d.%y %H:%M')))
            
            # Create posts table
            logger.info("Creating posts table...")
            # Create crossfit entries table (for lifts and WODs)
            logger.info("Creating crossfit entries table...")
            c.execute('''CREATE TABLE IF NOT EXISTS crossfit_entries (
                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                username VARCHAR(191) NOT NULL,
                type TEXT NOT NULL,
                name TEXT NOT NULL,
                weight REAL,
                reps INTEGER,
                score TEXT,
                score_numeric REAL,
                created_at TEXT NOT NULL
            )''')
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS posts
                           (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                            username VARCHAR(191) NOT NULL,
                            content TEXT NOT NULL,
                            image_path TEXT,
                            timestamp TEXT NOT NULL,
                            community_id INTEGER,
                            FOREIGN KEY (username) REFERENCES users(username))''')
                c.execute('''CREATE TABLE IF NOT EXISTS post_views
                           (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                            post_id INTEGER NOT NULL,
                            username VARCHAR(191) NOT NULL,
                            viewed_at DATETIME NOT NULL,
                            UNIQUE(post_id, username),
                            FOREIGN KEY (post_id) REFERENCES posts(id) ON DELETE CASCADE,
                            FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE)''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS posts
                           (id INTEGER PRIMARY KEY AUTOINCREMENT,
                            username VARCHAR(191) NOT NULL,
                            content TEXT NOT NULL,
                            image_path TEXT,
                            timestamp TEXT NOT NULL,
                            community_id INTEGER,
                            FOREIGN KEY (username) REFERENCES users(username))''')
                c.execute('''CREATE TABLE IF NOT EXISTS post_views
                           (id INTEGER PRIMARY KEY AUTOINCREMENT,
                            post_id INTEGER NOT NULL,
                            username VARCHAR(191) NOT NULL,
                            viewed_at TEXT NOT NULL,
                            UNIQUE(post_id, username),
                            FOREIGN KEY (post_id) REFERENCES posts(id) ON DELETE CASCADE,
                            FOREIGN KEY (username) REFERENCES users(username) ON DELETE CASCADE)''')

            # Create replies table
            logger.info("Creating replies table...")
            c.execute('''CREATE TABLE IF NOT EXISTS replies
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          post_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          content TEXT NOT NULL,
                          image_path TEXT,
                          timestamp TEXT NOT NULL,
                          community_id INTEGER,
                          FOREIGN KEY (post_id) REFERENCES posts(id),
                          FOREIGN KEY (username) REFERENCES users(username))''')

            # Create reactions table
            logger.info("Creating reactions table...")
            c.execute('''CREATE TABLE IF NOT EXISTS reactions
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          post_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          reaction_type TEXT NOT NULL,
                          FOREIGN KEY (post_id) REFERENCES posts(id),
                          FOREIGN KEY (username) REFERENCES users(username),
                          UNIQUE(post_id, username))''')

            # Create reply_reactions table
            logger.info("Creating reply_reactions table...")
            c.execute('''CREATE TABLE IF NOT EXISTS reply_reactions
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          reply_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          reaction_type TEXT NOT NULL,
                          FOREIGN KEY (reply_id) REFERENCES replies(id),
                          FOREIGN KEY (username) REFERENCES users(username),
                          UNIQUE(reply_id, username))''')

            # Create key_posts table (user-starred posts within communities)
            logger.info("Creating key_posts table...")
            c.execute('''CREATE TABLE IF NOT EXISTS key_posts
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          post_id INTEGER NOT NULL,
                          community_id INTEGER NOT NULL,
                          created_at TEXT NOT NULL,
                          FOREIGN KEY (post_id) REFERENCES posts(id),
                          FOREIGN KEY (community_id) REFERENCES communities(id),
                          UNIQUE(username, post_id))''')

            # Create communities table
            logger.info("Creating communities table...")
            c.execute('''CREATE TABLE IF NOT EXISTS communities
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          name TEXT NOT NULL,
                          type TEXT NOT NULL,
                          creator_username VARCHAR(191) NOT NULL,
                          join_code TEXT UNIQUE NOT NULL,
                          created_at TEXT NOT NULL,
                          description TEXT,
                          location TEXT,
                          background_path TEXT,
                          info TEXT,
                          info_updated_at TEXT,
                          template TEXT DEFAULT 'default',
                          background_color TEXT DEFAULT '#2d3839',
                          text_color TEXT DEFAULT '#ffffff',
                          accent_color TEXT DEFAULT '#4db6ac',
                          card_color TEXT DEFAULT '#1a2526',
                          parent_community_id INTEGER,
                          notify_on_new_member TINYINT(1) DEFAULT 0,
                          FOREIGN KEY (creator_username) REFERENCES users(username),
                          FOREIGN KEY (parent_community_id) REFERENCES communities(id))''')
            
            # Add notify_on_new_member column to existing communities table
            try:
                c.execute("SHOW COLUMNS FROM communities LIKE 'notify_on_new_member'")
                if not c.fetchone():
                    logger.info("Adding notify_on_new_member column to communities table...")
                    c.execute("ALTER TABLE communities ADD COLUMN notify_on_new_member TINYINT(1) DEFAULT 0")
                    conn.commit()
                    logger.info("Added notify_on_new_member column to communities table")
            except Exception as e:
                logger.warning(f"Could not add notify_on_new_member column: {e}")

            # Create user_communities table
            logger.info("Creating user_communities table...")
            c.execute('''CREATE TABLE IF NOT EXISTS user_communities
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          user_id INTEGER NOT NULL,
                          community_id INTEGER NOT NULL,
                          role TEXT,
                          joined_at TEXT NOT NULL,
                          FOREIGN KEY (user_id) REFERENCES users(id),
                          FOREIGN KEY (community_id) REFERENCES communities(id),
                          UNIQUE(user_id, community_id))''')

            # Add role column if it doesn't exist (migration for existing installations)
            try:
                c.execute("SHOW COLUMNS FROM user_communities LIKE 'role'")
                if not c.fetchone():
                    logger.info("Adding role column to user_communities table...")
                    # TEXT columns can't have default values in MySQL
                    c.execute("ALTER TABLE user_communities ADD COLUMN role TEXT")
                    c.execute("UPDATE user_communities SET role = 'member' WHERE role IS NULL")
                    conn.commit()
                    logger.info("Added role column to user_communities table")
            except Exception as e:
                logger.warning(f"Could not add role column: {e}")

            # Create groups (horizontal to communities) and group_members tables
            logger.info("Ensuring groups and group_members tables...")
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS `groups` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        community_id INTEGER NOT NULL,
                        name VARCHAR(255) NOT NULL,
                        approval_required TINYINT(1) DEFAULT 0,
                        created_by VARCHAR(191) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                        FOREIGN KEY (created_by) REFERENCES users(username)
                    )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS groups (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        community_id INTEGER NOT NULL,
                        name TEXT NOT NULL,
                        approval_required INTEGER DEFAULT 0,
                        created_by TEXT NOT NULL,
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                        FOREIGN KEY (created_by) REFERENCES users(username)
                    )''')
            except Exception as e:
                logger.warning(f"Could not ensure groups table: {e}")

            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS `group_members` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        group_id INTEGER NOT NULL,
                        username VARCHAR(191) NOT NULL,
                        status VARCHAR(16) NOT NULL DEFAULT 'member',
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (group_id) REFERENCES `groups`(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE KEY uniq_group_user (group_id, username)
                    )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS group_members (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_id INTEGER NOT NULL,
                        username TEXT NOT NULL,
                        status TEXT NOT NULL DEFAULT 'member',
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (group_id) REFERENCES groups(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE(group_id, username)
                    )''')
            except Exception as e:
                logger.warning(f"Could not ensure group_members table: {e}")

            # Group posts and replies (clean separation from community posts)
            try:
                if USE_MYSQL:
                    c.execute('''CREATE TABLE IF NOT EXISTS `group_posts` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        group_id INTEGER NOT NULL,
                        username VARCHAR(150) NOT NULL,
                        content TEXT NOT NULL,
                        image_path TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (group_id) REFERENCES `groups`(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS `group_post_reactions` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        group_post_id INTEGER NOT NULL,
                        username VARCHAR(150) NOT NULL,
                        reaction VARCHAR(32) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (group_post_id) REFERENCES `group_posts`(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE KEY uniq_gpr (group_post_id, username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS `group_replies` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        group_post_id INTEGER NOT NULL,
                        parent_reply_id INTEGER NULL,
                        username VARCHAR(150) NOT NULL,
                        content TEXT NOT NULL,
                        image_path TEXT,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (group_post_id) REFERENCES `group_posts`(id) ON DELETE CASCADE,
                        FOREIGN KEY (parent_reply_id) REFERENCES `group_replies`(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS `group_reply_reactions` (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        group_reply_id INTEGER NOT NULL,
                        username VARCHAR(150) NOT NULL,
                        reaction VARCHAR(32) NOT NULL,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (group_reply_id) REFERENCES `group_replies`(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE KEY uniq_grr (group_reply_id, username)
                    )''')
                else:
                    c.execute('''CREATE TABLE IF NOT EXISTS group_posts (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_id INTEGER NOT NULL,
                        username TEXT NOT NULL,
                        content TEXT NOT NULL,
                        image_path TEXT,
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (group_id) REFERENCES groups(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS group_post_reactions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_post_id INTEGER NOT NULL,
                        username TEXT NOT NULL,
                        reaction TEXT NOT NULL,
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (group_post_id) REFERENCES group_posts(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE(group_post_id, username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS group_replies (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_post_id INTEGER NOT NULL,
                        parent_reply_id INTEGER NULL,
                        username TEXT NOT NULL,
                        content TEXT NOT NULL,
                        image_path TEXT,
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (group_post_id) REFERENCES group_posts(id) ON DELETE CASCADE,
                        FOREIGN KEY (parent_reply_id) REFERENCES group_replies(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username)
                    )''')
                    c.execute('''CREATE TABLE IF NOT EXISTS group_reply_reactions (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        group_reply_id INTEGER NOT NULL,
                        username TEXT NOT NULL,
                        reaction TEXT NOT NULL,
                        created_at TEXT DEFAULT (datetime('now')),
                        FOREIGN KEY (group_reply_id) REFERENCES group_replies(id) ON DELETE CASCADE,
                        FOREIGN KEY (username) REFERENCES users(username),
                        UNIQUE(group_reply_id, username)
                    )''')
            except Exception as e:
                logger.warning(f"Could not ensure group post tables: {e}")

            
            # Create community_files table
            logger.info("Creating community_files table...")
            c.execute('''CREATE TABLE IF NOT EXISTS community_files
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          filename TEXT NOT NULL,
                          uploaded_by TEXT NOT NULL,
                          upload_date TEXT NOT NULL,
                          description TEXT,
                          FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                          FOREIGN KEY (uploaded_by) REFERENCES users(username))''')

            # Create notifications table
            logger.info("Creating notifications table...")
            c.execute('''CREATE TABLE IF NOT EXISTS notifications
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          user_id TEXT NOT NULL,
                          from_user TEXT,
                          type TEXT NOT NULL,
                          post_id INTEGER,
                          community_id INTEGER,
                          message TEXT,
                          is_read INTEGER DEFAULT 0,
                          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                          link TEXT,
                          FOREIGN KEY (post_id) REFERENCES posts(id),
                          FOREIGN KEY (community_id) REFERENCES communities(id),
                          UNIQUE KEY unique_notification (user_id, from_user, type, post_id, community_id))''')

            # Add unique constraint for existing installations (migration)
            try:
                c.execute("SHOW INDEX FROM notifications WHERE Key_name = 'unique_notification'")
                if not c.fetchone():
                    logger.info("Adding unique constraint to notifications table...")
                    # First, drop the old constraint if it exists
                    c.execute("ALTER TABLE notifications DROP INDEX IF EXISTS unique_notification")
                    c.execute("ALTER TABLE notifications ADD UNIQUE KEY unique_notification (user_id, from_user, type, post_id, community_id)")
                    conn.commit()
                    logger.info("Added unique constraint to notifications table")
            except Exception as e:
                logger.warning(f"Could not add unique constraint to notifications: {e}")

            # Useful documents (PDFs)
            logger.info("Ensuring useful_docs table...")
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS useful_docs (
                                 id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                 community_id INTEGER NULL,
                                 username VARCHAR(191) NOT NULL,
                                 file_path TEXT NOT NULL,
                                 description TEXT,
                                 created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                 FOREIGN KEY (community_id) REFERENCES communities(id)
                             )''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS useful_docs (
                                 id INTEGER PRIMARY KEY AUTOINCREMENT,
                                 community_id INTEGER NULL,
                                 username VARCHAR(191) NOT NULL,
                                 file_path TEXT NOT NULL,
                                 description TEXT,
                                 created_at TEXT DEFAULT (datetime('now'))
                             )''')

            # Useful links (URLs)
            logger.info("Ensuring useful_links table...")
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS useful_links (
                                 id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                 community_id INTEGER NULL,
                                 username VARCHAR(191) NOT NULL,
                                 url TEXT NOT NULL,
                                 description TEXT,
                                 created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                                 FOREIGN KEY (community_id) REFERENCES communities(id)
                             )''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS useful_links (
                                 id INTEGER PRIMARY KEY AUTOINCREMENT,
                                 community_id INTEGER NULL,
                                 username VARCHAR(191) NOT NULL,
                                 url TEXT NOT NULL,
                                 description TEXT,
                                 created_at TEXT DEFAULT (datetime('now'))
                             )''')
            
            # Create community_announcements table
            logger.info("Creating community_announcements table...")
            c.execute('''CREATE TABLE IF NOT EXISTS community_announcements
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          content TEXT NOT NULL,
                          created_by TEXT NOT NULL,
                          created_at TEXT NOT NULL,
                          FOREIGN KEY (community_id) REFERENCES communities(id) ON DELETE CASCADE,
                          FOREIGN KEY (created_by) REFERENCES users(username))''')

            # Create api_usage table
            logger.info("Creating api_usage table...")
            c.execute('''CREATE TABLE IF NOT EXISTS api_usage
                         (username VARCHAR(191), date TEXT, count INTEGER,
                          PRIMARY KEY (username, date))''')
            
            # Create saved_data table
            logger.info("Creating saved_data table...")
            c.execute('''CREATE TABLE IF NOT EXISTS saved_data
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT, username VARCHAR(191), type TEXT, data TEXT, timestamp TEXT)''')
            
            # Create messages table
            logger.info("Creating messages table...")
            c.execute('''CREATE TABLE IF NOT EXISTS messages
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          sender TEXT NOT NULL,
                          receiver TEXT NOT NULL,
                          message TEXT NOT NULL,
                          timestamp TEXT NOT NULL,
                          is_read INTEGER DEFAULT 0,
                          FOREIGN KEY (sender) REFERENCES users(username),
                          FOREIGN KEY (receiver) REFERENCES users(username))''')

            # Create workout-related tables (MySQL/SQLite compatible)
            logger.info("Creating workout tables...")
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS exercises
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              username VARCHAR(191) NOT NULL,
                              name TEXT NOT NULL,
                              muscle_group TEXT NOT NULL,
                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
                c.execute('''CREATE TABLE IF NOT EXISTS exercise_sets
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              exercise_id INTEGER NOT NULL,
                              weight REAL NOT NULL,
                              reps INTEGER NOT NULL,
                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                              FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                             )''')
                c.execute('''CREATE TABLE IF NOT EXISTS workouts
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              username VARCHAR(191) NOT NULL,
                              name TEXT NOT NULL,
                              date TEXT NOT NULL,
                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')
                c.execute('''CREATE TABLE IF NOT EXISTS workout_exercises
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              workout_id INTEGER NOT NULL,
                              exercise_id INTEGER NOT NULL,
                              sets INTEGER DEFAULT 0,
                              reps INTEGER DEFAULT 0,
                              weight REAL DEFAULT 0,
                              created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                              FOREIGN KEY (workout_id) REFERENCES workouts (id) ON DELETE CASCADE,
                              FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE)''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS exercises
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              username VARCHAR(191) NOT NULL,
                              name TEXT NOT NULL,
                              muscle_group TEXT NOT NULL,
                              created_at TEXT DEFAULT (datetime('now'))
                             )''')
                c.execute('''CREATE TABLE IF NOT EXISTS exercise_sets
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              exercise_id INTEGER NOT NULL,
                              weight REAL NOT NULL,
                              reps INTEGER NOT NULL,
                              created_at TEXT DEFAULT (datetime('now')),
                              FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                             )''')
                c.execute('''CREATE TABLE IF NOT EXISTS workouts
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              username VARCHAR(191) NOT NULL,
                              name TEXT NOT NULL,
                              date TEXT NOT NULL,
                              created_at TEXT DEFAULT (datetime('now'))
                             )''')
                c.execute('''CREATE TABLE IF NOT EXISTS workout_exercises
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              workout_id INTEGER NOT NULL,
                              exercise_id INTEGER NOT NULL,
                              sets INTEGER DEFAULT 0,
                              reps INTEGER DEFAULT 0,
                              weight REAL DEFAULT 0,
                              created_at TEXT DEFAULT (datetime('now')),
                              FOREIGN KEY (workout_id) REFERENCES workouts (id) ON DELETE CASCADE,
                              FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                             )''')

            # Add info column to communities table if it doesn't exist
            try:
                c.execute("SELECT info FROM communities LIMIT 1")
            except sqlite3.OperationalError:
                logger.info("Adding info column to communities table...")
                c.execute("ALTER TABLE communities ADD COLUMN info TEXT")
            
            # Add info_updated_at column to communities table if it doesn't exist
            try:
                c.execute("SELECT info_updated_at FROM communities LIMIT 1")
            except sqlite3.OperationalError:
                logger.info("Adding info_updated_at column to communities table...")
                c.execute("ALTER TABLE communities ADD COLUMN info_updated_at TEXT")
            
            # Add description column to community_files table if it doesn't exist
            try:
                c.execute("SELECT description FROM community_files LIMIT 1")
            except sqlite3.OperationalError:
                logger.info("Adding description column to community_files table...")
                c.execute("ALTER TABLE community_files ADD COLUMN description TEXT")
            
                        # Create polls table
            logger.info("Creating polls table...")
            c.execute('''        CREATE TABLE IF NOT EXISTS polls
         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
          post_id INTEGER NOT NULL,
          question TEXT NOT NULL,
          created_by TEXT NOT NULL,
          created_at TEXT NOT NULL,
          expires_at TEXT,
          is_active TINYINT(1) DEFAULT 1,
          single_vote TINYINT(1) DEFAULT 1,
          FOREIGN KEY (post_id) REFERENCES posts (id) ON DELETE CASCADE)''')
            
            # Add single_vote column if it doesn't exist
            try:
                c.execute("SELECT single_vote FROM polls LIMIT 1")
            except:
                logger.info("Adding single_vote column to polls table...")
                c.execute("ALTER TABLE polls ADD COLUMN single_vote TINYINT(1) DEFAULT 1")
            
            # Create poll_options table
            logger.info("Creating poll_options table...")
            c.execute('''CREATE TABLE IF NOT EXISTS poll_options
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          poll_id INTEGER NOT NULL,
                          option_text TEXT NOT NULL,
                          votes INTEGER DEFAULT 0,
                          FOREIGN KEY (poll_id) REFERENCES polls (id) ON DELETE CASCADE)''')
            
            # Create poll_votes table
            logger.info("Creating poll_votes table...")
            c.execute('''CREATE TABLE IF NOT EXISTS poll_votes
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          poll_id INTEGER NOT NULL,
                          option_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          voted_at TEXT NOT NULL,
                          FOREIGN KEY (poll_id) REFERENCES polls (id) ON DELETE CASCADE,
                          FOREIGN KEY (option_id) REFERENCES poll_options (id) ON DELETE CASCADE,
                          UNIQUE(poll_id, username))''')
            # Migrate poll_votes unique constraint to allow multiple votes per user per poll option
            try:
                # Check if poll_votes table needs migration by checking constraint
                c.execute("SHOW CREATE TABLE poll_votes")
                row = c.fetchone()
                if row and row['Create Table'] and 'UNIQUE(poll_id, username)' in row['Create Table'] and 'option_id' not in row['Create Table'].split('UNIQUE')[-1]:
                    logger.info('Migrating poll_votes unique constraint to (poll_id, username, option_id)')
                    c.execute('SET foreign_key_checks = 0')
                    c.execute('''CREATE TABLE IF NOT EXISTS poll_votes_new (
                        id INTEGER PRIMARY KEY AUTO_INCREMENT,
                        poll_id INTEGER NOT NULL,
                        option_id INTEGER NOT NULL,
                        username VARCHAR(191) NOT NULL,
                        voted_at TEXT NOT NULL,
                        FOREIGN KEY (poll_id) REFERENCES polls (id) ON DELETE CASCADE,
                        FOREIGN KEY (option_id) REFERENCES poll_options (id) ON DELETE CASCADE,
                        UNIQUE(poll_id, username, option_id)
                    )''')
                    c.execute('INSERT IGNORE INTO poll_votes_new (poll_id, option_id, username, voted_at) SELECT poll_id, option_id, username, voted_at FROM poll_votes')
                    c.execute('DROP TABLE poll_votes')
                    c.execute('ALTER TABLE poll_votes_new RENAME TO poll_votes')
                    c.execute('SET foreign_key_checks = 1')
                    logger.info('poll_votes migration completed')
            except Exception as e:
                logger.warning(f'poll_votes migration skipped or failed: {e}')
            
            # Create community_issues table
            logger.info("Creating community_issues table...")
            c.execute('''CREATE TABLE IF NOT EXISTS community_issues
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          title TEXT NOT NULL,
                          location TEXT NOT NULL,
                          priority TEXT NOT NULL,
                          description TEXT NOT NULL,
                          reported_by TEXT NOT NULL,
                          reported_at TEXT NOT NULL,
                          resolved TINYINT(1) DEFAULT 0,
                          resolved_by TEXT,
                          resolved_at TEXT,
                          upvotes INTEGER DEFAULT 0,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE,
                          FOREIGN KEY (reported_by) REFERENCES users (username))''')
            
            # Create issue_upvotes table
            logger.info("Creating issue_upvotes table...")
            c.execute('''CREATE TABLE IF NOT EXISTS issue_upvotes
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          issue_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          upvoted_at TEXT NOT NULL,
                          FOREIGN KEY (issue_id) REFERENCES community_issues (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username),
                          UNIQUE(issue_id, username))''')
            
            # Create password_reset_tokens table (MySQL/SQLite aware)
            logger.info("Creating password_reset_tokens table...")
            if USE_MYSQL:
                c.execute('''CREATE TABLE IF NOT EXISTS password_reset_tokens (
                                 id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                 username VARCHAR(191) NOT NULL,
                                 email VARCHAR(191) NOT NULL,
                                 token VARCHAR(191) NOT NULL UNIQUE,
                                 created_at TEXT NOT NULL,
                                 used TINYINT(1) DEFAULT 0
                             )''')
            else:
                c.execute('''CREATE TABLE IF NOT EXISTS password_reset_tokens
                             (id INTEGER PRIMARY KEY AUTOINCREMENT,
                              username VARCHAR(191) NOT NULL,
                              email TEXT NOT NULL,
                              token TEXT NOT NULL UNIQUE,
                              created_at TEXT NOT NULL,
                              used INTEGER DEFAULT 0,
                              FOREIGN KEY (username) REFERENCES users (username))''')
            
            # Create university_ads table
            logger.info("Creating university_ads table...")
            c.execute('''CREATE TABLE IF NOT EXISTS university_ads
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          title TEXT NOT NULL,
                          description TEXT,
                          price TEXT NOT NULL,
                          image_url TEXT NOT NULL,
                          link_url TEXT,
                          is_active TINYINT(1) DEFAULT 1,
                          display_order INTEGER DEFAULT 0,
                          created_at TEXT NOT NULL,
                          created_by TEXT NOT NULL,
                          clicks INTEGER DEFAULT 0,
                          impressions INTEGER DEFAULT 0,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE,
                          FOREIGN KEY (created_by) REFERENCES users (username))''')
            
            # Ensure university_ads table exists
            c.execute('''CREATE TABLE IF NOT EXISTS university_ads (
                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                community_id INTEGER NOT NULL,
                title TEXT NOT NULL,
                description TEXT,
                price TEXT NOT NULL,
                image_url TEXT NOT NULL,
                link_url TEXT,
                is_active TINYINT(1) DEFAULT 1,
                display_order INTEGER DEFAULT 0,
                created_at TEXT NOT NULL,
                created_by TEXT NOT NULL,
                clicks INTEGER DEFAULT 0,
                impressions INTEGER DEFAULT 0,
                FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE
            )''')
            
            # Add impressions column if it doesn't exist (for existing databases)
            try:
                c.execute("SELECT impressions FROM university_ads LIMIT 1")
            except:
                logger.info("Adding impressions column to university_ads table...")
                c.execute("ALTER TABLE university_ads ADD COLUMN impressions INTEGER DEFAULT 0")
            
            # Create user activity tracking tables
            logger.info("Creating user activity tracking tables...")
            
            # Login history table
            c.execute('''CREATE TABLE IF NOT EXISTS user_login_history
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(255) NOT NULL,
                          login_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                          ip_address VARCHAR(45),
                          user_agent TEXT,
                          FOREIGN KEY (username) REFERENCES users (username))''')
            
            # Community visit history table
            c.execute('''CREATE TABLE IF NOT EXISTS community_visit_history
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          username VARCHAR(191) NOT NULL,
                          community_id INTEGER NOT NULL,
                          visit_time TEXT NOT NULL,
                          FOREIGN KEY (username) REFERENCES users (username),
                          FOREIGN KEY (community_id) REFERENCES communities (id))''')
            
            # Create indexes for better performance
            c.execute("CREATE INDEX IF NOT EXISTS idx_login_username ON user_login_history(username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_login_time ON user_login_history(login_time)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_visit_username ON community_visit_history(username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_visit_community ON community_visit_history(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_visit_time ON community_visit_history(visit_time)")
            
            # Create resource sharing tables
            logger.info("Creating resource sharing tables...")
            
            # Resource posts table
            c.execute('''CREATE TABLE IF NOT EXISTS resource_posts
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          title TEXT NOT NULL,
                          content TEXT NOT NULL,
                          category TEXT,
                          attachment_url TEXT,
                          created_at TEXT NOT NULL,
                          updated_at TEXT,
                          upvotes INTEGER DEFAULT 0,
                          views INTEGER DEFAULT 0,
                          is_pinned TINYINT(1) DEFAULT 0,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username))''')
            
            # Resource comments table
            c.execute('''CREATE TABLE IF NOT EXISTS resource_comments
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          post_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          content TEXT NOT NULL,
                          created_at TEXT NOT NULL,
                          upvotes INTEGER DEFAULT 0,
                          FOREIGN KEY (post_id) REFERENCES resource_posts (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username))''')
            
            # Resource upvotes table (to track who upvoted what)
            c.execute('''CREATE TABLE IF NOT EXISTS resource_upvotes
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          post_id INTEGER,
                          comment_id INTEGER,
                          username VARCHAR(191) NOT NULL,
                          created_at TEXT NOT NULL,
                          FOREIGN KEY (post_id) REFERENCES resource_posts (id) ON DELETE CASCADE,
                          FOREIGN KEY (comment_id) REFERENCES resource_comments (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username),
                          UNIQUE(post_id, username),
                          UNIQUE(comment_id, username))''')
            
            # Create indexes for resource tables
            c.execute("CREATE INDEX IF NOT EXISTS idx_resource_posts_community ON resource_posts(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_resource_posts_username ON resource_posts(username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_resource_comments_post ON resource_comments(post_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_resource_upvotes_post ON resource_upvotes(post_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_resource_upvotes_comment ON resource_upvotes(comment_id)")
            
            # Create clubs and organizations tables
            logger.info("Creating clubs and organizations tables...")
            
            # Clubs table
            c.execute('''CREATE TABLE IF NOT EXISTS clubs
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          name TEXT NOT NULL,
                          description TEXT,
                          category TEXT,
                          contact_email TEXT,
                          contact_person TEXT,
                          meeting_schedule TEXT,
                          location TEXT,
                          website_url TEXT,
                          logo_url TEXT,
                          is_active TINYINT(1) DEFAULT 1,
                          member_count INTEGER DEFAULT 0,
                          created_by TEXT NOT NULL,
                          created_at TEXT NOT NULL,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE,
                          FOREIGN KEY (created_by) REFERENCES users (username))''')
            
            # Club members table
            c.execute('''CREATE TABLE IF NOT EXISTS club_members
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          club_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          role TEXT DEFAULT 'member',
                          joined_at TEXT NOT NULL,
                          FOREIGN KEY (club_id) REFERENCES clubs (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username),
                          UNIQUE(club_id, username))''')
            
            # Anonymous feedback table
            c.execute('''CREATE TABLE IF NOT EXISTS anonymous_feedback
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          feedback_text TEXT NOT NULL,
                          category TEXT,
                          priority TEXT DEFAULT 'normal',
                          status TEXT DEFAULT 'unread',
                          submitted_at TEXT NOT NULL,
                          response TEXT,
                          responded_at TEXT,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE)''')
            
            # Create indexes for clubs and feedback
            c.execute("CREATE INDEX IF NOT EXISTS idx_clubs_community ON clubs(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_club_members_club ON club_members(club_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_club_members_username ON club_members(username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_feedback_community ON anonymous_feedback(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_feedback_status ON anonymous_feedback(status)")
            
            # Create community admins table
            logger.info("Creating community admins table...")
            c.execute('''CREATE TABLE IF NOT EXISTS community_admins
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          community_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          appointed_by TEXT NOT NULL,
                          appointed_at TEXT NOT NULL,
                          FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username),
                          FOREIGN KEY (appointed_by) REFERENCES users (username),
                          UNIQUE(community_id, username))''')
            
            # Add is_active columns to users and communities if they don't exist
            logger.info("Adding is_active columns...")
            
            # Check and add is_active to users table
            c.execute("SHOW COLUMNS FROM users LIKE 'is_active'")
            if not c.fetchone():
                c.execute("ALTER TABLE users ADD COLUMN is_active TINYINT(1) DEFAULT 1")
                logger.info("Added is_active column to users table")
            
            # Ensure notifications table has required columns
            try:
                # Check if created_at column exists
                c.execute("SHOW COLUMNS FROM notifications LIKE 'created_at'")
                if not c.fetchone():
                    c.execute("ALTER TABLE notifications ADD COLUMN created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                    logger.info("Added created_at column to notifications table")
                
                # Check if link column exists
                c.execute("SHOW COLUMNS FROM notifications LIKE 'link'")
                if not c.fetchone():
                    c.execute("ALTER TABLE notifications ADD COLUMN link TEXT")
                    logger.info("Added link column to notifications table")
            except Exception as e:
                logger.error(f"Failed to update notifications table: {e}")
            
            # Check and add is_active to communities table  
            c.execute("SHOW COLUMNS FROM communities LIKE 'is_active'")
            if not c.fetchone():
                c.execute("ALTER TABLE communities ADD COLUMN is_active TINYINT(1) DEFAULT 1")
                logger.info("Added is_active column to communities table")
            
            # Create index for community admins
            c.execute("CREATE INDEX IF NOT EXISTS idx_community_admins_community ON community_admins(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_community_admins_username ON community_admins(username)")
            
            # Add community_id to calendar_events if it doesn't exist
            logger.info("Checking calendar_events table...")
            # Ensure calendar_events table exists before altering
            c.execute("""
                CREATE TABLE IF NOT EXISTS calendar_events (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    username VARCHAR(191) NOT NULL,
                    title TEXT NOT NULL,
                    date TEXT NOT NULL,
                    end_date TEXT,
                    time TEXT,
                    start_time TEXT,
                    end_time TEXT,
                    description TEXT,
                    location TEXT,
                    created_at DATETIME NOT NULL,
                    community_id INTEGER,
                    timezone VARCHAR(100),
                    FOREIGN KEY (username) REFERENCES users(username)
                )
            """)
            
            # Add missing columns if they don't exist
            required_columns = {
                'username': 'VARCHAR(191) NOT NULL',
                'date': 'TEXT NOT NULL',
                'end_date': 'TEXT',
                'time': 'TEXT',
                'created_at': 'DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP',
                'community_id': 'INTEGER',
                'timezone': 'VARCHAR(100)',
                'notification_preferences': "VARCHAR(50) DEFAULT 'all'"
            }
            
            for col_name, col_def in required_columns.items():
                c.execute(f"SHOW COLUMNS FROM calendar_events LIKE '{col_name}'")
                if not c.fetchone():
                    try:
                        c.execute(f"ALTER TABLE calendar_events ADD COLUMN {col_name} {col_def}")
                        logger.info(f"Added {col_name} column to calendar_events table")
                    except Exception as e:
                        logger.warning(f"Could not add {col_name} column: {e}")
            
            # Create event RSVPs table
            logger.info("Creating event RSVPs table...")
            c.execute('''CREATE TABLE IF NOT EXISTS event_rsvps
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          event_id INTEGER NOT NULL,
                          username VARCHAR(191) NOT NULL,
                          response TEXT NOT NULL CHECK(response IN ('going', 'maybe', 'not_going')),
                          responded_at TEXT NOT NULL,
                          note TEXT,
                          FOREIGN KEY (event_id) REFERENCES calendar_events (id) ON DELETE CASCADE,
                          FOREIGN KEY (username) REFERENCES users (username),
                          UNIQUE(event_id, username))''')
            
            # Create indexes for RSVPs
            c.execute("CREATE INDEX IF NOT EXISTS idx_rsvps_event ON event_rsvps(event_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_rsvps_username ON event_rsvps(username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_rsvps_response ON event_rsvps(response)")
            
            # Create event invitations table
            logger.info("Creating event invitations table...")
            c.execute('''CREATE TABLE IF NOT EXISTS event_invitations
                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                          event_id INTEGER NOT NULL,
                          invited_username VARCHAR(191) NOT NULL,
                          invited_by TEXT NOT NULL,
                          invited_at TEXT NOT NULL,
                          viewed TINYINT(1) DEFAULT 0,
                          FOREIGN KEY (event_id) REFERENCES calendar_events (id) ON DELETE CASCADE,
                          FOREIGN KEY (invited_username) REFERENCES users (username),
                          FOREIGN KEY (invited_by) REFERENCES users (username),
                          UNIQUE(event_id, invited_username))''')
            
            # Create indexes for invitations
            c.execute("CREATE INDEX IF NOT EXISTS idx_invitations_event ON event_invitations(event_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_invitations_username ON event_invitations(invited_username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_invitations_viewed ON event_invitations(viewed)")
            
            # Create event notification log table
            logger.info("Creating event_notification_log table...")
            c.execute('''CREATE TABLE IF NOT EXISTS event_notification_log (
                         id INTEGER PRIMARY KEY AUTO_INCREMENT,
                         event_id INTEGER NOT NULL,
                         username VARCHAR(191) NOT NULL,
                         notification_type VARCHAR(50) NOT NULL,
                         sent_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                         UNIQUE KEY unique_event_notif (event_id, username, notification_type),
                         FOREIGN KEY (event_id) REFERENCES calendar_events(id) ON DELETE CASCADE,
                         KEY idx_username (username)
                     )''')
            
            conn.commit()
            logger.info("Database initialization completed successfully")
            
    except Exception as e:
        logger.error(f"Error initializing database: {e}")
        raise

def ensure_indexes():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # ... (keep all your existing CREATE INDEX statements) ...

            # Add an index for the new table
            c.execute("CREATE INDEX IF NOT EXISTS idx_reactions_post_id ON reactions(post_id)")

            # Add index for reply reactions
            c.execute("CREATE INDEX IF NOT EXISTS idx_reply_reactions_reply_id ON reply_reactions(reply_id)")

            # Add indexes for communities
            c.execute("CREATE INDEX IF NOT EXISTS idx_communities_join_code ON communities(join_code)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_communities_creator ON communities(creator_username)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_user_communities_user_id ON user_communities(user_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_user_communities_community_id ON user_communities(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_posts_community_id ON posts(community_id)")
            c.execute("CREATE INDEX IF NOT EXISTS idx_replies_community_id ON replies(community_id)")
            # Groups indexes
            try:
                c.execute("CREATE INDEX IF NOT EXISTS idx_groups_community_id ON groups(community_id)")
            except Exception:
                pass
            try:
                c.execute("CREATE INDEX IF NOT EXISTS idx_group_members_group_id ON group_members(group_id)")
            except Exception:
                pass
            try:
                c.execute("CREATE INDEX IF NOT EXISTS idx_group_members_username ON group_members(username)")
            except Exception:
                pass

            conn.commit()
        logger.info("Database indexes ensured")
    except Exception as e:
        logger.error(f"Error ensuring indexes: {e}")
        abort(500)

def has_community_management_permission(username, community_id):
    """Check if user can manage a community (app admin, owner, or community admin)"""
    return (
        is_app_admin(username)
        or is_community_owner(username, community_id)
        or is_community_admin(username, community_id)
    )


def has_post_delete_permission(username, post_username, community_id):
    """Check if user can delete a post"""
    return (
        is_app_admin(username)
        or username == post_username
        or is_community_owner(username, community_id)
        or is_community_admin(username, community_id)
    )

if not USE_MYSQL:
    init_db()
    ensure_indexes()

# Always ensure missing tables are added for both SQLite and MySQL
# Guard this at import-time so a transient MySQL outage doesn't crash WSGI startup
try:
    add_missing_tables()
except Exception as e:
    logger.error(
        f"Startup DB bootstrap skipped due to error: {e}. "
        "Verify DB_BACKEND and MYSQL_* env vars on the server, or run setup_mysql_env.py."
    )

def ensure_admin_member_of_all():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Get admin id
            c.execute("SELECT id FROM users WHERE username='admin'")
            row = c.fetchone()
            if not row:
                return
            admin_id = row[0]
            # Get all communities
            c.execute("SELECT id FROM communities")
            comms = [r[0] if not isinstance(r, dict) else r['id'] for r in c.fetchall()]
            for cid in comms:
                c.execute("SELECT 1 FROM user_communities WHERE user_id=? AND community_id=?", (admin_id, cid))
                if not c.fetchone():
                    try:
                        add_user_to_community(c, admin_id, int(cid), role=None)
                    except CommunityMembershipLimitError:
                        logger.warning(f"Skipped adding admin to community {cid} due to free-plan member limit.")
            conn.commit()
    except Exception as e:
        logger.error(f"ensure_admin_member_of_all error: {e}")
ensure_admin_member_of_all()
# Initialize database on application startup
try:
    ensure_database_exists()
    logger.info("Database initialized successfully on startup")
except Exception as e:
    logger.error(f"Failed to initialize database on startup: {e}")
    print(f"WARNING: Database initialization failed on startup: {e}")

# Ensure communities table has community_type column and normalize Gym
def ensure_community_type_column():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            has_column = False
            try:
                if USE_MYSQL:
                    c.execute("SHOW COLUMNS FROM communities LIKE 'community_type'")
                    has_column = c.fetchone() is not None
                else:
                    c.execute("PRAGMA table_info(communities)")
                    rows = c.fetchall()
                    for r in rows:
                        col_name = r['name'] if hasattr(r, 'keys') else r[1]
                        if col_name == 'community_type':
                            has_column = True
                            break
            except Exception as e:
                logger.warning(f"Failed to check community_type column: {e}")

            if not has_column:
                try:
                    if USE_MYSQL:
                        c.execute("ALTER TABLE communities ADD COLUMN community_type VARCHAR(255) NULL")
                    else:
                        c.execute("ALTER TABLE communities ADD COLUMN community_type TEXT")
                    logger.info("Added community_type column to communities table")
                except Exception as e:
                    logger.warning(f"Failed to add community_type column (may already exist): {e}")

            # Backfill community_type from type if missing
            try:
                if USE_MYSQL:
                    c.execute("UPDATE communities SET community_type = type WHERE (community_type IS NULL OR community_type = '')")
                else:
                    c.execute("UPDATE communities SET community_type = type WHERE community_type IS NULL")
            except Exception as e:
                logger.warning(f"Failed backfilling community_type from type: {e}")

            # Ensure 'Gym' community row has type/community_type set to 'Gym'
            try:
                if USE_MYSQL:
                    c.execute("UPDATE communities SET type='Gym', community_type='Gym' WHERE LOWER(name)='gym'")
                else:
                    c.execute("UPDATE communities SET type='Gym', community_type='Gym' WHERE LOWER(name)='gym'")
            except Exception as e:
                logger.warning(f"Failed normalizing Gym community type: {e}")

            conn.commit()
    except Exception as e:
        logger.error(f"ensure_community_type_column error: {e}")

ensure_community_type_column()

def ensure_paulo_member_of_gym():
    """Ensure user 'Paulo' is a member of the Gym community."""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()

            # Find Paulo (case-insensitive)
            try:
                if USE_MYSQL:
                    c.execute(f"SELECT id, username FROM users WHERE LOWER(username)=LOWER({ph})", ('Paulo',))
                else:
                    c.execute(f"SELECT id, username FROM users WHERE LOWER(username)=LOWER({ph})", ('Paulo',))
                urow = c.fetchone()
                if not urow:
                    logger.info("Paulo user not found; skipping gym membership ensure")
                    return
                user_id = urow['id'] if hasattr(urow, 'keys') else urow[0]
            except Exception as e:
                logger.warning(f"Failed to find Paulo user: {e}")
                return

            # Find Gym community by name/type/community_type
            gym_id = None
            try:
                if USE_MYSQL:
                    c.execute("""
                        SELECT id FROM communities 
                        WHERE LOWER(name)='gym' OR LOWER(type)='gym' OR LOWER(COALESCE(community_type, ''))='gym'
                        ORDER BY id LIMIT 1
                    """)
                else:
                    c.execute("""
                        SELECT id FROM communities 
                        WHERE LOWER(name)='gym' OR LOWER(type)='gym' OR LOWER(COALESCE(community_type, ''))='gym'
                        ORDER BY id LIMIT 1
                    """)
                crow = c.fetchone()
                if crow:
                    gym_id = crow['id'] if hasattr(crow, 'keys') else crow[0]
            except Exception as e:
                logger.warning(f"Failed to find Gym community: {e}")
                return

            if not gym_id:
                logger.info("Gym community not found; skipping Paulo gym membership ensure")
                return

            # Ensure membership exists
            try:
                c.execute(f"SELECT 1 FROM user_communities WHERE user_id={ph} AND community_id={ph}", (user_id, gym_id))
                exists = c.fetchone() is not None
                if not exists:
                    try:
                        add_user_to_community(c, user_id, int(gym_id), role=None)
                        conn.commit()
                        logger.info(f"Added Paulo (user_id={user_id}) to Gym community (id={gym_id})")
                    except CommunityMembershipLimitError:
                        logger.warning(f"Skipped adding Paulo to Gym community {gym_id} due to free-plan member limit.")
                else:
                    logger.info("Paulo is already a member of the Gym community")
            except Exception as e:
                logger.error(f"Failed to ensure Paulo gym membership: {e}")
    except Exception as e:
        logger.error(f"ensure_paulo_member_of_gym error: {e}")

ensure_paulo_member_of_gym()

# Register the format_date Jinja2 filter
@app.template_filter('format_date')
def format_date(date_str, format_str):
    try:
        # Try multiple date formats
        for date_format in ['%m.%d.%y %H:%M', '%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M']:
            try:
                dt = datetime.strptime(date_str, date_format)
                return dt.strftime(format_str)
            except ValueError:
                continue
        # If none of the formats work, log error and return original
        logger.error(f"Invalid date format: {date_str}")
        return date_str
    except Exception as e:
        logger.error(f"Error formatting date {date_str}: {str(e)}")
        return date_str

def transcribe_audio_file(audio_file_path):
    """
    Transcribe an audio file using OpenAI Whisper API
    Returns the transcribed text or None if transcription fails
    """
    if not OPENAI_AVAILABLE:
        logger.warning("OpenAI package not available - run: pip install openai")
        return None
    
    if not OPENAI_API_KEY:
        logger.warning(f"OpenAI API key not set (length: {len(OPENAI_API_KEY)})")
        logger.warning("Set OPENAI_API_KEY in PythonAnywhere Web tab > Environment variables")
        return None
    
    try:
        logger.info(f"Transcribing audio file: {audio_file_path}")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # Handle both relative paths (uploads/audio/file.webm) and full paths
        if not os.path.isabs(audio_file_path):
            # Remove 'uploads/' prefix if present for consistency
            rel_path = audio_file_path.replace('uploads/', '', 1)
            full_path = os.path.join(app.config['UPLOAD_FOLDER'], rel_path)
        else:
            full_path = audio_file_path
        
        # Open and transcribe the audio file
        with open(full_path, 'rb') as audio_file:
            transcription = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                response_format="text"
            )
        
        logger.info(f"Transcription successful: {transcription[:100]}...")
        return transcription
    except Exception as e:
        logger.error(f"Error transcribing audio: {str(e)}")
        return None

def summarize_text(text, username=None):
    """
    Summarize text using OpenAI GPT
    Returns a concise summary or None if summarization fails
    """
    if not OPENAI_AVAILABLE:
        logger.warning("OpenAI package not available for summarization")
        return None
    
    if not OPENAI_API_KEY:
        logger.warning("OpenAI API key not set for summarization")
        return None
    
    if not text or len(text.strip()) < 20:
        logger.info("Text too short to summarize, returning as-is")
        return text.strip() if text else None
    
    try:
        logger.info(f"Summarizing text of length: {len(text)} for user: {username}")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        # Create a personalized prompt with the username and language instructions
        system_prompt = """You are a helpful assistant that summarizes audio transcriptions.

CRITICAL INSTRUCTION - LANGUAGE MATCHING:
You MUST write the summary in the EXACT SAME LANGUAGE as the transcription text you receive.
- If the transcription is in German ‚Üí summary MUST be in German
- If the transcription is in English ‚Üí summary MUST be in English  
- If the transcription is in French ‚Üí summary MUST be in French
- If the transcription is in Portuguese (ANY variant) ‚Üí summary MUST be in EUROPEAN PORTUGUESE from Portugal, using Portugal vocabulary, grammar, and expressions. NEVER use Brazilian Portuguese.
- If the transcription is in Spanish ‚Üí summary MUST be in Spanish
- If the transcription is in Italian ‚Üí summary MUST be in Italian
- If the transcription is in Mandarin ‚Üí summary MUST be in Mandarin

SPECIAL NOTE FOR PORTUGUESE:
Always use European Portuguese (Portugal) for any Portuguese text. Use words like "telem√≥vel" (not "celular"), "autocarro" (not "√¥nibus"), "comboio" (not "trem"), etc.

DO NOT translate. DO NOT use Portuguese by default for non-Portuguese audio. MATCH THE INPUT LANGUAGE.

Other requirements:
- Provide a concise 1-2 sentence summary of the main points
- Refer to the person by their name if provided, not as 'the speaker' or 'the user'"""
        
        if username:
            user_prompt = f"Summarize this audio transcription from {username}. IMPORTANT: Write your summary in the SAME language as this transcription text:\n\n{text}"
        else:
            user_prompt = f"Summarize this audio transcription. IMPORTANT: Write your summary in the SAME language as this transcription text:\n\n{text}"
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # Fast and cost-effective
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_prompt
                }
            ],
            max_tokens=150,
            temperature=0.5
        )
        
        summary = response.choices[0].message.content.strip()
        logger.info(f"Summary created: {summary}")
        return summary
    except Exception as e:
        logger.error(f"Error summarizing text: {str(e)}")
        return None

def process_audio_for_summary(audio_file_path, username=None):
    """
    Complete pipeline: transcribe audio and generate summary
    Returns summary text or None
    """
    if not audio_file_path:
        return None
    
    logger.info(f"Processing audio for AI summary: {audio_file_path} (user: {username})")
    
    # Step 1: Transcribe audio
    transcription = transcribe_audio_file(audio_file_path)
    if not transcription:
        logger.warning("Transcription failed, no summary generated")
        return None
    
    # Step 2: Summarize transcription with username
    summary = summarize_text(transcription, username=username)
    if not summary:
        logger.warning("Summarization failed, returning transcription")
        # Return first 200 chars of transcription as fallback
        return transcription[:200] + "..." if len(transcription) > 200 else transcription
    
    return summary


# --- Imagine (Runway & A2E) helpers ---

def imagine_style_prompt(style: str, nsfw_allowed: bool = False) -> str:
    safe_suffix = " Keep the result tasteful and safe for work." if not nsfw_allowed else ""
    base_prompts = {
        'normal': "Dynamic video animation: Natural flowing movements, gentle swaying and shifting, smooth body motion, subtle gestures, organic transitions, continuous movement throughout",
        'fun': "Energetic vibrant video: Playful bouncing and dancing, lively body movements, colorful dynamic motion, active gestures, cheerful swaying, continuous fun action",
        'spicy': "Create a dramatic, cinematic animation of this scene with bold lighting and dynamic motion"
    }
    key = style.lower()
    prompt = base_prompts.get(key, base_prompts['normal'])
    if key == 'spicy':
        if nsfw_allowed:
            # Make spicy style much more sexual/explicit when NSFW is allowed
            # Note: When using Kling AI (uncensored), this prompt will be replaced with an explicit one
            # This is only used as fallback if Kling is not available
            prompt = "Create a dramatic, intense video animation with bold camera movements, dynamic lighting, fluid motion, rhythmic pacing, expressive gestures, and heightened dramatic tension. Make it visually striking, emotionally charged, and artistically bold with dynamic and engaging movement."
        else:
            prompt = prompt + safe_suffix
    return prompt


def runway_headers() -> Dict[str, str]:
    if not RUNWAY_API_KEY:
        raise RuntimeError('Runway API key is not configured. Set RUNWAY_API_KEY environment variable.')
    return {
        'Authorization': f'Bearer {RUNWAY_API_KEY}',
        'Content-Type': 'application/json',
        'X-Runway-Version': os.environ.get('RUNWAY_API_VERSION', '2024-11-06')
    }


def runway_create_image_to_video_job(image_bytes: bytes, style_prompt: str) -> str:
    if not image_bytes:
        raise RuntimeError('Missing image bytes for Runway request')

    width = height = None
    mime_type = None
    try:
        kind = imghdr.what(None, h=image_bytes)
        if kind:
            if kind == 'jpeg':
                mime_type = 'image/jpeg'
            elif kind == 'png':
                mime_type = 'image/png'
            elif kind == 'gif':
                mime_type = 'image/gif'
            elif kind == 'webp':
                mime_type = 'image/webp'
    except Exception:
        mime_type = None

    # Compress and resize image before encoding to base64
    processed_image_bytes = image_bytes
    if PIL_AVAILABLE:
        try:
            with Image.open(BytesIO(image_bytes)) as img:
                original_width, original_height = img.size
                if not mime_type and img.format:
                    mime_type = f"image/{img.format.lower()}"
                
                # Runway API base64 limit is 2048 chars total for the data URI
                # We need to be very aggressive - resize to max 512px on longest side
                # and use low quality to ensure base64 string stays well under 1800 chars
                max_dimension = 512
                if original_width > max_dimension or original_height > max_dimension:
                    if original_width > original_height:
                        new_width = max_dimension
                        new_height = int(original_height * (max_dimension / original_width))
                    else:
                        new_height = max_dimension
                        new_width = int(original_width * (max_dimension / original_height))
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                
                # Convert to RGB if necessary (for JPEG compression)
                if img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', img.size, (255, 255, 255))
                    if img.mode == 'P':
                        img = img.convert('RGBA')
                    if img.mode in ('RGBA', 'LA'):
                        background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                    else:
                        background.paste(img)
                    img = background
                elif img.mode != 'RGB':
                    img = img.convert('RGB')
                
                # Aggressively compress to JPEG - start with quality 50
                # Keep trying lower quality until base64 string is under 1700 chars
                output = BytesIO()
                quality = 50
                base64_size = float('inf')
                max_base64_size = 1700  # Leave room for "data:image/jpeg;base64," prefix (~30 chars)
                
                while base64_size > max_base64_size and quality >= 20:
                    output = BytesIO()
                    img.save(output, format='JPEG', quality=quality, optimize=True)
                    processed_image_bytes = output.getvalue()
                    base64_size = len(base64.b64encode(processed_image_bytes).decode('utf-8'))
                    if base64_size > max_base64_size:
                        quality -= 10
                        logger.info(f"[Imagine] Image too large ({base64_size} chars), reducing quality to {quality}")
                
                if base64_size > max_base64_size:
                    # Last resort: resize even smaller
                    logger.warning(f"[Imagine] Image still too large ({base64_size} chars) after quality {quality}, resizing to 400px")
                    max_dimension = 400
                    if img.size[0] > max_dimension or img.size[1] > max_dimension:
                        if img.size[0] > img.size[1]:
                            new_size = (max_dimension, int(img.size[1] * (max_dimension / img.size[0])))
                        else:
                            new_size = (int(img.size[0] * (max_dimension / img.size[1])), max_dimension)
                        img = img.resize(new_size, Image.Resampling.LANCZOS)
                        output = BytesIO()
                        img.save(output, format='JPEG', quality=40, optimize=True)
                        processed_image_bytes = output.getvalue()
                
                mime_type = 'image/jpeg'
                width, height = img.size
        except Exception as e:
            logger.warning(f"[Imagine] Image processing failed: {e}, using original image")
            width = height = None
            processed_image_bytes = image_bytes

    if not mime_type:
        mime_type = 'image/jpeg'

    # Get dimensions for orientation calculation
    if not width or not height:
        if PIL_AVAILABLE:
            try:
                with Image.open(BytesIO(processed_image_bytes)) as img:
                    width, height = img.size
            except Exception:
                width = height = None

    orientation = 'landscape'
    if width and height:
        if abs(width - height) <= max(width, height) * 0.1:
            orientation = 'square'
        elif width > height:
            orientation = 'landscape'
        else:
            orientation = 'portrait'

    model_key = (RUNWAY_MODEL_ID or '').lower()
    legacy_model_map = {
        'gen-2': 'gen3a_turbo',
        'gen2': 'gen3a_turbo'
    }
    normalized_model = legacy_model_map.get(model_key, model_key)
    ratio_options = RUNWAY_MODEL_RATIO_OPTIONS.get(normalized_model)
    default_ratios = {
        'landscape': ['1280:720'],
        'portrait': ['720:1280'],
        'square': ['960:960']
    }

    def select_ratio() -> str:
        if ratio_options and orientation in ratio_options and ratio_options[orientation]:
            return ratio_options[orientation][0]
        if ratio_options:
            for fallback in ('landscape', 'portrait', 'square'):
                values = ratio_options.get(fallback)
                if values:
                    return values[0]
        fallback_values = default_ratios.get(orientation)
        if fallback_values:
            return fallback_values[0]
        return '1280:720'

    ratio = select_ratio()

    prompt_text = style_prompt.strip() if style_prompt else 'Animate this scene as a short cinematic video.'

    # Try to use a URL if PUBLIC_BASE_URL is configured, otherwise use base64
    # Runway accepts either a URL or base64 string (with 2048 char limit for base64)
    prompt_image = None
    
    # First try: Upload temporary image and use URL (if PUBLIC_BASE_URL is set)
    if PUBLIC_BASE_URL:
        try:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S_%f')
            temp_filename = f"temp_imagine_{timestamp}.jpg"
            temp_path = os.path.join(IMAGINE_OUTPUT_DIR, temp_filename)
            os.makedirs(IMAGINE_OUTPUT_DIR, exist_ok=True)
            with open(temp_path, 'wb') as fh:
                fh.write(processed_image_bytes)
            rel_path = f"uploads/{IMAGINE_OUTPUT_SUBDIR}/{temp_filename}"
            temp_url = f"{PUBLIC_BASE_URL}/{rel_path}"
            prompt_image = temp_url
            logger.info(f"[Imagine] Using temporary image URL: {temp_url}")
        except Exception as e:
            logger.warning(f"[Imagine] Failed to create temporary image URL: {e}, falling back to base64")

    # Fallback: Use base64 data URI (must be <=2048 chars total)
    if not prompt_image:
        base64_str = base64.b64encode(processed_image_bytes).decode('utf-8')
        data_uri = f"data:{mime_type};base64,{base64_str}"
        
        # Check if base64 string is still too large
        if len(data_uri) > 2048:
            logger.error(f"[Imagine] Base64 image too large ({len(data_uri)} chars), Runway will reject")
            # Try using just the base64 string without data URI prefix
            if len(base64_str) <= 2048:
                prompt_image = base64_str
                logger.info(f"[Imagine] Using base64 string without data URI prefix ({len(base64_str)} chars)")
            else:
                raise RuntimeError(f"Image too large even after compression ({len(data_uri)} chars for data URI, {len(base64_str)} chars for base64)")
        else:
            prompt_image = data_uri
            logger.info(f"[Imagine] Using base64 data URI ({len(data_uri)} chars)")

    payload: Dict[str, Any] = {
        'model': normalized_model or 'gen4_turbo',
        'promptText': prompt_text,
        'promptImage': prompt_image,
        'ratio': ratio
    }

    model_duration_defaults = {
        'gen4_turbo': 6,
        'gen3a_turbo': 5,
        'veo3.1': 6,
        'veo3.1_fast': 6,
        'veo3': 8
    }
    duration_value = model_duration_defaults.get(normalized_model or 'gen4_turbo')
    if duration_value is not None:
        payload['duration'] = duration_value

    base_url = RUNWAY_API_URL.rstrip('/')
    if base_url.endswith('/v1'):
        base_url = base_url[:-3]
    url = f"{base_url}/v1/image_to_video"
    response = requests.post(url, headers=runway_headers(), json=payload, timeout=(10, 45))
    if response.status_code >= 400:
        raise RuntimeError(f"Runway job creation failed ({response.status_code}): {response.text}")
    data = response.json()
    job_id = data.get('id') or data.get('job_id')
    if not job_id:
        raise RuntimeError('Runway API response missing job id')
    return job_id


def runway_get_job(runway_job_id: str) -> Dict[str, Any]:
    base_url = RUNWAY_API_URL.rstrip('/')
    if base_url.endswith('/v1'):
        base_url = base_url[:-3]
    url = f"{base_url}/v1/tasks/{runway_job_id}"
    response = requests.get(url, headers=runway_headers(), timeout=(10, 20))
    if response.status_code >= 400:
        raise RuntimeError(f"Runway job fetch failed ({response.status_code}): {response.text}")
    return response.json()


def runway_extract_asset_url(job_data: Dict[str, Any]) -> Optional[str]:
    def extract(value: Any) -> Optional[str]:
        if isinstance(value, str):
            return value
        if isinstance(value, dict):
            for url_key in ('url', 'asset_url', 'uri', 'href'):
                url_val = value.get(url_key)
                if url_val:
                    return extract(url_val)
            # Drill into common nested containers
            for nested_key in ('output', 'outputs', 'assets', 'data', 'videos', 'result'):
                if nested_key in value:
                    nested = extract(value[nested_key])
                    if nested:
                        return nested
        if isinstance(value, list) or isinstance(value, tuple):
            for item in value:
                nested = extract(item)
                if nested:
                    return nested
        return None

    for key in ('output', 'outputs', 'assets', 'data', 'result'):
        url = extract(job_data.get(key))
        if url:
            return url

    direct_url = job_data.get('result_url') or job_data.get('video_url')
    if isinstance(direct_url, str):
        return direct_url
    return None


def runway_download_asset(asset_url: str) -> bytes:
    response = requests.get(asset_url, timeout=(10, 60))
    if response.status_code >= 400:
        raise RuntimeError(f"Failed downloading Runway asset ({response.status_code}): {response.text[:200]}")
    return response.content


# --- Kling AI functions for uncensored/spicy videos ---
def kling_headers() -> Dict[str, str]:
    """Generate Kling AI authentication headers"""
    if not KLING_SECRET_KEY:
        raise RuntimeError('Kling API key is not configured. Set Kling_Secret_KEY environment variable.')
    return {
        'Authorization': f'Bearer {KLING_SECRET_KEY}',
        'Accept': 'application/json'
    }


def kling_create_image_to_video_job(image_bytes: bytes, prompt: str, duration: int = 5) -> str:
    """Create image-to-video job using Kling AI (for spicy content)"""
    if not KLING_SECRET_KEY:
        raise RuntimeError('Kling API key not configured. Set Kling_Secret_KEY environment variable.')
    if not image_bytes:
        raise RuntimeError('Missing image bytes for Kling request')
    
    headers = kling_headers()
    files = {'image': ('input.jpg', image_bytes, 'image/jpeg')}
    data = {
        'prompt': prompt,
        'duration': str(duration),
        'resolution': '1080p'
    }
    
    # Create job
    url = f'{KLING_API_URL}/video/generate'
    try:
        logger.info(f'[Imagine] Creating Kling AI job at {url}')
        logger.info(f'[Imagine] PROMPT BEING SENT: "{prompt}"')
        logger.info(f'[Imagine] Data payload: {data}')
        resp = requests.post(url, headers=headers, files=files, data=data, timeout=60)
        logger.info(f'[Imagine] Response status: {resp.status_code}')
        logger.info(f'[Imagine] Response body: {resp.text[:500]}')
        resp.raise_for_status()
        task_id = resp.json()['task_id']
        logger.info(f'[Imagine] Kling job created: {task_id}')
        return task_id
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f'Kling job creation failed: {str(e)}')
    except KeyError:
        raise RuntimeError(f'Kling response missing task_id: {resp.text[:200]}')


def kling_get_job_status(task_id: str) -> dict:
    """Poll Kling AI job status"""
    if not KLING_SECRET_KEY:
        raise RuntimeError('Kling API key not configured')
    
    headers = kling_headers()
    url = f'{KLING_API_URL}/video/{task_id}'
    
    try:
        resp = requests.get(url, headers=headers, timeout=30)
        resp.raise_for_status()
        return resp.json()
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f'Kling status check failed: {str(e)}')


def kling_download_video(video_url: str) -> bytes:
    """Download video from Kling AI"""
    try:
        response = requests.get(video_url, timeout=(10, 120))
        response.raise_for_status()
        return response.content
    except requests.exceptions.RequestException as e:
        raise RuntimeError(f'Failed downloading Kling video: {str(e)}')


def fetch_imagine_job(job_id: int) -> Optional[Dict[str, Any]]:
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT * FROM imagine_jobs WHERE id={ph}", (job_id,))
            row = c.fetchone()
            if not row:
                return None
            if hasattr(row, 'keys'):
                return dict(row)
            # SQLite tuple fallback
            columns = [col[0] for col in c.description]
            return dict(zip(columns, row))
    except Exception as e:
        logger.error(f"Failed fetching imagine job {job_id}: {e}")
        return None


def update_imagine_job(job_id: int, **fields):
    if not fields:
        return
    fields['updated_at'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    assignments = []
    values = []
    for key, value in fields.items():
        assignments.append(f"{key}={get_sql_placeholder()}")
        values.append(value)
    values.append(job_id)
    set_clause = ', '.join(assignments)
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"UPDATE imagine_jobs SET {set_clause} WHERE id={ph}", tuple(values))
            if not USE_MYSQL:
                conn.commit()
    except Exception as e:
        logger.error(f"Failed updating imagine job {job_id}: {e}")


def is_imagine_spicy_allowed(community_id: Optional[int]) -> bool:
    if not community_id:
        return False
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            column = 'allow_nsfw_imagine'
            ph = get_sql_placeholder()
            try:
                c.execute(f"SELECT {column} FROM communities WHERE id={ph}", (community_id,))
            except Exception:
                return False
            row = c.fetchone()
            if not row:
                return False
            value = row[column] if hasattr(row, 'keys') else row[0]
            return bool(value)
    except Exception as e:
        logger.warning(f"Failed checking NSFW imagine setting for community {community_id}: {e}")
        return False


def create_imagine_reply(job_row: Dict[str, Any], video_path: str, style: str) -> Optional[int]:
    username = job_row.get('created_by')
    target_type = (job_row.get('target_type') or '').lower()
    target_id = job_row.get('target_id')
    community_id = job_row.get('community_id')
    if not username or target_id is None:
        return None
    timestamp_db = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    content = f"AI Imagine ({style.title()})"
    post_id = None
    parent_reply_id = None
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            if target_type == 'reply':
                ph = get_sql_placeholder()
                c.execute(f"SELECT post_id, parent_reply_id, community_id FROM replies WHERE id={ph}", (target_id,))
                src = c.fetchone()
                if not src:
                    return None
                if hasattr(src, 'keys'):
                    post_id = src.get('post_id')
                    parent_reply_id = target_id
                    community_id = community_id or src.get('community_id')
                else:
                    post_id = src[0]
                    parent_reply_id = target_id
                    community_id = community_id or src[2]
            else:
                post_id = target_id
            if post_id is None:
                return None
            if community_id is None:
                ph = get_sql_placeholder()
                c.execute(f"SELECT community_id FROM posts WHERE id={ph}", (post_id,))
                post_row = c.fetchone()
                if post_row:
                    community_id = post_row['community_id'] if hasattr(post_row, 'keys') else post_row[0]
            placeholders = get_sql_placeholder()
            sql = (
                "INSERT INTO replies (post_id, username, content, image_path, audio_path, timestamp, community_id, parent_reply_id, video_path) "
                f"VALUES ({placeholders}, {placeholders}, {placeholders}, {placeholders}, {placeholders}, {placeholders}, {placeholders}, {placeholders}, {placeholders})"
            )
            params = (
                post_id,
                username,
                content,
                None,
                None,
                timestamp_db,
                community_id,
                parent_reply_id,
                video_path
            )
            c.execute(sql, params)
            reply_id = c.lastrowid
            if not USE_MYSQL:
                conn.commit()
        try:
            notify_post_reply_recipients(post_id=post_id, from_user=username, community_id=community_id, parent_reply_id=parent_reply_id)
        except Exception as notify_err:
            logger.warning(f"Imagine reply notification error: {notify_err}")
        return reply_id
    except Exception as e:
        logger.error(f"Failed creating imagine reply for job {job_row.get('id')}: {e}")
        return None


def process_imagine_job(job_id: int):
    logger.info(f"[Imagine] Starting job {job_id}")
    job = fetch_imagine_job(job_id)
    if not job:
        logger.error(f"[Imagine] Job {job_id} not found")
        return
    try:
        update_imagine_job(job_id, status=IMAGINE_STATUS_PROCESSING)
        source_path = job.get('source_path')
        image_bytes = load_upload_bytes(source_path)
        if not image_bytes:
            update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error='Source image missing or unreadable')
            return
        style = (job.get('style') or 'normal').lower()
        allow_nsfw = is_imagine_spicy_allowed(job.get('community_id'))
        style_prompt = imagine_style_prompt(style, allow_nsfw)
        
        # Use Kling AI for spicy videos when NSFW is allowed (uncensored)
        # Otherwise use Runway
        use_kling = (style == 'spicy' and allow_nsfw and KLING_SECRET_KEY)
        
        if use_kling:
            logger.info(f"[Imagine] Using Kling AI for spicy video (job {job_id})")
            # Compress image aggressively before sending to Kling to avoid 413 errors
            # Kling API server has limits, so we need to keep images small (<2MB ideally)
            kling_image_bytes = image_bytes
            original_size = len(image_bytes)
            if PIL_AVAILABLE:
                try:
                    with Image.open(BytesIO(image_bytes)) as img:
                        # Aggressively resize to max 1280px on longest side to keep file size small
                        max_dimension = 1280
                        if img.size[0] > max_dimension or img.size[1] > max_dimension:
                            if img.size[0] > img.size[1]:
                                new_size = (max_dimension, int(img.size[1] * (max_dimension / img.size[0])))
                            else:
                                new_size = (int(img.size[0] * (max_dimension / img.size[1])), max_dimension)
                            img = img.resize(new_size, Image.Resampling.LANCZOS)
                        
                        # Convert to RGB if necessary
                        if img.mode not in ('RGB', 'L'):
                            if img.mode in ('RGBA', 'LA', 'P'):
                                background = Image.new('RGB', img.size, (255, 255, 255))
                                if img.mode == 'P':
                                    img = img.convert('RGBA')
                                if img.mode in ('RGBA', 'LA'):
                                    background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                                else:
                                    background.paste(img)
                                img = background
                            else:
                                img = img.convert('RGB')
                        
                        # Compress to JPEG with lower quality (70) to keep file size under 2MB
                        quality = 70
                        output = BytesIO()
                        img.save(output, format='JPEG', quality=quality, optimize=True)
                        kling_image_bytes = output.getvalue()
                        
                        # If still too large (>2MB), reduce quality further
                        max_size = 2 * 1024 * 1024  # 2MB
                        if len(kling_image_bytes) > max_size:
                            quality = 50
                            output = BytesIO()
                            img.save(output, format='JPEG', quality=quality, optimize=True)
                            kling_image_bytes = output.getvalue()
                            
                            # If still too large, resize even smaller
                            if len(kling_image_bytes) > max_size:
                                logger.warning(f"[Imagine] Image still too large ({len(kling_image_bytes)} bytes), resizing to 1024px")
                                max_dimension = 1024
                                if img.size[0] > max_dimension or img.size[1] > max_dimension:
                                    if img.size[0] > img.size[1]:
                                        new_size = (max_dimension, int(img.size[1] * (max_dimension / img.size[0])))
                                    else:
                                        new_size = (int(img.size[0] * (max_dimension / img.size[1])), max_dimension)
                                    img = img.resize(new_size, Image.Resampling.LANCZOS)
                                    output = BytesIO()
                                    img.save(output, format='JPEG', quality=40, optimize=True)
                                    kling_image_bytes = output.getvalue()
                        
                        logger.info(f"[Imagine] Compressed image for Kling: {original_size} bytes -> {len(kling_image_bytes)} bytes")
                except Exception as e:
                    logger.error(f"[Imagine] Failed to compress image for Kling: {e}, error will occur", exc_info=True)
                    # Don't use original - it will fail
                    raise RuntimeError(f"Failed to compress image for Kling: {e}. Original size: {original_size} bytes")
            
            # Create Kling job with maximum movement-focused explicit prompt
            kling_prompt = "Erotic video with extreme motion: Vigorous writhing, intense grinding and thrusting, energetic sexy dancing, rapid hip swaying, active stroking, passionate movements, moaning, wet skin, climax, high motion."
            kling_task_id = kling_create_image_to_video_job(
                kling_image_bytes,
                kling_prompt,
                duration=5
            )
            update_imagine_job(job_id, runway_job_id=kling_task_id)  # Reuse runway_job_id field
            poll_interval = max(2, KLING_POLL_INTERVAL_SECONDS)
            max_wait = KLING_TIMEOUT_SECONDS
            start_time = time.time()
            last_error = None
            while time.time() - start_time < max_wait:
                time.sleep(max(poll_interval, 2))
                try:
                    kling_job = kling_get_job_status(kling_task_id)
                except Exception as e:
                    last_error = str(e)
                    continue
                status = str(kling_job.get('status') or kling_job.get('state') or '').lower()
                progress = kling_job.get('progress', 0)
                logger.info(f"[Imagine] Kling job {kling_task_id} status: {status}, progress: {progress}%")
                if status in ('succeeded', 'completed', 'complete', 'success', 'done'):
                    video_url = kling_job.get('video_url')
                    if not video_url:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error='Kling job completed without video URL')
                        return
                    video_bytes = kling_download_video(video_url)
                    if not video_bytes:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error='Failed downloading generated video')
                        return
                    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
                    filename = f"job{job_id}_{timestamp}.mp4"
                    abs_path = os.path.join(IMAGINE_OUTPUT_DIR, filename)
                    try:
                        with open(abs_path, 'wb') as fh:
                            fh.write(video_bytes)
                    except Exception as write_err:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=f'Failed writing video: {write_err}')
                        return
                    rel_path = f"uploads/{IMAGINE_OUTPUT_SUBDIR}/{filename}"
                    if job.get('is_owner'):
                        update_imagine_job(job_id, status=IMAGINE_STATUS_AWAITING_OWNER, result_path=rel_path)
                    else:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_COMPLETED, result_path=rel_path, action='carousel_only')
                    logger.info(f"[Imagine] Kling job {job_id} completed")
                    return
                if status in ('failed', 'error', 'cancelled'):
                    error_message = kling_job.get('error') or kling_job.get('message') or json.dumps(kling_job)[:200]
                    update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=error_message)
                    return
            update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=last_error or 'Timed out waiting for Kling job')
        else:
            # Use Runway for normal/fun styles or when Kling is not available
            logger.info(f"[Imagine] Using Runway for job {job_id}")
            runway_job_id = runway_create_image_to_video_job(image_bytes, style_prompt)
            update_imagine_job(job_id, runway_job_id=runway_job_id)
            poll_interval = int(os.environ.get('RUNWAY_POLL_INTERVAL', '5'))
            max_wait = int(os.environ.get('RUNWAY_MAX_WAIT_SECONDS', '240'))
            start_time = time.time()
            last_error = None
            while time.time() - start_time < max_wait:
                time.sleep(max(poll_interval, 2))
                try:
                    runway_job = runway_get_job(runway_job_id)
                except Exception as e:
                    last_error = str(e)
                    continue
                status = str(runway_job.get('status') or runway_job.get('state') or '').lower()
                if status in ('succeeded', 'completed', 'complete', 'success'):
                    asset_url = runway_extract_asset_url(runway_job)
                    if not asset_url:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error='Runway job completed without asset URL')
                        return
                    video_bytes = runway_download_asset(asset_url)
                    if not video_bytes:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error='Failed downloading generated video')
                        return
                    timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
                    filename = f"job{job_id}_{timestamp}.mp4"
                    abs_path = os.path.join(IMAGINE_OUTPUT_DIR, filename)
                    try:
                        with open(abs_path, 'wb') as fh:
                            fh.write(video_bytes)
                    except Exception as write_err:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=f'Failed writing video: {write_err}')
                        return
                    rel_path = f"uploads/{IMAGINE_OUTPUT_SUBDIR}/{filename}"
                    if job.get('is_owner'):
                        update_imagine_job(job_id, status=IMAGINE_STATUS_AWAITING_OWNER, result_path=rel_path)
                    else:
                        update_imagine_job(job_id, status=IMAGINE_STATUS_COMPLETED, result_path=rel_path, action='carousel_only')
                    logger.info(f"[Imagine] Runway job {job_id} completed")
                    return
                if status in ('failed', 'error', 'cancelled'):
                    error_message = runway_job.get('error') or runway_job.get('message') or json.dumps(runway_job)[:200]
                    update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=error_message)
                    return
            update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=last_error or 'Timed out waiting for Runway job')
    except Exception as e:
        logger.error(f"[Imagine] Unhandled exception for job {job_id}: {e}", exc_info=True)
        update_imagine_job(job_id, status=IMAGINE_STATUS_ERROR, error=str(e))


def schedule_imagine_job(job_id: int):
    try:
        imagine_executor.submit(process_imagine_job, job_id)
    except Exception as e:
        logger.error(f"Failed to schedule imagine job {job_id}: {e}")

# --- CSRF helpers ---
def get_csrf_token():
    """Temporarily disabled CSRF token generation"""
    return "disabled"

def validate_csrf():
    """Temporarily disabled CSRF validation"""
    return True




# Utility functions
def check_api_limit(username):
    today = datetime.now().strftime('%Y-%m-%d')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT count FROM api_usage WHERE username=? AND date=?", (username, today))
            result = c.fetchone()
            count = result['count'] if result else 0
            if count >= DAILY_API_LIMIT:
                return False
            if count == 0:
                c.execute("INSERT INTO api_usage (username, date, count) VALUES (?, ?, 1)", (username, today))
            else:
                c.execute("UPDATE api_usage SET count=? WHERE username=? AND date=?", (count + 1, username, today))
            conn.commit()
            return True
    except Exception as e:
        logger.error(f"Error checking API limit for {username}: {str(e)}")
        abort(500)

# Routes
# Public-facing index/welcome routes live in backend.blueprints.public
# Authentication flows (login/signup/logout) are registered via backend.blueprints.auth
# Onboarding flows (React shell, debug helpers) live in backend.blueprints.onboarding
# Notification pages/APIs and cron endpoints live in backend.blueprints.notifications

@app.route('/admin_profile')
@login_required
def admin_profile():
    """Admin profile page - only accessible to admin user"""
    username = session.get('username')
    
    # Check if user is admin
    if username != 'admin':
        abort(403)  # Forbidden - only admin can access this page
    # Redirect to React version to ensure consistent UI and scroll behavior
    return redirect(url_for('admin_profile_react'))

@app.route('/logout')
def logout():
    # Explicitly clear and mark session non-permanent
    session.clear()
    session.permanent = False
    # Clear remember token cookie
    from flask import make_response
    resp = make_response(redirect(url_for('public.index')))
    resp.set_cookie('remember_token', '', max_age=0, path='/', domain=app.config.get('SESSION_COOKIE_DOMAIN') or None)
    return resp
# Removed duplicate /login_password route - using auth blueprint version in backend/blueprints/auth.py instead

@app.route('/login_back', methods=['GET'])
def login_back():
    """Clear any staged login state and return to username entry page."""
    try:
        session.pop('pending_username', None)
    except Exception:
        pass
    return redirect(url_for('auth.login'))

@app.route('/dashboard')
@login_required
def dashboard():
    # All users go to premium dashboard (React app)
    return redirect('/premium_dashboard')

@app.route('/premium_dashboard')
@login_required
def premium_dashboard():
    """Serve React dashboard for all users"""
    try:
        # Server-side onboarding gate: check if user has communities
        try:
            username = session.get('username')
            if username:
                with get_db_connection() as conn:
                    c = conn.cursor()
                    ph = get_sql_placeholder()
                    def _count(q, args):
                        try:
                            c.execute(q, args)
                            r = c.fetchone()
                            return (r['cnt'] if hasattr(r,'keys') else (r[0] if r else 0)) or 0
                        except Exception:
                            return 0
                    membership_cnt = _count(f"""
                        SELECT COUNT(*) as cnt FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE u.username = {ph}
                    """, (username,))
                    created_cnt = _count(f"SELECT COUNT(*) as cnt FROM communities WHERE creator_username = {ph}", (username,))
                    admin_cnt = _count(f"SELECT COUNT(*) as cnt FROM community_admins WHERE username = {ph}", (username,))
                    total_cnt = membership_cnt + created_cnt + admin_cnt
                    if total_cnt == 0:
                        try:
                            session['show_join_community_prompt'] = True
                        except Exception:
                            pass
        except Exception:
            pass

        # Always serve React SPA
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        index_path = os.path.join(dist_dir, 'index.html')
        if os.path.exists(index_path):
            resp = send_from_directory(dist_dir, 'index.html')
            try:
                resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                resp.headers['Pragma'] = 'no-cache'
                resp.headers['Expires'] = '0'
            except Exception:
                pass
            return resp
        return ("React build not found. Please run 'npm run build' in client directory.", 500)
    except Exception as e:
        logger.error(f"Error in premium_dashboard: {str(e)}")
        return ("Internal Server Error", 500)

@app.route('/api/client_log', methods=['POST'])
def api_client_log():
    try:
        data = request.get_json(silent=True) or {}
        level = (data.get('level') or 'error').lower()
        prefix = 'CLIENT'
        msg = json.dumps(data)
        if level == 'warn':
            logger.warning(f"{prefix}: {msg}")
        else:
            logger.error(f"{prefix}: {msg}")
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error in api_client_log: {e}")
        return jsonify({'success': False}), 500

@app.route('/api/check_pending_login', methods=['GET'])
def api_check_pending_login():
    """Check if there's a pending username in session (for two-step login). No auth required."""
    try:
        pending_username = session.get('pending_username')
        cookie_names = list(request.cookies.keys())
        session_cookie = request.cookies.get('cpoint_session', 'NONE')
        # Debug logging - log everything!
        logger.info(f"check_pending_login: pending_username={pending_username}, session_keys={list(session.keys())}, cookie_names={cookie_names}, session_cookie_present={session_cookie != 'NONE'}")
        if pending_username:
            return jsonify({'success': True, 'pending_username': pending_username})
        return jsonify({
            'success': False, 
            'pending_username': None, 
            'debug': {
                'session_keys': list(session.keys()),
                'has_session_cookie': session_cookie != 'NONE',
                'cookie_names': cookie_names
            }
        })
    except Exception as e:
        logger.error(f"Error in api_check_pending_login: {e}")
        return jsonify({'success': False, 'pending_username': None, 'error': str(e)})

@app.route('/api/debug/login_test', methods=['POST'])
def api_debug_login_test():
    """
    Debug endpoint to test login credentials without creating a session.
    For diagnosing iOS login issues.
    
    POST body: {"username": "...", "password": "..."}
    """
    try:
        data = request.get_json() or {}
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        if not username or not password:
            return jsonify({'success': False, 'error': 'Username and password required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT password FROM users WHERE username=?", (username,))
            row = c.fetchone()
            
            if not row:
                return jsonify({
                    'success': False, 
                    'error': 'User not found',
                    'debug': {
                        'username_searched': username,
                        'username_length': len(username),
                        'username_repr': repr(username),
                    }
                })
            
            stored_password = row['password'] if hasattr(row, 'keys') else row[0]
            
            # Determine password type
            password_type = 'unknown'
            if stored_password is None:
                password_type = 'null'
                password_correct = False
            elif stored_password.startswith('$') or stored_password.startswith('scrypt:') or stored_password.startswith('pbkdf2:'):
                password_type = 'hashed'
                password_correct = check_password_hash(stored_password, password)
            else:
                password_type = 'plain'
                password_correct = stored_password == password
            
            return jsonify({
                'success': True,
                'password_correct': password_correct,
                'debug': {
                    'username': username,
                    'password_type': password_type,
                    'stored_password_preview': stored_password[:20] + '...' if stored_password and len(stored_password) > 20 else stored_password,
                    'input_password_length': len(password),
                    'user_agent': request.headers.get('User-Agent', 'unknown'),
                }
            })
    except Exception as e:
        logger.error(f"Debug login test error: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})
# React hashed assets are served by web server static mapping (/assets -> client/dist/assets)
@app.route('/api/community_group_feed/<int:parent_id>')
@login_required
def api_community_group_feed(parent_id: int):
    """Return recent posts (last 48h) for a parent community and all its child communities.
    
    OPTIMIZED VERSION: Uses batch queries instead of N+1 pattern.
    """
    from datetime import datetime, timedelta
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            
            # 1. Get all community IDs (parent + all descendants)
            descendant_ids = get_descendant_community_ids(c, parent_id) or []
            if not descendant_ids:
                return jsonify({'success': True, 'posts': [], 'username': username})

            placeholders = ','.join([ph] * len(descendant_ids))
            c.execute(
                f"SELECT id, name FROM communities WHERE id IN ({placeholders})",
                tuple(descendant_ids),
            )
            name_rows = c.fetchall()

            if not name_rows:
                return jsonify({'success': True, 'posts': [], 'username': username})

            name_map = {}
            for r in name_rows:
                cid = r['id'] if hasattr(r, 'keys') else r[0]
                cname = r['name'] if hasattr(r, 'keys') else r[1]
                name_map[cid] = cname

            if parent_id not in name_map:
                return jsonify({'success': True, 'posts': [], 'username': username})

            community_ids = [cid for cid in descendant_ids if cid in name_map]
            
            if not community_ids:
                return jsonify({'success': True, 'posts': [], 'username': username})
            
            placeholders = ','.join([ph for _ in community_ids])
            
            # 2. Fetch posts from last 48 hours with membership check - FILTER IN SQL
            # Use UTC for cutoff since posts are stored with datetime.utcnow()
            cutoff = datetime.utcnow() - timedelta(hours=48)
            cutoff_str = cutoff.strftime('%Y-%m-%d %H:%M:%S')
            
            c.execute(f"""
                SELECT DISTINCT p.id, p.username, p.content, p.community_id, 
                       p.created_at, p.timestamp, p.image_path, p.video_path,
                       p.audio_path, p.audio_summary
                FROM posts p
                JOIN user_communities uc ON uc.community_id = p.community_id
                JOIN users u ON u.id = uc.user_id
                WHERE p.community_id IN ({placeholders})
                  AND u.username = {ph}
                  AND (p.created_at >= {ph} OR p.timestamp >= {ph} OR p.created_at IS NULL)
                ORDER BY COALESCE(p.created_at, p.timestamp) DESC
                LIMIT 200
            """, tuple(community_ids) + (username, cutoff_str, cutoff_str))
            
            rows = c.fetchall()
            
            if not rows:
                return jsonify({'success': True, 'posts': [], 'username': username})
            
            # Extract post IDs for batch queries
            post_ids = []
            post_usernames = set()
            for row in rows:
                pid = row['id'] if hasattr(row, 'keys') else row[0]
                uname = row['username'] if hasattr(row, 'keys') else row[1]
                post_ids.append(pid)
                if uname:
                    post_usernames.add(uname)
            
            post_placeholders = ','.join([ph for _ in post_ids])
            
            # 3. Batch fetch all reactions for these posts
            reaction_map = {}  # {post_id: {reaction_type: count}}
            user_reaction_map = {}  # {post_id: reaction_type}
            
            if post_ids:
                # Get reaction counts grouped by post
                c.execute(f"""
                    SELECT post_id, reaction_type, COUNT(*) as count
                    FROM reactions
                    WHERE post_id IN ({post_placeholders})
                    GROUP BY post_id, reaction_type
                """, tuple(post_ids))
                for r in c.fetchall():
                    pid = r['post_id'] if hasattr(r, 'keys') else r[0]
                    rtype = r['reaction_type'] if hasattr(r, 'keys') else r[1]
                    cnt = r['count'] if hasattr(r, 'keys') else r[2]
                    if pid not in reaction_map:
                        reaction_map[pid] = {}
                    reaction_map[pid][rtype] = cnt
                
                # Get current user's reactions
                c.execute(f"""
                    SELECT post_id, reaction_type
                    FROM reactions
                    WHERE post_id IN ({post_placeholders}) AND username = {ph}
                """, tuple(post_ids) + (username,))
                for r in c.fetchall():
                    pid = r['post_id'] if hasattr(r, 'keys') else r[0]
                    rtype = r['reaction_type'] if hasattr(r, 'keys') else r[1]
                    user_reaction_map[pid] = rtype
            
            # 4. Batch fetch reply counts
            reply_count_map = {}  # {post_id: count}
            if post_ids:
                c.execute(f"""
                    SELECT post_id, COUNT(*) as cnt
                    FROM replies
                    WHERE post_id IN ({post_placeholders})
                    GROUP BY post_id
                """, tuple(post_ids))
                for r in c.fetchall():
                    pid = r['post_id'] if hasattr(r, 'keys') else r[0]
                    cnt = r['cnt'] if hasattr(r, 'keys') else r[1]
                    reply_count_map[pid] = cnt
            
            # 5. Batch fetch profile pictures
            pp_map = {}  # {username: profile_picture}
            if post_usernames:
                user_placeholders = ','.join([ph for _ in post_usernames])
                c.execute(f"""
                    SELECT username, profile_picture
                    FROM user_profiles
                    WHERE username IN ({user_placeholders})
                """, tuple(post_usernames))
                for r in c.fetchall():
                    uname = r['username'] if hasattr(r, 'keys') else r[0]
                    pp = r['profile_picture'] if hasattr(r, 'keys') else r[1]
                    pp_map[uname] = pp
            
            # 6. Batch fetch polls for these posts
            poll_map = {}  # {post_id: poll_obj}
            if post_ids:
                c.execute(f"""
                    SELECT * FROM polls
                    WHERE post_id IN ({post_placeholders}) AND is_active = 1
                """, tuple(post_ids))
                poll_rows = c.fetchall()
                
                poll_ids = []
                poll_post_map = {}  # {poll_id: post_id}
                for pr in poll_rows:
                    poll_id = pr['id'] if hasattr(pr, 'keys') else pr[0]
                    post_id = pr['post_id'] if hasattr(pr, 'keys') else pr[1]
                    poll_ids.append(poll_id)
                    poll_post_map[poll_id] = post_id
                    poll_map[post_id] = dict(pr) if hasattr(pr, 'keys') else {
                        'id': poll_id,
                        'post_id': post_id,
                        'question': pr[2] if len(pr) > 2 else '',
                        'is_active': pr[3] if len(pr) > 3 else 1,
                        'single_vote': pr[4] if len(pr) > 4 else 1,
                        'expires_at': pr[5] if len(pr) > 5 else None,
                    }
                    poll_map[post_id]['options'] = []
                
                if poll_ids:
                    poll_placeholders = ','.join([ph for _ in poll_ids])
                    
                    # Get all poll options
                    c.execute(f"""
                        SELECT * FROM poll_options
                        WHERE poll_id IN ({poll_placeholders})
                        ORDER BY poll_id, id
                    """, tuple(poll_ids))
                    option_rows = c.fetchall()
                    
                    option_ids = []
                    option_poll_map = {}  # {option_id: poll_id}
                    for opt in option_rows:
                        opt_id = opt['id'] if hasattr(opt, 'keys') else opt[0]
                        poll_id = opt['poll_id'] if hasattr(opt, 'keys') else opt[1]
                        option_ids.append(opt_id)
                        option_poll_map[opt_id] = poll_id
                        post_id = poll_post_map.get(poll_id)
                        if post_id and post_id in poll_map:
                            opt_dict = dict(opt) if hasattr(opt, 'keys') else {
                                'id': opt_id,
                                'poll_id': poll_id,
                                'option_text': opt[2] if len(opt) > 2 else '',
                            }
                            opt_dict['text'] = opt_dict.get('option_text', '')
                            opt_dict['votes'] = 0
                            opt_dict['user_voted'] = False
                            poll_map[post_id]['options'].append(opt_dict)
                    
                    if option_ids:
                        opt_placeholders = ','.join([ph for _ in option_ids])
                        
                        # Get vote counts per option
                        c.execute(f"""
                            SELECT option_id, COUNT(*) as count
                            FROM poll_votes
                            WHERE option_id IN ({opt_placeholders})
                            GROUP BY option_id
                        """, tuple(option_ids))
                        for vc in c.fetchall():
                            opt_id = vc['option_id'] if hasattr(vc, 'keys') else vc[0]
                            cnt = vc['count'] if hasattr(vc, 'keys') else vc[1]
                            poll_id = option_poll_map.get(opt_id)
                            post_id = poll_post_map.get(poll_id) if poll_id else None
                            if post_id and post_id in poll_map:
                                for opt in poll_map[post_id]['options']:
                                    if opt['id'] == opt_id:
                                        opt['votes'] = cnt
                                        break
                        
                        # Get user's votes
                        c.execute(f"""
                            SELECT option_id
                            FROM poll_votes
                            WHERE option_id IN ({opt_placeholders}) AND username = {ph}
                        """, tuple(option_ids) + (username,))
                        user_voted_options = set()
                        for uv in c.fetchall():
                            opt_id = uv['option_id'] if hasattr(uv, 'keys') else uv[0]
                            user_voted_options.add(opt_id)
                        
                        # Mark user's votes and calculate totals
                        for post_id, poll in poll_map.items():
                            total = 0
                            user_vote = None
                            for opt in poll.get('options', []):
                                total += opt.get('votes', 0)
                                if opt['id'] in user_voted_options:
                                    opt['user_voted'] = True
                                    user_vote = opt['id']
                            poll['total_votes'] = total
                            poll['user_vote'] = user_vote
            
            # 7. Build final posts list
            posts = []
            for row in rows:
                if hasattr(row, 'keys'):
                    pid = row['id']
                    uname = row.get('username')
                    cid = row.get('community_id')
                    post_obj = {
                        'id': pid,
                        'username': uname,
                        'content': row.get('content'),
                        'community_id': cid,
                        'community_name': name_map.get(cid),
                        'created_at': row.get('created_at') or row.get('timestamp'),
                        'image_path': row.get('image_path'),
                        'video_path': row.get('video_path'),
                        'audio_path': row.get('audio_path'),
                        'audio_summary': row.get('audio_summary'),
                        'profile_picture': pp_map.get(uname),
                        'reactions': reaction_map.get(pid, {}),
                        'user_reaction': user_reaction_map.get(pid),
                        'replies_count': reply_count_map.get(pid, 0),
                        'poll': poll_map.get(pid)
                    }
                else:
                    pid, uname, content, cid, created_at, timestamp, image_path, video_path, audio_path, audio_summary = row[:10]
                    post_obj = {
                        'id': pid,
                        'username': uname,
                        'content': content,
                        'community_id': cid,
                        'community_name': name_map.get(cid),
                        'created_at': created_at or timestamp,
                        'image_path': image_path,
                        'video_path': video_path,
                        'audio_path': audio_path,
                        'audio_summary': audio_summary,
                        'profile_picture': pp_map.get(uname),
                        'reactions': reaction_map.get(pid, {}),
                        'user_reaction': user_reaction_map.get(pid),
                        'replies_count': reply_count_map.get(pid, 0),
                        'poll': poll_map.get(pid)
                    }
                posts.append(post_obj)
            
            logger.info(f"Community group feed (optimized): parent_id={parent_id}, returning {len(posts)} posts")
            return jsonify({'success': True, 'posts': posts, 'username': username})
            
    except Exception as e:
        logger.error(f"Error in community_group_feed for parent {parent_id}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/community_photos')
@login_required
def api_community_photos():
    """Get all photos from a community feed, grouped by date."""
    username = session.get('username')
    community_id = request.args.get('community_id', type=int)
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Check if user is a member of the community
            if username != 'admin':
                c.execute("""
                    SELECT 1 FROM user_communities
                    JOIN users u ON user_communities.user_id = u.id
                    WHERE u.username = ? AND user_communities.community_id = ?
                    LIMIT 1
                """, (username, community_id))
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'Forbidden'}), 403

            # Get all posts and replies with images from this community
            c.execute("""
                SELECT
                    p.id as post_id,
                    NULL as reply_id,
                    p.username,
                    p.content,
                    p.image_path,
                    p.timestamp,
                    up.profile_picture
                FROM posts p
                LEFT JOIN user_profiles up ON p.username = up.username
                WHERE p.community_id = ? AND p.image_path IS NOT NULL AND p.image_path != ''

                UNION ALL

                SELECT
                    p.id as post_id,
                    r.id as reply_id,
                    r.username,
                    r.content,
                    r.image_path,
                    r.timestamp,
                    up.profile_picture
                FROM posts p
                JOIN replies r ON p.id = r.post_id
                LEFT JOIN user_profiles up ON r.username = up.username
                WHERE p.community_id = ? AND r.image_path IS NOT NULL AND r.image_path != ''
                ORDER BY timestamp DESC
            """, (community_id, community_id))

            posts_raw = c.fetchall()
            posts = [dict(row) for row in posts_raw]

            # Format posts as photos
            photos = []
            for post in posts:
                # Handle different database cursor types
                if hasattr(post, 'keys'):
                    post_id = post['post_id']
                    username_val = post['username']
                    content = post['content'] or ''
                    image_path = post['image_path']
                    timestamp = post['timestamp'] or ''
                    profile_picture = post['profile_picture']
                else:
                    post_id = post[0]
                    username_val = post[1]
                    content = post[2] or ''
                    image_path = post[3]
                    timestamp = post[4] or ''
                    profile_picture = post[5]

                # Skip if no image
                if not image_path:
                    continue

                # Format image URL
                if image_path.startswith('http'):
                    image_url = image_path
                elif image_path.startswith('/static') or image_path.startswith('/uploads'):
                    image_url = image_path
                elif image_path.startswith('uploads/'):
                    image_url = '/' + image_path
                else:
                    image_url = f"/uploads/{image_path}"

                photos.append({
                    'id': str(post_id),
                    'post_id': post_id,
                    'reply_id': None,
                    'username': username_val,
                    'image_url': image_url,
                    'created_at': timestamp,
                    'profile_picture': profile_picture
                })

            # Sort photos by creation date (newest first)
            photos.sort(key=lambda x: x['created_at'] or '', reverse=True)

            return jsonify({'success': True, 'photos': photos})

    except Exception as e:
        logger.error(f"Error in community_photos: {e}")
        return jsonify({'success': False, 'error': 'Failed to load photos'}), 500

@app.route('/api/community_posts_search')
@login_required
def api_community_posts_search():
    try:
        username = session.get('username')
        community_id = request.args.get('community_id', type=int)
        q = (request.args.get('q') or '').strip()
        if not community_id or not q:
            return jsonify({'success': False, 'error': 'community_id and q are required'}), 400
        token = q[1:] if q.startswith('#') else q
        if not token:
            return jsonify({'success': True, 'posts': []})
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                if username != 'admin':
                    c.execute("""
                        SELECT 1 FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE u.username = ? AND uc.community_id = ?
                        LIMIT 1
                    """, (username, community_id))
                    if not c.fetchone():
                        return jsonify({'success': False, 'error': 'Forbidden'}), 403
            except Exception:
                pass
            like_arg = f"%#{token}%"
            c.execute(
                """
                SELECT id, username, content, timestamp
                FROM posts
                WHERE community_id = ? AND LOWER(content) LIKE LOWER(?)
                ORDER BY id DESC
                LIMIT 100
                """,
                (community_id, like_arg)
            )
            rows = c.fetchall()
            results = []
            for r in rows:
                rid = r['id'] if hasattr(r, 'keys') else r[0]
                ruser = r['username'] if hasattr(r, 'keys') else r[1]
                rcontent = r['content'] if hasattr(r, 'keys') else r[2]
                rts = r['timestamp'] if hasattr(r, 'keys') else r[3]
                snippet = (rcontent or '')
                if len(snippet) > 140:
                    snippet = snippet[:137] + '‚Ä¶'
                results.append({'id': rid, 'username': ruser, 'content': snippet, 'timestamp': rts})
            return jsonify({'success': True, 'posts': results})
    except Exception as e:
        logger.error(f"Error in community_posts_search: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/vite.svg')
def vite_svg():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        return send_from_directory(dist_dir, 'vite.svg')
    except Exception as e:
        logger.error(f"Error serving vite.svg: {str(e)}")
        abort(404)

@app.route('/favicon.svg')
def favicon():
    try:
        return send_from_directory('static', 'favicon.svg')
    except Exception as e:
        logger.error(f"Error serving favicon.svg: {str(e)}")
        abort(404)

@app.route('/manifest.webmanifest')
def manifest():
    try:
        resp = send_from_directory('static', 'manifest.webmanifest')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving manifest.webmanifest: {str(e)}")
        abort(404)

@app.route('/icons/<path:filename>')
def icons(filename):
    try:
        return send_from_directory('static/icons', filename)
    except Exception as e:
        logger.error(f"Error serving icon {filename}: {str(e)}")
        abort(404)

# service worker served by web server static mapping (/sw.js -> client/dist/sw.js)

# web app manifest served by web server static mapping (/manifest.webmanifest -> client/public/manifest.webmanifest)

@app.route('/premium_dashboard_react')
@login_required
def premium_dashboard_react():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React premium dashboard: {str(e)}")
        abort(500)


@app.route('/followers')
@login_required
def followers_page():
    """Serve the React SPA for the Followers hub."""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving Followers page: {e}")
        abort(500)

@app.route('/admin_dashboard')
@login_required
def admin_dashboard_react():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        index_path = os.path.join(dist_dir, 'index.html')
        if os.path.exists(index_path):
            logger.info("Serving React index.html for admin_dashboard")
            resp = send_from_directory(dist_dir, 'index.html')
            try:
                resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                resp.headers['Pragma'] = 'no-cache'
                resp.headers['Expires'] = '0'
            except Exception:
                pass
            return resp
        # Fallback to communities page if React build not available
        return redirect(url_for('communities'))
    except Exception as e:
        logger.error(f"Error serving React admin dashboard: {str(e)}")
        abort(500)

@app.route('/admin_profile_react')
@login_required
def admin_profile_react():
    """Serve the React SPA for the admin profile page."""
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        index_path = os.path.join(dist_dir, 'index.html')
        if os.path.exists(index_path):
            logger.info("Serving React index.html for admin_profile_react")
            resp = send_from_directory(dist_dir, 'index.html')
            try:
                resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
                resp.headers['Pragma'] = 'no-cache'
                resp.headers['Expires'] = '0'
            except Exception:
                pass
            return resp
        # Fallback if React build not available
        return redirect(url_for('communities'))
    except Exception as e:
        logger.error(f"Error serving React admin profile: {str(e)}")
        abort(500)

@app.route('/saved_workouts')
@login_required
def saved_workouts():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user:
                logger.error(f"User {username} not found in database")
                flash("User not found!", "error")
                return redirect('/')
            if user['subscription'] != 'premium':
                logger.warning(f"User {username} attempted to access saved_workouts without premium subscription")
                return redirect(url_for('dashboard'))
            c.execute("SELECT id, workout, timestamp, week, weights FROM saved_workouts WHERE username=? ORDER BY timestamp DESC", (username,))
            raw_workouts = c.fetchall()
            logger.debug(f"Raw workouts for {username}: {raw_workouts}")
        processed_workouts = []
        for workout in raw_workouts:
            try:
                logger.debug(f"Processing workout {workout['id']}: {workout}")
                weights = json.loads(workout['weights'] or '[]')
                logger.debug(f"Parsed weights for workout {workout['id']}: {weights}")
                exercises = []
                lines = workout['workout'].replace('\r\n', '<br>').split('<br>')
                for i, line in enumerate(lines):
                    line = line.strip()
                    if '<b>' in line and '</b>' in line and "Hey" not in line:
                        name = line.replace('<b>', '').replace('</b>', '')
                        if i + 1 < len(lines):
                            next_line = lines[i + 1].strip()
                            parts = next_line.split(', ')
                            sets, reps = '', ''
                            for part in parts:
                                if part.startswith('Sets:'): sets = part.replace('Sets: ', '')
                                elif part.startswith('Reps:'): reps = part.replace('Reps: ', '')
                            weight_data = weights[len(exercises)]['session'] if len(exercises) < len(weights) else []
                            exercises.append({
                                'name': name,
                                'sets': sets,
                                'reps': reps,
                                'weights': weight_data
                            })
                processed_workouts.append({
                    'id': workout['id'],
                    'timestamp': workout['timestamp'],
                    'week': workout['week'],
                    'exercises': exercises
                })
                logger.debug(f"Processed workout {workout['id']}: {processed_workouts[-1]}")
            except (ValueError, IndexError) as e:
                logger.error(f"Error processing workout {workout['id']} for {username}: {str(e)}")
                continue
        logger.info(f"Rendering {len(processed_workouts)} workouts for {username}")
        logger.debug(f"Final processed workouts: {processed_workouts}")
        return render_template('saved_workouts.html', name=username, workouts=processed_workouts, subscription=user['subscription'])
    except Exception as e:
        logger.error(f"Exception in /saved_workouts for {username}: {str(e)}")
        abort(500)

@app.route('/generate_workout_page')
@login_required
def generate_workout_page():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
        if not user or user['subscription'] != 'premium':
            return redirect(url_for('dashboard'))
        return render_template('generate_workouts.html', name=username, subscription=user['subscription'])
    except Exception as e:
        logger.error(f"Error in generate_workout_page for {username}: {str(e)}")
        abort(500)

@app.route('/choose_workout_type')
@login_required
def choose_workout_type():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
        if not user or user['subscription'] != 'premium':
            return redirect(url_for('dashboard'))
        return render_template('choose_workout_type.html', name=username, subscription=user['subscription'])
    except Exception as e:
        logger.error(f"Error in choose_workout_type for {username}: {str(e)}")
        abort(500)

@app.route('/build_workout_page')
@login_required
def build_workout_page():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
        if not user or user['subscription'] != 'premium':
            return redirect(url_for('dashboard'))
        muscle_splits = list(workout_data.keys())
        return render_template('build_workout.html', name=username, subscription=user['subscription'], muscle_splits=muscle_splits)
    except Exception as e:
        logger.error(f"Error in build_workout_page for {username}: {str(e)}")
        abort(500)

@app.route('/get_exercises', methods=['GET'])
@login_required
def get_exercises():
    username = session['username']
    muscle_or_split = request.args.get('muscle_or_split')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
        if not user or user['subscription'] != 'premium':
            return jsonify({'error': 'Premium subscription required.'}), 403
        if not muscle_or_split or muscle_or_split not in workout_data:
            return jsonify({'error': 'Invalid or missing muscle group/split.'}), 400
        exercises = []
        for training_type in workout_data[muscle_or_split]:
            for variation in workout_data[muscle_or_split][training_type]:
                for exercise in variation:
                    if exercise not in exercises:
                        exercises.append(exercise)
        return jsonify({'exercises': exercises})
    except Exception as e:
        logger.error(f"Error in get_exercises for {username}: {str(e)}")
        return jsonify({'error': 'Server error. Please try again later.'}), 500

@app.route('/save_workout', methods=['POST'])
@login_required
def save_workout():
    username = session['username']
    workout = request.form.get('workout')
    if not workout:
        return jsonify({'error': 'No workout provided!'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                return jsonify({'error': 'Premium subscription required!'}), 403
            exercise_count = sum(1 for line in workout.split('<br>') if '<b>' in line and '</b>' in line) - 1
            initial_weights = json.dumps([{"session": [], "weight": ""} for _ in range(exercise_count)])
            timestamp = datetime.now().strftime('%m.%d.%y')
            c.execute("INSERT INTO saved_workouts (username, workout, timestamp, weights) VALUES (?, ?, ?, ?)",
                      (username, workout, timestamp, initial_weights))
            workout_id = c.lastrowid
            conn.commit()
        logger.info(f"Workout saved for {username} with ID {workout_id}")
        return jsonify({'success': True, 'message': 'Workout saved successfully'}), 200
    except Exception as e:
        logger.error(f"Error in save_workout for {username}: {str(e)}")
        return jsonify({'error': f'Unexpected error: {str(e)}'}), 500

@app.route('/saved_workout_detail/<int:workout_id>')
@login_required
def saved_workout_detail(workout_id):
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                logger.warning(f"User {username} attempted to access saved_workout_detail without premium subscription")
                return redirect(url_for('dashboard'))
            c.execute("SELECT workout, timestamp, week, weights FROM saved_workouts WHERE id=? AND username=?", (workout_id, username))
            workout = c.fetchone()
            if not workout:
                logger.error(f"Workout {workout_id} not found for user {username}")
                flash("Workout not found or unauthorized!", "error")
                return redirect('/')
            weights = json.loads(workout['weights'] or '[]')
            exercises = []
            lines = workout['workout'].replace('\r\n', '<br>').split('<br>')
            for i, line in enumerate(lines):
                line = line.strip()
                if '<b>' in line and '</b>' in line and "Hey" not in line:
                    name = line.replace('<b>', '').replace('</b>', '')
                    if i + 1 < len(lines):
                        next_line = lines[i + 1].strip()
                        parts = next_line.split(', ')
                        sets, reps = '', ''
                        for part in parts:
                            if part.startswith('Sets:'): sets = part.replace('Sets: ', '')
                            elif part.startswith('Reps:'): reps = part.replace('Reps: ', '')
                        weight_data = weights[len(exercises)]['session'] if len(exercises) < len(weights) else []
                        exercises.append({
                            'name': name,
                            'sets': sets,
                            'reps': reps,
                            'weights': weight_data
                        })
            workout_data = {
                'id': workout_id,
                'timestamp': workout['timestamp'],
                'week': workout['week'],
                'exercises': exercises
            }
        logger.info(f"Rendering saved workout detail for {username}, workout ID {workout_id}")
        return render_template('saved_workout_detail.html', name=username, workout=workout_data, subscription=user['subscription'])
    except Exception as e:
        logger.error(f"Error in saved_workout_detail for {username}, workout ID {workout_id}: {str(e)}")
        abort(500)

@app.route('/update_weight', methods=['POST'])
@login_required
def update_weight():
    username = session['username']
    workout_id = request.form.get('workout_id')
    exercise_index = request.form.get('exercise_index', type=int)
    week = request.form.get('week', type=int, default=1)
    weight = request.form.get('weight', '').strip()
    if not all([workout_id, weight]):
        logger.error(f"Missing required fields for {username}: {request.form}")
        return jsonify({'success': False, 'error': 'Missing workout ID or weight.'}), 400
    logger.debug(f"Update weight request for {username}: {request.form}")
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                logger.error(f"User {username} lacks premium subscription for weight update")
                return jsonify({'success': False, 'error': 'Premium subscription required.'}), 403
            c.execute("SELECT weights FROM saved_workouts WHERE id=? AND username=?", (workout_id, username))
            result = c.fetchone()
            if not result:
                logger.error(f"Workout {workout_id} not found or unauthorized for {username}")
                return jsonify({'success': False, 'error': 'Workout not found or unauthorized.'}), 404
            weights = json.loads(result['weights'] or '[]')
            if not isinstance(weights, list):
                weights = []
            while len(weights) <= exercise_index:
                weights.append({"session": [], "weight": ""})
            weights[exercise_index]["session"].append({
                "number": len(weights[exercise_index]["session"]) + 1,
                "weight": weight,
                "date": datetime.now().strftime('%d.%m.%y')
            })
            logger.debug(f"Updated weights: {weights}")
            c.execute("UPDATE saved_workouts SET weights=?, week=? WHERE id=? AND username=?",
                      (json.dumps(weights), week, workout_id, username))
            conn.commit()
            logger.info(f"Weight updated successfully for {username}, workout {workout_id}, exercise {exercise_index}")
            return jsonify({
                'success': True,
                'weight': weight,
                'session_number': len(weights[exercise_index]["session"]),
                'date': datetime.now().strftime('%d.%m.%y')
            }), 200
    except Exception as e:
        logger.error(f"Error updating weight for {username}: {str(e)}")
        return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500

# Old delete_workout route removed - replaced with new one below

@app.route('/delete_weight', methods=['POST'])
@login_required
def delete_weight():
    username = session['username']
    workout_id = request.form.get('workout_id')
    exercise_index = request.form.get('exercise_index', type=int)
    session_number = request.form.get('session_number', type=int)
    logger.debug(f"Delete weight request for {username}: {request.form}")
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                logger.error(f"User {username} lacks premium subscription for weight deletion")
                return jsonify({'success': False, 'error': 'Premium subscription required.'}), 403
            c.execute("SELECT weights FROM saved_workouts WHERE id=? AND username=?", (workout_id, username))
            result = c.fetchone()
            if not result:
                logger.error(f"Workout {workout_id} not found or unauthorized for {username}")
                return jsonify({'success': False, 'error': 'Workout not found or unauthorized.'}), 404
            weights = json.loads(result['weights'] or '[]')
            if not isinstance(weights, list) or exercise_index >= len(weights):
                logger.error(f"Invalid exercise index for {username}, workout {workout_id}, exercise {exercise_index}")
                return jsonify({'success': False, 'error': 'Invalid exercise index.'}), 400
            if not weights[exercise_index]["session"]:
                logger.error(f"No weights found for exercise {exercise_index} in workout {workout_id} for {username}")
                return jsonify({'success': False, 'error': 'No weights available for this exercise.'}), 400
            original_sessions = weights[exercise_index]["session"]
            weights[exercise_index]["session"] = [w for w in original_sessions if w["number"] != session_number]
            if len(weights[exercise_index]["session"]) == len(original_sessions):
                logger.error(f"Session number {session_number} not found for exercise {exercise_index} in workout {workout_id} for {username}")
                return jsonify({'success': False, 'error': 'Session number not found.'}), 400
            c.execute("UPDATE saved_workouts SET weights=? WHERE id=? AND username=?", (json.dumps(weights), workout_id, username))
            conn.commit()
            logger.info(f"Weight deleted successfully for {username}, workout {workout_id}, exercise {exercise_index}")
            return jsonify({'success': True, 'message': 'Weight deleted successfully'}), 200
    except json.JSONDecodeError as e:
        logger.error(f"JSON error deleting weight for {username}: {str(e)}")
        return jsonify({'success': False, 'error': 'Invalid weight data format.'}), 500
    except Exception as e:
        logger.error(f"Error deleting weight for {username}: {str(e)}")
        return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500
# Admin helper functions
def is_app_admin(username):
    """Check if a user is an app admin"""
    try:
        # Only the 'admin' account is treated as app admin
        return bool(username) and username.lower() == 'admin'
    except Exception:
        return False
@app.route('/delete_account', methods=['POST'])
@login_required
def delete_account():
    """Permanently delete the current user's account and related data where possible."""
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Try to find user id for FK cleanups
            c.execute(f"SELECT id FROM users WHERE username = {get_sql_placeholder()}", (username,))
            row = c.fetchone()
            user_id = None
            if row is not None:
                user_id = row['id'] if hasattr(row, 'keys') else row[0]

            # Best-effort delete dependent rows with foreign keys referencing users/username/user_id
            # Messages
            try: c.execute(f"DELETE FROM messages WHERE sender={get_sql_placeholder()} OR receiver={get_sql_placeholder()}", (username, username))
            except Exception: pass
            # Notifications (if exists)
            try:
                ph = get_sql_placeholder()
                c.execute(f"DELETE FROM notifications WHERE user_id={ph} OR from_user={ph}", (username, username))
            except Exception: pass
            # Push subscriptions
            try: c.execute(f"DELETE FROM push_subscriptions WHERE username={get_sql_placeholder()}", (username,))
            except Exception: pass
            # Remember tokens (FK to users.username)
            try: c.execute(f"DELETE FROM remember_tokens WHERE username={get_sql_placeholder()}", (username,))
            except Exception: pass
            # User profiles
            try: c.execute(f"DELETE FROM user_profiles WHERE username={get_sql_placeholder()}", (username,))
            except Exception: pass
            # User communities by user_id
            if user_id is not None:
                try: c.execute(f"DELETE FROM user_communities WHERE user_id={get_sql_placeholder()}", (user_id,))
                except Exception: pass

            # Reassign communities owned by this user to admin to avoid FK failures
            try:
                c.execute(f"UPDATE communities SET creator_username={get_sql_placeholder()} WHERE creator_username={get_sql_placeholder()}", ('admin', username))
            except Exception:
                pass

            # Finally, delete from users
            c.execute(f"DELETE FROM users WHERE username = {get_sql_placeholder()}", (username,))
            conn.commit()
        # Clear session
        session.clear()
        # Return success with instruction to clear localStorage
        return jsonify({'success': True, 'clear_storage': True})
    except Exception as e:
        try:
            logger.error(f"delete_account error for {username}: {e}")
        except Exception:
            pass
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/check_admin', methods=['GET'])
@login_required
def check_admin():
    """Check if current user is admin"""
    username = session.get('username')
    return jsonify({'is_admin': is_app_admin(username)})

@app.route('/health', methods=['GET'])
def health_check():
    """Simple health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2025.01.15'
    })

@app.route('/api/test', methods=['GET'])
def test_endpoint():
    """Test endpoint to verify server is running"""
    try:
        # Test database connection
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT COUNT(*) as count FROM users")
            result = c.fetchone()
            user_count = result['count'] if hasattr(result, 'keys') else result[0]
            
        return jsonify({
            'status': 'ok',
            'database': 'MySQL' if USE_MYSQL else 'SQLite',
            'user_count': user_count,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        import traceback
        return jsonify({
            'status': 'error',
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/clear_sessions')
def clear_sessions():
    """Clear all old session cookies"""
    from flask import make_response
    resp = make_response("""
    <html>
    <body style="background: black; color: white; padding: 50px; font-family: Arial;">
        <h1>Session Cookies Cleared</h1>
        <p>All old session cookies have been removed.</p>
        <p><a href="/" style="color: #4db6ac;">Go to login page</a></p>
    </body>
    </html>
    """)
    # Clear the old 'session' cookies
    resp.set_cookie('session', '', expires=0, path='/')
    # Clear any potential domain-specific cookies
    resp.set_cookie('session', '', expires=0, path='/', domain='.c-point.co')
    resp.set_cookie('session', '', expires=0, path='/', domain='www.c-point.co')
    # Also clear the new cookie name just in case
    resp.set_cookie('cpoint_session', '', expires=0, path='/')
    return resp

@app.route('/test_login')
def test_login_page():
    """Serve the test login page"""
    return render_template('test_login.html')

@app.route('/test_form', methods=['GET', 'POST'])
def test_form():
    """Test form to debug POST requests"""
    logger.info(f"Test form accessed: Method={request.method}")
    
    if request.method == 'POST':
        logger.info(f"Test form POST received: {dict(request.form)}")
        return f"""
        <html><body style="background: black; color: white; padding: 20px;">
        <h1>POST received successfully!</h1>
        <p>Form data: {dict(request.form)}</p>
        <p>Method: {request.method}</p>
        <p>Headers: Content-Type = {request.headers.get('Content-Type')}</p>
        <a href="/test_form" style="color: #4db6ac;">Try again</a>
        </body></html>
        """
    
    return """
    <html><body style="background: black; color: white; padding: 20px;">
    <h1>Test Form</h1>
    <p style="color: yellow;">This page tests if POST requests are working</p>
    
    <h2>1. Simple Test</h2>
    <form method="POST" action="/test_form">
        <input type="text" name="test_field" placeholder="Enter anything" style="padding: 10px; margin: 10px 0; color: black;">
        <button type="submit" style="padding: 10px 20px; background: #4db6ac; color: white; border: none; cursor: pointer;">
            Submit Test
        </button>
    </form>
    
    <hr style="margin: 20px 0;">
    
    <h2>2. Test Main Login Form</h2>
    <form method="POST" action="/">
        <input type="text" name="username" placeholder="Enter username" required style="padding: 10px; margin: 10px 0; color: black;">
        <button type="submit" style="padding: 10px 20px; background: #4db6ac; color: white; border: none; cursor: pointer;">
            Submit to Main Route
        </button>
    </form>
    
    <hr style="margin: 20px 0;">
    
    <h2>3. Direct Link Test</h2>
    <p>If forms don't work, try these direct links:</p>
    <a href="/health" style="color: #4db6ac;">Health Check</a> | 
    <a href="/api/test" style="color: #4db6ac;">API Test</a> | 
    <a href="/login_password" style="color: #4db6ac;">Login Password Page</a>
    </body></html>
    """
@app.route('/api/debug_communities', methods=['GET'])
@login_required
def debug_communities():
    """Debug endpoint to check all communities in database"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'error': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all communities
            c.execute("""
                SELECT id, name, type, parent_community_id, creator_username
                FROM communities
                ORDER BY id
            """)
            all_communities = c.fetchall()
            
            # Get user_communities count
            c.execute("SELECT COUNT(*) as count FROM user_communities")
            uc_count = get_scalar_result(c.fetchone(), column_name='count')
            
            # Get admin's communities
            placeholder = get_sql_placeholder()
            c.execute(f"""
                SELECT c.id, c.name
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {placeholder}
            """, ('admin',))
            admin_communities = c.fetchall()
            
            communities_list = []
            for comm in all_communities:
                communities_list.append({
                    'id': comm[0] if not hasattr(comm, 'keys') else comm['id'],
                    'name': comm[1] if not hasattr(comm, 'keys') else comm['name'],
                    'type': comm[2] if not hasattr(comm, 'keys') else comm['type'],
                    'parent_id': comm[3] if not hasattr(comm, 'keys') else comm['parent_community_id'],
                    'creator': comm[4] if not hasattr(comm, 'keys') else comm['creator_username']
                })
            
            admin_comm_list = []
            for comm in admin_communities:
                admin_comm_list.append({
                    'id': comm[0] if not hasattr(comm, 'keys') else comm['id'],
                    'name': comm[1] if not hasattr(comm, 'keys') else comm['name']
                })
            
            return jsonify({
                'total_communities': len(all_communities),
                'user_communities_entries': uc_count,
                'all_communities': communities_list,
                'admin_communities': admin_comm_list,
                'database_type': 'MySQL' if USE_MYSQL else 'SQLite'
            })
    except Exception as e:
        logger.error(f"Debug communities error: {e}")
        import traceback
        return jsonify({'error': str(e), 'traceback': traceback.format_exc()}), 500
@app.route('/api/admin/dashboard', methods=['GET'])
@login_required
def admin_dashboard_api():
    """API endpoint for admin dashboard data"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get statistics
            c.execute("SELECT COUNT(*) as count FROM users")
            total_users = get_scalar_result(c.fetchone(), column_name='count')
            
            c.execute("SELECT COUNT(*) as count FROM users WHERE subscription = 'premium'")
            premium_users = get_scalar_result(c.fetchone(), column_name='count')
            
            c.execute("SELECT COUNT(*) as count FROM communities")
            total_communities = get_scalar_result(c.fetchone(), column_name='count')
            
            c.execute("SELECT COUNT(*) as count FROM posts")
            total_posts = get_scalar_result(c.fetchone(), column_name='count')
            
            # Activity windows
            from datetime import datetime, timedelta
            # Use server-local midnight for "today" to better match stored timestamps
            today = datetime.now().date()
            start_of_day = datetime(today.year, today.month, today.day)
            start_of_30 = start_of_day - timedelta(days=30)

            # DAU/MAU (unique usernames with any activity: post, reaction, vote, or reading timeline)
            # Reading timeline proxy: community_feed/api hits tracked in community_visit_history
            def get_unique_between(table, field, ts_field, start_ts):
                try:
                    q = f"SELECT DISTINCT {field}, {ts_field} FROM {table} WHERE {ts_field} IS NOT NULL"
                    c.execute(q)
                    rows = c.fetchall() or []
                    vals = set()
                    for r in rows:
                        try:
                            username_val = r[field] if hasattr(r, 'keys') else r[0]
                            ts_val = r[ts_field] if hasattr(r, 'keys') else (r[1] if len(r) > 1 else None)
                            if not ts_val:
                                continue
                            s = str(ts_val)
                            dtv = None
                            # Fast path ISO-like
                            try:
                                dtv = datetime.strptime(s[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                            except Exception:
                                for fmt in ('%Y-%m-%d %H:%M', '%Y-%m-%d', '%m.%d.%y %H:%M'):
                                    try:
                                        dtv = datetime.strptime(s, fmt)
                                        break
                                    except Exception:
                                        continue
                            if dtv and dtv >= start_ts:
                                vals.add(username_val)
                        except Exception:
                            pass
                    return vals
                except Exception:
                    return set()

            dau_sets = []
            mau_sets = []
            for tbl, user_field, ts_field in (
                ('posts','username','timestamp'),
                ('reactions','username','created_at'),
                ('poll_votes','username','voted_at'),
                ('community_visit_history','username','visit_time'),
                ('messages','sender','timestamp'),
            ):
                dau_sets.append(get_unique_between(tbl, user_field, ts_field, start_of_day))
                mau_sets.append(get_unique_between(tbl, user_field, ts_field, start_of_30))

            dau = len(set().union(*dau_sets))
            mau = len(set().union(*mau_sets))
            dau_pct = round((dau / total_users) * 100, 2) if total_users else 0.0
            mau_pct = round((mau / total_users) * 100, 2) if total_users else 0.0

            # Average DAU over the past 30 days (including today):
            # For each day window [day_start, day_end), union distinct users across activity tables, then average the counts
            def get_unique_between_window(table, field, ts_field, start_ts, end_ts):
                try:
                    q = f"SELECT DISTINCT {field}, {ts_field} FROM {table} WHERE {ts_field} IS NOT NULL"
                    c.execute(q)
                    rows = c.fetchall() or []
                    vals = set()
                    for r in rows:
                        try:
                            username_val = r[field] if hasattr(r, 'keys') else r[0]
                            ts_val = r[ts_field] if hasattr(r, 'keys') else (r[1] if len(r) > 1 else None)
                            if not ts_val:
                                continue
                            s = str(ts_val)
                            dtv = None
                            try:
                                dtv = datetime.strptime(s[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                            except Exception:
                                for fmt in ('%Y-%m-%d %H:%M', '%Y-%m-%d', '%m.%d.%y %H:%M'):
                                    try:
                                        dtv = datetime.strptime(s, fmt)
                                        break
                                    except Exception:
                                        continue
                            if dtv and (dtv >= start_ts) and (dtv < end_ts):
                                vals.add(username_val)
                        except Exception:
                            pass
                    return vals
                except Exception:
                    return set()

            daily_counts = []
            for i in range(0, 30):
                day_start = start_of_day - timedelta(days=i)
                day_end = day_start + timedelta(days=1)
                day_sets = []
                for tbl, user_field, ts_field in (
                    ('posts','username','timestamp'),
                    ('reactions','username','created_at'),
                    ('poll_votes','username','voted_at'),
                    ('community_visit_history','username','visit_time'),
                    ('messages','sender','timestamp'),
                ):
                    day_sets.append(get_unique_between_window(tbl, user_field, ts_field, day_start, day_end))
                daily_counts.append(len(set().union(*day_sets)))
            avg_dau_30 = round(sum(daily_counts) / len(daily_counts), 2) if daily_counts else 0.0

            # Helper: get activity users for a window [start, end)
            def get_activity_users(start_ts, end_ts):
                users_union = set()
                for tbl, user_field, ts_field in (
                    ('posts','username','timestamp'),
                    ('reactions','username','created_at'),
                    ('poll_votes','username','voted_at'),
                    ('community_visit_history','username','visit_time'),
                    ('messages','sender','timestamp'),
                ):
                    users_union |= get_unique_between_window(tbl, user_field, ts_field, start_ts, end_ts)
                return users_union

            # Monthly returning users (current month vs previous month)
            from calendar import monthrange
            cur_month_start = start_of_day.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            # Prev month start
            if cur_month_start.month == 1:
                prev_month_start = cur_month_start.replace(year=cur_month_start.year-1, month=12)
            else:
                prev_month_start = cur_month_start.replace(month=cur_month_start.month-1)
            # Month ends
            days_in_prev_month = monthrange(prev_month_start.year, prev_month_start.month)[1]
            prev_month_end = prev_month_start.replace(day=days_in_prev_month, hour=23, minute=59, second=59)
            days_in_cur_month = monthrange(cur_month_start.year, cur_month_start.month)[1]
            cur_month_end = cur_month_start.replace(day=days_in_cur_month, hour=23, minute=59, second=59)

            users_prev_month = get_activity_users(prev_month_start, prev_month_end)
            users_cur_month = get_activity_users(cur_month_start, cur_month_end)
            mau_month = len(users_cur_month)
            mru = len(users_prev_month & users_cur_month)
            mru_repeat_rate = round((mru / mau_month) * 100, 2) if mau_month else 0.0

            # Weekly returning users (current week vs previous week), week starts Monday
            weekday = start_of_day.weekday()  # Mon=0
            start_of_week = start_of_day.replace(hour=0, minute=0, second=0, microsecond=0) - timedelta(days=weekday)
            prev_week_start = start_of_week - timedelta(days=7)
            prev_week_end = start_of_week - timedelta(seconds=1)
            cur_week_end = start_of_week + timedelta(days=7) - timedelta(seconds=1)
            users_prev_week = get_activity_users(prev_week_start, prev_week_end)
            users_cur_week = get_activity_users(start_of_week, cur_week_end)
            wau = len(users_cur_week)
            wru = len(users_prev_week & users_cur_week)
            wru_repeat_rate = round((wru / wau) * 100, 2) if wau else 0.0

            # Cohort retention (last 6 calendar months)
            cohorts = []
            # Build list of month starts (oldest to newest)
            month_starts = []
            ms = cur_month_start
            for _ in range(6):
                month_starts.append(ms)
                # go back one month
                if ms.month == 1:
                    ms = ms.replace(year=ms.year-1, month=12)
                else:
                    ms = ms.replace(month=ms.month-1)
            month_starts = list(reversed(month_starts))

            # Preload user signups
            c.execute("SELECT username, created_at FROM users")
            all_users = c.fetchall() or []
            def in_month(dt, y, m):
                return (dt.year == y and dt.month == m)
            # Pre-calc month windows
            month_windows = []
            for ms in month_starts:
                y = ms.year; m = ms.month
                days_in_month = monthrange(y, m)[1]
                start = ms
                end = ms.replace(day=days_in_month, hour=23, minute=59, second=59)
                month_windows.append((y, m, start, end))

            # Build cohorts
            for i, (y, m, start, end) in enumerate(month_windows):
                cohort_users = set()
                for u in all_users:
                    uname = u['username'] if hasattr(u,'keys') else u[0]
                    created = u['created_at'] if hasattr(u,'keys') else (u[1] if len(u)>1 else None)
                    if not created: continue
                    try:
                        s = str(created)
                        dtc = _dt.strptime(s[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                    except Exception:
                        try:
                            dtc = _dt.strptime(str(created), '%Y-%m-%d')
                        except Exception:
                            continue
                    if in_month(dtc, y, m):
                        cohort_users.add(uname)
                cohort_size = len(cohort_users)
                # Compute retention for subsequent months up to the latest window
                retention = []
                if cohort_size:
                    for j in range(i, len(month_windows)):
                        ys, ms_, ws, we = month_windows[j]
                        active = get_activity_users(ws, we)
                        retained = len(active & cohort_users)
                        retention.append(round((retained / cohort_size) * 100, 2))
                cohorts.append({
                    'month': f"{y:04d}-{m:02d}",
                    'size': cohort_size,
                    'retention': retention,
                })

            # Leaderboards
            def scalar_list(query, params=()):
                c.execute(query, params)
                rows = c.fetchall() or []
                out = []
                for r in rows:
                    if hasattr(r, 'keys'):
                        out.append({'username': r['username'], 'count': r['cnt']})
                    else:
                        out.append({'username': r[0], 'count': r[1]})
                return out

            top_posters = scalar_list("SELECT username, COUNT(*) as cnt FROM posts WHERE LOWER(username) <> 'admin' GROUP BY username ORDER BY cnt DESC LIMIT 10")
            top_reactors = scalar_list("SELECT username, COUNT(*) as cnt FROM reactions WHERE LOWER(username) <> 'admin' GROUP BY username ORDER BY cnt DESC LIMIT 10")
            top_voters = scalar_list("SELECT username, COUNT(*) as cnt FROM poll_votes WHERE LOWER(username) <> 'admin' GROUP BY username ORDER BY cnt DESC LIMIT 10")

            stats = {
                'total_users': total_users,
                'premium_users': premium_users,
                'total_communities': total_communities,
                'total_posts': total_posts,
                'dau': dau,
                'mau': mau,
                'dau_pct': dau_pct,
                'mau_pct': mau_pct,
                'avg_dau_30': avg_dau_30,
                'mau_month': mau_month,
                'mru': mru,
                'mru_repeat_rate_pct': mru_repeat_rate,
                'wau': wau,
                'wru': wru,
                'wru_repeat_rate_pct': wru_repeat_rate,
                'cohorts': cohorts,
                'leaderboards': {
                    'top_posters': top_posters,
                    'top_reactors': top_reactors,
                    'top_voters': top_voters,
                }
            }
            
            # Get users list
            c.execute("SELECT username, subscription FROM users ORDER BY username")
            users_raw = c.fetchall()
            users = []
            for user in users_raw:
                users.append({
                    'username': user['username'] if hasattr(user, 'keys') else user[0],
                    'subscription': user['subscription'] if hasattr(user, 'keys') else user[1],
                    'is_active': True,  # Default for now
                    'is_admin': is_app_admin(user['username'] if hasattr(user, 'keys') else user[0])
                })
            
            # Get all communities with parent information
            c.execute("""
                SELECT c.id, c.name, c.type, c.creator_username,
                       c.parent_community_id, COUNT(uc.user_id) as member_count
                FROM communities c
                LEFT JOIN user_communities uc ON c.id = uc.community_id
                GROUP BY c.id, c.name, c.type, c.creator_username, c.parent_community_id
                ORDER BY c.name
            """)
            communities_raw = c.fetchall()
            logger.info(f"Admin dashboard: Found {len(communities_raw)} total communities")
            
            # First, create all community objects (support dict or tuple rows)
            all_communities = {}
            for comm in communities_raw:
                if hasattr(comm, 'keys'):
                    cid = comm['id']
                    cname = comm['name']
                    ctype = comm['type']
                    ccreator = comm['creator_username']
                    cparent = comm['parent_community_id']
                    cmembers = comm['member_count']
                else:
                    cid = comm[0]
                    cname = comm[1]
                    ctype = comm[2]
                    ccreator = comm[3]
                    cparent = comm[4]
                    cmembers = comm[5]

                community_data = {
                    'id': cid,
                    'name': cname,
                    'type': ctype,
                    'creator_username': ccreator,
                    'parent_community_id': cparent,
                    'member_count': cmembers,
                    'is_active': True,
                    'children': []
                }
                all_communities[cid] = community_data
            
            # Now organize into parent-child structure
            root_communities = {}
            
            for comm_id, comm_data in all_communities.items():
                if comm_data['parent_community_id'] is None:
                    # This is a root community
                    root_communities[comm_id] = comm_data
                else:
                    # This is a child community - add it to its parent if parent exists
                    parent_id = comm_data['parent_community_id']
                    if parent_id in all_communities:
                        all_communities[parent_id]['children'].append(comm_data)
                    else:
                        # Parent doesn't exist, treat this as a root community
                        root_communities[comm_id] = comm_data
            
            # For any community that has children but isn't a root (nested hierarchy),
            # we need to ensure it appears as a root if its parent isn't in our list
            for comm_id, comm_data in all_communities.items():
                if comm_data['children'] and comm_id not in root_communities:
                    # Check if this community's parent is in our list
                    if comm_data['parent_community_id'] and comm_data['parent_community_id'] not in all_communities:
                        root_communities[comm_id] = comm_data
            
            # Convert to list and include all communities (even orphaned ones)
            communities = list(root_communities.values())
            
            # Also include any communities that might have been missed
            included_ids = set()
            
            def collect_ids(comm):
                included_ids.add(comm['id'])
                for child in comm['children']:
                    collect_ids(child)
            
            for comm in communities:
                collect_ids(comm)
            
            # Add any missing communities as root level
            for comm_id, comm_data in all_communities.items():
                if comm_id not in included_ids:
                    communities.append(comm_data)
            
            return jsonify({
                'success': True,
                'stats': stats,
                'users': users,
                'communities': communities
            })
            
    except Exception as e:
        logger.error(f"Error in admin dashboard API: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/admin/profile', methods=['GET'])
@login_required
def admin_profile_api():
    """Admin profile API returning admin info and system stats. Admin-only."""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403

    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Admin profile info (including profile picture if available)
            c.execute(f"""
                SELECT u.username, u.email, u.first_name, u.last_name, u.subscription, u.created_at,
                       p.profile_picture
                FROM users u
                LEFT JOIN user_profiles p ON u.username = p.username
                WHERE u.username = {get_sql_placeholder()}
            """, (username,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Admin user not found'}), 404
            admin_info = {
                'username': row['username'] if hasattr(row, 'keys') else row[0],
                'email': row['email'] if hasattr(row, 'keys') else row[1],
                'first_name': row['first_name'] if hasattr(row, 'keys') else row[2],
                'last_name': row['last_name'] if hasattr(row, 'keys') else row[3],
                'subscription': row['subscription'] if hasattr(row, 'keys') else row[4],
                'created_at': row['created_at'] if hasattr(row, 'keys') else row[5],
                'profile_picture': row['profile_picture'] if hasattr(row, 'keys') else row[6],
            }

            # System statistics (reuse logic from dashboard)
            c.execute("SELECT COUNT(*) as count FROM users")
            total_users = get_scalar_result(c.fetchone(), column_name='count')

            c.execute("SELECT COUNT(*) as count FROM posts")
            total_posts = get_scalar_result(c.fetchone(), column_name='count')

            c.execute("SELECT COUNT(*) as count FROM communities")
            total_communities = get_scalar_result(c.fetchone(), column_name='count')

            c.execute("SELECT COUNT(*) as count FROM users WHERE subscription = 'premium'")
            premium_users = get_scalar_result(c.fetchone(), column_name='count')

            stats = {
                'total_users': total_users,
                'total_posts': total_posts,
                'total_communities': total_communities,
                'premium_users': premium_users,
            }

        return jsonify({'success': True, 'admin': admin_info, 'stats': stats})
    except Exception as e:
        logger.error(f"Error loading admin profile API: {str(e)}")
        import traceback
        return jsonify({'success': False, 'error': str(e), 'traceback': traceback.format_exc()}), 500
@app.route('/api/admin/update_user', methods=['POST'])
@login_required
def admin_update_user():
    """Update user details as admin"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    data = request.get_json()
    target_user = data.get('username')
    
    if not target_user:
        return jsonify({'success': False, 'error': 'Username required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            if 'subscription' in data:
                c.execute("UPDATE users SET subscription = ? WHERE username = ?", 
                         (data['subscription'], target_user))
            
            conn.commit()
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error updating user: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/admin/update_community', methods=['POST'])
@login_required
def admin_update_community():
    """Update community details as admin"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    data = request.get_json()
    community_id = data.get('community_id')
    
    if not community_id:
        return jsonify({'success': False, 'error': 'Community ID required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # For now just return success
            # Add actual update logic as needed
            
            conn.commit()
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error updating community: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/admin/add_user', methods=['POST'])
@login_required
def admin_add_user():
    """Add a new user as admin"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    data = request.get_json()
    new_username = data.get('username')
    new_password = data.get('password')
    subscription = data.get('subscription', 'free')
    
    if not new_username or not new_password:
        return jsonify({'success': False, 'error': 'Username and password required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user already exists
            c.execute("SELECT 1 FROM users WHERE username = ?", (new_username,))
            if c.fetchone():
                return jsonify({'success': False, 'error': 'Username already exists'}), 400
            
            # Hash the password
            from werkzeug.security import generate_password_hash
            hashed_password = generate_password_hash(new_password)
            
            # Insert new user
            c.execute("""
                INSERT INTO users (username, password, subscription, created_at)
                VALUES (?, ?, ?, NOW())
            """, (new_username, hashed_password, subscription))
            
            conn.commit()
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error adding user: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/admin/compress_images', methods=['POST'])
@login_required
def admin_compress_images():
    """Admin-only: compress existing uploaded images on disk referenced by DB.
    Scans posts, replies, user profile pictures, community backgrounds, message photos.
    """
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403

    compressed = 0
    skipped = 0
    missing = 0
    errored = 0

    paths: set[str] = set()
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            for query in (
                "SELECT image_path FROM posts WHERE image_path IS NOT NULL AND image_path != ''",
                "SELECT image_path FROM replies WHERE image_path IS NOT NULL AND image_path != ''",
                "SELECT profile_picture FROM user_profiles WHERE profile_picture IS NOT NULL AND profile_picture != ''",
                "SELECT background_path FROM communities WHERE background_path IS NOT NULL AND background_path != ''",
                "SELECT image_path FROM messages WHERE image_path IS NOT NULL AND image_path != ''",
            ):
                try:
                    c.execute(query)
                    for row in c.fetchall():
                        try:
                            val = row[0] if not hasattr(row, 'keys') else list(row.values())[0]
                        except Exception:
                            # Fallback: handle mapping/dict-style
                            if hasattr(row, 'keys'):
                                val = next(iter(row.values()))
                            else:
                                val = None
                        if val:
                            paths.add(str(val))
                except Exception:
                    continue
    except Exception as e:
        logger.error(f"Error collecting image paths: {e}")
        return jsonify({'success': False, 'error': 'Failed to collect image paths'})

    base_dir = os.path.dirname(os.path.abspath(__file__))
    static_uploads = os.path.join(base_dir, 'static', 'uploads')
    root_uploads = os.path.join(base_dir, 'uploads')

    def resolve_path(p: str) -> str:
        clean = (p or '').replace('\r', '').replace('\n', '').strip('/')
        candidates = []
        if clean.startswith('uploads/'):
            candidates.append(os.path.join(base_dir, clean))
            candidates.append(os.path.join(static_uploads, clean.split('uploads/',1)[1]))
        else:
            candidates.append(os.path.join(static_uploads, clean))
            candidates.append(os.path.join(root_uploads, clean))
        for c in candidates:
            if os.path.exists(c):
                return c
        return candidates[0]

    for p in list(paths):
        disk_path = resolve_path(p)
        if not os.path.exists(disk_path):
            missing += 1
            continue
        try:
            before = os.path.getsize(disk_path)
            ok = optimize_image(disk_path, max_width=1280, quality=80)
            if ok:
                after = os.path.getsize(disk_path)
                compressed += 1
            else:
                skipped += 1
        except Exception as e:
            errored += 1
            logger.warning(f"Compress error {disk_path}: {e}")

    return jsonify({
        'success': True,
        'total_paths': len(paths),
        'compressed': compressed,
        'skipped': skipped,
        'missing': missing,
        'errored': errored,
    })

@app.route('/api/admin/delete_user', methods=['POST'])
@login_required
def admin_delete_user():
    """Delete a user as admin"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    data = request.get_json()
    target_username = data.get('username')
    
    if not target_username:
        return jsonify({'success': False, 'error': 'Username required'}), 400
    
    if target_username == 'admin':
        return jsonify({'success': False, 'error': 'Cannot delete admin user'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()

            # Resolve user id
            c.execute(f"SELECT id FROM users WHERE username={ph}", (target_username,))
            row = c.fetchone()
            user_id = (row['id'] if hasattr(row, 'keys') else (row[0] if row else None))
            if not user_id:
                return jsonify({'success': False, 'error': 'User not found'}), 404

            # Delete dependent rows first to satisfy FK constraints
            try:
                c.execute(f"DELETE FROM notifications WHERE user_id={ph} OR from_user={ph}", (target_username, target_username))
            except Exception:
                pass
            c.execute(f"DELETE FROM messages WHERE sender={ph} OR receiver={ph}", (target_username, target_username))
            c.execute(f"DELETE FROM notifications WHERE user_id={ph} OR from_user={ph}", (target_username, target_username))
            c.execute(f"DELETE FROM user_communities WHERE user_id={ph}", (user_id,))
            try:
                c.execute(f"DELETE FROM community_admins WHERE username={ph}", (target_username,))
            except Exception:
                pass
            c.execute(f"DELETE FROM posts WHERE username={ph}", (target_username,))
            c.execute(f"DELETE FROM replies WHERE username={ph}", (target_username,))
            c.execute(f"DELETE FROM reactions WHERE username={ph}", (target_username,))
            c.execute(f"DELETE FROM reply_reactions WHERE username={ph}", (target_username,))
            try:
                c.execute(f"DELETE FROM push_subscriptions WHERE username={ph}", (target_username,))
            except Exception:
                pass
            try:
                c.execute(f"DELETE FROM user_login_history WHERE username={ph}", (target_username,))
            except Exception:
                pass
            try:
                c.execute(f"DELETE FROM community_visit_history WHERE username={ph}", (target_username,))
            except Exception:
                pass
            try:
                c.execute(f"DELETE FROM typing_status WHERE user={ph} OR peer={ph}", (target_username, target_username))
            except Exception:
                pass
            try:
                c.execute(f"DELETE FROM remember_tokens WHERE username={ph}", (target_username,))
            except Exception:
                pass
            # Reassign communities owned by this user to 'admin' to satisfy FK fk_comm_owner
            try:
                c.execute(f"UPDATE communities SET creator_username={ph} WHERE creator_username={ph}", ('admin', target_username))
            except Exception:
                pass
            # Delete calendar and event related data
            try:
                # Delete RSVPs for events this user is involved in
                c.execute(f"DELETE FROM event_rsvps WHERE username={ph}", (target_username,))
                # Delete event invitations for this user
                c.execute(f"DELETE FROM event_invitations WHERE invited_username={ph} OR invited_by={ph}", (target_username, target_username))
                # Delete calendar events created by this user
                c.execute(f"DELETE FROM calendar_events WHERE username={ph}", (target_username,))
            except Exception as cal_err:
                logger.warning(f"Error deleting calendar/event data for {target_username}: {cal_err}")
                pass
            
            # Remove profile row before user to satisfy FK fk_profile_user
            c.execute(f"DELETE FROM user_profiles WHERE username={ph}", (target_username,))
            try:
                c.execute(f"DELETE FROM exercises WHERE username={ph}", (target_username,))
                c.execute(f"DELETE FROM workouts WHERE username={ph}", (target_username,))
                c.execute(f"DELETE FROM crossfit_entries WHERE username={ph}", (target_username,))
            except Exception:
                pass

            # Finally delete the user
            c.execute(f"DELETE FROM users WHERE username={ph}", (target_username,))
            
            conn.commit()
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error deleting user: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/admin/delete_community', methods=['POST'])
@login_required
def admin_delete_community():
    """Delete a community as admin"""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    data = request.get_json()
    community_id_raw = data.get('community_id') if data else None
    try:
        community_id = int(community_id_raw)
    except (TypeError, ValueError):
        community_id = None
    
    if not community_id:
        return jsonify({'success': False, 'error': 'Community ID required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            placeholder = get_sql_placeholder()
            c.execute(f"SELECT id FROM communities WHERE id = {placeholder}", (community_id,))
            existing = c.fetchone()
            if not existing:
                return jsonify({'success': False, 'error': 'Community not found'}), 404

            descendant_ids = get_descendant_community_ids(c, community_id)
            
            # Get all members of communities being deleted BEFORE deleting
            affected_usernames: Set[str] = set()
            for target_id in descendant_ids:
                ph = get_sql_placeholder()
                c.execute(f"""
                    SELECT DISTINCT u.username 
                    FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE uc.community_id = {ph}
                """, (target_id,))
                for row in c.fetchall():
                    uname = row['username'] if hasattr(row, 'keys') else row[0]
                    if uname:
                        affected_usernames.add(uname)
            
            deleted_ids: List[int] = []
            for target_id in descendant_ids:
                delete_community_records(c, target_id)
                deleted_ids.append(target_id)
            
            conn.commit()
            
            # Invalidate dashboard cache for ALL affected users
            for affected_user in affected_usernames:
                invalidate_user_cache(affected_user)
            logger.info(f"Admin delete: Invalidated cache for {len(affected_usernames)} users")
            
            return jsonify({'success': True, 'deleted_ids': deleted_ids})
            
    except Exception as e:
        logger.error(f"Error deleting community: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/admin', methods=['GET', 'POST'])
@login_required
def admin():
    if session['username'] != 'admin':
        return redirect(url_for('public.index'))
    
    # Serve React for all devices (mobile and desktop)
    base_dir = os.path.dirname(os.path.abspath(__file__))
    dist_dir = os.path.join(base_dir, 'client', 'dist')
    return send_from_directory(dist_dir, 'index.html')

# Old admin HTML code removed - now using React AdminDashboard.tsx
def _old_admin_removed():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Get statistics with error handling
            try:
                c.execute("SELECT COUNT(*) as count FROM users")
                total_users = get_scalar_result(c.fetchone(), column_name='count') or 0

                c.execute("SELECT COUNT(*) as count FROM users WHERE subscription = 'premium'")
                premium_users = get_scalar_result(c.fetchone(), column_name='count') or 0

                c.execute("SELECT COUNT(*) as count FROM communities")
                total_communities = get_scalar_result(c.fetchone(), column_name='count') or 0

                c.execute("SELECT COUNT(*) as count FROM posts")
                total_posts = get_scalar_result(c.fetchone(), column_name='count') or 0
            except Exception as stat_error:
                logger.error(f"Error getting statistics: {stat_error}")
                # Provide fallback values
                total_users = 0
                premium_users = 0
                total_communities = 0
                total_posts = 0
            
            # Initialize default values
            stats = {
                'total_users': total_users,
                'premium_users': premium_users,
                'total_communities': total_communities,
                'total_posts': total_posts
            }

            users = []
            communities = []

            # Get users list with is_active status (normalize shape for template)
            try:
                c.execute("SELECT username, subscription, is_active FROM users ORDER BY username")
                users_raw = c.fetchall()
                users = []
                for row in users_raw or []:
                    try:
                        if hasattr(row, 'keys'):
                            uname = row.get('username') if hasattr(row, 'get') else row['username']
                            sub = row.get('subscription') if hasattr(row, 'get') else row['subscription']
                            active = row.get('is_active') if hasattr(row, 'get') else row['is_active'] if 'is_active' in row.keys() else True
                        else:
                            uname = row[0]
                            sub = row[1] if len(row) > 1 else 'free'
                            active = row[2] if len(row) > 2 else True
                    except Exception:
                        # Defensive defaults
                        uname = row[0] if not hasattr(row, 'keys') else (row.get('username') if hasattr(row, 'get') else None)
                        sub = 'free'
                        active = True
                    users.append((uname, sub, bool(active) if active is not None else True))
            except Exception as users_error:
                logger.error(f"Error getting users list: {users_error}")

            # Get all communities with member counts and is_active status
            try:
                # Prefer query including is_active; fallback if column missing
                try:
                    c.execute("""
                        SELECT c.id, c.name, c.type, c.creator_username,
                               SUM(CASE WHEN u.username IS NOT NULL AND LOWER(u.username) <> 'admin' THEN 1 ELSE 0 END) as member_count,
                               c.is_active
                        FROM communities c
                        LEFT JOIN user_communities uc ON c.id = uc.community_id
                        LEFT JOIN users u ON uc.user_id = u.id
                        GROUP BY c.id, c.name, c.type, c.creator_username, c.is_active
                        ORDER BY c.name
                    """)
                except Exception:
                    c.execute("""
                        SELECT c.id, c.name, c.type, c.creator_username,
                               SUM(CASE WHEN u.username IS NOT NULL AND LOWER(u.username) <> 'admin' THEN 1 ELSE 0 END) as member_count
                        FROM communities c
                        LEFT JOIN user_communities uc ON c.id = uc.community_id
                        LEFT JOIN users u ON uc.user_id = u.id
                        GROUP BY c.id, c.name, c.type, c.creator_username
                        ORDER BY c.name
                    """)
                communities_raw = c.fetchall() or []
                
                # Convert to list of dictionaries for easier template access
                for community in communities_raw:
                    communities.append({
                        'id': community[0],
                        'name': community[1],
                        'type': community[2],
                        'creator_username': community[3],
                        'member_count': community[4] if len(community) > 4 else 0,
                        'is_active': (community[5] if len(community) > 5 else True)
                    })
            except Exception as communities_error:
                logger.error(f"Error getting communities list: {communities_error}")
                communities = []
            
            if request.method == 'POST':
                if 'add_user' in request.form:
                    new_username = request.form.get('new_username')
                    new_password = request.form.get('new_password')
                    new_subscription = request.form.get('new_subscription')
                    try:
                        c.execute("INSERT INTO users (username, subscription, password) VALUES (?, ?, ?)",
                                  (new_username, new_subscription, new_password))
                        conn.commit()
                        # Refresh users list
                        c.execute("SELECT username, subscription, is_active FROM users ORDER BY username")
                        users = c.fetchall()
                    except Exception as db_error:
                        # Handle both SQLite IntegrityError and MySQL IntegrityError
                        if 'UNIQUE constraint failed' in str(db_error) or 'Duplicate entry' in str(db_error) or 'Integrity constraint violation' in str(db_error):
                            return render_template('admin.html', users=users, communities=communities, stats=stats, error=f"Username {new_username} already exists!")
                        else:
                            raise db_error
                        
                elif 'update_user' in request.form:
                    user_to_update = request.form.get('username')
                    new_subscription = request.form.get('subscription')
                    c.execute("UPDATE users SET subscription=? WHERE username=?", (new_subscription, user_to_update))
                    conn.commit()
                    # Refresh users list
                    c.execute("SELECT username, subscription, is_active FROM users ORDER BY username")
                    users = c.fetchall()
                    
                elif 'update_subscription' in request.form:
                    user_to_update = request.form.get('username')
                    new_subscription = request.form.get('new_subscription')
                    c.execute("UPDATE users SET subscription=? WHERE username=?", (new_subscription, user_to_update))
                    conn.commit()
                    # Refresh users list
                    c.execute("SELECT username, subscription, is_active FROM users ORDER BY username")
                    users = c.fetchall()
                    
                elif 'delete_user' in request.form:
                    user_to_delete = request.form.get('username')
                    
                    # Prevent admin from deleting themselves
                    if user_to_delete == 'admin':
                        return render_template('admin.html', users=users, communities=communities, stats=stats, error="Cannot delete admin user!")
                    
                    try:
                        # Delete user's data from all related tables
                        # Notifications (FK to users.username)
                        try:
                            c.execute("DELETE FROM notifications WHERE user_id=? OR from_user=?", (user_to_delete, user_to_delete))
                        except Exception:
                            pass
                        # Web push subscriptions (FK on users.username in MySQL)
                        try:
                            c.execute("DELETE FROM push_subscriptions WHERE username=??", (user_to_delete,))
                        except Exception:
                            try:
                                c.execute("DELETE FROM push_subscriptions WHERE username=?", (user_to_delete,))
                            except Exception:
                                pass
                        # Remember tokens
                        try:
                            c.execute("DELETE FROM remember_tokens WHERE username=?", (user_to_delete,))
                        except Exception:
                            pass
                        # Login and visit history
                        try:
                            c.execute("DELETE FROM user_login_history WHERE username=?", (user_to_delete,))
                        except Exception:
                            pass
                        try:
                            c.execute("DELETE FROM community_visit_history WHERE username=?", (user_to_delete,))
                        except Exception:
                            pass
                        c.execute("DELETE FROM posts WHERE username=?", (user_to_delete,))
                        c.execute("DELETE FROM replies WHERE username=?", (user_to_delete,))
                        c.execute("DELETE FROM reactions WHERE username=?", (user_to_delete,))
                        c.execute("DELETE FROM reply_reactions WHERE username=?", (user_to_delete,))
                        # Reassign communities owned by this user to 'admin' to satisfy FK fk_comm_owner
                        try:
                            c.execute("UPDATE communities SET creator_username=? WHERE creator_username=?", ('admin', user_to_delete))
                        except Exception:
                            pass
                        # Remove profile row before deleting from users to satisfy FK fk_profile_user
                        try:
                            c.execute("DELETE FROM user_profiles WHERE username=?", (user_to_delete,))
                        except Exception:
                            pass
                        if USE_MYSQL:
                            c.execute("DELETE FROM user_communities WHERE user_id=(SELECT id FROM users WHERE username=?)", (user_to_delete,))
                        else:
                            c.execute("DELETE FROM user_communities WHERE user_id=(SELECT rowid FROM users WHERE username=?)", (user_to_delete,))
                        c.execute("DELETE FROM saved_data WHERE username=?", (user_to_delete,))
                        c.execute("DELETE FROM messages WHERE sender=?", (user_to_delete,))
                        c.execute("DELETE FROM messages WHERE receiver=?", (user_to_delete,))
                        
                        # Finally delete the user
                        c.execute("DELETE FROM users WHERE username=?", (user_to_delete,))
                        conn.commit()
                        
                        # Refresh users list
                        c.execute("SELECT username, subscription, is_active FROM users ORDER BY username")
                        users = c.fetchall()
                        
                    except Exception as delete_error:
                        logger.error(f"Error deleting user {user_to_delete}: {str(delete_error)}")
                        return render_template('admin.html', users=users, communities=communities, stats=stats, error=f"Error deleting user: {str(delete_error)}")
                        
                elif 'delete_community' in request.form:
                    community_id = request.form.get('community_id')
                    
                    try:
                        # Delete all posts in this community
                        c.execute("DELETE FROM post_views WHERE post_id IN (SELECT id FROM posts WHERE community_id=?)", (community_id,))
                        c.execute("DELETE FROM posts WHERE community_id=?", (community_id,))
                        
                        # Delete all user_community entries for this community
                        c.execute("DELETE FROM user_communities WHERE community_id=?", (community_id,))
                        
                        # Delete the community itself
                        c.execute("DELETE FROM communities WHERE id=?", (community_id,))
                        conn.commit()
                        
                        # Refresh communities list
                        c.execute("""
                            SELECT c.id, c.name, c.type, c.creator_username,
                                   COUNT(uc.user_id) as member_count
                            FROM communities c
                            LEFT JOIN user_communities uc ON c.id = uc.community_id
                            GROUP BY c.id, c.name, c.type, c.creator_username
                            ORDER BY c.name
                        """)
                        communities_raw = c.fetchall()
                        
                        # Convert to list of dictionaries
                        communities = []
                        for community in communities_raw:
                            communities.append({
                                'id': community[0],
                                'name': community[1],
                                'type': community[2],
                                'creator_username': community[3],
                                'member_count': community[4]
                            })
                        
                    except Exception as delete_error:
                        logger.error(f"Error deleting community {community_id}: {str(delete_error)}")
                        return render_template('admin.html', users=users, communities=communities, stats=stats, error=f"Error deleting community: {str(delete_error)}")
            
        return render_template('admin.html', users=users, communities=communities, stats=stats)

    except Exception as e:
        logger.error(f"Error in admin route: {str(e)}")
        # Provide fallback values for template
        stats = {'total_users': 0, 'premium_users': 0, 'total_communities': 0, 'total_posts': 0}
        users = []
        communities = []
        return render_template('admin.html', users=users, communities=communities, stats=stats, error=f"Error loading admin data: {str(e)}")

@app.route('/admin_test')
@login_required
def admin_test():
    if session['username'] != 'admin':
        return redirect(url_for('public.index'))
    return "Admin test route is working!"
                    

@app.route('/api/profile/<username>')
def api_public_profile(username):
    """Public profile data for a username (JSON)."""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            # Resolve actual username case-insensitively
            c.execute(f"SELECT username FROM users WHERE LOWER(username) = LOWER({ph})", (username,))
            user = c.fetchone()
            if not user:
                return jsonify({'success': False, 'error': 'not found'}), 404
            actual_username = user['username'] if hasattr(user, 'keys') else user[0]

            # Profile fields
            c.execute(f"""
                SELECT u.username, u.subscription,
                       u.gender, u.country, u.city, u.date_of_birth, u.age,
                       p.display_name, p.bio, p.location, p.website,
                       p.instagram, p.twitter, p.profile_picture, p.cover_photo,
                       COALESCE(p.is_public, 1)
                FROM users u
                LEFT JOIN user_profiles p ON u.username = p.username
                WHERE u.username = {ph}
            """, (actual_username,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'profile not found'}), 404

            def get_val(r, key, idx):
                try:
                    return r[key] if hasattr(r, 'keys') and key in r.keys() else r[idx]
                except Exception:
                    return None

            # Fetch user's professional info and share setting
            try:
                c.execute("SELECT role, company, industry, degree, school, skills, linkedin, experience, professional_about, professional_interests, professional_share_community_id FROM users WHERE username = ?", (actual_username,))
                urow = c.fetchone()
            except Exception:
                urow = None

            profile = {
                'username': actual_username,
                'subscription': get_val(row, 'subscription', 1),
                'display_name': get_val(row, 'display_name', 7) or actual_username,
                'bio': get_val(row, 'bio', 8),
                'location': get_val(row, 'location', 9),
                'website': get_val(row, 'website', 10),
                'instagram': get_val(row, 'instagram', 11),
                'twitter': get_val(row, 'twitter', 12),
                'profile_picture': get_val(row, 'profile_picture', 13),
                'cover_photo': get_val(row, 'cover_photo', 14),
                'is_public': bool(get_val(row, 'is_public', 15)),
                'personal': {
                    'display_name': (get_val(row, 'display_name', 7) or actual_username),
                    'gender': get_val(row, 'gender', 2),
                    'country': get_val(row, 'country', 3),
                    'city': get_val(row, 'city', 4),
                    'date_of_birth': get_val(row, 'date_of_birth', 5),
                    'age': get_val(row, 'age', 6),
                },
                'professional': None
            }

            # Include professional info if it's allowed to be public or scoped to a community, which public profile can render broadly
            if urow:
                def uval(idx_or_key):
                    try:
                        return urow[idx_or_key] if hasattr(urow, 'keys') else urow[idx_or_key]
                    except Exception:
                        return None
                interests_raw = uval('professional_interests') if hasattr(urow, 'keys') else uval(9)
                interests_list: list[str] = []
                if interests_raw:
                    try:
                        decoded = json.loads(interests_raw)
                        if isinstance(decoded, list):
                            interests_list = [
                                str(item).strip() for item in decoded if isinstance(item, (str, int, float)) and str(item).strip()
                            ]
                        else:
                            raise ValueError("unexpected format")
                    except Exception:
                        interests_list = [
                            part.strip() for part in str(interests_raw).split(',') if part and part.strip()
                        ]

                    interests_list = list(dict.fromkeys(interests_list))

                profile['professional'] = {
                    'role': uval('role') if hasattr(urow, 'keys') else uval(0),
                    'company': uval('company') if hasattr(urow, 'keys') else uval(1),
                    'industry': uval('industry') if hasattr(urow, 'keys') else uval(2),
                    'degree': uval('degree') if hasattr(urow, 'keys') else uval(3),
                    'school': uval('school') if hasattr(urow, 'keys') else uval(4),
                    'skills': uval('skills') if hasattr(urow, 'keys') else uval(5),
                    'linkedin': uval('linkedin') if hasattr(urow, 'keys') else uval(6),
                    'experience': uval('experience') if hasattr(urow, 'keys') else uval(7),
                    'about': uval('professional_about') if hasattr(urow, 'keys') else uval(8),
                    'interests': interests_list,
                    'share_community_id': uval('professional_share_community_id') if hasattr(urow, 'keys') else uval(10)
                }

            # Recent posts (kept for potential future use; frontend may ignore)
            c.execute(f"""
                SELECT id, content, image_path, timestamp
                FROM posts
                WHERE username = {ph}
                ORDER BY timestamp DESC
                LIMIT 20
            """, (actual_username,))
            posts = c.fetchall()
            posts_list = []
            for p in posts or []:
                def val(pv, key, idx):
                    try:
                        return pv[key] if hasattr(pv, 'keys') and key in pv.keys() else pv[idx]
                    except Exception:
                        return None
                posts_list.append({
                    'id': val(p, 'id', 0),
                    'content': val(p, 'content', 1),
                    'image_path': val(p, 'image_path', 2),
                    'timestamp': val(p, 'timestamp', 3),
                })

            profile['is_self'] = session.get('username') == actual_username
            viewer_username = session.get('username')
            try:
                summary_counts = get_follow_summary(c, actual_username)
            except Exception:
                summary_counts = {'followers': 0, 'following': 0, 'requests': 0}
            profile['followers_count'] = summary_counts.get('followers', 0)
            profile['following_count'] = summary_counts.get('following', 0)
            follow_status = 'self' if profile['is_self'] else 'none'
            if viewer_username and viewer_username.lower() != actual_username.lower():
                try:
                    ensure_followers_table(c)
                    placeholder = get_sql_placeholder()
                    c.execute(
                        f"SELECT status FROM followers WHERE follower_username = {placeholder} AND followed_username = {placeholder}",
                        (viewer_username, actual_username)
                    )
                    row = c.fetchone()
                    if row:
                        follow_status = row['status'] if hasattr(row, 'keys') and 'status' in row.keys() else row[0]
                    else:
                        follow_status = 'none'
                except Exception as follow_err:
                    logger.warning(f"follow status check failed for {viewer_username}->{actual_username}: {follow_err}")
                    follow_status = 'none'
            profile['follow_status'] = follow_status
            profile['is_following'] = follow_status == 'accepted'
            profile['has_pending_follow_request'] = follow_status == 'pending'

            return jsonify({'success': True, 'profile': profile, 'posts': posts_list})
    except Exception as e:
        logger.error(f"api_public_profile error for {username}: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500


def resolve_username_case(cursor, username: str) -> Optional[str]:
    """Resolve stored username given case-insensitive lookup."""
    if not username:
        return None
    placeholder = get_sql_placeholder()
    cursor.execute(f"SELECT username FROM users WHERE LOWER(username) = LOWER({placeholder})", (username,))
    row = cursor.fetchone()
    if not row:
        return None
    return row['username'] if hasattr(row, 'keys') else row[0]


def get_user_id(cursor, username: str) -> Optional[int]:
    """Return user id for username."""
    if not username:
        return None
    placeholder = get_sql_placeholder()
    cursor.execute(f"SELECT id FROM users WHERE username = {placeholder}", (username,))
    row = cursor.fetchone()
    if not row:
        return None
    value = row.get('id') if hasattr(row, 'keys') else row[0]
    return int(value) if value is not None else None


@app.route('/api/follow/<username>', methods=['POST', 'DELETE'])
@login_required
def api_follow_toggle(username):
    follower = session.get('username')
    if not follower:
        return jsonify({'success': False, 'error': 'Not authenticated'}), 401
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            actual_target = resolve_username_case(c, username)
            if not actual_target:
                return jsonify({'success': False, 'error': 'User not found'}), 404
            if actual_target.lower() == follower.lower():
                return jsonify({'success': False, 'error': 'You cannot follow yourself'}), 400

            ensure_followers_table(c)
            now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            placeholder = get_sql_placeholder()
            existing_status = None
            try:
                c.execute(
                    f"SELECT status FROM followers WHERE follower_username = {placeholder} AND followed_username = {placeholder}",
                    (follower, actual_target)
                )
                row = c.fetchone()
                if row:
                    existing_status = row['status'] if hasattr(row, 'keys') and 'status' in row.keys() else row[0]
            except Exception as status_err:
                logger.warning(f"follow status fetch failed {follower}->{actual_target}: {status_err}")
                existing_status = None

            new_status = existing_status or 'none'

            if request.method == 'POST':
                if existing_status:
                    if existing_status == 'pending':
                        try:
                            if USE_MYSQL:
                                c.execute(
                                    """
                                    UPDATE followers SET created_at = NOW()
                                    WHERE follower_username = %s AND followed_username = %s
                                    """,
                                    (follower, actual_target)
                                )
                            else:
                                c.execute(
                                    """
                                    UPDATE followers SET created_at = ?
                                    WHERE follower_username = ? AND followed_username = ?
                                    """,
                                    (now_str, follower, actual_target)
                                )
                        except Exception as refresh_err:
                            logger.warning(f"follow request timestamp refresh failed {follower}->{actual_target}: {refresh_err}")
                    new_status = existing_status
                else:
                    try:
                        if USE_MYSQL:
                            c.execute(
                                """
                                INSERT INTO followers (follower_username, followed_username, created_at, status)
                                VALUES (%s, %s, %s, 'pending')
                                """,
                                (follower, actual_target, now_str)
                            )
                        else:
                            c.execute(
                                """
                                INSERT INTO followers (follower_username, followed_username, created_at, status)
                                VALUES (?, ?, ?, 'pending')
                                """,
                                (follower, actual_target, now_str)
                            )
                        new_status = 'pending'
                    except Exception as insert_err:
                        logger.warning(f"follow insert failed {follower}->{actual_target}: {insert_err}")
                        new_status = existing_status or 'none'
                    else:
                        try:
                            message = f"{follower} requested to follow you"
                            create_notification(
                                user_id=actual_target,
                                from_user=follower,
                                notification_type='follow_request',
                                message=message,
                                link='/followers?tab=requests'
                            )
                        except Exception as notif_err:
                            logger.warning(f"follow request notification insert failed {follower}->{actual_target}: {notif_err}")
            else:
                try:
                    c.execute(
                        f"DELETE FROM followers WHERE follower_username = {placeholder} AND followed_username = {placeholder}",
                        (follower, actual_target)
                    )
                except Exception as delete_err:
                    logger.warning(f"follow delete failed {follower}->{actual_target}: {delete_err}")
                new_status = 'none'

                try:
                    delete_ph = get_sql_placeholder()
                    c.execute(
                        f"DELETE FROM notifications WHERE user_id = {delete_ph} AND from_user = {delete_ph} AND type = {delete_ph}",
                        (actual_target, follower, 'follow_request')
                    )
                except Exception as notif_delete_err:
                    logger.warning(f"Failed removing follow request notification {follower}->{actual_target}: {notif_delete_err}")

            conn.commit()

            target_summary = get_follow_summary(c, actual_target)
            viewer_summary = get_follow_summary(c, follower)

            if request.method == 'POST' and new_status == 'pending':
                try:
                    send_push_to_user(actual_target, {
                        'title': 'New follow request',
                        'body': f'{follower} requested to follow you',
                        'url': '/followers?tab=requests',
                        'tag': f'follow-request-{follower}-{actual_target}'
                    })
                except Exception as push_err:
                    logger.warning(f"follow request push failed {follower}->{actual_target}: {push_err}")

            return jsonify({
                'success': True,
                'status': new_status,
                'followers_count': target_summary.get('followers', 0),
                'following_count': target_summary.get('following', 0),
                'requests_count': target_summary.get('requests', 0),
                'viewer_followers_count': viewer_summary.get('followers', 0),
                'viewer_following_count': viewer_summary.get('following', 0),
                'target_username': actual_target,
            })
    except Exception as e:
        logger.error(f"api_follow_toggle error for {follower}->{username}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/followers', methods=['GET'])
@login_required
def api_followers_list():
    username = session.get('username')
    tab = (request.args.get('tab') or 'followers').strip().lower()
    if tab not in {'followers', 'following', 'requests'}:
        tab = 'followers'
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_followers_table(c)
            summary = get_follow_summary(c, username)
            placeholder = get_sql_placeholder()
            items: List[Dict[str, Any]] = []

            def normalize_pic(pic: Optional[str]) -> Optional[str]:
                if not pic:
                    return None
                pic = pic.strip()
                if not pic:
                    return None
                if pic.startswith('http') or pic.startswith('/'):
                    return pic
                return f"/static/{pic}"

            if tab == 'followers':
                c.execute(
                    f"""
                    SELECT f.follower_username AS username,
                           f.created_at,
                           f.accepted_at,
                           f.status,
                           up.display_name,
                           up.profile_picture
                    FROM followers f
                    LEFT JOIN user_profiles up ON up.username = f.follower_username
                    WHERE f.followed_username = {placeholder} AND f.status = 'accepted'
                    ORDER BY COALESCE(f.accepted_at, f.created_at) DESC
                    """,
                    (username,),
                )
            elif tab == 'following':
                c.execute(
                    f"""
                    SELECT f.followed_username AS username,
                           f.created_at,
                           f.accepted_at,
                           f.status,
                           up.display_name,
                           up.profile_picture
                    FROM followers f
                    LEFT JOIN user_profiles up ON up.username = f.followed_username
                    WHERE f.follower_username = {placeholder} AND f.status = 'accepted'
                    ORDER BY COALESCE(f.accepted_at, f.created_at) DESC
                    """,
                    (username,),
                )
            else:  # requests
                c.execute(
                    f"""
                    SELECT f.follower_username AS username,
                           f.created_at,
                           f.status,
                           up.display_name,
                           up.profile_picture
                    FROM followers f
                    LEFT JOIN user_profiles up ON up.username = f.follower_username
                    WHERE f.followed_username = {placeholder} AND f.status = 'pending'
                    ORDER BY f.created_at DESC
                    """,
                    (username,),
                )

            rows = c.fetchall() or []
            for row in rows:
                if hasattr(row, 'keys'):
                    data = row
                    created_raw = data.get('accepted_at') or data.get('created_at')
                    created_val = created_raw.isoformat() if hasattr(created_raw, 'isoformat') else created_raw
                    items.append({
                        'username': data.get('username'),
                        'display_name': data.get('display_name') or data.get('username'),
                        'profile_picture': normalize_pic(data.get('profile_picture')),
                        'status': data.get('status'),
                        'created_at': created_val,
                    })
                else:
                    username_val = row[0]
                    display_name = row[4] if len(row) > 4 else username_val
                    profile_pic = row[5] if len(row) > 5 else None
                    accepted_at_idx = 2 if tab != 'requests' else None
                    created_idx = 1
                    accepted_val = row[accepted_at_idx] if accepted_at_idx is not None and len(row) > accepted_at_idx else None
                    created_val = accepted_val or (row[created_idx] if len(row) > created_idx else None)
                    status_val = row[3] if len(row) > 3 else ('pending' if tab == 'requests' else 'accepted')
                    if tab == 'requests':
                        # For SQLite result ordering, indexes differ slightly
                        display_name = row[3] if len(row) > 3 else username_val
                        profile_pic = row[4] if len(row) > 4 else None
                        created_val = row[1] if len(row) > 1 else None
                        status_val = row[2] if len(row) > 2 else 'pending'
                    iso_created = created_val.isoformat() if hasattr(created_val, 'isoformat') else created_val
                    items.append({
                        'username': username_val,
                        'display_name': display_name or username_val,
                        'profile_picture': normalize_pic(profile_pic),
                        'status': status_val,
                        'created_at': iso_created,
                    })

            return jsonify({
                'success': True,
                'tab': tab,
                'items': items,
                'counts': summary,
            })
    except Exception as e:
        logger.error(f"api_followers_list error for {username}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/followers_feed', methods=['GET'])
@login_required
def api_followers_feed():
    """Return posts authored or interacted with by people the user follows."""
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_followers_table(c)
            placeholder = get_sql_placeholder()
            c.execute(
                f"""
                SELECT followed_username
                FROM followers
                WHERE follower_username = {placeholder} AND status = 'accepted'
                ORDER BY COALESCE(accepted_at, created_at) DESC
                """,
                (username,),
            )
            rows = c.fetchall() or []
            followings: List[str] = []
            for row in rows:
                value = row['followed_username'] if hasattr(row, 'keys') else row[0]
                if value:
                    followings.append(value)

            if not followings:
                return jsonify({'success': True, 'posts': []})

            c.execute(
                f"""
                SELECT c.id
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {placeholder}
                """,
                (username,),
            )
            community_rows = c.fetchall() or []
            shared_comm_ids: List[int] = []
            for row in community_rows:
                raw = row['id'] if hasattr(row, 'keys') else row[0]
                if raw is None:
                    continue
                try:
                    shared_comm_ids.append(int(raw))
                except (TypeError, ValueError):
                    continue

            shared_comm_ids = list(dict.fromkeys(shared_comm_ids))
            if not shared_comm_ids:
                return jsonify({'success': True, 'posts': []})

            MAX_FOLLOWINGS = 200
            if len(followings) > MAX_FOLLOWINGS:
                followings = followings[:MAX_FOLLOWINGS]

            in_placeholders = ','.join([get_sql_placeholder()] * len(followings))
            in_params = tuple(followings)
            community_placeholders = ','.join([get_sql_placeholder()] * len(shared_comm_ids))
            community_params = tuple(shared_comm_ids)

            c.execute(
                f"""
                SELECT id
                FROM posts
                WHERE username IN ({in_placeholders})
                  AND community_id IN ({community_placeholders})
                ORDER BY id DESC
                LIMIT 200
                """,
                in_params + community_params,
            )
            authored_ids = [
                row['id'] if hasattr(row, 'keys') else row[0] for row in (c.fetchall() or [])
            ]

            c.execute(
                f"""
                SELECT r.post_id, r.username
                FROM reactions r
                JOIN posts p ON p.id = r.post_id
                WHERE r.username IN ({in_placeholders})
                  AND p.community_id IN ({community_placeholders})
                ORDER BY r.id DESC
                LIMIT 400
                """,
                in_params + community_params,
            )
            reaction_rows = c.fetchall() or []
            c.execute(
                f"""
                SELECT rp.post_id, rp.username
                FROM replies rp
                JOIN posts p ON p.id = rp.post_id
                WHERE rp.username IN ({in_placeholders})
                  AND p.community_id IN ({community_placeholders})
                ORDER BY rp.id DESC
                LIMIT 400
                """,
                in_params + community_params,
            )
            reply_rows = c.fetchall() or []

            reaction_map: dict[int, List[str]] = defaultdict(list)
            reaction_ids: List[int] = []
            for row in reaction_rows:
                pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                reactor = row['username'] if hasattr(row, 'keys') else row[1]
                if not pid or not reactor:
                    continue
                reaction_ids.append(pid)
                reactor_clean = str(reactor).strip()
                if reactor_clean and reactor_clean not in reaction_map[pid]:
                    reaction_map[pid].append(reactor_clean)

            reply_map: dict[int, List[str]] = defaultdict(list)
            reply_ids: List[int] = []
            for row in reply_rows:
                pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                replier = row['username'] if hasattr(row, 'keys') else row[1]
                if not pid or not replier:
                    continue
                reply_ids.append(pid)
                replier_clean = str(replier).strip()
                if replier_clean and replier_clean not in reply_map[pid]:
                    reply_map[pid].append(replier_clean)

            combined_ids: List[int] = []
            seen: set[int] = set()
            for pid in authored_ids + reaction_ids + reply_ids:
                if not pid or pid in seen:
                    continue
                seen.add(pid)
                combined_ids.append(pid)
                if len(combined_ids) >= 50:
                    break

            if not combined_ids:
                return jsonify({'success': True, 'posts': []})

            post_placeholders = ','.join([get_sql_placeholder()] * len(combined_ids))
            c.execute(
                f"SELECT * FROM posts WHERE id IN ({post_placeholders}) ORDER BY id DESC",
                tuple(combined_ids),
            )
            raw_posts = [dict(row) for row in (c.fetchall() or [])]
            posts: List[dict[str, Any]] = []
            username_lower = username.lower() if isinstance(username, str) else ''
            for post in raw_posts:
                author = post.get('username')
                if author and username_lower and isinstance(author, str) and author.lower() == username_lower:
                    continue
                posts.append(post)
            if not posts:
                return jsonify({'success': True, 'posts': []})

            community_ids = {
                post.get('community_id')
                for post in posts
                if post.get('community_id')
            }
            community_map: Dict[int, str] = {}
            if community_ids:
                comm_placeholders = ','.join([get_sql_placeholder()] * len(community_ids))
                c.execute(
                    f"SELECT id, name FROM communities WHERE id IN ({comm_placeholders})",
                    tuple(community_ids),
                )
                for row in c.fetchall() or []:
                    cid = row['id'] if hasattr(row, 'keys') else row[0]
                    name = row['name'] if hasattr(row, 'keys') else row[1]
                    if cid:
                        community_map[cid] = name

            author_usernames = {
                post.get('username')
                for post in posts
                if post.get('username')
            }
            profile_map: Dict[str, str] = {}
            if author_usernames:
                profile_placeholders = ','.join([get_sql_placeholder()] * len(author_usernames))
                c.execute(
                    f"SELECT username, profile_picture FROM user_profiles WHERE username IN ({profile_placeholders})",
                    tuple(author_usernames),
                )
                for row in c.fetchall() or []:
                    uname = row['username'] if hasattr(row, 'keys') else row[0]
                    pic = row['profile_picture'] if hasattr(row, 'keys') else row[1]
                    if uname:
                        profile_map[uname] = pic

            def normalize_media_path(value: Optional[str]) -> Optional[str]:
                if not value:
                    return None
                path = str(value).strip()
                if not path:
                    return None
                if path.startswith('http://') or path.startswith('https://'):
                    return path
                if path.startswith('/'):
                    return path
                if path.startswith('uploads') or path.startswith('static'):
                    return f'/{path}'
                return f'/uploads/{path}'

            following_lookup = {name.lower(): name for name in followings if isinstance(name, str)}

            for post in posts:
                pid = post.get('id')
                post['community_name'] = community_map.get(post.get('community_id'))
                author = post.get('username')
                post['profile_picture'] = normalize_media_path(
                    profile_map.get(author) if author else None
                )
                post['image_path'] = normalize_media_path(post.get('image_path'))
                post['video_path'] = normalize_media_path(post.get('video_path'))
                post['followers_activity'] = {
                    'authored': bool(author and author.lower() in following_lookup),
                    'reacted_by': reaction_map.get(pid, [])[:3],
                    'replied_by': reply_map.get(pid, [])[:3],
                }

            return jsonify({'success': True, 'posts': posts})
    except Exception as e:
        logger.error(f"api_followers_feed error for {username}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/stripe/config', methods=['GET'])
@login_required
def api_stripe_config():
    """Expose publishable key so the client can initialize Stripe.js."""
    if not STRIPE_PUBLISHABLE_KEY:
        return jsonify({'success': False, 'error': 'stripe_not_configured'}), 400
    return jsonify({'success': True, 'publishableKey': STRIPE_PUBLISHABLE_KEY})


@app.route('/api/stripe/create_checkout_session', methods=['POST'])
@login_required
def api_stripe_create_checkout_session():
    """Create a Checkout session for upgrading to premium."""
    username = session.get('username')
    if not stripe or not STRIPE_API_KEY or STRIPE_API_KEY == DEFAULT_STRIPE_API_KEY:
        return jsonify({'success': False, 'error': 'Stripe is not configured'}), 400

    payload = request.get_json(silent=True) or {}
    plan_id = str(payload.get('plan_id', '')).strip().lower()
    billing_cycle = str(payload.get('billing_cycle', 'monthly')).strip().lower()
    if plan_id != 'premium':
        return jsonify({'success': False, 'error': 'Unsupported plan'}), 400
    if billing_cycle not in {'monthly', 'yearly'}:
        billing_cycle = 'monthly'

    price_key = STRIPE_PRICE_IDS.get(f'{plan_id}_{billing_cycle}')
    if not price_key:
        return jsonify({'success': False, 'error': 'Pricing is not configured'}), 400

    try:
        email_value = None
        with get_db_connection() as conn:
            c = conn.cursor()
            placeholder = get_sql_placeholder()
            c.execute(
                f"SELECT email FROM users WHERE username = {placeholder}",
                (username,),
            )
            row = c.fetchone()
            if row:
                email_value = row['email'] if hasattr(row, 'keys') else row[0]

        success_url = urljoin(request.host_url, 'success')
        cancel_url = urljoin(request.host_url, 'subscription_plans?status=cancelled')
        session_args = {
            'mode': 'subscription',
            'line_items': [{'price': price_key, 'quantity': 1}],
            'allow_promotion_codes': True,
            'success_url': success_url,
            'cancel_url': cancel_url,
            'metadata': {
                'plan_id': plan_id,
                'billing_cycle': billing_cycle,
                'username': username or '',
            },
        }
        if email_value:
            session_args['customer_email'] = email_value

        checkout_session = stripe.checkout.Session.create(**session_args)
        return jsonify({
            'success': True,
            'sessionId': checkout_session.get('id'),
            'url': checkout_session.get('url'),
        })
    except Exception as exc:
        logger.error(f"Stripe checkout creation failed for {username}: {exc}")
        return jsonify({'success': False, 'error': 'Unable to start checkout'}), 500


@app.route('/api/follow_requests/<username>/accept', methods=['POST'])
@login_required
def api_follow_request_accept(username):
    current_user = session.get('username')
    if not current_user:
        return jsonify({'success': False, 'error': 'Not authenticated'}), 401
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_followers_table(c)
            actual_follower = resolve_username_case(c, username)
            if not actual_follower:
                return jsonify({'success': False, 'error': 'Request not found'}), 404
            if actual_follower.lower() == current_user.lower():
                return jsonify({'success': False, 'error': 'Invalid follower'}), 400
            placeholder = get_sql_placeholder()
            c.execute(
                f"SELECT status FROM followers WHERE follower_username = {placeholder} AND followed_username = {placeholder}",
                (actual_follower, current_user)
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Request not found'}), 404
            status_val = row['status'] if hasattr(row, 'keys') and 'status' in row.keys() else row[0]
            if status_val != 'accepted':
                try:
                    if USE_MYSQL:
                        c.execute(
                            """
                            UPDATE followers
                            SET status = 'accepted', accepted_at = NOW()
                            WHERE follower_username = %s AND followed_username = %s
                            """,
                            (actual_follower, current_user)
                        )
                    else:
                        now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        c.execute(
                            """
                            UPDATE followers
                            SET status = 'accepted', accepted_at = ?
                            WHERE follower_username = ? AND followed_username = ?
                            """,
                            (now_str, actual_follower, current_user)
                        )
                except Exception as update_err:
                    logger.error(f"follow request accept update failed {actual_follower}->{current_user}: {update_err}")
                    return jsonify({'success': False, 'error': 'Could not accept request'}), 500
            conn.commit()

            summary_current = get_follow_summary(c, current_user)
            summary_follower = get_follow_summary(c, actual_follower)

            try:
                message = f"{current_user} accepted your follow request"
                create_notification(
                    user_id=actual_follower,
                    from_user=current_user,
                    notification_type='follow_accept',
                    message=message,
                    link=f"/profile/{current_user}"
                )
            except Exception as notif_err:
                logger.warning(f"follow accept notification insert failed {current_user}->{actual_follower}: {notif_err}")

            try:
                cleanup_ph = get_sql_placeholder()
                c.execute(
                    f"DELETE FROM notifications WHERE user_id = {cleanup_ph} AND from_user = {cleanup_ph} AND type = {cleanup_ph}",
                    (current_user, actual_follower, 'follow_request')
                )
                conn.commit()
            except Exception as cleanup_err:
                logger.warning(f"Failed clearing follow_request notification after acceptance {actual_follower}->{current_user}: {cleanup_err}")

            try:
                send_push_to_user(actual_follower, {
                    'title': 'Follow request accepted',
                    'body': f'{current_user} accepted your follow request',
                    'url': f'/profile/{current_user}',
                    'tag': f'follow-accepted-{current_user}-{actual_follower}'
                })
            except Exception as push_err:
                logger.warning(f"follow accept push failed {current_user}->{actual_follower}: {push_err}")

            return jsonify({
                'success': True,
                'counts': summary_current,
                'viewer_counts': summary_follower,
                'follower_username': actual_follower,
            })
    except Exception as e:
        logger.error(f"api_follow_request_accept error for {current_user}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/follow_requests/<username>', methods=['DELETE'])
@login_required
def api_follow_request_decline(username):
    current_user = session.get('username')
    if not current_user:
        return jsonify({'success': False, 'error': 'Not authenticated'}), 401
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_followers_table(c)
            actual_follower = resolve_username_case(c, username)
            if not actual_follower:
                return jsonify({'success': False, 'error': 'Request not found'}), 404
            placeholder = get_sql_placeholder()
            try:
                c.execute(
                    f"""
                    DELETE FROM followers
                    WHERE follower_username = {placeholder}
                      AND followed_username = {placeholder}
                      AND status = 'pending'
                    """,
                    (actual_follower, current_user)
                )
            except Exception as delete_err:
                logger.error(f"follow request decline delete failed {actual_follower}->{current_user}: {delete_err}")
                return jsonify({'success': False, 'error': 'Could not decline request'}), 500
            if getattr(c, 'rowcount', None) == 0:
                conn.commit()
                summary_current = get_follow_summary(c, current_user)
                return jsonify({'success': True, 'counts': summary_current})
            conn.commit()
            summary_current = get_follow_summary(c, current_user)
            try:
                cleanup_ph = get_sql_placeholder()
                c.execute(
                    f"DELETE FROM notifications WHERE user_id = {cleanup_ph} AND from_user = {cleanup_ph} AND type = {cleanup_ph}",
                    (current_user, actual_follower, 'follow_request')
                )
                conn.commit()
            except Exception as cleanup_err:
                logger.warning(f"Failed clearing follow_request notification after decline {actual_follower}->{current_user}: {cleanup_err}")
            return jsonify({'success': True, 'counts': summary_current})
    except Exception as e:
        logger.error(f"api_follow_request_decline error for {current_user}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/profile/<username>')
def public_profile(username):
    """Public profile page for any user"""
    logger.info(f"=== PROFILE ROUTE ACCESSED ===")
    logger.info(f"Username parameter: {username}")
    logger.info(f"Request URL: {request.url}")
    logger.info(f"Request path: {request.path}")
    try:
        # Serve React for all devices
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        return send_from_directory(dist_dir, 'index.html')

        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user exists (case-insensitive)
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM users WHERE LOWER(username) = LOWER({ph})", (username,))
            user = c.fetchone()
            if not user:
                logger.warning(f"User not found: {username}")
                flash('User not found', 'error')
                return redirect(url_for('feed'))
            actual_username = user['username'] if hasattr(user, 'keys') else user[0]
            
            # Get profile data for JSON API fallback
            c.execute(f"""
                SELECT u.username, u.email, u.subscription,
                       p.display_name, p.bio, p.location, p.website, 
                       p.instagram, p.twitter, p.profile_picture, p.cover_photo,
                       p.is_public
                FROM users u
                LEFT JOIN user_profiles p ON u.username = p.username
                WHERE u.username = {ph}
            """, (actual_username,))
            
            profile_data = c.fetchone()
            
            # This should never happen if user exists (checked above)
            if not profile_data:
                logger.error(f"Critical: User exists but no data returned for: {username}")
                flash('Profile data error', 'error')
                return redirect(url_for('feed'))
                
            logger.info(f"Profile data found for {username}")
            
            # Get user's posts
            c.execute(f"""
                SELECT id, content, image_path, timestamp 
                FROM posts 
                WHERE username = {ph} 
                ORDER BY timestamp DESC 
                LIMIT 20
            """, (actual_username,))
            posts = c.fetchall()
            
            # Get user's communities
            try:
                c.execute(f"""
                    SELECT c.id, c.name, c.description, c.accent_color
                    FROM communities c
                    JOIN user_communities uc ON c.id = uc.community_id
                    JOIN users u ON uc.user_id = u.id
                    WHERE u.username = {ph}
                    ORDER BY c.name
                """, (actual_username,))
                communities = c.fetchall()
                logger.info(f"Found {len(communities)} communities for {username}")
            except Exception as e:
                logger.error(f"Error fetching communities for {username}: {str(e)}")
                communities = []  # Continue with empty communities list instead of failing
            
            # Check if viewing own profile
            is_own_profile = 'username' in session and session['username'] == actual_username
            
            return render_template('public_profile.html',
                                 profile=profile_data,
                                 posts=posts,
                                 communities=communities,
                                 is_own_profile=is_own_profile,
                                 username=session.get('username'))
                                 
    except Exception as e:
        logger.error(f"Error loading profile for {username}: {str(e)}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        flash('Error loading profile', 'error')
        return redirect(url_for('feed'))

@app.route('/verify_email')
def verify_email():
    token = request.args.get('token', '')
    if not token:
        return render_template('verification_result.html', success=False, message='Invalid verification link')
    # New flow: finalize pending signup if token matches pending
    pending = verify_pending_signup_token(token)
    if pending:
        try:
            with get_db_connection() as conn:
                c = conn.cursor()
                c.execute("SELECT id, username, email, password, first_name, last_name, mobile FROM pending_signups WHERE id=?", (pending['pending_id'],))
                row = c.fetchone()
                if not row:
                    return render_template('verification_result.html', success=False, message='Pending registration not found or expired')
                def _val(r, key, idx):
                    return (r[key] if hasattr(r,'keys') else r[idx])
                pend_email = _val(row, 'email', 2) or ''
                if pend_email.lower() != str(pending.get('email','')).lower():
                    return render_template('verification_result.html', success=False, message='Verification link mismatch')
                # ensure username unique
                base_username = (_val(row, 'username', 1) or pend_email.split('@')[0] or 'user')
                import re as _re
                base_username = _re.sub(r'[^a-z0-9_]', '', base_username.lower()) or 'user'
                username = base_username
                try:
                    suffix = 1
                    while True:
                        c.execute("SELECT 1 FROM users WHERE username=?", (username,))
                        if not c.fetchone():
                            break
                        suffix += 1
                        username = f"{base_username}{suffix}"
                except Exception:
                    pass
                # if email exists, just mark verified, else insert
                c.execute("SELECT id FROM users WHERE email=?", (pend_email,))
                exists = c.fetchone()
                if exists:
                    c.execute("UPDATE users SET email_verified=1, email_verified_at=COALESCE(email_verified_at, ?) WHERE email=?", (datetime.now().isoformat(), pend_email))
                else:
                    first_name = _val(row, 'first_name', 4) or ''
                    last_name = _val(row, 'last_name', 5) or ''
                    password_hash = _val(row, 'password', 3)
                    mobile = _val(row, 'mobile', 6) or ''
                    c.execute("""
                        INSERT INTO users (username, email, password, first_name, last_name, age, gender, primary_goal, subscription, created_at, email_verified, email_verified_at)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, 'free', ?, 1, ?)
                    """, (username, pend_email, password_hash, first_name, last_name, None, '', '', datetime.now().strftime('%m.%d.%y %H:%M'), datetime.now().isoformat()))
                    if mobile:
                        c.execute("UPDATE users SET mobile=? WHERE username=?", (mobile, username))
                # cleanup pending
                try:
                    c.execute("DELETE FROM pending_signups WHERE id=?", (pending['pending_id'],))
                except Exception:
                    pass
                conn.commit()
            return render_template('verification_result.html', success=True, message='Your email has been verified! You can now sign in.')
        except Exception as e:
            logger.error(f"verify_email finalize error: {e}")
            return render_template('verification_result.html', success=False, message='Server error while finalizing registration')
    email = verify_email_token(token)
    if not email:
        return render_template('verification_result.html', success=False, message='Verification link is invalid or expired')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Only set email_verified_at on FIRST verification (when it's NULL)
            # This ensures the timestamp always represents the first time they verified
            c.execute("UPDATE users SET email_verified=1, email_verified_at=COALESCE(email_verified_at, ?) WHERE email=?", (datetime.now().isoformat(), email))
            conn.commit()
        return render_template('verification_result.html', success=True, message='Your email has been verified! You can close this tab.')
    except Exception as e:
        logger.error(f"verify_email error: {e}")
        return render_template('verification_result.html', success=False, message='Server error while verifying email')

@app.route('/resend_verification', methods=['POST'])
@login_required
def resend_verification():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT email, email_verification_sent_at FROM users WHERE username=?", (username,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'User not found'}), 404
            email = row['email'] if hasattr(row, 'keys') else row[0]
            sent_at = row['email_verification_sent_at'] if hasattr(row, 'keys') else (row[1] if len(row) > 1 else None)
            # Rate limit: 10 minutes
            if sent_at:
                try:
                    last = parsedate_to_datetime(sent_at) if isinstance(sent_at, str) and ',' in sent_at else datetime.fromisoformat(str(sent_at))
                    if datetime.now() - last < timedelta(minutes=10):
                        return jsonify({'success': False, 'error': 'Please wait before resending'}), 429
                except Exception:
                    pass
            token = generate_email_token(email)
            verify_url = _build_verify_url(token)
            subject = "Verify your C-Point email"
            html = f"""
                <div style='font-family:Arial,sans-serif;font-size:14px;color:#111'>
                  <p>Verify your email: <a href='{verify_url}'>{verify_url}</a></p>
                </div>
            """
            ok = _send_email_via_resend(email, subject, html)
            if ok:
                try:
                    c.execute("UPDATE users SET email_verification_sent_at=? WHERE username=?", (datetime.now().isoformat(), username))
                    conn.commit()
                except Exception:
                    pass
                return jsonify({'success': True})
            return jsonify({'success': False, 'error': 'Failed to send email'}), 500
    except Exception as e:
        logger.error(f"resend_verification error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/resend_verification_pending', methods=['POST'])
def resend_verification_pending():
    """Resend verification for a pending signup. Accepts email in form or JSON body.
    Does not require login."""
    try:
        email = request.form.get('email') or (request.json or {}).get('email') if request.is_json else None
        if not email:
            return jsonify({'success': False, 'error': 'email required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_pending_signups_table(c)
            c.execute("SELECT id, verification_sent_at FROM pending_signups WHERE email=?", (email,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'No pending signup for this email'}), 404
            pend_id = row['id'] if hasattr(row,'keys') else row[0]
            # No rate limit: always attempt to resend immediately
            token = generate_pending_signup_token(int(pend_id), email)
            verify_url = _build_verify_url(token)
            subject = "Verify your C-Point email"
            html = f"""
                <div style='font-family:Arial,sans-serif;font-size:14px;color:#111'>
                  <p>Verify your email: <a href='{verify_url}'>{verify_url}</a></p>
                </div>
            """
            ok = _send_email_via_resend(email, subject, html)
            # Always respond success for UX; log failures but don't block
            try:
                c.execute("UPDATE pending_signups SET verification_sent_at=? WHERE id=?", (datetime.now().isoformat(), pend_id))
                conn.commit()
            except Exception:
                pass
            if not ok:
                try:
                    logger.warning("Resend via Resend API failed; returning success to client for UX")
                except Exception:
                    pass
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"resend_verification_pending error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/api/email_verified_status', methods=['POST'])
def api_email_verified_status():
    """Public endpoint to check if an email has been verified.
    Returns { success: true, verified: boolean } and never reveals more.
    """
    try:
        email = None
        try:
            if request.is_json:
                data = request.get_json(silent=True) or {}
                email = (data.get('email') or '').strip()
        except Exception:
            email = None
        if not email:
            email = (request.form.get('email') or '').strip()
        if not email:
            return jsonify({'success': False, 'error': 'email required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                c.execute("SELECT email_verified FROM users WHERE email=?", (email,))
                row = c.fetchone()
                if row is None:
                    return jsonify({'success': True, 'verified': False})
                verified = bool(row['email_verified'] if hasattr(row, 'keys') else row[0])
                return jsonify({'success': True, 'verified': bool(verified)})
            except Exception:
                # On any error, do not leak state
                return jsonify({'success': True, 'verified': False})
    except Exception:
        return jsonify({'success': True, 'verified': False})

@app.route('/account_settings')
@login_required
def account_settings():
    """Account settings page - serves React app for mobile, HTML for desktop"""
    username = session['username']
    try:
        # Smart UA: mobile -> SPA, desktop -> HTML template
        ua = request.headers.get('User-Agent', '')
        is_mobile = any(k in ua for k in ['Mobi', 'Android', 'iPhone', 'iPad'])
        
        if is_mobile:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            dist_dir = os.path.join(base_dir, 'client', 'dist')
            return send_from_directory(dist_dir, 'index.html')
        else:
            # Desktop: serve HTML template
            with get_db_connection() as conn:
                c = conn.cursor()
                c.execute("SELECT username, email, subscription FROM users WHERE username=?", (username,))
                user = c.fetchone()
                
            if user:
                # Serve React app for account settings
                base_dir = os.path.dirname(os.path.abspath(__file__))
                dist_dir = os.path.join(base_dir, 'client', 'dist')
                index_path = os.path.join(dist_dir, 'index.html')
                if os.path.exists(index_path):
                    return send_from_directory(dist_dir, 'index.html')
                return redirect('/account_settings_react')
            flash("User not found!", "error")
            return redirect('/')
    except Exception as e:
        logger.error(f"Error in account settings for {username}: {str(e)}")
        abort(500)

@app.route('/profile')
@login_required
def profile():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get user data and profile data (only columns that definitely exist)
            c.execute("""
                SELECT u.username, u.email, u.subscription,
                       p.display_name, p.bio, p.location, p.website, 
                       p.instagram, p.twitter, p.profile_picture, p.cover_photo
                FROM users u
                LEFT JOIN user_profiles p ON u.username = p.username
                WHERE u.username = ?
            """, (username,))
            user = c.fetchone()
            
        if user:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            dist_dir = os.path.join(base_dir, 'client', 'dist')
            try:
                return send_from_directory(dist_dir, 'index.html')
            except Exception as serve_err:
                logger.warning(f"Failed to serve React profile page: {serve_err}")
                return redirect('/profile_react')
        flash("User profile not found!", "error")
        return redirect('/')
    except Exception as e:
        logger.error(f"Error in profile for {username}: {str(e)}")
        abort(500)

@app.route('/api/profile_me')
@login_required
def api_profile_me():
    username = session['username']
    
    # Check cache first for faster profile loading
    cache_key = f"profile:{username}"
    cached_profile = cache.get(cache_key)
    if cached_profile:
        logger.debug(f"üöÄ Cache hit: profile for {username}")
        return jsonify({'success': True, 'profile': cached_profile})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT u.username, u.email, u.subscription, u.email_verified, u.email_verified_at,
                       u.first_name, u.last_name, u.gender, u.country, u.city, u.date_of_birth, u.age,
                       p.display_name, p.bio, p.location, p.website,
                       p.instagram, p.twitter, p.profile_picture, p.cover_photo
                FROM users u
                LEFT JOIN user_profiles p ON u.username = p.username
                WHERE u.username = ?
            """, (username,))
            row = c.fetchone()
            if not row:
                return jsonify({ 'success': False, 'error': 'not found' }), 404
            def get_val(key_or_idx):
                try:
                    if hasattr(row, 'keys'):
                        if isinstance(key_or_idx, str):
                            return row.get(key_or_idx)
                        return row[key_or_idx]
                    else:
                        return row[key_or_idx]
                except Exception:
                    return None
            profile = {
                'username': username,
                'email': get_val('email') if hasattr(row, 'keys') else row[1],
                'subscription': get_val('subscription') if hasattr(row, 'keys') else row[2],
                'email_verified': bool(get_val('email_verified') if hasattr(row, 'keys') else row[3]),
                'email_verified_at': get_val('email_verified_at') if hasattr(row, 'keys') else row[4],
                'first_name': get_val('first_name') if hasattr(row, 'keys') else row[5],
                'last_name': get_val('last_name') if hasattr(row, 'keys') else row[6],
                'gender': get_val('gender') if hasattr(row, 'keys') else row[7],
                'country': get_val('country') if hasattr(row, 'keys') else row[8],
                'city': get_val('city') if hasattr(row, 'keys') else row[9],
                'date_of_birth': get_val('date_of_birth') if hasattr(row, 'keys') else row[10],
                'age': get_val('age') if hasattr(row, 'keys') else row[11],
                'display_name': get_val('display_name') if hasattr(row, 'keys') else row[12],
                'bio': get_val('bio') if hasattr(row, 'keys') else row[13],
                'location': get_val('location') if hasattr(row, 'keys') else row[14],
                'website': get_val('website') if hasattr(row, 'keys') else row[15],
                'instagram': get_val('instagram') if hasattr(row, 'keys') else row[16],
                'twitter': get_val('twitter') if hasattr(row, 'keys') else row[17],
                'profile_picture': get_val('profile_picture') if hasattr(row, 'keys') else row[18],
                'cover_photo': get_val('cover_photo') if hasattr(row, 'keys') else row[19],
                'personal': {
                    'display_name': (get_val('display_name') if hasattr(row, 'keys') else row[12]) or username,
                    'date_of_birth': get_val('date_of_birth') if hasattr(row, 'keys') else row[10],
                    'gender': get_val('gender') if hasattr(row, 'keys') else row[7],
                    'country': get_val('country') if hasattr(row, 'keys') else row[8],
                    'city': get_val('city') if hasattr(row, 'keys') else row[9],
                }
            }
            
            # Cache profile for faster future requests
            from redis_cache import USER_CACHE_TTL
            cache.set(cache_key, profile, USER_CACHE_TTL)  # Optimized TTL
            logger.debug(f"üíæ Cached profile for {username}")
            
            return jsonify({ 'success': True, 'profile': profile })
    except Exception as e:
        logger.error(f"Error in api_profile_me: {e}")
        logger.error(f"Error details: {str(e)}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500


@app.route('/api/geo/countries')
@login_required
def api_geo_countries():
    try:
        countries = get_cached_countries()
        return jsonify({'success': True, 'countries': countries})
    except Exception as e:
        logger.error(f"Failed to load countries: {e}")
        return jsonify({'success': False, 'error': 'Failed to load countries'}), 500


@app.route('/api/geo/cities')
@login_required
def api_geo_cities():
    country = (request.args.get('country') or '').strip()
    if not country:
        return jsonify({'success': False, 'error': 'country required'}), 400
    try:
        cities = get_cached_cities(country)
        return jsonify({'success': True, 'country': country, 'cities': cities})
    except Exception as e:
        logger.error(f"Failed to load cities for {country}: {e}")
        return jsonify({'success': False, 'error': 'Failed to load cities'}), 500

@app.route('/upload_logo', methods=['POST'])
@login_required
def upload_logo():
    """Upload a new logo (admin only)"""
    username = session.get('username')
    
    # Check if user is admin
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            if 'logo' not in request.files:
                return jsonify({'success': False, 'error': 'No file provided'})

            file = request.files['logo']
            if file.filename == '':
                return jsonify({'success': False, 'error': 'No file selected'})

            if file and allowed_file(file.filename):
                # Save the logo file
                filename = 'logo.png'  # Always save as logo.png
                filepath = os.path.join('static', filename)
                file.save(filepath)

            # Generate PWA/app icons from uploaded logo (both new and legacy names)
            try:
                from PIL import Image
                icons_dir = os.path.join('static', 'icons')
                os.makedirs(icons_dir, exist_ok=True)
                src = Image.open(filepath).convert('RGBA')

                def make_icon(size: int, out_name: str):
                    canvas = Image.new('RGBA', (size, size), (0, 0, 0, 0))
                    img = src.copy()
                    img.thumbnail((size, size), Image.LANCZOS)
                    ox = max(0, (size - img.width) // 2)
                    oy = max(0, (size - img.height) // 2)
                    canvas.paste(img, (ox, oy), img)
                    canvas.save(os.path.join(icons_dir, out_name), format='PNG')

                # New names
                make_icon(192, 'app-icon-192.png')
                make_icon(512, 'app-icon-512.png')
                # Legacy names referenced by some manifests
                make_icon(192, 'icon-192.png')
                make_icon(512, 'icon-512.png')
                # Apple touch icon
                make_icon(180, 'apple-touch-icon-180.png')
            except Exception as _gen_err:
                logger.warning(f"Icon generation skipped on upload: {_gen_err}")

                # Ensure site_settings table exists and upsert logo path (SQLite vs MySQL)
                try:
                    if USE_MYSQL:
                        # Create table if missing (MySQL)
                        c.execute(
                            """
                            CREATE TABLE IF NOT EXISTS site_settings (
                                `key` VARCHAR(191) PRIMARY KEY,
                                `value` TEXT
                            )
                            """
                        )
                        # Upsert using ON DUPLICATE KEY UPDATE
                        c.execute(
                            "INSERT INTO site_settings (`key`, `value`) VALUES (%s, %s) ON DUPLICATE KEY UPDATE `value`=VALUES(`value`)",
                            ('logo_path', filename)
                        )
                    else:
                        # Create table if missing (SQLite)
                        c.execute(
                            """
                            CREATE TABLE IF NOT EXISTS site_settings (
                                key TEXT PRIMARY KEY,
                                value TEXT
                            )
                            """
                        )
                        # Upsert using SQLite syntax
                        c.execute(
                            "INSERT INTO site_settings (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value=excluded.value",
                            ('logo_path', filename)
                        )
                    conn.commit()
                except Exception as db_err:
                    logger.error(f"Logo upsert error: {db_err}")
                    raise

                return jsonify({
                    'success': True,
                    'message': 'Logo uploaded successfully',
                    'logo_url': url_for('static', filename=filename)
                })
            else:
                return jsonify({'success': False, 'error': 'Invalid file type'})
            
    except Exception as e:
        logger.error(f"Error uploading logo: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'})
@app.route('/upload_signup_image', methods=['POST'])
@login_required
def upload_signup_image():
    """Upload the left-side signup image (admin only)"""
    username = session.get('username')
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    try:
        if 'image' not in request.files:
            return jsonify({'success': False, 'error': 'No file provided'})
        file = request.files['image']
        if file.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'})
        if file and allowed_file(file.filename):
            filename = 'signup_side.jpg'
            filepath = os.path.join('static', filename)
            file.save(filepath)
            return jsonify({'success': True, 'image_url': url_for('static', filename=filename)})
        return jsonify({'success': False, 'error': 'Invalid file type'})
    except Exception as e:
        logger.error(f"Error uploading signup image: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/admin/regenerate_app_icons', methods=['POST'])
@login_required
def regenerate_app_icons():
    """Regenerate PWA icons from current logo - ADMIN ONLY"""
    username = session.get('username')
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    try:
        logo_path = os.path.join('static', 'logo.png')
        if not os.path.exists(logo_path):
            return jsonify({'success': False, 'error': 'logo.png not found. Upload a logo first.'}), 400
        # Best-effort icon generation
        try:
            from PIL import Image
            icons_dir = os.path.join('static', 'icons')
            os.makedirs(icons_dir, exist_ok=True)
            src = Image.open(logo_path).convert('RGBA')

            def make_icon(size: int, out_name: str):
                canvas = Image.new('RGBA', (size, size), (0, 0, 0, 0))
                img = src.copy()
                img.thumbnail((size, size), Image.LANCZOS)
                ox = max(0, (size - img.width) // 2)
                oy = max(0, (size - img.height) // 2)
                canvas.paste(img, (ox, oy), img)
                out_path = os.path.join(icons_dir, out_name)
                canvas.save(out_path, format='PNG')

            # New and legacy names to satisfy various manifests
            make_icon(192, 'app-icon-192.png')
            make_icon(512, 'app-icon-512.png')
            make_icon(192, 'icon-192.png')
            make_icon(512, 'icon-512.png')
            # Apple touch icon common size
            make_icon(180, 'apple-touch-icon-180.png')
        except Exception as gen_err:
            logger.warning(f"Icon generation skipped: {gen_err}")

        # Bump a version based on mtime for clients to cache-bust
        try:
            v = int(time.time())
        except Exception:
            v = 0
        return jsonify({'success': True, 'message': 'App icons regenerated', 'version': v})
    except Exception as e:
        logger.error(f"regenerate_app_icons error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/apple-touch-icon.png')
def apple_touch_icon_route():
    """Serve iOS touch icon with minimal caching."""
    try:
        preferred = os.path.join('static', 'icons', 'apple-touch-icon-180.png')
        fallback = os.path.join('static', 'icons', 'icon-192.png')
        # Use absolute BASE_DIR to be safe under WSGI
        abs_preferred = os.path.join(BASE_DIR, preferred)
        abs_fallback = os.path.join(BASE_DIR, fallback)
        path = abs_preferred if os.path.exists(abs_preferred) else abs_fallback
        from flask import send_file
        resp = send_file(path, mimetype='image/png')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"apple-touch-icon route error: {e}")
        abort(404)

@app.route('/icons/<path:filename>')
def serve_generated_icons(filename):
    """Serve generated PWA icons from static/icons with no-cache headers."""
    try:
        directory = os.path.join('static', 'icons')
        resp = send_from_directory(directory, filename)
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.warning(f"icons serve error: {e}")
        abort(404)

@app.route('/check_profile_picture')
@login_required
def check_profile_picture():
    """Debug route to check profile picture status"""
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT profile_picture FROM user_profiles WHERE username=?", (username,))
            result = c.fetchone()
            if result:
                return f"Profile picture for {username}: {result['profile_picture']}"
            else:
                return f"No profile found for {username}"
    except Exception as e:
        return f"Error: {str(e)}"
@app.route('/update_public_profile', methods=['POST'])
@login_required
def update_public_profile():
    """Update public profile information"""
    username = session['username']
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get form data
            display_name = request.form.get('display_name', '').strip()
            bio = request.form.get('bio', '').strip()
            location = request.form.get('location', '').strip()
            website = request.form.get('website', '').strip()
            instagram = request.form.get('instagram', '').strip()
            twitter = request.form.get('twitter', '').strip()
            is_public = 1 if request.form.get('is_public') == 'on' else 0
            
            # Handle profile picture upload
            profile_picture_path = None
            if 'profile_picture' in request.files:
                file = request.files['profile_picture']
                logger.info(f"Profile picture upload attempt for {username}: {file.filename if file else 'No file'}")
                
                if file and file.filename != '' and allowed_file(file.filename):
                    # Save the uploaded file
                    profile_picture_path = save_uploaded_file(file, subfolder='profile_pictures')
                    logger.info(f"Profile picture saved for {username}: {profile_picture_path}")
                    
                    # Get current profile picture to delete old one if exists
                    c.execute("SELECT profile_picture FROM user_profiles WHERE username=?", (username,))
                    old_profile = c.fetchone()
                    if old_profile and old_profile['profile_picture']:
                        # Delete old profile picture file
                        old_path = os.path.join('static', old_profile['profile_picture'])
                        if os.path.exists(old_path):
                            try:
                                os.remove(old_path)
                                logger.info(f"Deleted old profile picture: {old_path}")
                            except Exception as e:
                                logger.warning(f"Could not delete old profile picture: {e}")
            
            # Check if profile exists
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM user_profiles WHERE username = {ph}", (username,))
            exists = c.fetchone()
            
            if exists:
                # Update existing profile
                if profile_picture_path:
                    c.execute("""
                        UPDATE user_profiles 
                        SET display_name=?, bio=?, location=?, website=?, 
                            instagram=?, twitter=?, is_public=?, 
                            profile_picture=?, updated_at=CURRENT_TIMESTAMP
                        WHERE username=?
                    """, (display_name, bio, location, website, instagram, 
                         twitter, is_public, profile_picture_path, username))
                    logger.info(f"Updated profile with picture for {username}: {profile_picture_path}")
                else:
                    c.execute("""
                        UPDATE user_profiles 
                        SET display_name=?, bio=?, location=?, website=?, 
                            instagram=?, twitter=?, is_public=?, 
                            updated_at=CURRENT_TIMESTAMP
                        WHERE username=?
                    """, (display_name, bio, location, website, instagram, 
                         twitter, is_public, username))
                    logger.info(f"Updated profile without picture for {username}")
            else:
                # Create new profile
                c.execute("""
                    INSERT INTO user_profiles 
                    (username, display_name, bio, location, website, 
                     instagram, twitter, is_public, profile_picture)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (username, display_name, bio, location, website, 
                     instagram, twitter, is_public, profile_picture_path))
                logger.info(f"Created new profile with picture for {username}: {profile_picture_path}")
            
            conn.commit()
            logger.info(f"Profile committed to database for {username}")
            # Invalidate cached profile so clients see updates immediately
            try:
                invalidate_user_cache(username)
            except Exception:
                pass
            flash('Public profile updated successfully!', 'success')
            
    except Exception as e:
        logger.error(f"Error updating public profile: {str(e)}")
        flash('Error updating profile', 'error')
    
    return redirect(url_for('profile'))

@app.route('/upload_profile_picture', methods=['POST'])
@login_required
def upload_profile_picture():
    """Upload profile picture"""
    username = session['username']

    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Handle profile picture upload
            profile_picture_path = None
            if 'profile_picture' in request.files:
                file = request.files['profile_picture']
                logger.info(f"Profile picture upload attempt for {username}: {file.filename if file else 'No file'}")

                if file and file.filename != '' and allowed_file(file.filename):
                    # Save the uploaded file
                    profile_picture_path = save_uploaded_file(file, subfolder='profile_pictures')
                    logger.info(f"Profile picture saved for {username}: {profile_picture_path}")

                    # Get current profile picture to delete old one if exists
                    c.execute("SELECT profile_picture FROM user_profiles WHERE username=?", (username,))
                    old_profile = c.fetchone()
                    if old_profile and old_profile['profile_picture']:
                        old_path = os.path.join(app.root_path, 'static', old_profile['profile_picture'].lstrip('/'))
                        try:
                            os.remove(old_path)
                            logger.info(f"Deleted old profile picture: {old_path}")
                        except Exception as e:
                            logger.warning(f"Could not delete old profile picture: {e}")

            if profile_picture_path:
                # Check if profile exists
                c.execute("SELECT username FROM user_profiles WHERE username=?", (username,))
                exists = c.fetchone()

                if exists:
                    # Update existing profile
                    c.execute("""
                        UPDATE user_profiles
                        SET profile_picture=?, updated_at=CURRENT_TIMESTAMP
                        WHERE username=?
                    """, (profile_picture_path, username))
                    logger.info(f"Updated profile picture for {username}: {profile_picture_path}")
                else:
                    # Create new profile with just the picture
                    c.execute("""
                        INSERT INTO user_profiles (username, profile_picture)
                        VALUES (?, ?)
                    """, (username, profile_picture_path))
                    logger.info(f"Created new profile with picture for {username}: {profile_picture_path}")

                conn.commit()
                logger.info(f"Profile picture committed to database for {username}")
                try:
                    invalidate_user_cache(username)
                except Exception:
                    pass
                return jsonify({'success': True, 'profile_picture': profile_picture_path})
            else:
                return jsonify({'success': False, 'error': 'No file uploaded'}), 400

    except Exception as e:
        logger.error(f"Error uploading profile picture: {str(e)}")
        return jsonify({'success': False, 'error': 'Upload failed'}), 500

@app.route('/update_password', methods=['POST'])
@login_required
def update_password():
    username = session['username']
    current_password = request.form.get('current_password')
    new_password = request.form.get('new_password')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT password FROM users WHERE username=?", (username,))
            user = c.fetchone()
            
            if not user:
                return jsonify({'success': False, 'error': 'User not found'})
            
            stored_password = user['password']
            
            # Check current password - handle both hashed and plain text
            if stored_password and (stored_password.startswith('$') or stored_password.startswith('scrypt:') or stored_password.startswith('pbkdf2:')):
                # Password is hashed
                if not check_password_hash(stored_password, current_password):
                    return jsonify({'success': False, 'error': 'Current password is incorrect'})
            else:
                # Password is plain text (legacy)
                if stored_password != current_password:
                    return jsonify({'success': False, 'error': 'Current password is incorrect'})
            
            # Hash the new password before storing
            hashed_password = generate_password_hash(new_password)
            c.execute("UPDATE users SET password=? WHERE username=?", (hashed_password, username))
            conn.commit()
            
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error updating password for {username}: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/update_email', methods=['POST'])
@login_required
def update_email():
    username = session['username']
    new_email = request.form.get('new_email') or request.form.get('email')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            if not new_email:
                return jsonify({'success': False, 'error': 'Email required'}), 400

            # Check if email is already taken
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM users WHERE email={ph} AND username!={ph}", (new_email, username))
            existing_user = c.fetchone()
            if existing_user:
                return jsonify({'success': False, 'error': 'Email is already in use'})
            
            # Update email and mark as unverified
            c.execute(f"UPDATE users SET email={ph}, email_verified=0 WHERE username={ph}", (new_email, username))
            try:
                c.execute(f"UPDATE users SET email_verification_sent_at={ph} WHERE username={ph}", (datetime.now().isoformat(), username))
            except Exception:
                pass
            conn.commit()

            # Send verification email to new address
            try:
                token = generate_email_token(new_email)
                verify_url = _build_verify_url(token)
                subject = "Verify your new C-Point email"
                html = f"""
                    <div style='font-family:Arial,sans-serif;font-size:14px;color:#111'>
                      <p>You requested to change the email on your C-Point account.</p>
                      <p>Please verify your new email address by clicking below:</p>
                      <p><a href='{verify_url}' style='display:inline-block;background:#111;color:#fff;padding:10px 16px;border-radius:6px;text-decoration:none'>Verify Email</a></p>
                      <p>Or open this link: <a href='{verify_url}'>{verify_url}</a></p>
                      <p>This link expires in 24 hours.</p>
                    </div>
                """
                sent_ok = _send_email_via_resend(new_email, subject, html)
            except Exception as e:
                logger.warning(f"Could not send verification email for update_email: {e}")
                sent_ok = False
            
            return jsonify({'success': True, 'verification_sent': bool(sent_ok)})
    except Exception as e:
        logger.error(f"Error updating email for {username}: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/update_professional', methods=['POST'])
@login_required
def update_professional():
    """Update professional information"""
    username = session['username']
    try:
        role = request.form.get('role', '').strip()
        company = request.form.get('company', '').strip()
        industry = request.form.get('industry', '').strip()
        degree = request.form.get('degree', '').strip()
        school = request.form.get('school', '').strip()
        skills = request.form.get('skills', '').strip()
        linkedin = request.form.get('linkedin', '').strip()
        experience = request.form.get('experience', type=int)
        professional_about = request.form.get('about', '').strip()
        interests_raw = (request.form.get('interests') or '').strip()
        interests_payload = None
        if interests_raw:
            try:
                parsed = json.loads(interests_raw)
                if isinstance(parsed, list):
                    cleaned = [str(item).strip() for item in parsed if isinstance(item, (str, int, float)) and str(item).strip()]
                    if cleaned:
                        interests_payload = json.dumps(cleaned)
                else:
                    raise ValueError("unexpected format")
            except Exception:
                cleaned = [part.strip() for part in interests_raw.split(',') if part and part.strip()]
                if cleaned:
                    interests_payload = json.dumps(cleaned)
        share_raw = request.form.get('share_community_id')
        professional_share_community_id = None
        try:
            if share_raw not in (None, '', 'null', 'None'):
                share_int = int(share_raw)
                professional_share_community_id = share_int if share_int > 0 else None
        except Exception:
            professional_share_community_id = None
        
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            update_sql = f"""
                UPDATE users SET 
                    role={ph}, company={ph}, industry={ph}, degree={ph}, school={ph}, 
                    skills={ph}, linkedin={ph}, experience={ph}, professional_about={ph},
                    professional_interests={ph}, professional_share_community_id={ph}
                WHERE username={ph}
            """
            c.execute(update_sql, (
                role, company, industry, degree, school, skills, linkedin, experience, professional_about,
                interests_payload, professional_share_community_id, username
            ))
            conn.commit()
        
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error updating professional info for {username}: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/update_personal_info', methods=['POST'])
@login_required
def update_personal_info():
    username = session['username']
    display_name = (request.form.get('display_name') or '').strip()
    bio_text = (request.form.get('bio') or '').strip()
    date_of_birth = request.form.get('date_of_birth')
    gender = (request.form.get('gender') or '').strip() or None
    country = (request.form.get('country') or '').strip() or None
    city = (request.form.get('city') or '').strip() or None
    age = request.form.get('age')  # legacy support
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Convert age to appropriate type
            age_val = None
            if date_of_birth:
                try:
                    dob_obj = datetime.strptime(date_of_birth, '%Y-%m-%d')
                    today = datetime.utcnow().date()
                    age_val = int((today - dob_obj.date()).days / 365.2425)
                    date_of_birth_iso = dob_obj.strftime('%Y-%m-%d')
                except Exception:
                    date_of_birth_iso = None
            else:
                date_of_birth_iso = None
            # Fallback to provided age if DOB not supplied
            if age and age_val is None:
                try:
                    age_val = int(age)
                except Exception:
                    age_val = None
            c.execute("""UPDATE users SET age=?, gender=?, country=?, city=?, date_of_birth=? 
                        WHERE username=?""", (age_val, gender, country, city, date_of_birth_iso, username))
            
            if display_name:
                try:
                    if USE_MYSQL:
                        c.execute(
                            "INSERT INTO user_profiles (username, display_name) VALUES (%s, %s) "
                            "ON DUPLICATE KEY UPDATE display_name=VALUES(display_name)",
                            (username, display_name)
                        )
                    else:
                        c.execute(
                            "INSERT INTO user_profiles (username, display_name) VALUES (?, ?) "
                            "ON CONFLICT(username) DO UPDATE SET display_name=excluded.display_name",
                            (username, display_name)
                        )
                except Exception as profile_err:
                    logger.warning(f"Failed to upsert display name for {username}: {profile_err}")

            bio_value = bio_text or None
            try:
                if USE_MYSQL:
                    c.execute(
                        "INSERT INTO user_profiles (username, bio) VALUES (%s, %s) "
                        "ON DUPLICATE KEY UPDATE bio=VALUES(bio)",
                        (username, bio_value)
                    )
                else:
                    c.execute(
                        "INSERT INTO user_profiles (username, bio) VALUES (?, ?) "
                        "ON CONFLICT(username) DO UPDATE SET bio=excluded.bio",
                        (username, bio_value)
                    )
            except Exception as bio_err:
                logger.warning(f"Failed to update bio for {username}: {bio_err}")
            
            location_value = None
            if city and country:
                location_value = f"{city}, {country}"
            elif city:
                location_value = city
            elif country:
                location_value = country
            if location_value is not None:
                try:
                    if USE_MYSQL:
                        c.execute(
                            "INSERT INTO user_profiles (username, location) VALUES (%s, %s) "
                            "ON DUPLICATE KEY UPDATE location=VALUES(location)",
                            (username, location_value)
                        )
                    else:
                        c.execute(
                            "INSERT INTO user_profiles (username, location) VALUES (?, ?) "
                            "ON CONFLICT(username) DO UPDATE SET location=excluded.location",
                            (username, location_value)
                        )
                except Exception as location_err:
                    logger.warning(f"Failed to update profile location for {username}: {location_err}")
            
            conn.commit()
            try:
                invalidate_user_cache(username)
            except Exception as cache_err:
                logger.warning(f"Failed to invalidate user cache for {username}: {cache_err}")
            
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error updating personal info for {username}: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/edit_profile', methods=['GET', 'POST'])
@login_required
def edit_profile():
    """Edit profile - redirect to React profile page"""
    return redirect('/profile')

# Old edit_profile code removed
def _old_edit_profile_removed():
    username = session['username']
    try:
        if request.method == 'POST':
            gender = request.form.get('gender')
            weight = float(request.form.get('weight', 0)) if request.form.get('weight') else None
            height = float(request.form.get('height', 0)) if request.form.get('height') else None
            blood_type = request.form.get('blood_type')
            muscle_mass = float(request.form.get('muscle_mass', 0)) if request.form.get('muscle_mass') else None
            bmi = round(weight / ((height / 100) ** 2), 1) if weight and height else None
            with get_db_connection() as conn:
                c = conn.cursor()
                c.execute("UPDATE users SET gender=?, weight=?, height=?, blood_type=?, muscle_mass=?, bmi=? WHERE username=?",
                          (gender, weight, height, blood_type, muscle_mass, bmi, username))
                conn.commit()
            return redirect(url_for('profile'))
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription, gender, weight, height, blood_type, muscle_mass FROM users WHERE username=?", (username,))
            user = c.fetchone()
        return render_template('edit_profile.html', name=username, subscription=user['subscription'], **dict(user))
    except Exception as e:
        logger.error(f"Error in edit_profile for {username}: {str(e)}")
        abort(500)

@app.route('/generate_workout', methods=['POST'])
@login_required
def generate_workout():
    username = session['username']
    muscle_or_split = request.form.get('muscle_or_split')
    training_type = request.form.get('training_type')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
        subscription = user['subscription'] if user else 'free'
        if not muscle_or_split or not training_type:
            return jsonify({'error': 'Please provide all details!'})
        try:
            variations = workout_data[muscle_or_split][training_type]
            if subscription == 'free':
                selected_program = variations[0][:1]
                workout_text = "Upgrade to Premium for more options!<br><br>"
            else:
                selected_program = random.choice(variations)
                workout_text = ""
            for exercise in selected_program:
                workout_text += f"<b>{exercise['name']}</b><br>Sets: {exercise['sets']}, Reps: {exercise['reps']}<br><br>"
            return jsonify({'workout': workout_text})
        except KeyError:
            return jsonify({'error': f'No data for {muscle_or_split} - {training_type}!'})
    except Exception as e:
        logger.error(f"Server error in generate_workout for {username}: {str(e)}")
        return jsonify({'error': 'Server error. Please try again later.'}), 500

@app.route('/blood_test_analysis', methods=['GET', 'POST'])
@login_required
def legacy_blood_test_analysis():
    """Gracefully retire the legacy blood test HTML workflow."""
    message = 'Blood test analysis has moved to the React dashboard.'
    if request.method == 'POST' or prefers_json_response():
        return jsonify({'success': False, 'message': message, 'redirect': '/premium_dashboard'}), 410
    flash(message, 'info')
    return redirect(url_for('premium_dashboard'))

@app.route('/subscribe', methods=['GET', 'POST'])
@login_required
def subscribe():
    username = session['username']
    if request.method == 'POST':
        plan = request.form['plan']
        if not stripe:
            flash("Stripe not configured!", "error")
            return redirect('/')
        try:
            price_id = 'price_monthly_id' if plan == 'monthly' else 'price_yearly_id'
            checkout_session = stripe.checkout.Session.create(
                payment_method_types=['card'],
                line_items=[{'price': price_id, 'quantity': 1}],
                mode='subscription',
                success_url=url_for('success', _external=True),
                cancel_url=url_for('subscribe', _external=True)
            )
            return redirect(checkout_session.url, code=303)
        except Exception as e:
            logger.error(f"Stripe error in subscribe for {username}: {str(e)}")
            abort(500)
    return render_template('subscribe.html', name=username)

@app.route('/success')
@login_required
def success():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("UPDATE users SET subscription='premium' WHERE username=?", (username,))
            conn.commit()
        return render_template('success.html', name=username, subscription='premium')
    except Exception as e:
        logger.error(f"Error in success for {username}: {str(e)}")
        abort(500)



@app.route('/business_login', methods=['GET', 'POST'])
def business_login():
    # Business login temporarily disabled
    flash('Business login is not available at this time.', 'error')
    return redirect(url_for('public.index'))

@app.route('/business_logout')
def business_logout():
    session.pop('business_id', None)
    session.pop('business_name', None)
    return redirect(url_for('business_login'))

@app.route('/delete_chat', methods=['POST'])
@login_required
def delete_chat():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                return jsonify({'success': False, 'error': 'Premium subscription required!'})
            receiver = request.form.get('receiver')
            if not receiver:
                return jsonify({'success': False, 'error': 'Receiver required!'})
            c.execute("DELETE FROM messages WHERE (sender=? AND receiver=?) OR (sender=? AND receiver=?)",
                      (username, receiver, receiver, username))
            deleted_count = c.rowcount
            conn.commit()
        return jsonify({'success': True, 'deleted_count': deleted_count})
    except Exception as e:
        logger.error(f"Error deleting chat for {username}: {str(e)}")
        abort(500)
@app.route('/get_messages', methods=['POST'])
@login_required
def get_messages():
    """Get messages between current user and another user"""
    username = session.get('username')
    other_user_id = request.form.get('other_user_id')
    
    if not other_user_id:
        return jsonify({'success': False, 'error': 'Other user ID required'})
    
    # Short-lived cache to reduce DB latency (viewer-specific; invalidated on write)
    cache_key = None
    try:
        # Resolve other username for stable key
        with get_db_connection() as _conn:
            _c = _conn.cursor()
            _c.execute("SELECT username FROM users WHERE id = ?", (other_user_id,))
            _row = _c.fetchone()
            if _row:
                other_username_for_key = _row['username'] if hasattr(_row, 'keys') else _row[0]
                from redis_cache import messages_view_cache_key
                cache_key = messages_view_cache_key(username, other_username_for_key)
    except Exception:
        cache_key = None
    if cache_key:
        cached_messages = cache.get(cache_key)
        if cached_messages:
            return jsonify({'success': True, 'messages': cached_messages})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get current user ID
            c.execute("SELECT id FROM users WHERE LOWER(username) = LOWER(?)", (username,))
            user = c.fetchone()
            if not user:
                return jsonify({'success': False, 'error': 'User not found'})
            
            user_id = user['id'] if hasattr(user, 'keys') else user[0]
            
            # Get other user's username
            c.execute("SELECT username FROM users WHERE id = ?", (other_user_id,))
            other_user = c.fetchone()
            if not other_user:
                return jsonify({'success': False, 'error': 'Other user not found'})
            
            other_username = other_user['username'] if hasattr(other_user, 'keys') else other_user[0]
            
            # Get messages between users (compat: edited_at and encryption fields may not exist yet)
            with_edited = True
            with_encryption = True
            try:
                c.execute(
                    """
                    SELECT id, sender, receiver, message, image_path, video_path, audio_path, audio_duration_seconds, audio_mime, 
                           is_encrypted, encrypted_body, encrypted_body_for_sender, timestamp, edited_at
                    FROM messages
                    WHERE (sender = ? AND receiver = ?)
                       OR (sender = ? AND receiver = ?)
                    ORDER BY timestamp ASC
                    """,
                    (username, other_username, other_username, username),
                )
            except Exception:
                # Fallback without encryption fields
                with_encryption = False
                try:
                    c.execute(
                        """
                        SELECT id, sender, receiver, message, image_path, video_path, audio_path, audio_duration_seconds, audio_mime, timestamp, edited_at
                        FROM messages
                        WHERE (sender = ? AND receiver = ?)
                           OR (sender = ? AND receiver = ?)
                        ORDER BY timestamp ASC
                        """,
                        (username, other_username, other_username, username),
                    )
                except Exception:
                    with_edited = False
                    c.execute(
                        """
                        SELECT id, sender, receiver, message, image_path, video_path, audio_path, audio_duration_seconds, audio_mime, timestamp
                        FROM messages
                        WHERE (sender = ? AND receiver = ?)
                           OR (sender = ? AND receiver = ?)
                        ORDER BY timestamp ASC
                        """,
                        (username, other_username, other_username, username),
                    )
            
            messages = []
            for msg in c.fetchall():
                if hasattr(msg, 'keys'):
                    image_path_val = msg.get('image_path')
                    video_path_val = msg.get('video_path')
                    audio_path_val = msg.get('audio_path')
                    audio_duration_val = msg.get('audio_duration_seconds')
                    audio_mime_val = msg.get('audio_mime')
                else:
                    image_path_val = msg[4] if len(msg) > 4 else None
                    video_path_val = msg[5] if len(msg) > 5 else None
                    audio_path_val = msg[6] if len(msg) > 6 else None
                    audio_duration_val = msg[7] if len(msg) > 7 else None
                    audio_mime_val = msg[8] if len(msg) > 8 else None
                edited_at_val = None
                if with_edited:
                    if hasattr(msg, 'get'):
                        edited_at_val = msg.get('edited_at')
                    elif len(msg):
                        edited_at_val = msg[-1]
                msg_dict = {
                    'id': msg['id'],
                    'text': msg['message'],
                    'image_path': image_path_val,
                    'video_path': video_path_val,
                    'audio_path': audio_path_val,
                    'audio_duration_seconds': audio_duration_val,
                    'audio_mime': audio_mime_val,
                    'sent': msg['sender'] == username,
                    'time': msg['timestamp'],
                    'edited_at': edited_at_val
                }
                
                # Add encryption fields if available
                if with_encryption:
                    is_encrypted_val = msg.get('is_encrypted') if hasattr(msg, 'get') else msg[9] if len(msg) > 9 else 0
                    encrypted_body_val = msg.get('encrypted_body') if hasattr(msg, 'get') else msg[10] if len(msg) > 10 else None
                    encrypted_body_for_sender_val = msg.get('encrypted_body_for_sender') if hasattr(msg, 'get') else msg[11] if len(msg) > 11 else None
                    
                    msg_dict['is_encrypted'] = is_encrypted_val
                    msg_dict['encrypted_body'] = encrypted_body_val
                    msg_dict['encrypted_body_for_sender'] = encrypted_body_for_sender_val
                    
                    # Signal Protocol: if encrypted but no traditional encrypted_body, it's Signal Protocol
                    # The ciphertexts are stored separately in message_ciphertexts table
                    if is_encrypted_val and not encrypted_body_val:
                        msg_dict['signal_protocol'] = True
                
                messages.append(msg_dict)
            
            # Mark messages from other user as read
            c.execute("UPDATE messages SET is_read=1 WHERE sender=? AND receiver=? AND is_read=0", (other_username, username))
            conn.commit()
            
            # Invalidate chat threads cache so unread count updates
            try:
                cache.delete(f"chat_threads:{username}")
                logger.info(f"Invalidated chat_threads cache for {username}")
            except Exception:
                pass
            
            # Clear message notification from notifications table
            try:
                # First check if there are any message notifications to delete
                c.execute(
                    "SELECT COUNT(*) as count FROM notifications WHERE user_id = ? AND from_user = ? AND type = 'message'",
                    (username, other_username)
                )
                row = c.fetchone()
                msg_notif_count = row['count'] if (row and hasattr(row, 'keys')) else (row[0] if row else 0)
                
                if msg_notif_count > 0:
                    c.execute(
                        "DELETE FROM notifications WHERE user_id = ? AND from_user = ? AND type = 'message'",
                        (username, other_username)
                    )
                    deleted = c.rowcount
                    conn.commit()
                    logger.info(f"Deleted {deleted} message notification(s) from {other_username} to {username}")
                else:
                    logger.info(f"No message notifications to delete from {other_username} to {username}")
                
                # Send badge update with new unread count
                try:
                    from backend.services.firebase_notifications import send_fcm_to_user_badge_only
                    # Get updated unread count
                    c.execute("SELECT COUNT(*) as count FROM notifications WHERE user_id = ? AND is_read = 0", (username,))
                    row = c.fetchone()
                    new_unread_count = row['count'] if (row and hasattr(row, 'keys')) else (row[0] if row else 0)
                    # Send badge update
                    send_fcm_to_user_badge_only(username, new_unread_count)
                    logger.info(f"Updated badge for {username} after reading messages from {other_username}: {new_unread_count} unread")
                except Exception as badge_err:
                    logger.warning(f"Could not update badge after reading messages: {badge_err}")
            except Exception as notif_err:
                logger.warning(f"Could not clear message notification: {notif_err}")
            
            # Write-through cache for fast subsequent polls
            try:
                from redis_cache import MESSAGE_CACHE_TTL
                if cache_key:
                    cache.set(cache_key, messages, MESSAGE_CACHE_TTL)
            except Exception:
                pass
            
            return jsonify({'success': True, 'messages': messages})
            
    except Exception as e:
        logger.error(f"Error fetching messages: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to fetch messages'})
@app.route('/send_message', methods=['POST'])
@login_required
def send_message():
    """Send a message to another user (supports E2E encryption)"""
    username = session.get('username')
    recipient_id = request.form.get('recipient_id')
    message = request.form.get('message', '')
    
    # Encryption fields
    is_encrypted = request.form.get('is_encrypted', '0') == '1'
    encrypted_body = request.form.get('encrypted_body', '')  # Encrypted for recipient
    encrypted_body_for_sender = request.form.get('encrypted_body_for_sender', '')  # Encrypted for sender
    
    if not recipient_id:
        return jsonify({'success': False, 'error': 'Recipient required'})
    
    # For encrypted messages, we don't store plaintext at all
    # For unencrypted messages, we need the message
    if not is_encrypted and not message:
        return jsonify({'success': False, 'error': 'Message required'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get recipient username
            c.execute("SELECT username FROM users WHERE id = ?", (recipient_id,))
            recipient = c.fetchone()
            if not recipient:
                return jsonify({'success': False, 'error': 'Recipient not found'})
            
            recipient_username = recipient['username'] if hasattr(recipient, 'keys') else recipient[0]
            
            # Check for duplicate message in last 5 seconds to prevent double-sends
            if USE_MYSQL:
                c.execute("""
                    SELECT id FROM messages 
                    WHERE sender = %s AND receiver = %s AND message = %s
                    AND timestamp > DATE_SUB(NOW(), INTERVAL 5 SECOND)
                    LIMIT 1
                """, (username, recipient_username, message))
            else:
                c.execute("""
                    SELECT id FROM messages 
                    WHERE sender = ? AND receiver = ? AND message = ?
                    AND datetime(timestamp) > datetime('now','-5 seconds')
                    LIMIT 1
                """, (username, recipient_username, message))
            
            if c.fetchone():
                # Duplicate message detected, return success but don't insert
                return jsonify({'success': True, 'message': 'Message already sent'})
            
            # Insert message with optional encryption support
            if USE_MYSQL:
                c.execute("""
                    INSERT INTO messages (sender, receiver, message, is_encrypted, encrypted_body, encrypted_body_for_sender, timestamp)
                    VALUES (%s, %s, %s, %s, %s, %s, NOW())
                """, (username, recipient_username, message if not is_encrypted else '', 1 if is_encrypted else 0, 
                     encrypted_body if is_encrypted else None, encrypted_body_for_sender if is_encrypted else None))
            else:
                # SQLite: store as text 'YYYY-MM-DD HH:MM:SS'
                _ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                c.execute("""
                    INSERT INTO messages (sender, receiver, message, is_encrypted, encrypted_body, encrypted_body_for_sender, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (username, recipient_username, message if not is_encrypted else '', 1 if is_encrypted else 0, 
                     encrypted_body if is_encrypted else None, encrypted_body_for_sender if is_encrypted else None, _ts))
            
            conn.commit()
            # Fetch inserted id and timestamp for immediate client update
            try:
                inserted_id = getattr(c, 'lastrowid', None)
                inserted_time = None
                if inserted_id:
                    if USE_MYSQL:
                        c.execute("SELECT timestamp FROM messages WHERE id = %s", (inserted_id,))
                    else:
                        c.execute("SELECT timestamp FROM messages WHERE id = ?", (inserted_id,))
                    row = c.fetchone()
                    if row is not None:
                        inserted_time = row['timestamp'] if hasattr(row, 'keys') else row[0]
            except Exception as _fe:
                inserted_id = None
                inserted_time = None
            
            # Invalidate message caches for faster updates
            invalidate_message_cache(username, recipient_username)
            
            # Invalidate chat threads cache so preview updates
            try:
                cache.delete(f"chat_threads:{username}")
                cache.delete(f"chat_threads:{recipient_username}")
            except Exception:
                pass
            
            # Create or update notification for the recipient (truly atomic)
            try:
                if USE_MYSQL:
                    c.execute("""
                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                        VALUES (?, ?, 'message', NULL, NULL, ?, NOW(), 0, ?)
                        ON DUPLICATE KEY UPDATE
                            created_at = NOW(),
                            message = VALUES(message),
                            is_read = 0,
                            link = VALUES(link)
                    """, (recipient_username, username, f"You have new messages from {username}", f"/user_chat/chat/{username}"))
                else:
                    c.execute("""
                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                        VALUES (?, ?, 'message', NULL, NULL, ?, datetime('now'), 0, ?)
                        ON CONFLICT(user_id, from_user, type, post_id, community_id)
                        DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                    """, (recipient_username, username, f"You have new messages from {username}", f"/user_chat/chat/{username}"))
                conn.commit()
            except Exception as notif_e:
                logger.warning(f"Could not create/update message notification: {notif_e}")
            
            # Push notification to recipient (if subscribed) ‚Äî skip if recipient is actively viewing this thread
            try:
                should_push = True
                try:
                    with get_db_connection() as conn2:
                        c2 = conn2.cursor()
                        # If recipient's active view is this chat, suppress push
                        # Consider presence fresh if updated within last 20 seconds
                        if USE_MYSQL:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND updated_at > DATE_SUB(NOW(), INTERVAL 20 SECOND)
                                LIMIT 1
                            """, (recipient_username, username))
                        else:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND datetime(updated_at) > datetime('now','-20 seconds')
                                LIMIT 1
                            """, (recipient_username, username))
                        if c2.fetchone():
                            should_push = False
                except Exception as pe:
                    logger.warning(f"active chat presence check failed: {pe}")
                if should_push:
                    send_push_to_user(recipient_username, {
                        'title': f'Message from {username}',
                        'body': f'You have new messages from {username}',
                        'url': f'/user_chat/chat/{username}',
                        'tag': f'message-{username}',
                    })
            except Exception as _e:
                logger.warning(f"push send_message warn: {_e}")

            return jsonify({'success': True, 'message': 'Message sent successfully', 'message_id': inserted_id, 'time': inserted_time})
            
    except Exception as e:
        logger.error(f"Error sending message: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to send message'})

@app.route('/api/chat/edit_message', methods=['POST'])
@login_required
def edit_message_api():
    """Edit an existing message's text. Only the sender can edit. Records edited_at."""
    username = session.get('username')
    if request.is_json:
        data = request.get_json(silent=True) or {}
        message_id = data.get('message_id')
        new_text = (data.get('text') or '').strip()
    else:
        message_id = request.form.get('message_id')
        new_text = (request.form.get('text') or '').strip()
    if not message_id or new_text is None:
        return jsonify({'success': False, 'error': 'message_id and text required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure edited_at column exists (best-effort)
            try:
                if USE_MYSQL:
                    c.execute("SHOW COLUMNS FROM messages LIKE 'edited_at'")
                    if not c.fetchone():
                        c.execute("ALTER TABLE messages ADD COLUMN edited_at DATETIME NULL")
                else:
                    # SQLite: check pragma
                    c.execute("PRAGMA table_info(messages)")
                    cols = [row[1] for row in c.fetchall()]
                    if 'edited_at' not in cols:
                        c.execute("ALTER TABLE messages ADD COLUMN edited_at TEXT")
            except Exception:
                pass
            # Enforce sender and 5-minute edit window
            c.execute("SELECT sender, timestamp FROM messages WHERE id = ?", (message_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Not found'}), 404
            sender = row['sender'] if hasattr(row, 'keys') else row[0]
            sent_ts_val = row['timestamp'] if hasattr(row, 'keys') else row[1]
            if str(sender) != str(username):
                return jsonify({'success': False, 'error': 'Not permitted'}), 403
            # Parse timestamp
            from datetime import datetime as _dt
            sent_dt = None
            s = str(sent_ts_val or '')
            try:
                sent_dt = _dt.strptime(s[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
            except Exception:
                for fmt in ('%Y-%m-%d %H:%M', '%Y-%m-%d'):
                    try:
                        sent_dt = _dt.strptime(s, fmt)
                        break
                    except Exception:
                        continue
            if not sent_dt:
                # If unknown, deny edit to be safe
                return jsonify({'success': False, 'error': 'Invalid timestamp'}), 400
            if (_dt.now() - sent_dt).total_seconds() > 5*60:
                return jsonify({'success': False, 'error': 'Edit window expired'}), 400
            # Update only if sender is current user
            # Clear encryption fields since we're storing plain text now
            # (Re-encrypting would require access to both users' keys which we don't have here)
            try:
                c.execute(
                    """UPDATE messages 
                       SET message = ?, edited_at = ?, is_encrypted = 0, 
                           encrypted_body = NULL, encrypted_body_for_sender = NULL 
                       WHERE id = ? AND sender = ?""",
                    (new_text, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), message_id, username)
                )
            except Exception:
                # Fallback if encryption columns don't exist
                c.execute(
                    "UPDATE messages SET message = ?, edited_at = ? WHERE id = ? AND sender = ?",
                    (new_text, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), message_id, username)
                )
            if c.rowcount == 0:
                return jsonify({'success': False, 'error': 'Not found or not permitted'}), 403
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"edit_message_api error: {e}")
        return jsonify({'success': False, 'error': 'Failed to edit message'}), 500

@app.route('/send_photo_message', methods=['POST'])
@login_required
def send_photo_message():
    """Send a photo message to another user"""
    username = session.get('username')
    recipient_id = request.form.get('recipient_id')
    message = request.form.get('message', '')  # Optional text with photo
    
    if not recipient_id:
        return jsonify({'success': False, 'error': 'Recipient required'})
    
    # Check if photo was uploaded
    if 'photo' not in request.files:
        return jsonify({'success': False, 'error': 'No photo uploaded'})
    
    photo = request.files['photo']
    if photo.filename == '':
        return jsonify({'success': False, 'error': 'No photo selected'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get recipient username
            c.execute("SELECT username FROM users WHERE id = ?", (recipient_id,))
            recipient = c.fetchone()
            if not recipient:
                return jsonify({'success': False, 'error': 'Recipient not found'})
            
            recipient_username = recipient['username'] if hasattr(recipient, 'keys') else recipient[0]
            
            # Save the photo using R2-enabled media service
            stored_path = save_uploaded_file(
                photo,
                subfolder='message_photos',
                allowed_extensions={'png', 'jpg', 'jpeg', 'gif', 'webp'}
            )
            if not stored_path:
                return jsonify({'success': False, 'error': 'Failed to save photo'})
            
            # stored_path is either CDN URL or local path like "uploads/message_photos/..."
            # For database, store the path/URL as-is
            relative_path = stored_path
            
            # Check for duplicate message in last 5 seconds
            c.execute("""
                SELECT id FROM messages 
                WHERE sender = ? AND receiver = ? AND image_path = ?
                AND timestamp > DATE_SUB(NOW(), INTERVAL 5 SECOND)
                LIMIT 1
            """, (username, recipient_username, relative_path))
            
            if c.fetchone():
                # Duplicate photo message detected
                return jsonify({'success': True, 'message': 'Photo already sent'})
            
            # Insert photo message
            c.execute("""
                INSERT INTO messages (sender, receiver, message, image_path, timestamp)
                VALUES (?, ?, ?, ?, NOW())
            """, (username, recipient_username, message, relative_path))
            
            conn.commit()
            inserted_id = getattr(c, 'lastrowid', None)
            inserted_time = None
            if inserted_id:
                try:
                    if USE_MYSQL:
                        c.execute("SELECT timestamp FROM messages WHERE id = %s", (inserted_id,))
                    else:
                        c.execute("SELECT timestamp FROM messages WHERE id = ?", (inserted_id,))
                    row = c.fetchone()
                    if row is not None:
                        inserted_time = row['timestamp'] if hasattr(row, 'keys') else row[0]
                except Exception:
                    inserted_time = None
            
            invalidate_message_cache(username, recipient_username)
            
            # Create or update notification for the recipient (truly atomic)
            try:
                c.execute("""
                    INSERT INTO notifications (user_id, from_user, type, message, created_at, is_read)
                    VALUES (?, ?, 'message', ?, NOW(), 0)
                    ON DUPLICATE KEY UPDATE
                        created_at = NOW(),
                        message = VALUES(message),
                        is_read = 0
                """, (recipient_username, username, f"You have new messages from {username}"))
                conn.commit()
            except Exception as notif_e:
                logger.warning(f"Could not create/update photo message notification: {notif_e}")
            
            # Push notification ‚Äî skip if recipient is actively viewing this thread
            try:
                should_push = True
                try:
                    with get_db_connection() as conn2:
                        c2 = conn2.cursor()
                        if USE_MYSQL:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND updated_at > DATE_SUB(NOW(), INTERVAL 20 SECOND)
                                LIMIT 1
                            """, (recipient_username, username))
                        else:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND datetime(updated_at) > datetime('now','-20 seconds')
                                LIMIT 1
                            """, (recipient_username, username))
                        if c2.fetchone():
                            should_push = False
                except Exception as pe:
                    logger.warning(f"active chat presence check (photo) failed: {pe}")
                if should_push:
                    send_push_to_user(recipient_username, {
                        'title': f'Message from {username}',
                        'body': f'You have new messages from {username}',
                        'url': f'/user_chat/chat/{username}',
                        'tag': f'message-{username}',
                    })
            except Exception as _e:
                logger.warning(f"push send_photo_message warn: {_e}")

            return jsonify({
                'success': True, 
                'message': 'Photo sent successfully',
                'image_path': relative_path,
                'id': inserted_id,
                'time': inserted_time
            })
            
    except Exception as e:
        logger.error(f"Error sending photo message: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to send photo'})

# Message videos served via /uploads/message_videos mapping

@app.route('/send_video_message', methods=['POST'])
@login_required
def send_video_message():
    """Send a video message to another user"""
    username = session.get('username')
    recipient_id = request.form.get('recipient_id')
    message = request.form.get('message', '')
    
    if not recipient_id:
        return jsonify({'success': False, 'error': 'Recipient required'})
    if 'video' not in request.files:
        return jsonify({'success': False, 'error': 'No video uploaded'})
    
    video = request.files['video']
    if video.filename == '':
        return jsonify({'success': False, 'error': 'No video selected'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            c.execute("SELECT username FROM users WHERE id = ?", (recipient_id,))
            recipient = c.fetchone()
            if not recipient:
                return jsonify({'success': False, 'error': 'Recipient not found'})
            recipient_username = recipient['username'] if hasattr(recipient, 'keys') else recipient[0]
            
            stored_path = save_uploaded_file(video, subfolder='message_videos')
            if not stored_path:
                return jsonify({'success': False, 'error': 'Invalid video type'})
            relative_path = stored_path[7:] if stored_path.startswith('uploads/') else stored_path
            
            c.execute("""
                INSERT INTO messages (sender, receiver, message, video_path, timestamp)
                VALUES (?, ?, ?, ?, NOW())
            """, (username, recipient_username, message, relative_path))
            conn.commit()
            
            inserted_id = getattr(c, 'lastrowid', None)
            inserted_time = None
            if inserted_id:
                try:
                    if USE_MYSQL:
                        c.execute("SELECT timestamp FROM messages WHERE id = %s", (inserted_id,))
                    else:
                        c.execute("SELECT timestamp FROM messages WHERE id = ?", (inserted_id,))
                    row = c.fetchone()
                    if row is not None:
                        inserted_time = row['timestamp'] if hasattr(row, 'keys') else row[0]
                except Exception:
                    inserted_time = None
            
            invalidate_message_cache(username, recipient_username)
            
            try:
                c.execute("""
                    INSERT INTO notifications (user_id, from_user, type, message, created_at, is_read)
                    VALUES (?, ?, 'message', ?, NOW(), 0)
                    ON DUPLICATE KEY UPDATE
                        created_at = NOW(),
                        message = VALUES(message),
                        is_read = 0
                """, (recipient_username, username, f"You have new messages from {username}"))
                conn.commit()
            except Exception as notif_e:
                logger.warning(f"Could not create/update video message notification: {notif_e}")
            
            try:
                should_push = True
                try:
                    with get_db_connection() as conn2:
                        c2 = conn2.cursor()
                        if USE_MYSQL:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND updated_at > DATE_SUB(NOW(), INTERVAL 20 SECOND)
                                LIMIT 1
                            """, (recipient_username, username))
                        else:
                            c2.execute("""
                                SELECT 1 FROM active_chat_status 
                                WHERE user=? AND peer=? AND datetime(updated_at) > datetime('now','-20 seconds')
                                LIMIT 1
                            """, (recipient_username, username))
                        if c2.fetchone():
                            should_push = False
                except Exception as pe:
                    logger.warning(f"active chat presence check (video) failed: {pe}")
                if should_push:
                    send_push_to_user(recipient_username, {
                        'title': f'Message from {username}',
                        'body': f'You have new messages from {username}',
                        'url': f'/user_chat/chat/{username}',
                        'tag': f'message-{username}',
                    })
            except Exception as _e:
                logger.warning(f"push send_video_message warn: {_e}")
            
            return jsonify({
                'success': True,
                'video_path': relative_path,
                'id': inserted_id,
                'time': inserted_time
            })
    except Exception as e:
        logger.error(f"Error sending video message: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to send video'})

# Message photos served by web server static mapping (/uploads/message_photos -> uploads/message_photos)

@app.route('/send_audio_message', methods=['POST'])
@login_required
def send_audio_message():
    """Send a voice message to another user"""
    username = session.get('username')
    recipient_id = request.form.get('recipient_id')
    duration_seconds_raw = (request.form.get('duration_seconds') or '').strip()
    try:
        duration_seconds = int(duration_seconds_raw) if duration_seconds_raw else None
    except Exception:
        duration_seconds = None

    if not recipient_id:
        return jsonify({'success': False, 'error': 'Recipient required'})
    if 'audio' not in request.files:
        return jsonify({'success': False, 'error': 'No audio uploaded'})
    audio = request.files['audio']
    if audio.filename == '':
        return jsonify({'success': False, 'error': 'No audio selected'})

    # Validate MIME (best-effort)
    allowed_mimes = {
        'audio/webm': 'webm', 'audio/ogg': 'ogg', 'audio/mpeg': 'mp3',
        'audio/mp4': 'm4a', 'audio/x-m4a': 'm4a', 'audio/aac': 'aac',
        'audio/wav': 'wav', 'audio/3gpp': '3gp', 'audio/3gpp2': '3g2'
    }
    mime = (audio.mimetype or '').lower()
    ext = None
    if mime in allowed_mimes:
        ext = allowed_mimes[mime]
    else:
        # Fallback by filename extension
        try:
            ext = audio.filename.rsplit('.', 1)[1].lower()
        except Exception:
            ext = 'webm'

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Resolve recipient username
            c.execute("SELECT username FROM users WHERE id = ?", (recipient_id,))
            rec = c.fetchone()
            if not rec:
                return jsonify({'success': False, 'error': 'Recipient not found'})
            recipient_username = rec['username'] if hasattr(rec, 'keys') else rec[0]

            # Save audio file using R2-enabled media service
            # Include all common audio formats (iOS may send .caf, .aac, .m4a, etc.)
            stored_path = save_uploaded_file(
                audio,
                subfolder='voice_messages',
                allowed_extensions={'webm', 'ogg', 'mp3', 'm4a', 'wav', 'opus', 'aac', 'caf', '3gp', '3g2', 'mpeg', 'mp4'}
            )
            if not stored_path:
                # Log more details for debugging
                logger.error(f"Failed to save audio: filename={audio.filename}, mimetype={audio.mimetype}, content_length={audio.content_length}")
                return jsonify({'success': False, 'error': 'Failed to save audio - unsupported format'})

            # stored_path is either CDN URL or local path
            rel_path = stored_path

            # Insert audio message
            c.execute(
                """
                INSERT INTO messages (sender, receiver, message, audio_path, audio_duration_seconds, audio_mime, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, NOW())
                """,
                (username, recipient_username, '', rel_path, duration_seconds, mime)
            )
            conn.commit()

            # Invalidate caches
            invalidate_message_cache(username, recipient_username)

            # Notification (same as text/photo)
            try:
                c.execute(
                    """
                    INSERT INTO notifications (user_id, from_user, type, message, created_at, is_read)
                    VALUES (?, ?, 'message', ?, NOW(), 0)
                    ON DUPLICATE KEY UPDATE
                        created_at = NOW(),
                        message = VALUES(message),
                        is_read = 0
                    """,
                    (recipient_username, username, f"You have new messages from {username}")
                )
                conn.commit()
            except Exception as notif_e:
                logger.warning(f"Could not create/update audio message notification: {notif_e}")

            # Push (suppress if actively viewing)
            try:
                should_push = True
                try:
                    with get_db_connection() as conn2:
                        c2 = conn2.cursor()
                        if USE_MYSQL:
                            c2.execute(
                                """
                                SELECT 1 FROM active_chat_status
                                WHERE user=? AND peer=? AND updated_at > DATE_SUB(NOW(), INTERVAL 20 SECOND)
                                LIMIT 1
                                """,
                                (recipient_username, username)
                            )
                        else:
                            c2.execute(
                                """
                                SELECT 1 FROM active_chat_status
                                WHERE user=? AND peer=? AND datetime(updated_at) > datetime('now','-20 seconds')
                                LIMIT 1
                                """,
                                (recipient_username, username)
                            )
                        if c2.fetchone():
                            should_push = False
                except Exception as pe:
                    logger.warning(f"active chat presence check (audio) failed: {pe}")
                if should_push:
                    send_push_to_user(recipient_username, {
                        'title': f'Message from {username}',
                        'body': f'You have new messages from {username}',
                        'url': f'/user_chat/chat/{username}',
                        'tag': f'message-{username}',
                    })
            except Exception as _e:
                logger.warning(f"push send_audio_message warn: {_e}")

            return jsonify({'success': True, 'audio_path': rel_path})
    except Exception as e:
        logger.error(f"Error sending audio message: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to send audio'})

@app.route('/debug/r2_status')
@login_required
def debug_r2_status():
    """Debug route to check R2 CDN configuration and connectivity"""
    try:
        from backend.services.r2_storage import (
            R2_ENABLED, R2_ACCESS_KEY, R2_SECRET_KEY, R2_BUCKET, 
            R2_ENDPOINT, R2_PUBLIC_URL, get_s3_client, upload_to_r2
        )
        
        status = {
            'r2_enabled': R2_ENABLED,
            'env_vars': {
                'CLOUDFLARE_R2_ENABLED': os.environ.get('CLOUDFLARE_R2_ENABLED', 'NOT SET'),
                'CLOUDFLARE_R2_ACCESS_KEY': '***' + R2_ACCESS_KEY[-4:] if R2_ACCESS_KEY else 'NOT SET',
                'CLOUDFLARE_R2_SECRET_KEY': '***' + R2_SECRET_KEY[-4:] if R2_SECRET_KEY else 'NOT SET',
                'CLOUDFLARE_R2_BUCKET': R2_BUCKET or 'NOT SET',
                'CLOUDFLARE_R2_ENDPOINT': R2_ENDPOINT or 'NOT SET',
                'CLOUDFLARE_R2_PUBLIC_URL': R2_PUBLIC_URL or 'NOT SET',
            },
            'boto3_installed': False,
            'client_created': False,
            'test_upload': None,
        }
        
        # Check boto3
        try:
            import boto3
            status['boto3_installed'] = True
            status['boto3_version'] = boto3.__version__
        except ImportError:
            status['boto3_installed'] = False
            status['boto3_error'] = 'boto3 not installed - run: pip install boto3'
        
        # Try to create client
        if R2_ENABLED and status['boto3_installed']:
            client = get_s3_client()
            status['client_created'] = client is not None
            
            # Try a test upload
            if client:
                try:
                    test_content = b'R2 CDN test file - safe to delete'
                    test_key = 'test/r2_connectivity_test.txt'
                    success, url = upload_to_r2(test_content, test_key, 'text/plain')
                    status['test_upload'] = {
                        'success': success,
                        'url': url,
                        'message': 'Test file uploaded successfully!' if success else 'Upload failed'
                    }
                except Exception as e:
                    status['test_upload'] = {
                        'success': False,
                        'error': str(e)
                    }
        
        return jsonify(status)
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })


@app.route('/debug/message_photos')
@login_required
def debug_message_photos():
    """Debug route to check message photos directory"""
    try:
        uploads_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'uploads', 'message_photos')
        
        if not os.path.exists(uploads_dir):
            return jsonify({
                'success': False,
                'error': 'Message photos directory does not exist',
                'expected_path': uploads_dir
            })
        
        # List files in directory
        files = os.listdir(uploads_dir) if os.path.exists(uploads_dir) else []
        
        return jsonify({
            'success': True,
            'uploads_directory': uploads_dir,
            'files_count': len(files),
            'files': files[:10],  # First 10 files
            'directory_exists': os.path.exists(uploads_dir),
            'directory_writable': os.access(uploads_dir, os.W_OK) if os.path.exists(uploads_dir) else False
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        })

@app.route('/api/chat_threads')
@login_required
def api_chat_threads():
    """Return list of chat threads for the current user with avatar and last message sent by the user.
    Shape: { success, threads: [ { other_username, display_name, profile_picture_url, last_sent_text, last_sent_time, last_activity_time } ] }
    """
    username = session.get('username')
    
    # Check cache first
    cache_key = f"chat_threads:{username}"
    cached_threads = cache.get(cache_key)
    if cached_threads:
        logger.debug(f"üöÄ Cache hit: chat_threads for {username}")
        return jsonify({'success': True, 'threads': cached_threads})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Gather all counterpart usernames the user has messages with (either direction)
            c.execute(
                """
                SELECT DISTINCT receiver AS other_username
                FROM messages
                WHERE sender = ?
                UNION
                SELECT DISTINCT sender AS other_username
                FROM messages
                WHERE receiver = ?
                ORDER BY other_username
                """,
                (username, username),
            )
            counterpart_rows = c.fetchall()

            threads = []
            for row in counterpart_rows:
                try:
                    other_username = row['other_username'] if isinstance(row, dict) or hasattr(row, 'keys') else row[0]

                    # Last message in either direction (preview)
                    # Include is_encrypted to handle encrypted messages
                    try:
                        c.execute(
                            """
                            SELECT message, timestamp, sender, is_encrypted
                            FROM messages
                            WHERE (sender = ? AND receiver = ?) OR (sender = ? AND receiver = ?)
                            ORDER BY timestamp DESC
                            LIMIT 1
                            """,
                            (username, other_username, other_username, username),
                        )
                    except Exception:
                        # Fallback if is_encrypted column doesn't exist
                        c.execute(
                            """
                            SELECT message, timestamp, sender
                            FROM messages
                            WHERE (sender = ? AND receiver = ?) OR (sender = ? AND receiver = ?)
                            ORDER BY timestamp DESC
                            LIMIT 1
                            """,
                            (username, other_username, other_username, username),
                        )
                    last_row = c.fetchone()
                    last_message_text = None
                    last_activity_time = None
                    last_sender = None
                    is_encrypted = False
                    if last_row:
                        if hasattr(last_row, 'keys'):
                            last_message_text = last_row['message']
                            last_activity_time = last_row['timestamp']
                            last_sender = last_row['sender']
                            is_encrypted = bool(last_row.get('is_encrypted', 0))
                        else:
                            last_message_text = last_row[0]
                            last_activity_time = last_row[1]
                            last_sender = last_row[2]
                            is_encrypted = bool(last_row[3]) if len(last_row) > 3 else False
                    
                    # If message is encrypted and text is empty, show placeholder
                    if is_encrypted and not last_message_text:
                        last_message_text = 'üîí Encrypted message'

                    # Unread count for this thread (messages sent by other -> me)
                    c.execute("SELECT COUNT(*) as count FROM messages WHERE sender=? AND receiver=? AND is_read=0", (other_username, username))
                    unread_row = c.fetchone()
                    unread_count = unread_row['count'] if hasattr(unread_row, 'keys') else (unread_row[0] if unread_row else 0)

                    # Profile info (avatar)
                    c.execute(
                        "SELECT display_name, profile_picture FROM user_profiles WHERE username = ?",
                        (other_username,),
                    )
                    profile = c.fetchone()
                    display_name = None
                    profile_picture_rel = None
                    if profile:
                        if hasattr(profile, 'keys') and 'display_name' in profile.keys():
                            display_name = profile['display_name']
                        else:
                            try:
                                display_name = profile[0]
                            except Exception:
                                display_name = None
                        if hasattr(profile, 'keys') and 'profile_picture' in profile.keys():
                            profile_picture_rel = profile['profile_picture']
                        else:
                            try:
                                profile_picture_rel = profile[1]
                            except Exception:
                                profile_picture_rel = None
                    display_name = display_name or other_username

                    profile_picture_url = url_for('static', filename=profile_picture_rel) if profile_picture_rel else None

                    threads.append({
                        'other_username': other_username,
                        'display_name': display_name,
                        'profile_picture_url': profile_picture_url,
                        'last_message_text': last_message_text,
                        'last_activity_time': last_activity_time,
                        'last_sender': last_sender,
                        'unread_count': int(unread_count or 0),
                    })
                except Exception as inner_e:
                    logger.warning(f"Failed to build thread for counterpart: {inner_e}")
                    continue

        # Sort threads by most recent activity; filter out any without counterpart
        threads = [t for t in threads if t.get('other_username')]
        threads.sort(key=lambda t: (t.get('last_activity_time') or ''), reverse=True)
        
        # Cache the result for faster future requests
        from redis_cache import CHAT_THREADS_TTL
        cache.set(cache_key, threads, CHAT_THREADS_TTL)  # Optimized TTL
        logger.debug(f"üíæ Cached chat_threads for {username}")
        
        return jsonify({'success': True, 'threads': threads})
    except Exception as e:
        logger.error(f"Error building chat threads for {username}: {e}")
        return jsonify({'success': False, 'error': 'Failed to load chats'}), 500

@app.route('/user_chat')
@login_required
def user_chat():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Allow verified users (and admin) to access messages regardless of subscription
            c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
            row = c.fetchone()
            is_verified = False
            try:
                is_verified = bool(row['email_verified'] if hasattr(row, 'keys') else (row[0] if row else 0))
            except Exception:
                is_verified = False
            if username != 'admin' and not is_verified:
                return redirect(url_for('verify_required'))

        # Serve React SPA from client/dist with cache-busting headers
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error in user_chat route: {e}")
        abort(500)

@app.route('/user_chat/<path:subpath>')
@login_required
def user_chat_subpath(subpath):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving user_chat subpath {subpath}: {e}")
        abort(500)

@app.route('/delete_message', methods=['POST'])
@login_required
def delete_message():
    username = session['username']
    message_id = request.form.get('message_id')
    if not message_id:
        return jsonify({'success': False, 'error': 'Message ID required'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT subscription FROM users WHERE username=?", (username,))
            user = c.fetchone()
            if not user or user['subscription'] != 'premium':
                return jsonify({'success': False, 'error': 'Premium subscription required!'})
            c.execute("DELETE FROM messages WHERE id=? AND (sender=? OR receiver=?)",
                      (message_id, username, username))
            if c.rowcount == 0:
                return jsonify({'success': False, 'error': 'Message not found or not yours'})
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error deleting message for {username}: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to delete message'}), 500

@app.route('/delete_chat_thread', methods=['POST'])
@login_required
def delete_chat_thread():
    """Delete all messages between the current user and the specified other user"""
    username = session['username']
    other_username = request.form.get('other_username')
    if not other_username:
        return jsonify({'success': False, 'error': 'Other username required'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Allow verified users to manage their chat threads
            try:
                c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
                ver_row = c.fetchone()
                is_verified = bool(ver_row['email_verified'] if hasattr(ver_row,'keys') else (ver_row[0] if ver_row else 0))
            except Exception:
                is_verified = False
            if username != 'admin' and not is_verified:
                return jsonify({'success': False, 'error': 'Email verification required!'})

            # Delete messages in both directions
            c.execute(
                """
                DELETE FROM messages
                WHERE (sender=? AND receiver=?) OR (sender=? AND receiver=?)
                """,
                (username, other_username, other_username, username),
            )
            conn.commit()

            # Invalidate chat threads cache for both users so the thread does not reappear
            try:
                cache.delete(f"chat_threads:{username}")
            except Exception:
                pass
            try:
                cache.delete(f"chat_threads:{other_username}")
            except Exception:
                pass
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"delete_chat_thread error for {username} with {other_username}: {e}")
        return jsonify({'success': False, 'error': 'Failed to delete chat'}), 500

# Community membership/admin routes now reside in backend.blueprints.communities.



@app.route('/update_user_password', methods=['POST'])
@login_required
def update_user_password():
    username = session['username']
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Admin access required'})
    
    target_username = request.form.get('username')
    new_password = request.form.get('new_password')
    
    if not target_username or not new_password:
        return jsonify({'success': False, 'error': 'Username and new password required'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Check if target user exists
            ph = get_sql_placeholder()
            c.execute(f"SELECT id FROM users WHERE username = {ph}", (target_username,))
            user = c.fetchone()
            if not user:
                return jsonify({'success': False, 'error': 'User not found'})
            
            # Hash the new password
            hashed_password = generate_password_hash(new_password)
            
            # Update the password
            c.execute("UPDATE users SET password = ? WHERE username = ?", (hashed_password, target_username))
            conn.commit()
            
        return jsonify({'success': True, 'message': f'Password updated successfully for {target_username}'})
    except Exception as e:
        logger.error(f"Error updating password for {target_username}: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/debug_password/<username>')
def debug_password(username):
    """Temporary debug route to check password status - REMOVE IN PRODUCTION"""
    # Only allow admin to access this
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT password FROM users WHERE username=?", (username,))
            user = c.fetchone()
            
            if not user:
                return f"User '{username}' not found"
            
            password = user[0] if user else None
            
            info = {
                'username': username,
                'password_exists': password is not None,
                'password_length': len(password) if password else 0,
                'is_hashed': False,
                'hash_type': 'plain text'
            }
            
            if password:
                if password.startswith('$2b$') or password.startswith('$2a$') or password.startswith('$2y$'):
                    info['is_hashed'] = True
                    info['hash_type'] = 'bcrypt'
                elif password.startswith('scrypt:'):
                    info['is_hashed'] = True
                    info['hash_type'] = 'scrypt'
                elif password.startswith('pbkdf2:'):
                    info['is_hashed'] = True
                    info['hash_type'] = 'pbkdf2'
                    
                # Show first 20 chars for debugging (safe for hashed passwords)
                info['password_preview'] = password[:20] + '...' if len(password) > 20 else password
            
            return f"""
            <h2>Password Debug Info for {username}</h2>
            <pre>{json.dumps(info, indent=2)}</pre>
            <br>
            <h3>Reset Password for {username}:</h3>
            <form action="/reset_password_debug/{username}" method="POST">
                <input type="password" name="new_password" placeholder="New password" required>
                <button type="submit">Reset Password (Plain Text)</button>
            </form>
            <form action="/reset_password_debug_hashed/{username}" method="POST">
                <input type="password" name="new_password" placeholder="New password" required>
                <button type="submit">Reset Password (Hashed)</button>
            </form>
            """
    except Exception as e:
        return f"Error: {str(e)}"

@app.route('/reset_password_debug/<username>', methods=['POST'])
def reset_password_debug(username):
    """Reset password as plain text - TEMPORARY DEBUG"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    new_password = request.form.get('new_password')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Set as plain text
            c.execute("UPDATE users SET password=? WHERE username=?", (new_password, username))
            conn.commit()
        return f"Password for {username} reset to plain text: '{new_password}'. <a href='/'>Go to login</a>"
    except Exception as e:
        return f"Error: {str(e)}"

@app.route('/reset_password_debug_hashed/<username>', methods=['POST'])
def reset_password_debug_hashed(username):
    """Reset password as hashed - TEMPORARY DEBUG"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    new_password = request.form.get('new_password')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Hash the password
            hashed = generate_password_hash(new_password)
            c.execute("UPDATE users SET password=? WHERE username=?", (hashed, username))
            conn.commit()
        return f"Password for {username} reset to hashed version of: '{new_password}'. <a href='/'>Go to login</a>"
    except Exception as e:
        return f"Error: {str(e)}"

@app.route('/request_password_reset', methods=['POST'])
def request_password_reset():
    """Handle password reset requests"""
    try:
        data = request.get_json(silent=True) or {}
        username = None  # Deprecated: we now reset by email only
        email = (data.get('email') if isinstance(data, dict) else None) or request.form.get('email') or request.args.get('email')
        try:
            logger.info(f"PW reset incoming: ct={request.content_type} user={username} has_email={bool(email)}")
        except Exception:
            pass
        
        if not email:
            return jsonify({'success': True, 'message': 'If an account exists with the provided information, a reset link has been sent.'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_password_reset_table(c)
            
            # Find user by email
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM users WHERE email = {ph}", (email,))
            result = c.fetchone()
            
            # For security, always return success even if user doesn't exist
            if result:
                matched_username = result['username'] if hasattr(result, 'keys') else result[0]
                # Generate secure token
                token = secrets.token_urlsafe(32)
                created_at = datetime.now().isoformat()
                
                # Rate limiting: only one active token within 10 minutes
                try:
                    c.execute(f"SELECT created_at FROM password_reset_tokens WHERE username={ph} AND used=0 ORDER BY id DESC LIMIT 1", (matched_username,))
                    last = c.fetchone()
                    if last:
                        last_time = datetime.fromisoformat(last['created_at'] if hasattr(last, 'keys') else last[0])
                        if datetime.now() - last_time < timedelta(minutes=10):
                            # Still respond success without sending a new email
                            return jsonify({'success': True, 'message': 'If an account exists, a reset link has been sent.'})
                except Exception:
                    pass
                # Delete any existing unused tokens for this user (cleanup)
                c.execute(f"DELETE FROM password_reset_tokens WHERE username = {ph} AND used = 0", (matched_username,))
                
                # Insert new token
                ins_ph = ', '.join([ph, ph, ph, ph])
                c.execute(f"""
                    INSERT INTO password_reset_tokens (username, email, token, created_at)
                    VALUES ({ins_ph})
                """, (matched_username, email, token, created_at))
                conn.commit()
                
                # Build reset link using canonical host
                base = f"{CANONICAL_SCHEME}://{CANONICAL_HOST}" if CANONICAL_HOST else request.host_url.rstrip('/')
                reset_link = f"{base}/reset_password/{token}"
                logger.info(f"Password reset link generated for {matched_username}")

                # Send email via Resend
                subject = "Reset your C-Point password"
                html = f"""
                    <div style='font-family:Arial,sans-serif;font-size:14px;color:#111'>
                      <p>We received a request to reset the password for your C-Point account.</p>
                      <p><a href='{reset_link}' style='display:inline-block;background:#111;color:#fff;padding:10px 16px;border-radius:6px;text-decoration:none'>Reset Password</a></p>
                      <p>Or open this link: <a href='{reset_link}'>{reset_link}</a></p>
                      <p>This link expires in 24 hours. If you did not request this, you can ignore this email.</p>
                    </div>
                """
                sent_ok = _send_email_via_resend(email, subject, html)
                logger.info(f"PW reset email send status for {username}: {sent_ok}")
        
        # Always return success for security
        return jsonify({'success': True, 'message': 'If an account exists with the provided information, a reset link has been sent.'})
        
    except Exception as e:
        logger.error(f"Error in password reset request: {e}")
        # Still return success for security
        return jsonify({'success': True, 'message': 'If an account exists with the provided information, a reset link has been sent.'})

@app.route('/reset_password/<token>', methods=['GET', 'POST'])
def reset_password(token):
    """Handle password reset with token"""
    if request.method == 'GET':
        # Verify token is valid and not expired (24 hours)
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"""
                SELECT username, created_at, used 
                FROM password_reset_tokens 
                WHERE token = {ph}
            """, (token,))
            result = c.fetchone()
            
            if not result:
                flash('Invalid or expired reset link.', 'error')
                return redirect(url_for('public.index'))
            
            if result['used']:
                flash('This reset link has already been used.', 'error')
                return redirect(url_for('public.index'))
            
            # Check if token is expired (24 hours)
            created_at = datetime.fromisoformat(result['created_at'])
            if datetime.now() - created_at > timedelta(hours=24):
                flash('This reset link has expired.', 'error')
                return redirect(url_for('public.index'))
            
            return render_template('reset_password.html', token=token, username=result['username'])
    
    elif request.method == 'POST':
        new_password = request.form.get('password')
        confirm_password = request.form.get('confirm_password')
        
        if not new_password or not confirm_password:
            flash('Please fill in all fields.', 'error')
            return redirect(url_for('reset_password', token=token))
        
        if new_password != confirm_password:
            flash('Passwords do not match.', 'error')
            return redirect(url_for('reset_password', token=token))
        
        if len(new_password) < 6:
            flash('Password must be at least 6 characters long.', 'error')
            return redirect(url_for('reset_password', token=token))
        
        try:
            with get_db_connection() as conn:
                c = conn.cursor()
                
                # Verify token again
                ph = get_sql_placeholder()
                c.execute(f"""
                    SELECT username, created_at, used 
                    FROM password_reset_tokens 
                    WHERE token = {ph}
                """, (token,))
                result = c.fetchone()
                
                if not result or result['used']:
                    flash('Invalid or expired reset link.', 'error')
                    return redirect(url_for('public.index'))
                
                # Check expiration again
                created_at = datetime.fromisoformat(result['created_at'])
                if datetime.now() - created_at > timedelta(hours=24):
                    flash('This reset link has expired.', 'error')
                    return redirect(url_for('public.index'))
                
                # Update password
                hashed_password = generate_password_hash(new_password)
                c.execute(f"UPDATE users SET password = {ph} WHERE username = {ph}", 
                         (hashed_password, result['username']))
                
                # Mark token as used
                c.execute(f"UPDATE password_reset_tokens SET used = 1 WHERE token = {ph}", (token,))
                conn.commit()
                
                flash('Your password has been successfully reset. You can now log in with your new password.', 'success')
                return redirect(url_for('public.index'))
                
        except Exception as e:
            logger.error(f"Error resetting password: {e}")
            flash('An error occurred. Please try again.', 'error')
            return redirect(url_for('reset_password', token=token))

@app.route('/test_password_hash')
def test_password_hash():
    """Test password hashing and verification"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    test_password = "test123"
    
    # Test different hash methods
    from werkzeug.security import generate_password_hash, check_password_hash
    
    results = []
    
    # Test default hash
    try:
        hash1 = generate_password_hash(test_password)
        verify1 = check_password_hash(hash1, test_password)
        results.append({
            'method': 'default',
            'hash': hash1[:50] + '...',
            'verify_same': verify1,
            'verify_wrong': check_password_hash(hash1, "wrong")
        })
    except Exception as e:
        results.append({'method': 'default', 'error': str(e)})
    
    # Test with specific method
    try:
        hash2 = generate_password_hash(test_password, method='pbkdf2:sha256')
        verify2 = check_password_hash(hash2, test_password)
        results.append({
            'method': 'pbkdf2:sha256',
            'hash': hash2[:50] + '...',
            'verify_same': verify2,
            'verify_wrong': check_password_hash(hash2, "wrong")
        })
    except Exception as e:
        results.append({'method': 'pbkdf2:sha256', 'error': str(e)})
    
    # Test with scrypt
    try:
        hash3 = generate_password_hash(test_password, method='scrypt')
        verify3 = check_password_hash(hash3, test_password)
        results.append({
            'method': 'scrypt',
            'hash': hash3[:50] + '...',
            'verify_same': verify3,
            'verify_wrong': check_password_hash(hash3, "wrong")
        })
    except Exception as e:
        results.append({'method': 'scrypt', 'error': str(e)})
    
    return f"""
    <h2>Password Hash Testing</h2>
    <p>Test password: "{test_password}"</p>
    <pre>{json.dumps(results, indent=2)}</pre>
    <br>
    <h3>Test Specific Password:</h3>
    <form method="POST" action="/test_specific_password">
        <input type="text" name="username" placeholder="Username" required><br>
        <input type="password" name="password" placeholder="Password to test" required><br>
        <button type="submit">Test Login</button>
    </form>
    """
@app.route('/test_specific_password', methods=['POST'])
def test_specific_password():
    """Test a specific username/password combination"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    test_username = request.form.get('username')
    test_password = request.form.get('password')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT password FROM users WHERE username=?", (test_username,))
            user = c.fetchone()
            
            if not user:
                return f"User '{test_username}' not found"
            
            stored_password = user[0]
            
            result = {
                'username': test_username,
                'input_password': test_password,
                'stored_password_preview': stored_password[:30] + '...' if len(stored_password) > 30 else stored_password,
                'stored_password_length': len(stored_password),
                'starts_with_dollar': stored_password.startswith('$'),
                'starts_with_scrypt': stored_password.startswith('scrypt:'),
                'starts_with_pbkdf2': stored_password.startswith('pbkdf2:'),
            }
            
            # Test our login logic
            if stored_password and (stored_password.startswith('$') or stored_password.startswith('scrypt:') or stored_password.startswith('pbkdf2:')):
                result['detected_as'] = 'hashed'
                try:
                    from werkzeug.security import check_password_hash
                    password_correct = check_password_hash(stored_password, test_password)
                    result['check_password_hash_result'] = password_correct
                    
                    # Try to manually verify for debugging
                    import hashlib
                    result['debug_info'] = {
                        'werkzeug_version': 'checking...',
                        'hash_method_detected': stored_password.split(':')[0] if ':' in stored_password else 'unknown'
                    }
                except Exception as e:
                    result['check_password_hash_error'] = str(e)
                    password_correct = False
            else:
                result['detected_as'] = 'plain text'
                password_correct = (stored_password == test_password)
                result['plain_text_match'] = password_correct
            
            result['would_login_work'] = password_correct
            
            return f"""
            <h2>Password Test Results for {test_username}</h2>
            <pre>{json.dumps(result, indent=2)}</pre>
            <br>
            <a href="/debug_password/{test_username}">Go to password debug/reset page</a>
            """
            
    except Exception as e:
        return f"Error: {str(e)}"
@app.route('/migrate_passwords')
def migrate_passwords():
    """Migrate all plain text passwords to hashed passwords - ADMIN ONLY"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all users
            c.execute("SELECT username, password FROM users")
            users = c.fetchall()
            
            results = {
                'total_users': len(users),
                'already_hashed': 0,
                'migrated': 0,
                'failed': 0,
                'details': []
            }
            
            for user in users:
                username = user[0]
                password = user[1]
                
                if not password:
                    results['failed'] += 1
                    results['details'].append(f"{username}: No password set")
                    continue
                
                # Check if already hashed
                if password.startswith('$') or password.startswith('scrypt:') or password.startswith('pbkdf2:'):
                    results['already_hashed'] += 1
                    results['details'].append(f"{username}: Already hashed")
                else:
                    # It's plain text, hash it
                    try:
                        hashed_password = generate_password_hash(password)
                        c.execute("UPDATE users SET password = ? WHERE username = ?", 
                                (hashed_password, username))
                        results['migrated'] += 1
                        results['details'].append(f"{username}: Migrated successfully")
                    except Exception as e:
                        results['failed'] += 1
                        results['details'].append(f"{username}: Failed - {str(e)}")
            
            # Commit all changes
            conn.commit()
            
            # Format results for display
            return f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Password Migration Results</title>
                <style>
                    body {{
                        background: #000;
                        color: #fff;
                        font-family: Arial, sans-serif;
                        padding: 20px;
                        max-width: 800px;
                        margin: 0 auto;
                    }}
                    .success {{ color: #4db6ac; }}
                    .warning {{ color: #ffa726; }}
                    .error {{ color: #ef5350; }}
                    .stats {{
                        background: #1a1a1a;
                        padding: 20px;
                        border-radius: 8px;
                        margin: 20px 0;
                    }}
                    .details {{
                        background: #0a0a0a;
                        padding: 15px;
                        border-radius: 8px;
                        margin: 20px 0;
                        max-height: 400px;
                        overflow-y: auto;
                    }}
                    .detail-item {{
                        padding: 5px 0;
                        border-bottom: 1px solid #333;
                    }}
                    button {{
                        background: #4db6ac;
                        color: white;
                        border: none;
                        padding: 10px 20px;
                        border-radius: 4px;
                        cursor: pointer;
                        margin-top: 20px;
                    }}
                    button:hover {{
                        background: #5bc7bd;
                    }}
                </style>
            </head>
            <body>
                <h1>Password Migration Results</h1>
                <div class="stats">
                    <h2>Summary</h2>
                    <p>Total Users: <strong>{results['total_users']}</strong></p>
                    <p class="success">‚úì Successfully Migrated: <strong>{results['migrated']}</strong></p>
                    <p class="warning">‚ö† Already Hashed: <strong>{results['already_hashed']}</strong></p>
                    <p class="error">‚úó Failed: <strong>{results['failed']}</strong></p>
                </div>
                <div class="details">
                    <h3>Details</h3>
                    {''.join([f'<div class="detail-item">{detail}</div>' for detail in results['details']])}
                </div>
                <button onclick="window.location.href='/admin'">Back to Admin Dashboard</button>
                <button onclick="window.location.href='/test_password_hash'">Test Password Hashing</button>
            </body>
            </html>
            """
            
    except Exception as e:
        logger.error(f"Error during password migration: {str(e)}")
        return f"Migration failed: {str(e)}", 500

@app.route('/check_password_status')
def check_password_status():
    """Check the status of passwords in the database - ADMIN ONLY"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all users and their password status
            c.execute("SELECT username, password FROM users")
            users = c.fetchall()
            
            plain_text = []
            hashed = []
            no_password = []
            
            for user in users:
                username = user[0]
                password = user[1]
                
                if not password:
                    no_password.append(username)
                elif password.startswith('$') or password.startswith('scrypt:') or password.startswith('pbkdf2:'):
                    hashed.append(username)
                else:
                    plain_text.append(username)
            
            return f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Password Status Check</title>
                <style>
                    body {{
                        background: #000;
                        color: #fff;
                        font-family: Arial, sans-serif;
                        padding: 20px;
                        max-width: 800px;
                        margin: 0 auto;
                    }}
                    .section {{
                        background: #1a1a1a;
                        padding: 20px;
                        border-radius: 8px;
                        margin: 20px 0;
                    }}
                    .plain-text {{ border-left: 4px solid #ef5350; }}
                    .hashed {{ border-left: 4px solid #4db6ac; }}
                    .no-password {{ border-left: 4px solid #ffa726; }}
                    .user-list {{
                        display: flex;
                        flex-wrap: wrap;
                        gap: 10px;
                        margin-top: 10px;
                    }}
                    .user-item {{
                        background: #0a0a0a;
                        padding: 5px 10px;
                        border-radius: 4px;
                    }}
                    .migrate-btn {{
                        background: #ef5350;
                        color: white;
                        border: none;
                        padding: 15px 30px;
                        border-radius: 4px;
                        cursor: pointer;
                        font-size: 16px;
                        margin: 20px 0;
                    }}
                    .migrate-btn:hover {{
                        background: #f44336;
                    }}
                    button {{
                        background: #4db6ac;
                        color: white;
                        border: none;
                        padding: 10px 20px;
                        border-radius: 4px;
                        cursor: pointer;
                        margin-right: 10px;
                    }}
                    button:hover {{
                        background: #5bc7bd;
                    }}
                </style>
            </head>
            <body>
                <h1>Password Security Status</h1>
                
                <div class="section plain-text">
                    <h2>‚ö†Ô∏è Plain Text Passwords ({len(plain_text)} users)</h2>
                    <p>These passwords are stored in plain text and need to be migrated:</p>
                    <div class="user-list">
                        {''.join([f'<span class="user-item">{u}</span>' for u in plain_text]) if plain_text else '<em>None</em>'}
                    </div>
                </div>
                
                <div class="section hashed">
                    <h2>‚úÖ Hashed Passwords ({len(hashed)} users)</h2>
                    <p>These passwords are properly hashed and secure:</p>
                    <div class="user-list">
                        {''.join([f'<span class="user-item">{u}</span>' for u in hashed]) if hashed else '<em>None</em>'}
                    </div>
                </div>
                
                <div class="section no-password">
                    <h2>‚ùì No Password Set ({len(no_password)} users)</h2>
                    <p>These users have no password set:</p>
                    <div class="user-list">
                        {''.join([f'<span class="user-item">{u}</span>' for u in no_password]) if no_password else '<em>None</em>'}
                    </div>
                </div>
                
                {f'''
                <button class="migrate-btn" onclick="if(confirm(&quot;This will hash all {len(plain_text)} plain text passwords. Continue?&quot;)) window.location.href=&quot;/migrate_passwords&quot;">
                    üîí Migrate {len(plain_text)} Plain Text Passwords to Hashed
                </button>
                ''' if plain_text else '<p style="color: #4db6ac; font-size: 18px;">‚úÖ All passwords are already hashed!</p>'}
                
                <div style="margin-top: 30px;">
                    <button onclick="window.location.href='/admin'">Back to Admin Dashboard</button>
                    <button onclick="window.location.reload()">Refresh Status</button>
                </div>
            </body>
            </html>
            """
            
    except Exception as e:
        logger.error(f"Error checking password status: {str(e)}")
        return f"Error: {str(e)}", 500
def check_duplicate_users():
    """Check for duplicate usernames in the database - ADMIN ONLY"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check for duplicate usernames
            c.execute("""
                SELECT username, COUNT(*) as count, GROUP_CONCAT(rowid) as ids, 
                       GROUP_CONCAT(password, '|||') as passwords,
                       GROUP_CONCAT(email, '|||') as emails,
                       GROUP_CONCAT(subscription, '|||') as subscriptions
                FROM users 
                GROUP BY LOWER(username) 
                HAVING count > 1
            """)
            duplicates = c.fetchall()
            
            # Get all admin records specifically
            c.execute("""
                SELECT rowid, username, email, password, subscription, created_at
                FROM users 
                WHERE LOWER(username) = 'admin'
                ORDER BY rowid
            """)
            admin_records = c.fetchall()
            
            # Build the duplicates table HTML
            duplicates_html = ""
            if duplicates:
                duplicates_rows = []
                for dup in duplicates:
                    username = str(dup[0])
                    count = str(dup[1])
                    row_ids = str(dup[2])
                    password_preview = str(dup[3])[:50] if dup[3] else ""
                    emails = str(dup[4])
                    subscriptions = str(dup[5])
                    
                    row_html = f'''
                        <tr>
                            <td>{username}</td>
                            <td>{count}</td>
                            <td>{row_ids}</td>
                            <td class="password-cell">{password_preview}...</td>
                            <td>{emails}</td>
                            <td>{subscriptions}</td>
                            <td>
                                <button class="fix-btn" onclick="if(confirm('Keep only the first record and delete duplicates for {username}?')) window.location.href='/fix_duplicate_user/{username}'">
                                    Fix Duplicates
                                </button>
                            </td>
                        </tr>'''
                    duplicates_rows.append(row_html)
                
                duplicates_html = f'''
                <div class="section duplicate">
                    <h2>‚ö†Ô∏è Duplicate Usernames Found ({len(duplicates)} usernames)</h2>
                    <table>
                        <tr>
                            <th>Username</th>
                            <th>Count</th>
                            <th>Row IDs</th>
                            <th>Passwords</th>
                            <th>Emails</th>
                            <th>Subscriptions</th>
                            <th>Action</th>
                        </tr>
                        {"".join(duplicates_rows)}
                    </table>
                </div>'''
            else:
                duplicates_html = '''
                <div class="section" style="border-left: 4px solid #4db6ac;">
                    <h2>‚úÖ No Duplicate Usernames Found</h2>
                    <p>All usernames in the database are unique.</p>
                </div>'''
            
            # Build admin records HTML
            admin_rows = []
            for record in admin_records:
                row_id = str(record[0])
                username = str(record[1])
                email = str(record[2]) if record[2] else 'N/A'
                password_preview = str(record[3])[:30] if record[3] else 'N/A'
                subscription = str(record[4]) if record[4] else 'N/A'
                created_at = str(record[5]) if record[5] else 'N/A'
                
                admin_row = f'''
                        <tr>
                            <td>{row_id}</td>
                            <td>{username}</td>
                            <td>{email}</td>
                            <td class="password-cell">{password_preview}...</td>
                            <td>{subscription}</td>
                            <td>{created_at}</td>
                        </tr>'''
                admin_rows.append(admin_row)
            
            admin_warning = ''
            admin_fix_button = ''
            if len(admin_records) > 1:
                admin_warning = '''
                    <div class="warning">
                        ‚ö†Ô∏è Found multiple records for admin account. There should only be 1.
                    </div>'''
                admin_fix_button = '''
                    <button class="fix-btn" onclick="if(confirm('This will keep the first admin record and delete the rest. Continue?')) window.location.href='/fix_duplicate_user/admin'">
                        Fix Admin Duplicates
                    </button>'''
            
            return f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Duplicate Users Check</title>
                <style>
                    body {{
                        background: #000;
                        color: #fff;
                        font-family: Arial, sans-serif;
                        padding: 20px;
                        max-width: 1200px;
                        margin: 0 auto;
                    }}
                    .section {{
                        background: #1a1a1a;
                        padding: 20px;
                        border-radius: 8px;
                        margin: 20px 0;
                    }}
                    .duplicate {{
                        border-left: 4px solid #ef5350;
                    }}
                    .admin-records {{
                        border-left: 4px solid #ffa726;
                    }}
                    table {{
                        width: 100%;
                        border-collapse: collapse;
                        margin-top: 15px;
                    }}
                    th, td {{
                        padding: 10px;
                        text-align: left;
                        border-bottom: 1px solid #333;
                    }}
                    th {{
                        background: #0a0a0a;
                        color: #4db6ac;
                    }}
                    .password-cell {{
                        font-family: monospace;
                        font-size: 12px;
                        word-break: break-all;
                    }}
                    .fix-btn {{
                        background: #ef5350;
                        color: white;
                        border: none;
                        padding: 8px 15px;
                        border-radius: 4px;
                        cursor: pointer;
                        margin: 5px;
                    }}
                    .fix-btn:hover {{
                        background: #f44336;
                    }}
                    button {{
                        background: #4db6ac;
                        color: white;
                        border: none;
                        padding: 10px 20px;
                        border-radius: 4px;
                        cursor: pointer;
                        margin-right: 10px;
                    }}
                    button:hover {{
                        background: #5bc7bd;
                    }}
                    .warning {{
                        background: rgba(255, 152, 0, 0.1);
                        border: 1px solid #ff9800;
                        padding: 15px;
                        border-radius: 4px;
                        margin: 15px 0;
                    }}
                </style>
            </head>
            <body>
                <h1>Duplicate Users Check</h1>
                
                {duplicates_html}
    
                <div class="section admin-records">
                    <h2>Admin Account Records ({len(admin_records)} records)</h2>
                    {admin_warning}
                    <table>
                        <tr>
                            <th>Row ID</th>
                            <th>Username</th>
                            <th>Email</th>
                            <th>Password (first 30 chars)</th>
                            <th>Subscription</th>
                            <th>Created At</th>
                        </tr>
                        {"".join(admin_rows)}
                    </table>
                    {admin_fix_button}
                </div>
                
                <div style="margin-top: 30px;">
                    <button onclick="window.location.href='/admin'">Back to Admin Dashboard</button>
                    <button onclick="window.location.reload()">Refresh</button>
                    <button onclick="window.location.href='/check_password_status'">Check Password Status</button>
                </div>
            </body>
            </html>
            """
            
    except Exception as e:
        logger.error(f"Error checking duplicate users: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return f"Error: {str(e)}", 500

@app.route('/fix_duplicate_user/<username>')
def fix_duplicate_user(username):
    """Fix duplicate user records by keeping only the first one - ADMIN ONLY"""
    if session.get('username') != 'admin':
        return "Unauthorized", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all records for this username
            c.execute("""
                SELECT rowid, username, password, email, subscription
                FROM users 
                WHERE LOWER(username) = LOWER(?)
                ORDER BY rowid
            """, (username,))
            records = c.fetchall()
            
            if len(records) <= 1:
                return f"No duplicates found for {username}. <a href='/check_duplicate_users'>Go back</a>"
            
            # Keep the first record, delete the rest
            keep_record = records[0]
            delete_ids = [str(r[0]) for r in records[1:]]
            
            # Delete duplicate records
            c.execute(f"""
                DELETE FROM users 
                WHERE rowid IN ({','.join(['?' for _ in delete_ids])})
            """, delete_ids)
            
            conn.commit()
            
            return f"""
            <!DOCTYPE html>
            <html>
            <head>
                <title>Duplicate Fixed</title>
                <style>
                    body {{
                        background: #000;
                        color: #fff;
                        font-family: Arial, sans-serif;
                        padding: 20px;
                        max-width: 800px;
                        margin: 0 auto;
                    }}
                    .success {{
                        background: rgba(77, 182, 172, 0.1);
                        border: 1px solid #4db6ac;
                        padding: 20px;
                        border-radius: 8px;
                        margin: 20px 0;
                    }}
                    button {{
                        background: #4db6ac;
                        color: white;
                        border: none;
                        padding: 10px 20px;
                        border-radius: 4px;
                        cursor: pointer;
                        margin-right: 10px;
                        margin-top: 20px;
                    }}
                    button:hover {{
                        background: #5bc7bd;
                    }}
                </style>
            </head>
            <body>
                <h1>Duplicate Fixed</h1>
                <div class="success">
                    <h2>‚úÖ Successfully Fixed Duplicates for {username}</h2>
                    <p>Kept record ID: {keep_record[0]}</p>
                    <p>Deleted {len(delete_ids)} duplicate records (IDs: {', '.join(delete_ids)})</p>
                    <p>Email: {keep_record[3] or 'N/A'}</p>
                    <p>Subscription: {keep_record[4] or 'N/A'}</p>
                </div>
                <button onclick="window.location.href='/check_duplicate_users'">Check for More Duplicates</button>
                <button onclick="window.location.href='/admin'">Back to Admin Dashboard</button>
            </body>
            </html>
            """
            
    except Exception as e:
        logger.error(f"Error fixing duplicate user {username}: {str(e)}")
        return f"Error: {str(e)}", 500

@app.route('/check_unread_messages')
@login_required
def check_unread_messages():
    username = session['username']
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT COUNT(*) as count FROM messages WHERE receiver=? AND is_read=0", (username,))
            result = c.fetchone()
            unread_count = result['count'] if hasattr(result, 'keys') else result[0]
        return jsonify({'unread_count': unread_count})
    except Exception as e:
        logger.error(f"Error checking unread messages for {username}: {str(e)}")
        abort(500)
@app.route('/feed')
@login_required
def feed():
    """Old feed route - redirect to home timeline React page"""
    return redirect('/home')
@app.route('/add_reaction', methods=['POST'])
@login_required
def add_reaction():
    username = session['username']
    post_id = request.form.get('post_id', type=int)
    reaction_type = request.form.get('reaction')

    if not all([post_id, reaction_type]):
        return jsonify({'success': False, 'error': 'Missing data'}), 400

    try:
        comm_id = None
        view_count = None
        with get_db_connection() as conn:
            c = conn.cursor()

            # Check if the user already reacted to this post
            c.execute("SELECT id, reaction_type FROM reactions WHERE post_id = ? AND username = ?", (post_id, username))
            existing = c.fetchone()

            # Retrieve post metadata upfront (owner + community)
            c.execute("SELECT username, community_id FROM posts WHERE id = ?", (post_id,))
            post_data = c.fetchone()
            comm_id = post_data['community_id'] if post_data and hasattr(post_data, 'keys') else (post_data[1] if post_data and len(post_data) > 1 else None)

            if existing:
                if existing['reaction_type'] == reaction_type:
                    # User clicked the same reaction again, so remove it (toggle off)
                    c.execute("DELETE FROM reactions WHERE id = ?", (existing['id'],))
                else:
                    # User changed their reaction, so update it
                    c.execute("UPDATE reactions SET reaction_type = ? WHERE id = ?", (reaction_type, existing['id']))
            else:
                # No existing reaction, so insert a new one
                c.execute("INSERT INTO reactions (post_id, username, reaction_type) VALUES (?, ?, ?)",
                          (post_id, username, reaction_type))

            # Create notification for post owner and other engaged users (only if adding/changing reaction, not removing)
            if post_data and (existing is None or (existing and existing['reaction_type'] != reaction_type)):
                logger.info(f"Reaction notification check - Post owner: {post_data['username'] if post_data else 'None'}, Reactor: {username}")
                owner = post_data['username']
                recipients = set()
                if owner and owner != username:
                    recipients.add(owner)
                # Prior repliers
                try:
                    c.execute("SELECT DISTINCT username FROM replies WHERE post_id=?", (post_id,))
                    for rr in c.fetchall() or []:
                        u = rr['username'] if hasattr(rr,'keys') else rr[0]
                        if u and u != username and u != owner:
                            recipients.add(u)
                except Exception:
                    pass
                # Prior reactors
                try:
                    c.execute("SELECT DISTINCT username FROM reactions WHERE post_id=?", (post_id,))
                    for rv in c.fetchall() or []:
                        u = rv['username'] if hasattr(rv,'keys') else rv[0]
                        if u and u != username and u != owner:
                            recipients.add(u)
                except Exception:
                    pass
                # Insert notifications
                for target in recipients:
                    try:
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message)
                            VALUES (?, ?, 'reaction', ?, ?, ?)
                        """, (target, username, post_id, comm_id, f"{username} reacted in a thread you follow"))
                    except Exception:
                        try:
                            c.execute("""
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                                VALUES (?, ?, 'reaction', ?, ?, ?, NOW(), 0)
                                ON CONFLICT(user_id, from_user, type, post_id, community_id) DO UPDATE SET created_at=excluded.created_at, is_read=0, message=excluded.message
                            """, (target, username, post_id, comm_id, f"{username} reacted in a thread you follow"))
                        except Exception:
                            pass
                logger.info(f"Created reaction notifications for {len(recipients)} recipients")
            
            conn.commit()

            new_counts, new_user_reaction = get_post_reaction_summary(c, post_id, username)

            try:
                view_count = upsert_post_view(c, int(post_id), username)
                conn.commit()
            except Exception as view_err:
                logger.warning(f"add_reaction view tracking failed for post {post_id}: {view_err}")

            return jsonify({
                'success': True,
                'counts': new_counts,
                'user_reaction': new_user_reaction,
                'view_count': int(view_count or 0) if view_count is not None else None
            })

    except Exception as e:
        logger.error(f"Error adding reaction: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

    finally:
        try:
            if comm_id:
                invalidate_community_cache(comm_id)
        except Exception as cache_err:
            logger.warning(f"Failed to invalidate cache after reaction for community {comm_id}: {cache_err}")




def notify_post_reply_recipients(*, post_id: int, from_user: str, community_id: int|None, parent_reply_id: int|None):
    """Create in-app notifications and web push for post reply recipients.
    Recipients: post owner and (if applicable) parent reply author; excludes sender; dedup within short window.
    Additionally notify prior engagers (users who replied or reacted on the post), excluding the actor and already-notified recipients.
    """
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Determine recipients
            recipients = set()
            c.execute("SELECT username FROM posts WHERE id=?", (post_id,))
            row = c.fetchone()
            post_owner = (row['username'] if hasattr(row,'keys') else row[0]) if row else None
            if post_owner and post_owner != from_user:
                recipients.add(post_owner)
            parent_author = None
            if parent_reply_id:
                c.execute("SELECT username FROM replies WHERE id=?", (parent_reply_id,))
                r2 = c.fetchone()
                parent_author = (r2['username'] if hasattr(r2,'keys') else r2[0]) if r2 else None
                if parent_author and parent_author not in (from_user, post_owner):
                    recipients.add(parent_author)

            # Include prior engagers: anyone who replied on this post
            try:
                c.execute("SELECT DISTINCT username FROM replies WHERE post_id=?", (post_id,))
                for rr in c.fetchall() or []:
                    uname = rr['username'] if hasattr(rr,'keys') else rr[0]
                    if uname and uname not in (from_user, post_owner, parent_author):
                        recipients.add(uname)
            except Exception as qe:
                logger.warning(f"collect prior repliers failed: {qe}")
            # Include prior reactors
            try:
                c.execute("SELECT DISTINCT username FROM reactions WHERE post_id=?", (post_id,))
                for rv in c.fetchall() or []:
                    uname = rv['username'] if hasattr(rv,'keys') else rv[0]
                    if uname and uname not in (from_user, post_owner, parent_author):
                        recipients.add(uname)
            except Exception as qe2:
                logger.warning(f"collect prior reactors failed: {qe2}")

            # Insert notifications (dedupe 10s by same from_user/post/type/recipient)
            for target in recipients:
                try:
                    if USE_MYSQL:
                        c.execute("""
                            SELECT id FROM notifications
                            WHERE user_id=? AND from_user=? AND type='reply' AND post_id=?
                              AND created_at > DATE_SUB(NOW(), INTERVAL 10 SECOND)
                            LIMIT 1
                        """, (target, from_user, post_id))
                    else:
                        c.execute("""
                            SELECT id FROM notifications
                            WHERE user_id=? AND from_user=? AND type='reply' AND post_id=?
                              AND datetime(created_at) > datetime('now','-10 seconds')
                            LIMIT 1
                        """, (target, from_user, post_id))
                    exists = c.fetchone()
                    if not exists:
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                            VALUES (?, ?, 'reply', ?, ?, ?, NOW(), 0)
                            ON DUPLICATE KEY UPDATE
                                created_at = NOW(),
                                message = VALUES(message),
                                is_read = 0
                        """, (target, from_user, post_id, community_id, f"{from_user} replied"))
                        conn.commit()
                except Exception as ne:
                    logger.warning(f"reply notify db error to {target}: {ne}")

                # Push notify (tag per user+post to allow coalescing)
                try:
                    send_push_to_user(target, {
                        'title': f'New reply from {from_user}',
                        'body': 'Tap to view the conversation',
                        'url': f'/community/{community_id}/polls_react',
                        'tag': f'post-reply-{post_id}-{target}'
                    })
                except Exception as pe:
                    logger.warning(f"reply push error to {target}: {pe}")
    except Exception as e:
        logger.error(f"notify_post_reply_recipients error: {e}")


# ---- Community Tasks: DB helpers ----
def ensure_tasks_table():
    ensure_tasks_table_service()


def is_community_admin_or_owner(username: str, community_id: int) -> bool:
    return bool(is_app_admin(username) or service_is_community_admin_or_owner(username, community_id))


@app.route('/api/community_tasks')
@login_required
def api_community_tasks():
    """List community-wide tasks (assigned to entire community)."""
    community_id = request.args.get('community_id', type=int)
    if not community_id:
        return jsonify({'success': False, 'error': 'community_id required'}), 400
    try:
        ensure_tasks_table()
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute(
                """
                SELECT id, community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status
                FROM tasks
                WHERE community_id = ? AND (assigned_to_username IS NULL OR assigned_to_username = '')
                ORDER BY (CASE WHEN due_date IS NULL THEN 1 ELSE 0 END), due_date ASC, id DESC
                """,
                (community_id,)
            )
            tasks = [dict(row) for row in c.fetchall()]
        return jsonify({'success': True, 'tasks': tasks})
    except Exception as e:
        logger.error(f"api_community_tasks error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/my_tasks')
@login_required
def api_my_tasks():
    """List tasks assigned to the current user for a community."""
    username = session['username']
    community_id = request.args.get('community_id', type=int)
    if not community_id:
        return jsonify({'success': False, 'error': 'community_id required'}), 400
    try:
        ensure_tasks_table()
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute(
                """
                SELECT id, community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status
                FROM tasks
                WHERE community_id = ? AND assigned_to_username = ?
                ORDER BY (CASE WHEN due_date IS NULL THEN 1 ELSE 0 END), due_date ASC, id DESC
                """,
                (community_id, username)
            )
            tasks = [dict(row) for row in c.fetchall()]
        return jsonify({'success': True, 'tasks': tasks})
    except Exception as e:
        logger.error(f"api_my_tasks error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/create_task', methods=['POST'])
@login_required
def api_create_task():
    """Create a task. Non-admins can only assign to themselves. Admins can assign to any member or entire community."""
    username = session['username']
    title = (request.form.get('title') or '').strip()
    description = (request.form.get('description') or '').strip()
    due_date = (request.form.get('due_date') or '').strip()  # 'YYYY-MM-DD' or empty
    community_id = request.form.get('community_id', type=int)
    assign_all = (request.form.get('assign_all') or '').strip().lower() == 'true'
    assigned_members = request.form.getlist('assigned_members[]') or []
    status = (request.form.get('status') or 'not_started').strip().lower()
    if status not in ('not_started','ongoing','completed'):
        status = 'not_started'

    if not community_id or not title:
        return jsonify({'success': False, 'error': 'community_id and title are required'}), 400

    try:
        ensure_tasks_table()
        # Permission checks
        admin_ok = is_community_admin_or_owner(username, community_id)
        if assign_all and not admin_ok:
            return jsonify({'success': False, 'error': 'Only admins can assign to entire community'}), 403
        if assigned_members:
            # If non-admin, can only assign to self
            if not admin_ok:
                if not (len(assigned_members) == 1 and assigned_members[0] == username):
                    return jsonify({'success': False, 'error': 'You can only assign tasks to yourself'}), 403
            else:
                # Validate assignees are members of the community
                try:
                    with get_db_connection() as _conn2:
                        _c2 = _conn2.cursor()
                        placeholders = ','.join(['?'] * len(assigned_members)) if assigned_members else ''
                        if placeholders:
                            _c2.execute(
                                f"""
                                SELECT u.username
                                FROM users u JOIN user_communities uc ON u.id = uc.user_id
                                WHERE uc.community_id = ? AND u.username IN ({placeholders})
                                """,
                                (community_id, *assigned_members)
                            )
                            rows = _c2.fetchall() or []
                            valid = set([r['username'] if hasattr(r, 'keys') else r[0] for r in rows])
                            assigned_members = [u for u in assigned_members if u in valid]
                except Exception as ve:
                    logger.warning(f"assignee validation failed: {ve}")
                if not assigned_members:
                    return jsonify({'success': False, 'error': 'No valid assignees in this community'}), 400
        if not assign_all and not assigned_members:
            # Default to self assignment
            assigned_members = [username]

        with get_db_connection() as conn:
            c = conn.cursor()
            created_at_sql = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

            # Create tasks
            created_ids = []
            if assign_all:
                # Community-wide task (single row with NULL assignee)
                try:
                    if 'USE_MYSQL' in globals() and USE_MYSQL:
                        c.execute(
                            """
                            INSERT INTO tasks (community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status)
                            VALUES (?, ?, ?, NULLIF(?, ''), NULL, ?, NOW(), 0, ?)
                            """,
                            (community_id, title, description, due_date, username, status)
                        )
                    else:
                        c.execute(
                            """
                            INSERT INTO tasks (community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status)
                            VALUES (?, ?, ?, NULLIF(?, ''), NULL, ?, ?, 0, ?)
                            """,
                            (community_id, title, description, due_date, username, created_at_sql, status)
                        )
                    task_id = c.lastrowid
                    created_ids.append(task_id)
                except Exception as ie:
                    logger.error(f"insert community task error: {ie}")
                # Notify all members except creator
                try:
                    c.execute(
                        """
                        SELECT u.username FROM users u
                        JOIN user_communities uc ON u.id = uc.user_id
                        WHERE uc.community_id = ? AND u.username != ?
                        """,
                        (community_id, username)
                    )
                    members = [r['username'] if hasattr(r, 'keys') else r[0] for r in c.fetchall()]
                    # community name
                    community_name = None
                    try:
                        c.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
                        rr = c.fetchone()
                        if rr:
                            community_name = rr['name'] if hasattr(rr, 'keys') else rr[0]
                    except Exception:
                        pass
                    message = f"New community task in {community_name}: {title}" if community_name else f"New community task: {title}"
                    link = f"/community/{community_id}/tasks_react"
                    for m in members:
                        try:
                            if 'USE_MYSQL' in globals() and USE_MYSQL:
                                c.execute(
                                    """
                                    INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                                    VALUES (?, ?, 'task_assigned', ?, ?, NOW(), 0, ?)
                                    ON DUPLICATE KEY UPDATE created_at = NOW(), message = VALUES(message), is_read = 0, link = VALUES(link)
                                    """,
                                    (m, username, community_id, message, link)
                                )
                            else:
                                c.execute(
                                    """
                                    INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                                    VALUES (?, ?, 'task_assigned', ?, ?, datetime('now'), 0, ?)
                                    ON CONFLICT(user_id, from_user, type, community_id)
                                    DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                                    """,
                                    (m, username, community_id, message, link)
                                )
                        except Exception as ne:
                            logger.warning(f"task assign notify (community) error to {m}: {ne}")
                        try:
                            send_push_to_user(m, {
                                'title': 'New community task',
                                'body': title[:100],
                                'url': link,
                                'tag': f'task-{community_id}-{m}'
                            })
                        except Exception:
                            pass
                except Exception as notify_all_err:
                    logger.warning(f"notify all tasks error: {notify_all_err}")
            else:
                # Individual assignments (one task row per assignee)
                for assignee in assigned_members:
                    try:
                        if 'USE_MYSQL' in globals() and USE_MYSQL:
                            c.execute(
                                """
                                INSERT INTO tasks (community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status)
                                VALUES (?, ?, ?, NULLIF(?, ''), ?, ?, NOW(), 0, ?)
                                """,
                                (community_id, title, description, due_date, assignee, username, status)
                            )
                        else:
                            c.execute(
                                """
                                INSERT INTO tasks (community_id, title, description, due_date, assigned_to_username, created_by_username, created_at, completed, status)
                                VALUES (?, ?, ?, NULLIF(?, ''), ?, ?, ?, 0, ?)
                                """,
                                (community_id, title, description, due_date, assignee, username, created_at_sql, status)
                            )
                        task_id = c.lastrowid
                        created_ids.append(task_id)
                        # Notify assignee (skip self-notification)
                        link = f"/community/{community_id}/tasks_react"
                        message = f"{username} assigned you a task: {title}"
                        if assignee != username:
                            try:
                                if 'USE_MYSQL' in globals() and USE_MYSQL:
                                    c.execute(
                                        """
                                        INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                                        VALUES (?, ?, 'task_assigned', ?, ?, NOW(), 0, ?)
                                        ON DUPLICATE KEY UPDATE created_at = NOW(), message = VALUES(message), is_read = 0, link = VALUES(link)
                                        """,
                                        (assignee, username, community_id, message, link)
                                    )
                                else:
                                    c.execute(
                                        """
                                        INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                                        VALUES (?, ?, 'task_assigned', ?, ?, datetime('now'), 0, ?)
                                        ON CONFLICT(user_id, from_user, type, community_id)
                                        DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                                        """,
                                        (assignee, username, community_id, message, link)
                                    )
                            except Exception as ne:
                                logger.warning(f"task assign notify error to {assignee}: {ne}")
                            try:
                                send_push_to_user(assignee, {
                                    'title': 'New task assigned',
                                    'body': title[:100],
                                    'url': link,
                                    'tag': f'task-{community_id}-{assignee}'
                                })
                            except Exception:
                                pass
                    except Exception as ie:
                        logger.error(f"insert individual task error: {ie}")

            conn.commit()
        return jsonify({'success': True, 'task_ids': created_ids})
    except Exception as e:
        logger.error(f"api_create_task error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/complete_task', methods=['POST'])
@login_required
def api_complete_task():
    """Mark a task complete. Only assignee or admin/owner can mark complete."""
    username = session['username']
    task_id = request.form.get('task_id', type=int)
    community_id = request.form.get('community_id', type=int)
    completed = request.form.get('completed', 'true').lower() == 'true'
    if not task_id or not community_id:
        return jsonify({'success': False, 'error': 'task_id and community_id required'}), 400
    try:
        ensure_tasks_table()
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT assigned_to_username FROM tasks WHERE id = ? AND community_id = ?", (task_id, community_id))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Task not found'}), 404
            assignee = row['assigned_to_username'] if hasattr(row, 'keys') else row[0]
            admin_ok = is_community_admin_or_owner(username, community_id)
            if assignee and assignee != username and not admin_ok:
                return jsonify({'success': False, 'error': 'Not allowed'}), 403
            if completed:
                c.execute("UPDATE tasks SET completed = 1, status = 'completed' WHERE id = ?", (task_id,))
            else:
                # If unchecking completed, move to ongoing unless explicitly set otherwise later
                c.execute("UPDATE tasks SET completed = 0, status = CASE WHEN status='completed' THEN 'ongoing' ELSE status END WHERE id = ?", (task_id,))
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_complete_task error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/edit_task', methods=['POST'])
@login_required
def api_edit_task():
    """Edit a task (title, description, due_date, status). Only creator or admin/owner."""
    username = session['username']
    task_id = request.form.get('task_id', type=int)
    community_id = request.form.get('community_id', type=int)
    if not task_id or not community_id:
        return jsonify({'success': False, 'error': 'task_id and community_id required'}), 400
    title = (request.form.get('title') or '').strip()
    description = (request.form.get('description') or '').strip()
    due_date = (request.form.get('due_date') or '').strip()
    status = (request.form.get('status') or '').strip().lower()
    if status and status not in ('not_started','ongoing','completed'):
        status = ''
    try:
        ensure_tasks_table()
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT created_by_username FROM tasks WHERE id=? AND community_id=?", (task_id, community_id))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Task not found'}), 404
            creator = row['created_by_username'] if hasattr(row, 'keys') else row[0]
            admin_ok = is_community_admin_or_owner(username, community_id)
            if username != creator and not admin_ok:
                return jsonify({'success': False, 'error': 'Not allowed'}), 403
            sets = []
            params = []
            if title:
                sets.append('title = ?')
                params.append(title)
            if description or description == '':
                sets.append('description = ?')
                params.append(description)
            if due_date or due_date == '':
                sets.append("due_date = NULLIF(?, '')")
                params.append(due_date)
            if status:
                sets.append('status = ?')
                params.append(status)
            if not sets:
                return jsonify({'success': True})
            params.extend([task_id, community_id])
            c.execute(f"UPDATE tasks SET {', '.join(sets)} WHERE id = ? AND community_id = ?", tuple(params))
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_edit_task error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/delete_task', methods=['POST'])
@login_required
def api_delete_task():
    """Delete a task. Only creator or admin/owner."""
    username = session['username']
    task_id = request.form.get('task_id', type=int)
    community_id = request.form.get('community_id', type=int)
    if not task_id or not community_id:
        return jsonify({'success': False, 'error': 'task_id and community_id required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT created_by_username FROM tasks WHERE id=? AND community_id=?", (task_id, community_id))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Task not found'}), 404
            creator = row['created_by_username'] if hasattr(row, 'keys') else row[0]
            admin_ok = is_community_admin_or_owner(username, community_id)
            if username != creator and not admin_ok:
                return jsonify({'success': False, 'error': 'Not allowed'}), 403
            c.execute("DELETE FROM tasks WHERE id=? AND community_id=?", (task_id, community_id))
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_delete_task error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/admin/grant_admin', methods=['POST'])
@login_required
def admin_grant_admin():
    """Grant community admin role to a user. Requires app admin or the community owner.
    Accepts community_id or community_name, and username.
    """
    actor = session.get('username')
    target_username = (request.form.get('username') or '').strip()
    community_id = request.form.get('community_id', type=int)
    community_name = (request.form.get('community_name') or '').strip()
    if not target_username or (not community_id and not community_name):
        return jsonify({'success': False, 'error': 'username and community_id or community_name required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Resolve community_id by name if needed
            if not community_id and community_name:
                c.execute("SELECT id, creator_username FROM communities WHERE name = ?", (community_name,))
                row = c.fetchone()
                if not row:
                    return jsonify({'success': False, 'error': 'Community not found'}), 404
                community_id = row['id'] if hasattr(row, 'keys') else row[0]
                owner_username = row['creator_username'] if hasattr(row, 'keys') else row[1]
            else:
                c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
                rr = c.fetchone()
                if not rr:
                    return jsonify({'success': False, 'error': 'Community not found'}), 404
                owner_username = rr['creator_username'] if hasattr(rr, 'keys') else rr[0]

            # Permission: app admin or owner
            if actor != 'admin' and actor != owner_username:
                return jsonify({'success': False, 'error': 'Not authorized'}), 403

            # Ensure target user exists
            c.execute("SELECT id FROM users WHERE LOWER(username) = LOWER(?)", (target_username,))
            ur = c.fetchone()
            if not ur:
                return jsonify({'success': False, 'error': 'Target user not found'}), 404
            target_id = ur['id'] if hasattr(ur, 'keys') else ur[0]

            # Ensure membership in user_communities
            now_sql = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            try:
                if 'USE_MYSQL' in globals() and USE_MYSQL:
                    c.execute(
                        """
                        INSERT INTO user_communities (user_id, community_id, role, joined_at)
                        VALUES (?, ?, 'admin', ?)
                        ON DUPLICATE KEY UPDATE role='admin'
                        """,
                        (target_id, community_id, now_sql)
                    )
                else:
                    c.execute(
                        """
                        INSERT INTO user_communities (user_id, community_id, role, joined_at)
                        VALUES (?, ?, 'admin', ?)
                        ON CONFLICT(user_id, community_id) DO UPDATE SET role='admin'
                        """,
                        (target_id, community_id, now_sql)
                    )
            except Exception:
                # Fallback: update if exists
                try:
                    c.execute("UPDATE user_communities SET role='admin' WHERE user_id=? AND community_id=?", (target_id, community_id))
                except Exception:
                    pass

            # Also record in legacy community_admins (best-effort)
            try:
                if 'USE_MYSQL' in globals() and USE_MYSQL:
                    c.execute("INSERT IGNORE INTO community_admins (community_id, username) VALUES (?, ?)", (community_id, target_username))
                else:
                    c.execute("INSERT OR IGNORE INTO community_admins (community_id, username) VALUES (?, ?)", (community_id, target_username))
            except Exception:
                pass

            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"admin_grant_admin error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500




@app.route('/get_logo')
def get_logo():
    """Get the current logo path"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Quote `key` to avoid reserved word issues on MySQL
            c.execute("SELECT value FROM site_settings WHERE `key` = 'logo_path'")
            result = c.fetchone()
        # Normalize row to filename string
        try:
            filename = get_scalar_result(result, column_index=0, column_name='value')
        except Exception:
            try:
                filename = result['value'] if hasattr(result, 'keys') else (result[0] if result else None)
            except Exception:
                filename = None

        if not filename:
            return jsonify({'success': True, 'logo_path': None})

        # Append a cache-busting query using file mtime (or current time fallback)
        try:
            static_path = os.path.join('static', filename)
            version = int(os.path.getmtime(static_path))
        except Exception:
            version = int(time.time())
        return jsonify({'success': True, 'logo_path': f"{filename}?v={version}"})
    except:
        return jsonify({'success': True, 'logo_path': None})


@app.route('/remove_logo', methods=['POST'])
@login_required
def remove_logo():
    """Remove the logo - admin only"""
    if session['username'] != 'admin':
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get current logo path to delete file
            c.execute("SELECT value FROM site_settings WHERE `key` = 'logo_path'")
            result = c.fetchone()
            
            if result and result['value']:
                # Delete the file
                logo_path = os.path.join('static', result['value'])
                if os.path.exists(logo_path):
                    os.remove(logo_path)
            
            # Remove from database (quote column in case of MySQL)
            c.execute("DELETE FROM site_settings WHERE `key` = 'logo_path'")
            conn.commit()
        
        return jsonify({'success': True, 'message': 'Logo removed successfully'})
        
    except Exception as e:
        logger.error(f"Error removing logo: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500


@app.route('/post_status', methods=['POST'])
@login_required
def post_status():
    username = session['username']
    content = request.form.get('content', '').strip()
    community_id_raw = request.form.get('community_id')
    community_id = int(community_id_raw) if community_id_raw else None
    token = (request.form.get('dedupe_token') or '').strip()
    
    # If community_id is not in form, try to get it from referer URL
    if not community_id:
        referer = request.headers.get('Referer', '')
        logger.info(f"Referer URL: {referer}")
        if '/community_feed/' in referer:
            try:
                # Extract community_id from URL like /community_feed/4
                community_id = int(referer.split('/community_feed/')[1].split('/')[0])
                logger.info(f"Extracted community_id from referer: {community_id}")
            except (IndexError, ValueError) as e:
                logger.warning(f"Could not extract community_id from referer: {e}")
    
    logger.info(f"Received post request for {username} with content: {content} in community: {community_id} (raw: {community_id_raw})")
    
    # Debug: Log all form data
    logger.info(f"All form data: {dict(request.form)}")
    
    # Handle file upload (image, video, or audio)
    image_path = None
    audio_path = None
    video_path = None
    # Robustly detect both files regardless of field name casing
    files = request.files
    if 'image' in files and files['image'].filename:
        file = files['image']
        image_path = save_uploaded_file(file)
        if not image_path:
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                return jsonify({'success': False, 'error': 'Invalid image type'}), 400
            else:
                msg = '?error=Invalid image type'
                if community_id:
                    return redirect(url_for('community_feed', community_id=community_id) + msg)
                else:
                    return redirect(url_for('feed') + msg)
    if 'audio' in files and files['audio'].filename:
        afile = files['audio']
        audio_path = save_uploaded_file(afile, subfolder='audio')
        if not audio_path:
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                return jsonify({'success': False, 'error': 'Invalid audio type'}), 400
            else:
                msg = '?error=Invalid audio type'
                if community_id:
                    return redirect(url_for('community_feed', community_id=community_id) + msg)
                else:
                    return redirect(url_for('feed') + msg)
    if 'video' in files and files['video'].filename:
        vfile = files['video']
        video_path = save_uploaded_file(vfile, subfolder='video')
        if not video_path:
            if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                return jsonify({'success': False, 'error': 'Invalid video type'}), 400
            else:
                msg = '?error=Invalid video type'
                if community_id:
                    return redirect(url_for('community_feed', community_id=community_id) + msg)
                else:
                    return redirect(url_for('feed') + msg)
    
    if not content and not image_path and not audio_path and not video_path:
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return jsonify({'success': False, 'error': 'Content, image, video or audio is required!'}), 400
        else:
            if community_id:
                return redirect(url_for('community_feed', community_id=community_id) + '?error=Content, image, video or audio is required!')
            else:
                return redirect(url_for('feed') + '?error=Content, image, video or audio is required!')
    
    # Store in DB-friendly ISO format in UTC to avoid MySQL zero-datetime coercion
    timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Dedupe: if a token is provided and seen in last 60 seconds for this user, skip insert
            if token:
                try:
                    if USE_MYSQL:
                        c.execute("""
                            SELECT 1 FROM recent_post_tokens
                            WHERE token=? AND username=? AND created_at > DATE_SUB(NOW(), INTERVAL 60 SECOND)
                            LIMIT 1
                        """, (token, username))
                    else:
                        c.execute("""
                            SELECT 1 FROM recent_post_tokens
                            WHERE token=? AND username=? AND datetime(created_at) > datetime('now','-60 seconds')
                            LIMIT 1
                        """, (token, username))
                    if c.fetchone():
                        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                            return jsonify({'success': True, 'message': 'Duplicate suppressed'}), 200
                        else:
                            if community_id:
                                return redirect(url_for('community_feed', community_id=community_id))
                            return redirect(url_for('feed'))
                except Exception as de:
                    logger.warning(f"post dedupe check failed: {de}")
            
            # If community_id is provided, verify user is member (admin bypass)
            if community_id and username != 'admin':
                c.execute("""
                    SELECT 1 FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE u.username = ? AND uc.community_id = ?
                """, (username, community_id))
                if not c.fetchone():
                    if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
                        return jsonify({'success': False, 'error': 'You are not a member of this community'}), 403
                    else:
                        return redirect(url_for('community_feed', community_id=community_id) + '?error=You are not a member of this community')
            
            # Debug: Log the exact values being inserted
            logger.info(f"About to insert post with values: username={username}, content={content}, image_path={image_path}, video_path={video_path}, timestamp={timestamp}, community_id={community_id} (type: {type(community_id)})")
            
            # Ensure audio columns exist for posts (migration-light)
            try:
                c.execute("ALTER TABLE posts ADD COLUMN audio_path TEXT")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE posts ADD COLUMN audio_duration_seconds INTEGER")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE posts ADD COLUMN audio_mime TEXT")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE posts ADD COLUMN audio_summary TEXT")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE posts ADD COLUMN video_path TEXT")
            except Exception:
                pass

            # Generate AI summary if audio is present
            audio_summary = None
            if audio_path:
                try:
                    logger.info(f"Generating AI summary for audio post: {audio_path}")
                    audio_summary = process_audio_for_summary(audio_path, username=username)
                    if audio_summary:
                        logger.info(f"AI summary generated successfully: {audio_summary[:100]}...")
                    else:
                        logger.warning("AI summary generation returned None")
                except Exception as e:
                    logger.error(f"Error generating AI summary: {str(e)}")
                    # Don't fail the post creation if summarization fails
                    audio_summary = None

            c.execute("INSERT INTO posts (username, content, image_path, video_path, audio_path, audio_summary, timestamp, community_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
                      (username, content, image_path, video_path, audio_path, audio_summary, timestamp, community_id))
            conn.commit()
            post_id = c.lastrowid
            logger.info(f"Post added successfully for {username} with ID: {post_id} in community: {community_id}")
            # Also set created_at to match timestamp for feeds that rely on created_at
            try:
                c.execute("UPDATE posts SET created_at = ? WHERE id = ?", (timestamp, post_id))
                conn.commit()
            except Exception as ua:
                logger.warning(f"could not set created_at for post {post_id}: {ua}")
            
            # Verify the post was saved with correct community_id
            c.execute("SELECT community_id FROM posts WHERE id = ?", (post_id,))
            saved_post = c.fetchone()
            logger.info(f"Verified post {post_id} has community_id: {saved_post['community_id'] if saved_post else 'None'}")
            
            # Also check what posts exist for this community
            c.execute("SELECT id, username, content, community_id FROM posts WHERE community_id = ? ORDER BY id DESC", (community_id,))
            community_posts = c.fetchall()
            logger.info(f"Total posts in community {community_id}: {len(community_posts)}")
            for post in community_posts:
                logger.info(f"  Post {post['id']}: {post['username']} - {post['content'][:50]}... (community_id: {post['community_id']})")

            # Record token to prevent duplicates
            try:
                if token:
                    c.execute("INSERT IGNORE INTO recent_post_tokens (token, username) VALUES (?, ?)", (token, username))
                    conn.commit()
            except Exception:
                try:
                    if token:
                        c.execute("INSERT OR IGNORE INTO recent_post_tokens (token, username) VALUES (?, ?)", (token, username))
                        conn.commit()
                except Exception as te:
                    logger.warning(f"post dedupe token write failed: {te}")

            # Mentions processing deferred to helper for robustness (always on)
            try:
                try:
                    logger.info(f"mentions-post: post_id={post_id} author={username} comm={community_id}")
                except Exception:
                    pass
                process_mentions_for_post(post_id=post_id, author_username=username)
            except Exception as e:
                logger.warning(f"mention post helper error: {e}")

            # Notify community members (excluding creator) - push + in-app notification row
            try:
                # Get all members of the community (excluding author)
                c.execute(
                    """
                    SELECT DISTINCT u.username
                    FROM users u
                    JOIN user_communities uc ON u.id = uc.user_id
                    WHERE uc.community_id = ? AND u.username != ?
                    """,
                    (community_id, username)
                )
                members = [row['username'] if hasattr(row, 'keys') else row[0] for row in c.fetchall()]

                # Resolve community name for nicer message
                community_name = None
                try:
                    c.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
                    r = c.fetchone()
                    if r:
                        try:
                            community_name = r['name'] if hasattr(r, 'keys') else r[0]
                        except Exception:
                            community_name = None
                except Exception:
                    community_name = None

                notif_message = (
                    f"{username} made a new post on {community_name}" if community_name else f"{username} made a new post"
                )
                notif_link = f"/community_feed_react/{community_id}"

                for member in members:
                    logger.info(f"Attempting to notify member: {member}")
                    # In-app notification row (dedupe by unique key if present)
                    try:
                        if 'USE_MYSQL' in globals() and USE_MYSQL:
                            c.execute(
                                """
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                                VALUES (?, ?, 'community_post', ?, ?, ?, NOW(), 0, ?)
                                ON DUPLICATE KEY UPDATE
                                  created_at = NOW(),
                                  message = VALUES(message),
                                  is_read = 0,
                                  link = VALUES(link)
                                """,
                                (member, username, post_id, community_id, notif_message, notif_link),
                            )
                        else:
                            c.execute(
                                """
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                                VALUES (?, ?, 'community_post', ?, ?, ?, datetime('now'), 0, ?)
                                ON CONFLICT(user_id, from_user, type, post_id, community_id)
                                DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                                """,
                                (member, username, post_id, community_id, notif_message, notif_link),
                            )
                        conn.commit()
                    except Exception as ne:
                        try:
                            # Fallback simple insert (best effort)
                            c.execute(
                                """
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                                VALUES (?, ?, 'community_post', ?, ?, ?, datetime('now'), 0, ?)
                                """,
                                (member, username, post_id, community_id, notif_message, notif_link),
                            )
                            conn.commit()
                        except Exception as ne2:
                            logger.warning(f"community post notify db error to {member}: {ne2}")

                    # Web push (non-blocking)
                    try:
                        send_push_to_user(
                            member,
                            {
                                'title': 'New community post',
                                'body': f"{username}: {content[:100]}",
                                'url': notif_link,
                                'tag': f"community-post-{community_id}",
                            },
                        )
                    except Exception as pe:
                        logger.warning(f"push notify community warn: {pe}")
            except Exception as notify_err:
                logger.warning(f"community notify block error: {notify_err}")
        
        # Invalidate community feed cache so new post shows immediately
        if community_id:
            try:
                invalidate_community_cache(community_id)
                logger.info(f"Invalidated cache for community {community_id} after new post")
            except Exception as cache_err:
                logger.warning(f"Failed to invalidate cache after post for community {community_id}: {cache_err}")
        
        # Check if this is an AJAX request
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return jsonify({
                'success': True,
                'message': 'Post added!',
                'post': {
                    'id': c.lastrowid, 
                    'username': username, 
                    'content': content, 
                    'image_path': image_path,
                    'video_path': video_path,
                    'timestamp': timestamp,
                    'community_id': community_id
                }
            }), 200
        else:
            # Regular form submission - redirect back to the appropriate page
            if community_id:
                return redirect(url_for('community_feed', community_id=community_id))
            else:
                return redirect(url_for('feed'))
    except Exception as e:
        logger.error(f"Error posting status for {username}: {str(e)}", exc_info=True)
        if request.headers.get('X-Requested-With') == 'XMLHttpRequest':
            return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500
        else:
            # For regular form submissions, redirect with error
            if community_id:
                return redirect(url_for('community_feed', community_id=community_id) + '?error=' + str(e))
            else:
                return redirect(url_for('feed') + '?error=' + str(e))

@app.route('/post_reply', methods=['POST'])
@login_required
def post_reply():
    username = session['username']
    
    # Debug CSRF token
    logger.info(f"CSRF validation for user {username}")
    logger.info(f"Request form data: {dict(request.form)}")
    logger.info(f"Request headers: {dict(request.headers)}")
    
    post_id = request.form.get('post_id', type=int)
    content = request.form.get('content', '').strip()
    logger.debug(f"Received reply request for {username} to post {post_id} with content: {content}")

    if not post_id:
        return jsonify({'success': False, 'error': 'Post ID is required!'}), 400

    # Handle file upload for reply (image or audio)
    image_path = None
    audio_path = None
    if 'image' in request.files:
        file = request.files['image']
        if file.filename != '':
            image_path = save_uploaded_file(file)
            if not image_path:
                return jsonify({'success': False, 'error': 'Invalid file type. Allowed: png, jpg, jpeg, gif, webp'}), 400
    if 'audio' in request.files:
        afile = request.files['audio']
        if afile.filename != '':
            audio_path = save_uploaded_file(afile, subfolder='audio')
            if not audio_path:
                return jsonify({'success': False, 'error': 'Invalid audio type'}), 400

    if not content and not image_path and not audio_path:
        return jsonify({'success': False, 'error': 'Content, image or audio is required!'}), 400

    # Idempotency token (optional)
    dedupe_token = (request.form.get('dedupe_token') or '').strip()

    # Use DB-friendly ISO for storage in UTC; frontend will format for display
    now = datetime.utcnow()
    timestamp_db = now.strftime('%Y-%m-%d %H:%M:%S')
    timestamp_display = now.strftime('%d-%m-%Y')

    community_id = None
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT id FROM posts WHERE id= ?", (post_id,))
            if not c.fetchone():
                return jsonify({'success': False, 'error': 'Post not found!'}), 404

            # Get the community_id from the post
            c.execute("SELECT community_id FROM posts WHERE id = ?", (post_id,))
            post_data = c.fetchone()
            community_id = post_data['community_id'] if post_data else None
            
            parent_reply_id = request.form.get('parent_reply_id', type=int)

            # Strong dedupe: token-based and content-based within window
            try:
                if dedupe_token:
                    if USE_MYSQL:
                        c.execute("""
                            SELECT 1 FROM recent_reply_tokens
                            WHERE token=? AND username=? AND created_at > DATE_SUB(NOW(), INTERVAL 60 SECOND)
                            LIMIT 1
                        """, (dedupe_token, username))
                    else:
                        c.execute("""
                            SELECT 1 FROM recent_reply_tokens
                            WHERE token=? AND username=? AND datetime(created_at) > datetime('now','-60 seconds')
                            LIMIT 1
                        """, (dedupe_token, username))
                    if c.fetchone():
                        return jsonify({'success': True, 'message': 'Duplicate suppressed'}), 200
                if content:
                    if USE_MYSQL:
                        c.execute("""
                            SELECT id FROM replies
                            WHERE post_id=? AND username=? AND IFNULL(parent_reply_id,0)=IFNULL(?,0)
                              AND content=? AND timestamp > DATE_SUB(NOW(), INTERVAL 30 SECOND)
                            LIMIT 1
                        """, (post_id, username, parent_reply_id, content))
                    else:
                        c.execute("""
                            SELECT id FROM replies
                            WHERE post_id=? AND username=? AND IFNULL(parent_reply_id,0)=IFNULL(?,0)
                              AND content=? AND datetime(timestamp) > datetime('now','-30 seconds')
                            LIMIT 1
                        """, (post_id, username, parent_reply_id, content))
                    if c.fetchone():
                        return jsonify({'success': True, 'message': 'Duplicate suppressed'}), 200
            except Exception as de:
                logger.warning(f"reply dedupe check failed: {de}")
            # Ensure audio columns on replies
            try:
                c.execute("ALTER TABLE replies ADD COLUMN audio_path TEXT")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE replies ADD COLUMN audio_duration_seconds INTEGER")
            except Exception:
                pass
            try:
                c.execute("ALTER TABLE replies ADD COLUMN audio_mime TEXT")
            except Exception:
                pass
            c.execute("INSERT INTO replies (post_id, username, content, image_path, audio_path, timestamp, community_id, parent_reply_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?)",
                      (post_id, username, content, image_path, audio_path, timestamp_db, community_id, parent_reply_id))
            reply_id = c.lastrowid

            # Record token
            try:
                if dedupe_token:
                    c.execute("INSERT IGNORE INTO recent_reply_tokens (token, username) VALUES (?, ?)", (dedupe_token, username))
                    conn.commit()
            except Exception:
                try:
                    if dedupe_token:
                        c.execute("INSERT OR IGNORE INTO recent_reply_tokens (token, username) VALUES (?, ?)", (dedupe_token, username))
                        conn.commit()
                except Exception as te:
                    logger.warning(f"reply dedupe token write failed: {te}")
            
            # Mentions processing deferred to helper for robustness (always on)
            try:
                process_mentions_for_reply(post_id=post_id, author_username=username, community_id=community_id, reply_id=reply_id)
            except Exception as e:
                logger.warning(f"mention reply helper error: {e}")

            # Notify recipients (post owner and parent reply author)
            try:
                notify_post_reply_recipients(post_id=post_id, from_user=username, community_id=community_id, parent_reply_id=parent_reply_id)
            except Exception as ne:
                logger.warning(f"notify recipients failed: {ne}")
            
            conn.commit()

            try:
                upsert_post_view(c, post_id, username)
                conn.commit()
            except Exception as view_err:
                logger.warning(f"post_reply view tracking failed for post {post_id}: {view_err}")

        logger.info(f"Reply added successfully for {username} to post {post_id} with ID: {reply_id}")

        try:
            if community_id:
                invalidate_community_cache(community_id)
        except Exception as cache_err:
            logger.warning(f"Failed to invalidate cache after reply for community {community_id}: {cache_err}")

        return jsonify({
            'success': True,
            'message': 'Reply added!',
            'reply': {
                'id': reply_id,
                'post_id': post_id,
                'username': username,
                'content': content,
            'image_path': image_path,
            'audio_path': audio_path,
                'timestamp': timestamp_db,  # Return precise timestamp for clients
                'reactions': {},
                'user_reaction': None,
                'parent_reply_id': parent_reply_id
            }
        }), 200
    except Exception as e:
        logger.error(f"Error posting reply for {username}: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500


@app.route('/create_poll', methods=['POST'])
@login_required
def create_poll():
    """Create a new poll"""
    username = session['username']
    content = request.form.get('content', '').strip()
    question = request.form.get('question', '').strip()
    options = request.form.getlist('options[]')
    community_id_raw = request.form.get('community_id')
    community_id = int(community_id_raw) if community_id_raw else None
    
    # Validate input
    if not question or not options or len(options) < 2:
        return jsonify({'success': False, 'error': 'Question and at least 2 options are required!'})
    
    # Remove empty options
    options = [opt.strip() for opt in options if opt.strip()]
    if len(options) < 2:
        return jsonify({'success': False, 'error': 'At least 2 non-empty options are required!'})
    
    # Limit to 6 options
    if len(options) > 6:
        return jsonify({'success': False, 'error': 'Maximum 6 options allowed!'})
    
    timestamp = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    expires_at_raw = request.form.get('expires_at', '').strip()
    expires_at_sql = None
    if expires_at_raw:
        try:
            # Accept both 'YYYY-MM-DDTHH:MM' and 'YYYY-MM-DD'
            # Frontend should send UTC time (or we convert from local)
            if 'T' in expires_at_raw:
                dt = datetime.strptime(expires_at_raw, '%Y-%m-%dT%H:%M')
            else:
                dt = datetime.strptime(expires_at_raw, '%Y-%m-%d')
            
            # Validate: expiry date must be in the future
            now = datetime.utcnow()
            if dt <= now:
                return jsonify({'success': False, 'error': 'Poll expiry date must be in the future'})
            
            expires_at_sql = dt.strftime('%Y-%m-%d %H:%M:%S')
            logger.info(f"üìÖ Poll deadline: {expires_at_sql} (treating as UTC)")
        except Exception as e:
            logger.error(f"Error parsing poll expiry date: {e}")
            expires_at_sql = None
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # If community_id is provided, verify user is member (admin bypass)
            if community_id and username != 'admin':
                c.execute("""
                    SELECT 1 FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE u.username = ? AND uc.community_id = ?
                """, (username, community_id))
                
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'You are not a member of this community'}), 403
            
            # Create the post first
            c.execute("INSERT INTO posts (username, content, image_path, timestamp, community_id) VALUES (?, ?, ?, ?, ?)",
                      (username, content, None, timestamp, community_id))
            post_id = c.lastrowid
            
            # Get single vote setting
            single_vote_raw = request.form.get('single_vote', 'true')
            logger.info(f"Creating poll - single_vote raw value: {single_vote_raw}")
            single_vote = single_vote_raw.lower() == 'true'
            logger.info(f"Creating poll - single_vote processed: {single_vote}")
            
            # Log all form data for debugging
            logger.info(f"Creating poll - all form data: {dict(request.form)}")
            
            # Create the poll
            # Insert with optional expiry if column exists
            try:
                c.execute("INSERT INTO polls (post_id, question, created_by, created_at, single_vote, expires_at) VALUES (?, ?, ?, ?, ?, ?)",
                          (post_id, question, username, timestamp, single_vote, expires_at_sql))
            except Exception:
                c.execute("INSERT INTO polls (post_id, question, created_by, created_at, single_vote) VALUES (?, ?, ?, ?, ?)",
                          (post_id, question, username, timestamp, single_vote))
            poll_id = c.lastrowid
            
            # Create poll options
            for option_text in options:
                c.execute("INSERT INTO poll_options (poll_id, option_text) VALUES (?, ?)",
                          (poll_id, option_text))
            
            # Get community members before committing
            member_usernames = []
            if community_id:
                try:
                    logger.info(f"üîç Fetching members for community {community_id}, USE_MYSQL={USE_MYSQL}")
                    if USE_MYSQL:
                        c.execute("""
                            SELECT DISTINCT u.username
                            FROM user_communities uc
                            JOIN users u ON uc.user_id = u.id
                            WHERE uc.community_id = %s AND u.username != %s
                        """, (community_id, username))
                    else:
                        c.execute("""
                            SELECT DISTINCT u.username
                            FROM user_communities uc
                            JOIN users u ON uc.user_id = u.id
                            WHERE uc.community_id = ? AND u.username != ?
                        """, (community_id, username))
                    # Handle both dict rows (MySQL) and tuple rows (SQLite)
                    rows = c.fetchall()
                    member_usernames = [row['username'] if hasattr(row, 'keys') else row[0] for row in rows]
                    logger.info(f"‚úÖ Found {len(member_usernames)} members to notify for poll in community {community_id}")
                except Exception as e:
                    logger.error(f"‚ùå Error fetching community members for poll notifications: {type(e).__name__}: {str(e)}")
                    import traceback
                    logger.error(traceback.format_exc())
            
            conn.commit()
            
            # Notify all community members about the new poll (after commit)
            if member_usernames:
                try:
                    for member_username in member_usernames:
                        create_notification(
                            user_id=member_username,
                            from_user=username,
                            notification_type='poll',
                            post_id=post_id,
                            community_id=community_id,
                            message=f'New poll: {question}'
                        )
                    logger.info(f"‚úÖ Created {len(member_usernames)} poll notifications for post {post_id}")
                except Exception as e:
                    logger.error(f"‚ùå Error creating poll notifications: {str(e)}")
                    import traceback
                    logger.error(traceback.format_exc())
            
            return jsonify({'success': True, 'message': 'Poll created successfully!', 'post_id': post_id})
            
    except Exception as e:
        logger.error(f"Error creating poll: {str(e)}")
        return jsonify({'success': False, 'error': 'Error creating poll'})

@app.route('/close_poll', methods=['POST'])
@login_required
def close_poll():
    """Close a poll and move it to historical"""
    username = session['username']
    
    if request.is_json:
        data = request.get_json()
        poll_id = data.get('poll_id')
    else:
        poll_id = request.form.get('poll_id', type=int)
    
    if not poll_id:
        return jsonify({'success': False, 'error': 'Invalid poll ID'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if poll exists and user has permission to close it
            c.execute("SELECT created_by, post_id FROM polls WHERE id = ? AND is_active = 1", (poll_id,))
            poll_data = c.fetchone()
            
            if not poll_data:
                return jsonify({'success': False, 'error': 'Poll not found or already closed'})
            
            # Only poll creator, community admin/owner, or global admin can close
            allowed = False
            if poll_data['created_by'] == username or username == 'admin':
                allowed = True
            else:
                # Determine community of the poll via post
                c.execute("SELECT community_id FROM posts WHERE id = ?", (poll_data['post_id'],))
                pr = c.fetchone()
                community_id = pr['community_id'] if pr else None
                if community_id:
                    # Check if user is community admin or owner
                    # Owner = communities.creator_username
                    c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
                    cr = c.fetchone()
                    if cr and cr['creator_username'] == username:
                        allowed = True
                    else:
                        # Community admin check (if you have a roles table, replace this logic)
                        c.execute("""
                            SELECT 1 FROM community_admins
                            WHERE community_id = ? AND username = ?
                        """, (community_id, username))
                        if c.fetchone():
                            allowed = True
            if not allowed:
                return jsonify({'success': False, 'error': 'You do not have permission to close this poll'})
            
            # Close the poll
            c.execute("UPDATE polls SET is_active = 0 WHERE id = ?", (poll_id,))
            conn.commit()
            
            # Send "poll closed" notifications to all community members
            try:
                c.execute("SELECT community_id FROM posts WHERE id = ?", (poll_data['post_id'],))
                post_row = c.fetchone()
                if post_row:
                    community_id = post_row['community_id'] if hasattr(post_row, 'keys') else post_row[0]
                    
                    if community_id:
                        # Get poll question
                        c.execute("SELECT question FROM polls WHERE id = ?", (poll_id,))
                        poll_question_row = c.fetchone()
                        poll_question = poll_question_row['question'] if hasattr(poll_question_row, 'keys') else poll_question_row[0] if poll_question_row else "a poll"
                        
                        # Get all community members
                        c.execute("""
                            SELECT DISTINCT u.id, u.username
                            FROM user_communities uc
                            JOIN users u ON uc.user_id = u.id
                            WHERE uc.community_id = ?
                        """, (community_id,))
                        
                        members = c.fetchall()
                        for member_row in members:
                            # Extract username (no need for member_id since we pass username to create_notification)
                            member_username = member_row['username'] if hasattr(member_row, 'keys') else member_row[1]
                            
                            # Check if not already notified
                            c.execute("SELECT id FROM poll_notification_log WHERE poll_id=? AND username=? AND notification_type='closed'", 
                                     (poll_id, member_username))
                            if not c.fetchone():
                                # Get community name for notification
                                comm_name = ""
                                try:
                                    c.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
                                    comm_row = c.fetchone()
                                    if comm_row:
                                        comm_name = comm_row['name'] if hasattr(comm_row, 'keys') else comm_row[0]
                                except Exception:
                                    pass
                                
                                message = f"üîí Poll in {comm_name} closed. Check results!" if comm_name else "üîí Poll closed. Check results!"
                                
                                try:
                                    # Pass username (not user_id) to match production DB foreign key constraint
                                    create_notification(member_username, None, 'poll_closed', poll_data['post_id'], community_id, message)
                                    send_push_to_user(member_username, {
                                        'title': f'{comm_name} Poll Closed' if comm_name else 'Poll Closed',
                                        'body': message,
                                        'url': f'/community/{community_id}/polls_react',
                                        'tag': f'poll-closed-{poll_id}'
                                    })
                                    
                                    # Log notification
                                    c.execute("INSERT INTO poll_notification_log (poll_id, username, notification_type) VALUES (?, ?, 'closed')", 
                                             (poll_id, member_username))
                                except Exception as ne:
                                    logger.warning(f"Error sending poll closed notification to {member_username}: {ne}")
                        
                        conn.commit()
            except Exception as close_notify_err:
                logger.error(f"Error sending poll closed notifications: {close_notify_err}")
            
            return jsonify({'success': True, 'message': 'Poll closed successfully'})
            
    except Exception as e:
        logger.error(f"Error closing poll: {str(e)}")
        return jsonify({'success': False, 'error': 'Error closing poll'})

@app.route('/edit_poll', methods=['POST'])
@login_required
def edit_poll():
    """Edit an existing poll - question and options"""
    username = session['username']
    
    if request.is_json:
        data = request.get_json()
        poll_id = data.get('poll_id')
        question = data.get('question', '').strip()
        options = data.get('options', [])
        expires_at_raw = (data.get('expires_at') or '').strip() if isinstance(data.get('expires_at'), str) else ''
    else:
        poll_id = request.form.get('poll_id', type=int)
        question = request.form.get('question', '').strip()
        options = request.form.getlist('options[]')
        expires_at_raw = request.form.get('expires_at', '').strip()
    
    if not poll_id or not question:
        return jsonify({'success': False, 'error': 'Poll ID and question are required'})
    
    # Remove empty options
    options = [opt.strip() for opt in options if opt.strip()]
    if len(options) < 2:
        return jsonify({'success': False, 'error': 'At least 2 non-empty options are required'})
    
    if len(options) > 6:
        return jsonify({'success': False, 'error': 'Maximum 6 options allowed'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if poll exists and user has permission to edit it
            c.execute("SELECT created_by, post_id FROM polls WHERE id = ? AND is_active = 1", (poll_id,))
            poll_data = c.fetchone()
            
            if not poll_data:
                return jsonify({'success': False, 'error': 'Poll not found or already closed'})
            
            # Only poll creator, community admin/owner, or global admin can edit
            allowed = False
            if poll_data['created_by'] == username or username == 'admin':
                allowed = True
            else:
                # Determine community of the poll via post
                c.execute("SELECT community_id FROM posts WHERE id = ?", (poll_data['post_id'],))
                pr = c.fetchone()
                community_id = pr['community_id'] if pr else None
                if community_id:
                    # Check if user is community admin or owner
                    c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
                    cr = c.fetchone()
                    if cr and cr['creator_username'] == username:
                        allowed = True
                    else:
                        c.execute("""
                            SELECT 1 FROM community_admins
                            WHERE community_id = ? AND username = ?
                        """, (community_id, username))
                        if c.fetchone():
                            allowed = True
            
            if not allowed:
                return jsonify({'success': False, 'error': 'You do not have permission to edit this poll'})
            
            # Parse optional deadline
            expires_at_sql = None
            if expires_at_raw:
                try:
                    if 'T' in expires_at_raw:
                        dt = datetime.strptime(expires_at_raw, '%Y-%m-%dT%H:%M')
                    else:
                        dt = datetime.strptime(expires_at_raw, '%Y-%m-%d')
                    expires_at_sql = dt.strftime('%Y-%m-%d %H:%M:%S')
                except Exception:
                    expires_at_sql = None

            # Update poll question and optional expires_at (if column exists)
            try:
                c.execute("UPDATE polls SET question = ?, expires_at = ? WHERE id = ?", (question, expires_at_sql, poll_id))
            except Exception:
                # Fallback for schemas without expires_at column
                c.execute("UPDATE polls SET question = ? WHERE id = ?", (question, poll_id))
            
            # Get existing options
            c.execute("SELECT id, option_text FROM poll_options WHERE poll_id = ? ORDER BY id", (poll_id,))
            existing_options = c.fetchall()
            
            # Update existing options and add new ones
            for idx, option_text in enumerate(options):
                if idx < len(existing_options):
                    # Update existing option
                    c.execute("UPDATE poll_options SET option_text = ? WHERE id = ?", 
                             (option_text, existing_options[idx]['id']))
                else:
                    # Add new option
                    c.execute("INSERT INTO poll_options (poll_id, option_text, votes) VALUES (?, ?, 0)",
                             (poll_id, option_text))
            
            # Remove extra options if new list is shorter
            if len(options) < len(existing_options):
                for idx in range(len(options), len(existing_options)):
                    option_id = existing_options[idx]['id']
                    # Delete votes for this option first
                    c.execute("DELETE FROM poll_votes WHERE option_id = ?", (option_id,))
                    # Delete the option
                    c.execute("DELETE FROM poll_options WHERE id = ?", (option_id,))
            
            conn.commit()
            return jsonify({'success': True, 'message': 'Poll updated successfully'})
            
    except Exception as e:
        logger.error(f"Error editing poll: {str(e)}")
        return jsonify({'success': False, 'error': 'Error editing poll'})

@app.route('/vote_poll', methods=['POST'])
@login_required
def vote_poll():
    """Vote on a poll"""
    username = session['username']
    
    # Handle both JSON and form data
    if request.is_json:
        data = request.get_json()
        poll_id = data.get('poll_id')
        option_id = data.get('option_id')
        toggle_vote = data.get('toggle_vote', False)  # New parameter for vote toggling
    else:
        poll_id = request.form.get('poll_id', type=int)
        option_id = request.form.get('option_id', type=int)
        toggle_vote = request.form.get('toggle_vote', False)
    
    # Convert toggle_vote to boolean if it's a string
    if isinstance(toggle_vote, str):
        toggle_vote = toggle_vote.lower() == 'true'
    
    logger.info(f"Vote request: poll_id={poll_id}, option_id={option_id}, toggle_vote={toggle_vote}")
    
    if not poll_id or not option_id:
        return jsonify({'success': False, 'error': 'Invalid poll or option ID'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if poll exists and is active
            c.execute("SELECT p.*, po.id as option_id FROM polls p JOIN poll_options po ON p.id = po.poll_id WHERE p.id = ? AND po.id = ? AND p.is_active = 1", (poll_id, option_id))
            poll_data = c.fetchone()
            
            # Convert to dict to make it mutable
            if poll_data:
                poll_data = dict(poll_data)
                # Handle case where single_vote column might not exist
                if 'single_vote' not in poll_data:
                    poll_data['single_vote'] = True  # Default to single vote
            
            if not poll_data:
                return jsonify({'success': False, 'error': 'Poll not found or inactive'})
            
            # Block voting if poll is past its deadline (expires_at <= now)
            try:
                expires_at_val = poll_data.get('expires_at') if hasattr(poll_data, 'keys') else None
            except Exception:
                expires_at_val = None
            if expires_at_val:
                try:
                    exp = None
                    try:
                        exp = datetime.strptime(str(expires_at_val)[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                    except Exception:
                        for fmt in ('%Y-%m-%d %H:%M', '%Y-%m-%d'):
                            try:
                                exp = datetime.strptime(str(expires_at_val).replace('T',' '), fmt)
                                break
                            except Exception:
                                continue
                    if exp and datetime.now() >= exp:
                        return jsonify({'success': False, 'error': 'Poll has expired'}), 400
                except Exception:
                    pass
            
            # Check if user already voted on this specific option
            c.execute("SELECT id FROM poll_votes WHERE poll_id = ? AND username = ? AND option_id = ?", (poll_id, username, option_id))
            existing_vote_on_option = c.fetchone()
            
            # Check if user already voted on this poll (for single vote mode)
            c.execute("SELECT id, option_id FROM poll_votes WHERE poll_id = ? AND username = ?", (poll_id, username))
            existing_vote = c.fetchone()
            
            if existing_vote_on_option:
                # User already voted on this specific option - toggle it off (remove)
                logger.info(f"Toggling vote off: poll_id={poll_id}, username={username}, option_id={option_id}")
                c.execute("DELETE FROM poll_votes WHERE poll_id = ? AND username = ? AND option_id = ?", (poll_id, username, option_id))
                message = "Vote removed!"
            elif existing_vote and poll_data['single_vote']:
                # Single vote mode: user voted on a different option - update to new option
                c.execute("UPDATE poll_votes SET option_id = ?, voted_at = ? WHERE poll_id = ? AND username = ?",
                          (option_id, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), poll_id, username))
                message = "Vote updated!"
            else:
                # User hasn't voted on this option yet - add vote
                c.execute("INSERT INTO poll_votes (poll_id, option_id, username, voted_at) VALUES (?, ?, ?, ?)",
                          (poll_id, option_id, username, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
                message = "Vote recorded successfully!"
            
            # Update vote count for the selected option
            c.execute("UPDATE poll_options SET votes = (SELECT COUNT(*) FROM poll_votes WHERE option_id = ?) WHERE id = ?", (option_id, option_id))
            
            # Update vote count for the previously selected option (if any and in single vote mode)
            if existing_vote and poll_data['single_vote'] and existing_vote['option_id'] != option_id:
                c.execute("UPDATE poll_options SET votes = (SELECT COUNT(*) FROM poll_votes WHERE option_id = ?) WHERE id = ?", (existing_vote['option_id'], existing_vote['option_id']))
            
            conn.commit()
            
            # EVENT-DRIVEN NOTIFICATION CHECK
            # Check this poll for notifications immediately after vote
            # This provides instant notifications without waiting for cron
            try:
                check_single_poll_notifications(poll_id, conn)
            except Exception as notif_err:
                logger.warning(f"Event-driven notification check failed for poll {poll_id}: {notif_err}")
            
            # Get updated poll results with user vote info
            c.execute("""
                SELECT po.id, po.option_text, po.votes, 
                       (SELECT COUNT(*) FROM poll_votes WHERE poll_id = ?) as total_votes,
                       (SELECT option_id FROM poll_votes WHERE poll_id = ? AND username = ?) as user_vote,
                       (SELECT COUNT(*) FROM poll_votes WHERE poll_id = ? AND username = ? AND option_id = po.id) as user_voted
                FROM poll_options po 
                WHERE po.poll_id = ?
                ORDER BY po.id
            """, (poll_id, poll_id, username, poll_id, username, poll_id))
            poll_results = c.fetchall()
            
            return jsonify({
                'success': True, 
                'message': message,
                'poll_results': [dict(row) for row in poll_results]
            })
            
    except Exception as e:
        logger.error(f"Error voting on poll: {str(e)}")
        return jsonify({'success': False, 'error': 'Error recording vote'})

@app.route('/get_poll_results/<int:poll_id>')
@login_required
def get_poll_results(poll_id):
    """Get poll results"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            c.execute("""
                SELECT po.id, po.option_text, po.votes, 
                       (SELECT COUNT(*) FROM poll_votes WHERE poll_id = ?) as total_votes,
                       (SELECT option_id FROM poll_votes WHERE poll_id = ? AND username = ?) as user_vote,
                       (SELECT COUNT(*) FROM poll_votes WHERE poll_id = ? AND username = ? AND option_id = po.id) as user_voted
                FROM poll_options po 
                WHERE po.poll_id = ?
                ORDER BY po.id
            """, (poll_id, poll_id, session['username'], poll_id, session['username'], poll_id))
            
            poll_results = c.fetchall()
            
            if not poll_results:
                return jsonify({'success': False, 'error': 'Poll not found'})
            
            return jsonify({
                'success': True,
                'poll_results': [dict(row) for row in poll_results]
            })
            
    except Exception as e:
        logger.error(f"Error getting poll results: {str(e)}")
        return jsonify({'success': False, 'error': 'Error retrieving poll results'})

@app.route('/get_poll_voters/<int:poll_id>')
@login_required
def get_poll_voters(poll_id):
    """Get list of voters for each option in a poll"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Verify poll exists
            c.execute("SELECT id FROM polls WHERE id = ?", (poll_id,))
            if not c.fetchone():
                return jsonify({'success': False, 'error': 'Poll not found'})
            
            # Get all poll options
            c.execute("SELECT id, option_text FROM poll_options WHERE poll_id = ? ORDER BY id", (poll_id,))
            options = [dict(row) for row in c.fetchall()]
            
            # For each option, get the list of voters
            for option in options:
                c.execute("""
                    SELECT pv.username, up.profile_picture, pv.voted_at
                    FROM poll_votes pv
                    LEFT JOIN user_profiles up ON pv.username = up.username
                    WHERE pv.poll_id = ? AND pv.option_id = ?
                    ORDER BY pv.voted_at DESC
                """, (poll_id, option['id']))
                voters = []
                for row in c.fetchall():
                    voter_data = dict(row)
                    # Normalize profile picture path
                    pp = voter_data.get('profile_picture')
                    if pp:
                        pp_str = str(pp).strip()
                        if pp_str.startswith('http://') or pp_str.startswith('https://'):
                            voter_data['profile_picture'] = pp_str
                        elif pp_str.startswith('/uploads') or pp_str.startswith('/static'):
                            voter_data['profile_picture'] = pp_str
                        elif pp_str.startswith('uploads/'):
                            voter_data['profile_picture'] = '/' + pp_str
                        else:
                            voter_data['profile_picture'] = f"/uploads/{pp_str}"
                    voters.append(voter_data)
                option['voters'] = voters
            
            return jsonify({
                'success': True,
                'options': options
            })
            
    except Exception as e:
        logger.error(f"Error getting poll voters: {str(e)}")
        return jsonify({'success': False, 'error': 'Error getting poll voters'})


@app.route('/get_post_reactors/<int:post_id>')
@login_required
def get_post_reactors(post_id: int):
    """Return users who reacted to a post, grouped by reaction type.
    Response:
      { success: true, groups: [{ reaction_type, users: [{ username, profile_picture }] }] }
    """
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Validate post exists
            c.execute("SELECT id FROM posts WHERE id = ?", (post_id,))
            if not c.fetchone():
                return jsonify({'success': False, 'error': 'Post not found'}), 404

            c.execute(
                """
                SELECT r.reaction_type, r.username, up.profile_picture
                FROM reactions r
                LEFT JOIN user_profiles up ON up.username = r.username
                WHERE r.post_id = ?
                ORDER BY r.reaction_type, r.id DESC
                """,
                (post_id,)
            )
            rows = c.fetchall() or []

            by_type = {}
            for row in rows:
                if hasattr(row, 'keys'):
                    rt = row['reaction_type']
                    uname = row['username']
                    pic = row.get('profile_picture') if 'profile_picture' in row.keys() else None
                else:
                    rt = row[0]
                    uname = row[1]
                    pic = row[2] if len(row) > 2 else None
                by_type.setdefault(rt, []).append({'username': uname, 'profile_picture': pic})

            groups = [{'reaction_type': k, 'users': v} for k, v in by_type.items()]
            # Preferred ordering
            order = {'heart': 0, 'thumbs-up': 1, 'thumbs-down': 2}
            groups.sort(key=lambda g: order.get(g['reaction_type'], 99))

            # Normalize image paths
            def _normalize_pic(value: Optional[str]) -> Optional[str]:
                if not value:
                    return None
                try:
                    s = str(value).strip()
                    if s.startswith(('http://', 'https://', '/uploads', '/static')):
                        return s
                    if s.startswith('uploads/'):
                        return '/' + s
                    return f"/uploads/{s}"
                except Exception:
                    return None

            for g in groups:
                for u in g['users']:
                    normalized = _normalize_pic(u.get('profile_picture'))
                    u['profile_picture'] = normalized

            view_count = _count_post_views_excluding_admin(c, post_id) or 0
            viewers: List[Dict[str, Any]] = []

            viewer_rows = []
            try:
                c.execute(
                    """
                    SELECT pv.username, pv.viewed_at, up.profile_picture
                    FROM post_views pv
                    LEFT JOIN user_profiles up ON up.username = pv.username
                    WHERE pv.post_id = ?
                      AND LOWER(pv.username) <> LOWER(?)
                    ORDER BY pv.viewed_at DESC
                    LIMIT 100
                    """,
                    (post_id, 'admin'),
                )
                viewer_rows = c.fetchall() or []
            except Exception as viewer_err:
                logger.warning(f"Could not fetch viewers for post {post_id}: {viewer_err}")

            for row in viewer_rows:
                if hasattr(row, 'keys'):
                    uname = row.get('username')
                    viewed_at_raw = row.get('viewed_at')
                    pic = row.get('profile_picture')
                else:
                    uname = row[0] if len(row) > 0 else None
                    viewed_at_raw = row[1] if len(row) > 1 else None
                    pic = row[2] if len(row) > 2 else None
                if not uname:
                    continue
                viewed_at_str: Optional[str]
                if isinstance(viewed_at_raw, datetime):
                    viewed_at_str = viewed_at_raw.isoformat()
                elif isinstance(viewed_at_raw, str):
                    viewed_at_str = viewed_at_raw.strip()
                else:
                    viewed_at_str = None
                viewers.append({
                    'username': uname,
                    'profile_picture': _normalize_pic(pic),
                    'viewed_at': viewed_at_str,
                })

            return jsonify({
                'success': True,
                'groups': groups,
                'view_count': int(view_count or 0),
                'viewers': viewers,
            })
    except Exception as e:
        logger.error(f"get_post_reactors error: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/get_active_polls')
@login_required
def get_active_polls():
    """Get all active polls for a specific community"""
    try:
        username = session['username']
        community_id = request.args.get('community_id', type=int)
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get ALL polls (both active and archived) for the specific community
            if community_id:
                c.execute("""
                    SELECT p.*, po.timestamp as created_at, po.username
                    FROM polls p 
                    JOIN posts po ON p.post_id = po.id 
                    WHERE po.community_id = ?
                    ORDER BY p.is_active DESC, po.timestamp DESC
                """, (community_id,))
            else:
                # Fallback to all polls if no community_id provided
                c.execute("""
                    SELECT p.*, po.timestamp as created_at, po.username
                    FROM polls p 
                    JOIN posts po ON p.post_id = po.id 
                    WHERE p.is_active = 1 AND (p.expires_at IS NULL OR p.expires_at >= NOW())
                    ORDER BY po.timestamp DESC
                """)
            polls_raw = c.fetchall()
            
            polls = []
            for poll_raw in polls_raw:
                poll = dict(poll_raw)
                
                # Get poll options
                c.execute("SELECT * FROM poll_options WHERE poll_id = ? ORDER BY id", (poll['id'],))
                options_raw = c.fetchall()
                poll['options'] = [dict(option) for option in options_raw]
                
                # Get user's vote
                c.execute("SELECT option_id FROM poll_votes WHERE poll_id = ? AND username = ?", (poll['id'], username))
                user_vote_raw = c.fetchone()
                poll['user_vote'] = user_vote_raw['option_id'] if user_vote_raw else None
                
                # Calculate total votes
                total_votes = sum(option['votes'] for option in poll['options'])
                poll['total_votes'] = total_votes
                
                polls.append(poll)
            
            return jsonify({'success': True, 'polls': polls})
            
    except Exception as e:
        logger.error(f"Error getting active polls: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_poll', methods=['POST'])
@login_required
def delete_poll():
    """Delete a poll permanently (admin or poll creator or community owner)"""
    username = session['username']
    data = request.get_json(silent=True) or {}
    poll_id = data.get('poll_id') or request.form.get('poll_id', type=int)
    if not poll_id:
        return jsonify({'success': False, 'error': 'Invalid poll ID'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Fetch poll and related post/community
            c.execute("SELECT p.created_by, p.post_id FROM polls p WHERE p.id=?", (poll_id,))
            pr = c.fetchone()
            if not pr:
                return jsonify({'success': False, 'error': 'Poll not found'})
            created_by = pr['created_by']
            c.execute("SELECT community_id FROM posts WHERE id=?", (pr['post_id'],))
            sr = c.fetchone()
            community_id = sr['community_id'] if sr else None
            # Permission: admin, poll creator, or community owner
            allowed = username == 'admin' or username == created_by
            if community_id and not allowed:
                c.execute("SELECT creator_username FROM communities WHERE id=?", (community_id,))
                cr = c.fetchone()
                if cr and cr['creator_username'] == username:
                    allowed = True
            if not allowed:
                return jsonify({'success': False, 'error': 'Not authorized'})
            # Delete poll (cascade removes options and votes)
            c.execute("DELETE FROM polls WHERE id=?", (poll_id,))
            # Also delete the associated post to completely remove the poll
            # Polls should be independent - deleting a poll removes everything
            c.execute("DELETE FROM posts WHERE id=?", (pr['post_id'],))
            conn.commit()
            logger.info(f"Deleted poll {poll_id} and associated post {pr['post_id']}")
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error deleting poll: {e}")
        return jsonify({'success': False, 'error': 'Error deleting poll'})
@app.route('/remove_poll_option', methods=['POST'])
@login_required
def remove_poll_option():
    """Remove a poll option (only poll creator can do this)"""
    username = session['username']
    
    if request.is_json:
        data = request.get_json()
        option_id = data.get('option_id')
    else:
        option_id = request.form.get('option_id', type=int)
    
    if not option_id:
        return jsonify({'success': False, 'error': 'Invalid option ID'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is the poll creator
            c.execute("""
                SELECT p.created_by, po.poll_id 
                FROM poll_options po 
                JOIN polls p ON po.poll_id = p.id 
                WHERE po.id = ?
            """, (option_id,))
            poll_data = c.fetchone()
            
            if not poll_data:
                return jsonify({'success': False, 'error': 'Option not found'})
            
            if poll_data['created_by'] != username and username != 'admin':
                return jsonify({'success': False, 'error': 'Only poll creator can remove options'})
            
            # Check if this is the last option
            c.execute("SELECT COUNT(*) as count FROM poll_options WHERE poll_id = ?", (poll_data['poll_id'],))
            option_count = c.fetchone()['count']
            
            if option_count <= 2:
                return jsonify({'success': False, 'error': 'Cannot remove option - minimum 2 options required'})
            
            # Remove the option and all its votes
            c.execute("DELETE FROM poll_votes WHERE option_id = ?", (option_id,))
            c.execute("DELETE FROM poll_options WHERE id = ?", (option_id,))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Option removed successfully'})
            
    except Exception as e:
        logger.error(f"Error removing poll option: {str(e)}")
        return jsonify({'success': False, 'error': 'Error removing option'})





@app.route('/get_historical_polls')
@login_required
def get_historical_polls():
    """Get historical (expired) polls for a specific community"""
    try:
        username = session['username']
        community_id = request.args.get('community_id', type=int)
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get historical polls (expired or inactive) for the specific community
            if community_id:
                c.execute("""
                    SELECT p.*, po.timestamp as created_at, po.username
                    FROM polls p 
                    JOIN posts po ON p.post_id = po.id 
                    WHERE (p.is_active = 0 OR (p.expires_at IS NOT NULL AND p.expires_at < NOW()))
                    AND po.community_id = ?
                    ORDER BY po.timestamp DESC
                """, (community_id,))
            else:
                # Fallback to all polls if no community_id provided
                c.execute("""
                    SELECT p.*, po.timestamp as created_at, po.username
                    FROM polls p 
                    JOIN posts po ON p.post_id = po.id 
                    WHERE p.is_active = 0 OR (p.expires_at IS NOT NULL AND p.expires_at < NOW())
                    ORDER BY po.timestamp DESC
                """)
            polls_raw = c.fetchall()
            
            polls = []
            for poll_raw in polls_raw:
                poll = dict(poll_raw)
                
                # Get poll options
                c.execute("SELECT * FROM poll_options WHERE poll_id = ? ORDER BY id", (poll['id'],))
                options_raw = c.fetchall()
                poll['options'] = [dict(option) for option in options_raw]
                
                # Get user's vote
                c.execute("SELECT option_id FROM poll_votes WHERE poll_id = ? AND username = ?", (poll['id'], username))
                user_vote_raw = c.fetchone()
                poll['user_vote'] = user_vote_raw['option_id'] if user_vote_raw else None
                
                # Calculate total votes
                total_votes = sum(option['votes'] for option in poll['options'])
                poll['total_votes'] = total_votes
                
                polls.append(poll)
            
            return jsonify({'success': True, 'polls': polls})
            
    except Exception as e:
        logger.error(f"Error getting historical polls: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/report_issue', methods=['POST'])
@login_required
def report_issue():
    """Report a new issue for a community"""
    try:
        username = session['username']
        data = request.get_json()
        
        community_id = data.get('community_id')
        title = data.get('title')
        location = data.get('location')
        priority = data.get('priority', 'medium')
        description = data.get('description')
        
        if not all([community_id, title, location, description]):
            return jsonify({'success': False, 'error': 'Missing required fields'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Insert the new issue
            c.execute("""
                INSERT INTO community_issues 
                (community_id, title, location, priority, description, reported_by, reported_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (community_id, title, location, priority, description, username, 
                  datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Issue reported successfully'})
            
    except Exception as e:
        logger.error(f"Error reporting issue: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})
def get_community_issues():
    """Get issues for a specific community"""
    try:
        username = session['username']
        community_id = request.args.get('community_id', type=int)
        status = request.args.get('status', 'active')  # 'active' or 'resolved'
        
        if not community_id:
            return jsonify({'success': False, 'error': 'Community ID required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get issues based on status
            if status == 'active':
                c.execute("""
                    SELECT ci.*, 
                           (SELECT COUNT(*) FROM issue_upvotes WHERE issue_id = ci.id) as upvote_count,
                           EXISTS(SELECT 1 FROM issue_upvotes WHERE issue_id = ci.id AND username = ?) as user_upvoted
                    FROM community_issues ci
                    WHERE ci.community_id = ? AND ci.resolved = 0
                    ORDER BY ci.reported_at DESC
                """, (username, community_id))
            else:  # resolved
                c.execute("""
                    SELECT ci.*, 
                           (SELECT COUNT(*) FROM issue_upvotes WHERE issue_id = ci.id) as upvote_count,
                           EXISTS(SELECT 1 FROM issue_upvotes WHERE issue_id = ci.id AND username = ?) as user_upvoted
                    FROM community_issues ci
                    WHERE ci.community_id = ? AND ci.resolved = 1
                    ORDER BY ci.resolved_at DESC
                """, (username, community_id))
            
            issues_raw = c.fetchall()
            issues = [dict(issue) for issue in issues_raw]
            
            # Format dates for display
            for issue in issues:
                # Convert reported_at to relative time
                reported_at = datetime.strptime(issue['reported_at'], '%Y-%m-%d %H:%M:%S')
                now = datetime.now()
                diff = now - reported_at
                
                if diff.days > 0:
                    issue['reported_at_display'] = f"{diff.days} day{'s' if diff.days > 1 else ''} ago"
                elif diff.seconds > 3600:
                    hours = diff.seconds // 3600
                    issue['reported_at_display'] = f"{hours} hour{'s' if hours > 1 else ''} ago"
                else:
                    minutes = diff.seconds // 60
                    issue['reported_at_display'] = f"{minutes} minute{'s' if minutes > 1 else ''} ago"
            
            return jsonify({'success': True, 'issues': issues})
            
    except Exception as e:
        logger.error(f"Error getting community issues: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/upvote_issue', methods=['POST'])
@login_required
def upvote_issue():
    """Upvote or remove upvote from an issue"""
    try:
        username = session['username']
        data = request.get_json()
        issue_id = data.get('issue_id')
        
        if not issue_id:
            return jsonify({'success': False, 'error': 'Issue ID required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user already upvoted
            c.execute("SELECT id FROM issue_upvotes WHERE issue_id = ? AND username = ?", 
                     (issue_id, username))
            existing_vote = c.fetchone()
            
            if existing_vote:
                # Remove upvote
                c.execute("DELETE FROM issue_upvotes WHERE issue_id = ? AND username = ?",
                         (issue_id, username))
                action = 'removed'
            else:
                # Add upvote
                c.execute("INSERT INTO issue_upvotes (issue_id, username, upvoted_at) VALUES (?, ?, ?)",
                         (issue_id, username, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
                action = 'added'
            
            # Update upvote count in issues table
            c.execute("""
                UPDATE community_issues 
                SET upvotes = (SELECT COUNT(*) FROM issue_upvotes WHERE issue_id = ?)
                WHERE id = ?
            """, (issue_id, issue_id))
            
            conn.commit()
            
            # Get updated count
            c.execute("SELECT upvotes FROM community_issues WHERE id = ?", (issue_id,))
            new_count = c.fetchone()['upvotes']
            
            return jsonify({'success': True, 'action': action, 'new_count': new_count})
            
    except Exception as e:
        logger.error(f"Error upvoting issue: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/resolve_issue', methods=['POST'])
@login_required
def resolve_issue():
    """Mark an issue as resolved"""
    try:
        username = session['username']
        data = request.get_json()
        issue_id = data.get('issue_id')
        
        if not issue_id:
            return jsonify({'success': False, 'error': 'Issue ID required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is admin or community creator
            c.execute("""
                SELECT c.creator_username 
                FROM community_issues ci
                JOIN communities c ON ci.community_id = c.id
                WHERE ci.id = ?
            """, (issue_id,))
            
            community = c.fetchone()
            if not community:
                return jsonify({'success': False, 'error': 'Issue not found'})
            
            if username != 'admin' and username != community['creator_username']:
                return jsonify({'success': False, 'error': 'Unauthorized'})
            
            # Mark issue as resolved
            c.execute("""
                UPDATE community_issues 
                SET resolved = 1, resolved_by = ?, resolved_at = ?
                WHERE id = ?
            """, (username, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), issue_id))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Issue marked as resolved'})
            
    except Exception as e:
        logger.error(f"Error resolving issue: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})
@app.route('/get_university_ads')
@login_required
def get_university_ads():
    """Get ads for a university community"""
    try:
        community_id = request.args.get('community_id', type=int)
        
        if not community_id:
            return jsonify({'success': False, 'message': 'Community ID is required'}), 400
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get active ads for the community
            c.execute("""
                SELECT id, title, description, price, image_url, link_url
                FROM university_ads
                WHERE community_id = ? AND is_active = 1
                ORDER BY display_order ASC, created_at DESC
                LIMIT 10
            """, (community_id,))
            
            ads = []
            ad_ids = []
            for row in c.fetchall():
                img = row['image_url'] if hasattr(row, 'keys') else row[4]
                link = row['link_url'] if hasattr(row, 'keys') else row[5]
                ads.append({
                    'id': row['id'] if hasattr(row, 'keys') else row[0],
                    'title': row['title'] if hasattr(row, 'keys') else row[1],
                    'description': row['description'] if hasattr(row, 'keys') else row[2],
                    'price': row['price'] if hasattr(row, 'keys') else row[3],
                    'image_url': img,
                    'link_url': link or '#'
                })
                ad_ids.append(row['id'])
            
            # Track impressions for displayed ads
            if ad_ids:
                c.execute(f"""
                    UPDATE university_ads 
                    SET impressions = impressions + 1 
                    WHERE id IN ({','.join('?' * len(ad_ids))})
                """, ad_ids)
                conn.commit()
            
            # If no ads, return sample data for demo
            if not ads:
                ads = [
                    {
                        'id': 0,
                        'title': 'University Hoodie',
                        'description': 'Official university hoodie',
                        'price': '$49.99',
                        'image_url': 'https://via.placeholder.com/800x600/2d8a7e/ffffff?text=University+Hoodie',
                        'link_url': '#'
                    },
                    {
                        'id': 0,
                        'title': 'Campus T-Shirt',
                        'description': 'Comfortable cotton t-shirt',
                        'price': '$24.99',
                        'image_url': 'https://via.placeholder.com/800x600/4db6ac/ffffff?text=Campus+Tee',
                        'link_url': '#'
                    },
                    {
                        'id': 0,
                        'title': 'Student Backpack',
                        'description': 'Durable laptop backpack',
                        'price': '$79.99',
                        'image_url': 'https://via.placeholder.com/800x600/37a69c/ffffff?text=Backpack',
                        'link_url': '#'
                    }
                ]
            
            return jsonify({'success': True, 'ads': ads})
            
    except Exception as e:
        logger.error(f"Error fetching university ads: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/track_ad_click', methods=['POST'])
@login_required
def track_ad_click():
    """Track when an ad is clicked"""
    try:
        data = request.get_json()
        ad_id = data.get('ad_id')
        
        if ad_id and ad_id != 0:  # Don't track sample ads
            with get_db_connection() as conn:
                c = conn.cursor()
                c.execute("UPDATE university_ads SET clicks = clicks + 1 WHERE id = ?", (ad_id,))
                conn.commit()
        
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error tracking ad click: {e}")
        return jsonify({'success': False}), 500

@app.route('/manage_ads/<int:community_id>')
@login_required
def manage_ads(community_id):
    """Ads management page for community admins"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is admin or community creator
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community:
                flash('Community not found', 'error')
                return redirect(url_for('communities'))
            
            if username != 'admin' and username != community['creator_username']:
                flash('You do not have permission to manage ads for this community', 'error')
                return redirect(url_for('community_feed', community_id=community_id))
            
            # Get all ads for this community
            c.execute("""
                SELECT id, title, description, price, image_url, link_url, 
                       is_active, display_order, clicks, impressions, created_at
                FROM university_ads
                WHERE community_id = ?
                ORDER BY display_order ASC, created_at DESC
            """, (community_id,))
            
            ads = []
            for row in c.fetchall():
                ads.append({
                    'id': row['id'],
                    'title': row['title'],
                    'description': row['description'],
                    'price': row['price'],
                    'image_url': row['image_url'],
                    'link_url': row['link_url'],
                    'is_active': row['is_active'],
                    'display_order': row['display_order'],
                    'clicks': row['clicks'],
                    'impressions': row['impressions'],
                    'ctr': f"{(row['clicks'] / row['impressions'] * 100):.2f}%" if row['impressions'] > 0 else "0%",
                    'created_at': row['created_at']
                })
            
            return render_template('manage_ads.html', 
                                 community=community, 
                                 ads=ads,
                                 username=username)
    except Exception as e:
        logger.error(f"Error in manage_ads: {e}")
        flash('An error occurred', 'error')
        return redirect(url_for('communities'))

@app.route('/add_ad/<int:community_id>', methods=['POST'])
@login_required
def add_ad(community_id):
    """Add a new ad"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check permissions
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community or (username != 'admin' and username != community['creator_username']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Get form data
            title = request.form.get('title')
            description = request.form.get('description')
            price = request.form.get('price')
            image_url = request.form.get('image_url')
            link_url = request.form.get('link_url')
            display_order = request.form.get('display_order', 0)
            
            # Insert new ad
            c.execute("""
                INSERT INTO university_ads 
                (community_id, title, description, price, image_url, link_url, 
                 display_order, created_at, created_by)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (community_id, title, description, price, image_url, link_url,
                  display_order, datetime.now().isoformat(), username))
            conn.commit()
            
            flash('Ad added successfully!', 'success')
            return redirect(url_for('manage_ads', community_id=community_id))
            
    except Exception as e:
        logger.error(f"Error adding ad: {e}")
        flash('Error adding ad', 'error')
        return redirect(url_for('manage_ads', community_id=community_id))

@app.route('/toggle_ad/<int:ad_id>', methods=['POST'])
@login_required
def toggle_ad(ad_id):
    """Toggle ad active status"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check permissions
            c.execute("""
                SELECT a.*, c.creator_username 
                FROM university_ads a
                JOIN communities c ON a.community_id = c.id
                WHERE a.id = ?
            """, (ad_id,))
            ad = c.fetchone()
            
            if not ad or (username != 'admin' and username != ad['creator_username']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Toggle status
            new_status = 0 if ad['is_active'] else 1
            c.execute("UPDATE university_ads SET is_active = ? WHERE id = ?", (new_status, ad_id))
            conn.commit()
            
            return jsonify({'success': True, 'new_status': new_status})
            
    except Exception as e:
        logger.error(f"Error toggling ad: {e}")
        return jsonify({'success': False}), 500

@app.route('/update_ad/<int:ad_id>', methods=['POST'])
@login_required
def update_ad(ad_id):
    """Update an existing ad"""
    username = session.get('username')
    
    try:
        data = request.get_json()
        title = data.get('title', '').strip()
        description = data.get('description', '').strip()
        price = data.get('price', '').strip()
        image_url = data.get('image_url', '').strip()
        link_url = data.get('link_url', '').strip()
        
        if not title or not price or not image_url:
            return jsonify({'success': False, 'message': 'Title, price, and image URL are required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check permissions
            c.execute("""
                SELECT a.*, c.creator_username 
                FROM university_ads a
                JOIN communities c ON a.community_id = c.id
                WHERE a.id = ?
            """, (ad_id,))
            ad = c.fetchone()
            
            if not ad or (username != 'admin' and username != ad['creator_username']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Update ad
            c.execute("""
                UPDATE university_ads 
                SET title = ?, description = ?, price = ?, image_url = ?, link_url = ?
                WHERE id = ?
            """, (title, description, price, image_url, link_url, ad_id))
            conn.commit()
            
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error updating ad: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/delete_ad/<int:ad_id>', methods=['POST'])
@login_required
def delete_ad(ad_id):
    """Delete an ad"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check permissions
            c.execute("""
                SELECT a.*, c.creator_username 
                FROM university_ads a
                JOIN communities c ON a.community_id = c.id
                WHERE a.id = ?
            """, (ad_id,))
            ad = c.fetchone()
            
            if not ad or (username != 'admin' and username != ad['creator_username']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Delete ad
            c.execute("DELETE FROM university_ads WHERE id = ?", (ad_id,))
            conn.commit()
            
            return jsonify({'success': True})
            
    except Exception as e:
        logger.error(f"Error deleting ad: {e}")
        return jsonify({'success': False}), 500

@app.route('/community/<int:community_id>/resources')
@login_required
def community_resources(community_id):
    """Community resource sharing forum - mobile -> React, desktop -> HTML"""
    username = session.get('username')
    # UA-based routing
    try:
        ua = request.headers.get('User-Agent', '')
        is_mobile = any(k in ua for k in ['Mobi', 'Android', 'iPhone', 'iPad'])
        if is_mobile:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            dist_dir = os.path.join(base_dir, 'client', 'dist')
            index_path = os.path.join(dist_dir, 'index.html')
            if os.path.exists(index_path):
                return send_from_directory(dist_dir, 'index.html')
    except Exception as _e:
        logger.warning(f"React resources not available: {_e}")

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get community info
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            if not community:
                flash('Community not found', 'error')
                return redirect(url_for('communities'))
            
            # Get resource posts for this community with profile pictures
            c.execute("""
                SELECT p.*,
                       up.profile_picture,
                       (SELECT COUNT(*) FROM resource_comments WHERE post_id = p.id) as comment_count,
                       (SELECT COUNT(*) FROM resource_upvotes WHERE post_id = p.id) as upvote_count,
                       EXISTS(SELECT 1 FROM resource_upvotes WHERE post_id = p.id AND username = ?) as user_upvoted
                FROM resource_posts p
                LEFT JOIN user_profiles up ON p.username = up.username
                WHERE p.community_id = ?
                ORDER BY p.is_pinned DESC, p.created_at DESC
            """, (username, community_id))
            
            posts = []
            for row in c.fetchall():
                posts.append(dict(row))
            
            return render_template('community_resources.html', 
                                 community=dict(community), 
                                 posts=posts,
                                 username=username)
                                 
    except Exception as e:
        logger.error(f"Error loading community resources: {e}")
        flash('Error loading resources', 'error')
        return redirect(url_for('community_feed', community_id=community_id))

@app.route('/community/<int:community_id>/resources/create', methods=['POST'])
@login_required
def create_resource_post(community_id):
    """Create a new resource post"""
    username = session.get('username')
    
    try:
        data = request.get_json()
        title = data.get('title', '').strip()
        content = data.get('content', '').strip()
        category = data.get('category', 'General')
        attachment_url = data.get('attachment_url', '')
        
        if not title or not content:
            return jsonify({'success': False, 'message': 'Title and content are required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Create post directly (access control is handled at page level)
            c.execute("""
                INSERT INTO resource_posts 
                (community_id, username, title, content, category, attachment_url, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (community_id, username, title, content, category, attachment_url, 
                  datetime.now().isoformat()))
            
            conn.commit()
            post_id = c.lastrowid
            
            return jsonify({'success': True, 'post_id': post_id})
            
    except Exception as e:
        logger.error(f"Error creating resource post: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
def upvote_resource_post(post_id):
    """Toggle upvote on a resource post"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if already upvoted
            c.execute("""
                SELECT 1 FROM resource_upvotes 
                WHERE post_id = ? AND username = ?
            """, (post_id, username))
            
            if c.fetchone():
                # Remove upvote
                c.execute("""
                    DELETE FROM resource_upvotes 
                    WHERE post_id = ? AND username = ?
                """, (post_id, username))
                
                c.execute("""
                    UPDATE resource_posts 
                    SET upvotes = upvotes - 1 
                    WHERE id = ?
                """, (post_id,))
                
                action = 'removed'
            else:
                # Add upvote
                c.execute("""
                    INSERT INTO resource_upvotes (post_id, username, created_at)
                    VALUES (?, ?, ?)
                """, (post_id, username, datetime.now().isoformat()))
                
                c.execute("""
                    UPDATE resource_posts 
                    SET upvotes = upvotes + 1 
                    WHERE id = ?
                """, (post_id,))
                
                action = 'added'
            
            conn.commit()
            
            # Get updated count
            c.execute("SELECT upvotes FROM resource_posts WHERE id = ?", (post_id,))
            upvotes = c.fetchone()['upvotes']
            
            return jsonify({'success': True, 'action': action, 'upvotes': upvotes})
            
    except Exception as e:
        logger.error(f"Error upvoting post: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/resource/post/<int:post_id>/delete', methods=['DELETE'])
@login_required
def delete_resource_post(post_id):
    """Delete a resource post"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get post details and community info
            c.execute("""
                SELECT p.*, c.creator_username 
                FROM resource_posts p
                JOIN communities c ON p.community_id = c.id
                WHERE p.id = ?
            """, (post_id,))
            
            post = c.fetchone()
            
            if not post:
                return jsonify({'success': False, 'message': 'Post not found'}), 404
            
            # Check permissions (post creator, admin, or community creator)
            if username != post['username'] and username != 'admin' and username != post['creator_username']:
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Delete the post (cascade will handle comments and upvotes)
            c.execute("DELETE FROM resource_posts WHERE id = ?", (post_id,))
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Post deleted successfully'})
            
    except Exception as e:
        logger.error(f"Error deleting post: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/post/<int:post_id>/delete', methods=['DELETE'])
@login_required
def delete_community_post(post_id):
    """Delete a community post"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get post details
            c.execute("SELECT * FROM posts WHERE id = ?", (post_id,))
            post = c.fetchone()
            
            if not post:
                return jsonify({'success': False, 'message': 'Post not found'}), 404
            
            # Check permissions using the new permission system
            if not has_post_delete_permission(username, post['username'], post['community_id']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Delete the post
            c.execute("DELETE FROM posts WHERE id = ?", (post_id,))
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Post deleted successfully'})
            
    except Exception as e:
        logger.error(f"Error deleting community post: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/appoint_admin', methods=['POST'])
@login_required
def appoint_community_admin(community_id):
    """Appoint a community admin (only community owner or app admin can do this)"""
    username = session.get('username')
    
    try:
        # Check if user has permission to appoint admins
        if not is_app_admin(username) and not is_community_owner(username, community_id):
            return jsonify({'success': False, 'message': 'Only community owner or app admin can appoint admins'}), 403
        
        data = request.get_json()
        new_admin = data.get('username', '').strip()
        
        if not new_admin:
            return jsonify({'success': False, 'message': 'Username is required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user exists
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM users WHERE username = {ph}", (new_admin,))
            if not c.fetchone():
                return jsonify({'success': False, 'message': 'User not found'}), 404
            
            # Check if already an admin
            c.execute("""
                SELECT role FROM user_communities
                WHERE user_id = (SELECT id FROM users WHERE username = ?) AND community_id = ?
            """, (new_admin, community_id))
            existing_role = c.fetchone()
            if existing_role and (existing_role['role'] == 'admin' if hasattr(existing_role, 'keys') else existing_role[0] == 'admin'):
                return jsonify({'success': False, 'message': 'User is already an admin'}), 400

            # Appoint as admin using user_communities table
            c.execute("""
                INSERT INTO user_communities (user_id, community_id, role, joined_at)
                VALUES ((SELECT id FROM users WHERE username = ?), ?, 'admin', NOW())
                ON DUPLICATE KEY UPDATE role = 'admin'
            """, (new_admin, community_id))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': f'{new_admin} appointed as community admin'})
            
    except Exception as e:
        logger.error(f"Error appointing admin: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/migrate_user_communities_role', methods=['POST'])
def migrate_user_communities_role():
    """Migrate user_communities table to add role column - no login required for setup"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Check if role column exists
            c.execute("SHOW COLUMNS FROM user_communities LIKE 'role'")
            if not c.fetchone():
                logger.info("Adding role column to user_communities table...")
                # TEXT columns can't have default values in MySQL
                c.execute("ALTER TABLE user_communities ADD COLUMN role TEXT")
                # Set default value for existing rows
                c.execute("UPDATE user_communities SET role = 'member' WHERE role IS NULL")
                conn.commit()
                logger.info("Added role column to user_communities table")
                return jsonify({'success': True, 'message': 'Role column added successfully'})
            else:
                return jsonify({'success': True, 'message': 'Role column already exists'})
    except Exception as e:
        logger.error(f"Error adding role column: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/community/<int:community_id>/remove_admin', methods=['POST'])
@login_required
def remove_community_admin(community_id):
    """Remove a community admin (only community owner or app admin can do this)"""
    username = session.get('username')
    
    try:
        # Check if user has permission to remove admins
        if not is_app_admin(username) and not is_community_owner(username, community_id):
            return jsonify({'success': False, 'message': 'Only community owner or app admin can remove admins'}), 403
        
        data = request.get_json()
        admin_to_remove = data.get('username', '').strip()
        
        if not admin_to_remove:
            return jsonify({'success': False, 'message': 'Username is required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Remove admin role using user_communities table
            c.execute("""
                INSERT INTO user_communities (user_id, community_id, role, joined_at)
                VALUES ((SELECT id FROM users WHERE username = ?), ?, 'member', NOW())
                ON DUPLICATE KEY UPDATE role = 'member'
            """, (admin_to_remove, community_id))

            if c.rowcount == 0:
                return jsonify({'success': False, 'message': 'User is not an admin'}), 404
            
            conn.commit()
            
            return jsonify({'success': True, 'message': f'{admin_to_remove} removed as community admin'})
            
    except Exception as e:
        logger.error(f"Error removing admin: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/admins')
@login_required
def get_community_admins(community_id):
    """Get list of community admins"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT ca.*, u.email 
                FROM community_admins ca
                JOIN users u ON ca.username = u.username
                WHERE ca.community_id = ?
                ORDER BY ca.appointed_at DESC
            """, (community_id,))
            
            admins = []
            for row in c.fetchall():
                admins.append(dict(row))
            
            return jsonify({'success': True, 'admins': admins})
            
    except Exception as e:
        logger.error(f"Error getting community admins: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
@app.route('/community/<int:community_id>/clubs')
@login_required
def clubs_directory(community_id):
    """Clubs and organizations directory for university communities"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get community info
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            if not community:
                flash('Community not found', 'error')
                return redirect(url_for('communities'))
            
            # Check if this is a parent university community
            if community['type'] != 'University' or community['parent_community_id']:
                flash('Clubs directory is only available for main university communities', 'error')
                return redirect(url_for('community_feed', community_id=community_id))
            
            # Get all clubs for this community
            c.execute("""
                SELECT c.*, 
                       (SELECT COUNT(*) FROM club_members WHERE club_id = c.id) as member_count,
                       EXISTS(SELECT 1 FROM club_members WHERE club_id = c.id AND username = ?) as is_member,
                       (SELECT role FROM club_members WHERE club_id = c.id AND username = ?) as user_role
                FROM clubs c
                WHERE c.community_id = ? AND c.is_active = 1
                ORDER BY c.name
            """, (username, username, community_id))
            
            clubs = []
            for row in c.fetchall():
                clubs.append(dict(row))
            
            return render_template('clubs_directory.html', 
                                 community=dict(community), 
                                 clubs=clubs,
                                 username=username)
                                 
    except Exception as e:
        logger.error(f"Error loading clubs directory: {e}")
        flash('Error loading clubs directory', 'error')
        return redirect(url_for('community_feed', community_id=community_id))

@app.route('/community/<int:community_id>/clubs/create', methods=['POST'])
@login_required
def create_club(community_id):
    """Create a new club"""
    username = session.get('username')
    
    try:
        data = request.get_json()
        name = data.get('name', '').strip()
        description = data.get('description', '').strip()
        category = data.get('category', 'General')
        contact_email = data.get('contact_email', '')
        contact_person = data.get('contact_person', '')
        meeting_schedule = data.get('meeting_schedule', '')
        location = data.get('location', '')
        website_url = data.get('website_url', '')
        
        if not name or not description:
            return jsonify({'success': False, 'message': 'Name and description are required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Create club
            c.execute("""
                INSERT INTO clubs 
                (community_id, name, description, category, contact_email, contact_person,
                 meeting_schedule, location, website_url, created_by, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (community_id, name, description, category, contact_email, contact_person,
                  meeting_schedule, location, website_url, username, datetime.now().isoformat()))
            
            club_id = c.lastrowid
            
            # Add creator as president
            c.execute("""
                INSERT INTO club_members (club_id, username, role, joined_at)
                VALUES (?, ?, 'president', ?)
            """, (club_id, username, datetime.now().isoformat()))
            
            conn.commit()
            
            return jsonify({'success': True, 'club_id': club_id})
            
    except Exception as e:
        logger.error(f"Error creating club: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/club/<int:club_id>/join', methods=['POST'])
@login_required
def join_club(club_id):
    """Join or leave a club"""
    username = session.get('username')
    # Enforce verified email (mobile join path)
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
            row = c.fetchone()
            if row is not None:
                is_verified = bool(row['email_verified'] if hasattr(row, 'keys') else row[0])
                if not is_verified:
                    return jsonify({'success': False, 'error': 'please verify your email'}), 403
    except Exception:
        pass

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if already a member
            c.execute("""
                SELECT 1 FROM club_members 
                WHERE club_id = ? AND username = ?
            """, (club_id, username))
            
            if c.fetchone():
                # Leave club
                c.execute("""
                    DELETE FROM club_members 
                    WHERE club_id = ? AND username = ?
                """, (club_id, username))
                action = 'left'
            else:
                # Join club
                c.execute("""
                    INSERT INTO club_members (club_id, username, joined_at)
                    VALUES (?, ?, ?)
                """, (club_id, username, datetime.now().isoformat()))
                action = 'joined'
            
            conn.commit()
            
            # Get updated member count
            c.execute("SELECT COUNT(*) as count FROM club_members WHERE club_id = ?", (club_id,))
            member_count = c.fetchone()['count']
            
            return jsonify({'success': True, 'action': action, 'member_count': member_count})
            
    except Exception as e:
        logger.error(f"Error joining/leaving club: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/feedback', methods=['POST'])
@login_required
def submit_feedback(community_id):
    """Submit anonymous feedback"""
    try:
        data = request.get_json()
        feedback_text = data.get('feedback', '').strip()
        category = data.get('category', 'General')
        priority = data.get('priority', 'normal')
        
        if not feedback_text:
            return jsonify({'success': False, 'message': 'Feedback text is required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Submit feedback
            c.execute("""
                INSERT INTO anonymous_feedback 
                (community_id, feedback_text, category, priority, submitted_at)
                VALUES (?, ?, ?, ?, ?)
            """, (community_id, feedback_text, category, priority, datetime.now().isoformat()))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Feedback submitted successfully'})
            
    except Exception as e:
        logger.error(f"Error submitting feedback: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/members/list')
@login_required
def get_community_members_list(community_id):
    """Get list of community members - visible to all members of the community"""
    try:
        username = session.get('username')
        logger.info(f"Fetching members for community {community_id} requested by {username}")
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # First check if community exists
            c.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            if not community:
                logger.warning(f"Community {community_id} not found")
                return jsonify({'success': False, 'message': 'Community not found'}), 404

            # Ensure the requester is a member of the community
            c.execute("SELECT id FROM users WHERE username = ?", (username,))
            user_row = c.fetchone()
            if not user_row:
                return jsonify({'success': False, 'message': 'User not found'}), 404
            requester_user_id = user_row['id'] if hasattr(user_row, 'keys') else user_row[0]
            c.execute("""
                SELECT 1 FROM user_communities 
                WHERE user_id = ? AND community_id = ?
            """, (requester_user_id, community_id))
            is_member = c.fetchone() is not None
            if not is_member:
                logger.info(f"User {username} attempted to view members of community {community_id} without membership")
                return jsonify({'success': False, 'message': 'Forbidden: not a member of this community'}), 403
            
            # Get community members with profile pictures and roles
            # Check if role column exists first
            try:
                c.execute("SHOW COLUMNS FROM user_communities LIKE 'role'")
                role_column_exists = c.fetchone() is not None
            except:
                role_column_exists = False

            if role_column_exists:
                # Use the full query with role information
                c.execute("""
                    SELECT DISTINCT
                        u.username,
                        up.profile_picture,
                        c.creator_username,
                        COALESCE(uc.role, 'member') as role,
                        CASE WHEN c.creator_username = u.username THEN 1 ELSE 0 END as is_creator
                    FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    LEFT JOIN user_profiles up ON u.username = up.username
                    JOIN communities c ON c.id = uc.community_id
                    WHERE uc.community_id = ?
                    ORDER BY
                        CASE WHEN c.creator_username = u.username THEN 0 ELSE 1 END,
                        CASE WHEN COALESCE(uc.role, 'member') = 'admin' THEN 0
                             WHEN COALESCE(uc.role, 'member') = 'owner' THEN 1
                             ELSE 2 END,
                        u.username
                """, (community_id,))
            else:
                # Fallback query without role information for backward compatibility
                logger.warning("Role column doesn't exist in user_communities table, using fallback query")
                c.execute("""
                    SELECT DISTINCT
                        u.username,
                        up.profile_picture,
                        c.creator_username,
                        'member' as role,
                        CASE WHEN c.creator_username = u.username THEN 1 ELSE 0 END as is_creator
                    FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    LEFT JOIN user_profiles up ON u.username = up.username
                    JOIN communities c ON c.id = uc.community_id
                    WHERE uc.community_id = ?
                    ORDER BY
                        CASE WHEN c.creator_username = u.username THEN 0 ELSE 1 END,
                        u.username
                """, (community_id,))

            members = []
            rows = c.fetchall()
            logger.info(f"Found {len(rows)} members in community {community_id}")

            for row in rows:
                # Handle different database cursor types (dict vs tuple)
                if hasattr(row, 'keys'):
                    username_val = row['username']
                    profile_picture_val = row['profile_picture']
                    creator_username = row['creator_username']
                    role_val = row['role']
                    is_creator_val = row['is_creator']
                else:
                    username_val = row[0]
                    profile_picture_val = row[1]
                    creator_username = row[2]
                    role_val = row[3]
                    is_creator_val = row[4]

                # Hide the global app admin from visible lists
                if str(username_val).lower() == 'admin':
                    continue
                members.append({
                    'username': username_val,
                    'profile_picture': profile_picture_val,
                    'role': role_val,
                    'is_creator': bool(is_creator_val),
                    'is_current_user': username_val == username
                })
            
            return jsonify({
                'success': True,
                'members': members,
                'total': len(members),
                'community_name': community['name']
            })
            
    except Exception as e:
        logger.error(f"Error fetching community members for community {community_id}: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/event/<int:event_id>/rsvp')
@login_required
def event_rsvp_page(community_id, event_id):
    """Display RSVP page for an event invitation"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get event details
            c.execute("""
                SELECT e.*, c.name as community_name, c.background_color
                FROM calendar_events e
                JOIN communities c ON e.community_id = c.id
                WHERE e.id = ? AND e.community_id = ?
            """, (event_id, community_id))
            
            event = c.fetchone()
            if not event:
                flash('Event not found', 'error')
                return redirect(url_for('community_feed', community_id=community_id))
            
            # Check if user is invited
            c.execute("""
                SELECT * FROM event_invitations
                WHERE event_id = ? AND invited_username = ?
            """, (event_id, username))
            
            invitation = c.fetchone()
            
            # Get current RSVP status
            c.execute("""
                SELECT response FROM event_rsvps
                WHERE event_id = ? AND username = ?
            """, (event_id, username))
            
            rsvp = c.fetchone()
            
            # Get RSVP counts
            c.execute("""
                SELECT response, COUNT(*) as count
                FROM event_rsvps
                WHERE event_id = ?
                GROUP BY response
            """, (event_id,))
            
            rsvp_counts = {'going': 0, 'maybe': 0, 'not_going': 0}
            for row in c.fetchall():
                rsvp_counts[row['response']] = row['count']
            
            # Mark invitation as viewed
            if invitation:
                c.execute("""
                    UPDATE event_invitations
                    SET viewed = 1
                    WHERE event_id = ? AND invited_username = ?
                """, (event_id, username))
                conn.commit()
            
            return render_template('event_rsvp.html',
                                   event=event,
                                   community_id=community_id,
                                   invitation=invitation,
                                   current_rsvp=rsvp['response'] if rsvp else None,
                                   rsvp_counts=rsvp_counts)
    
    except Exception as e:
        logger.error(f"Error displaying RSVP page: {e}")
        flash('An error occurred', 'error')
        return redirect(url_for('community_feed', community_id=community_id))

@app.route('/event/<int:event_id>/rsvp', methods=['POST'])
@login_required
def rsvp_event(event_id):
    """RSVP to a calendar event (accepts JSON or form), returns updated counts including no_response and user_rsvp"""
    username = session.get('username')
    try:
        data = request.get_json(silent=True) or {}
        response = (request.form.get('response') or data.get('response') or '').strip()
        note = (request.form.get('note') or data.get('note') or '').strip()
        if response not in ('going','maybe','not_going'):
            return jsonify({'success': False, 'message': 'Invalid response'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure event exists and get community_id and creator
            ph = get_sql_placeholder()
            c.execute(f"SELECT community_id, username FROM calendar_events WHERE id = {ph}", (event_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'message': 'Event not found'}), 404
            community_id_val = row['community_id'] if hasattr(row, 'keys') else row[0]
            event_creator = row['username'] if hasattr(row, 'keys') else row[1]
            
            # Check if user is invited or is the event creator
            if username != event_creator:
                c.execute(f"SELECT 1 FROM event_invitations WHERE event_id = {ph} AND invited_username = {ph}", (event_id, username))
                if not c.fetchone():
                    return jsonify({'success': False, 'message': 'You are not invited to this event'}), 403
            # Upsert RSVP
            c.execute(f"""
                INSERT INTO event_rsvps (event_id, username, response, note, responded_at)
                VALUES ({ph}, {ph}, {ph}, {ph}, {ph})
                ON DUPLICATE KEY UPDATE response=VALUES(response), note=VALUES(note), responded_at=VALUES(responded_at)
            """, (event_id, username, response, note, datetime.now().isoformat()))
            # Counts
            ph = get_sql_placeholder()
            c.execute(f"SELECT response, COUNT(*) as count FROM event_rsvps WHERE event_id={ph} GROUP BY response", (event_id,))
            counts = {'going': 0, 'maybe': 0, 'not_going': 0}
            for r in c.fetchall():
                counts[r['response']] = r['count']
            # Calculate no_response based on invited users only
            no_response = 0
            total_invited = 0
            try:
                # Count total invited users (including creator)
                c.execute(f"SELECT COUNT(DISTINCT invited_username) as cnt FROM event_invitations WHERE event_id={ph}", (event_id,))
                invited_row = c.fetchone()
                if invited_row:
                    total_invited = invited_row['cnt'] if hasattr(invited_row, 'keys') else invited_row[0]
                else:
                    total_invited = 0
                # Add 1 for event creator
                total_invited += 1
                
                # Count users who responded
                c.execute(f"SELECT COUNT(DISTINCT username) as cnt FROM event_rsvps WHERE event_id={ph}", (event_id,))
                responded_row = c.fetchone()
                if responded_row:
                    responded = responded_row['cnt'] if hasattr(responded_row, 'keys') else responded_row[0]
                else:
                    responded = 0
                no_response = max(0, total_invited - responded)
            except Exception as e:
                logger.warning(f"Error calculating no_response in RSVP endpoint for event {event_id}: {e}")
                no_response = 0
            counts['no_response'] = no_response
            counts['total_invited'] = total_invited
            conn.commit()
        return jsonify({'success': True, 'counts': counts, 'user_rsvp': response})
    except Exception as e:
        logger.error(f"Error updating RSVP: {e}")
        return jsonify({'success': False, 'message': 'Server error'}), 500

@app.route('/event/<int:event_id>/rsvps')
@login_required
def get_event_rsvps(event_id):
    """Get all RSVPs for an event"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get event details
            c.execute("""
                SELECT e.*, c.name as community_name
                FROM calendar_events e
                JOIN communities c ON e.community_id = c.id
                WHERE e.id = ?
            """, (event_id,))
            
            event = c.fetchone()
            if not event:
                return jsonify({'success': False, 'message': 'Event not found'}), 404
            
            # Get all RSVPs with user profiles
            c.execute("""
                SELECT r.*, up.profile_picture
                FROM event_rsvps r
                LEFT JOIN user_profiles up ON r.username = up.username
                WHERE r.event_id = ?
                ORDER BY r.response, r.responded_at DESC
            """, (event_id,))
            
            rsvps = []
            for row in c.fetchall():
                rsvps.append({
                    'username': row['username'],
                    'response': row['response'],
                    'note': row['note'],
                    'responded_at': row['responded_at'],
                    'profile_picture': row['profile_picture']
                })
            
            # Get current user's RSVP
            c.execute("""
                SELECT response FROM event_rsvps
                WHERE event_id = ? AND username = ?
            """, (event_id, username))
            
            user_rsvp = c.fetchone()
            
            # Get counts
            counts = {'going': 0, 'maybe': 0, 'not_going': 0}
            for rsvp in rsvps:
                counts[rsvp['response']] += 1
            
            return jsonify({
                'success': True,
                'event': dict(event),
                'rsvps': rsvps,
                'counts': counts,
                'user_rsvp': user_rsvp['response'] if user_rsvp else None
            })
            
    except Exception as e:
        logger.error(f"Error fetching RSVPs: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/event/<int:event_id>/rsvp', methods=['DELETE'])
@login_required
def cancel_rsvp(event_id):
    """Cancel RSVP for an event"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            c.execute("""
                DELETE FROM event_rsvps
                WHERE event_id = ? AND username = ?
            """, (event_id, username))
            
            if c.rowcount == 0:
                return jsonify({'success': False, 'message': 'No RSVP found'}), 404
            
            conn.commit()
            
            # Get updated counts
            c.execute("""
                SELECT response, COUNT(*) as count
                FROM event_rsvps
                WHERE event_id = ?
                GROUP BY response
            """, (event_id,))
            
            counts = {'going': 0, 'maybe': 0, 'not_going': 0}
            for row in c.fetchall():
                counts[row['response']] = row['count']
            
            return jsonify({
                'success': True,
                'message': 'RSVP cancelled',
                'counts': counts
            })
            
    except Exception as e:
        logger.error(f"Error cancelling RSVP: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/community/<int:community_id>/feedback/view')
@login_required
def view_feedback(community_id):
    """View feedback (admin/creator only)"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check permissions
            c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community or (username != 'admin' and username != community['creator_username']):
                return jsonify({'success': False, 'message': 'Unauthorized'}), 403
            
            # Get feedback
            c.execute("""
                SELECT * FROM anonymous_feedback 
                WHERE community_id = ?
                ORDER BY submitted_at DESC
            """, (community_id,))
            
            feedback = []
            for row in c.fetchall():
                feedback.append(dict(row))
            
            return jsonify({'success': True, 'feedback': feedback})
            
    except Exception as e:
        logger.error(f"Error viewing feedback: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/admin/deactivate_user/<username>', methods=['POST'])
@login_required
def deactivate_user(username):
    """Deactivate/reactivate a user (app admin only)"""
    current_user = session.get('username')
    
    if not is_app_admin(current_user):
        return jsonify({'success': False, 'message': 'Unauthorized'}), 403
    
    if username == 'admin':
        return jsonify({'success': False, 'message': 'Cannot deactivate app admin'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Toggle user active status
            c.execute("SELECT is_active FROM users WHERE username = ?", (username,))
            user = c.fetchone()
            
            if not user:
                return jsonify({'success': False, 'message': 'User not found'}), 404
            
            new_status = 0 if user['is_active'] else 1
            c.execute("UPDATE users SET is_active = ? WHERE username = ?", (new_status, username))
            conn.commit()
            
            action = 'activated' if new_status else 'deactivated'
            return jsonify({'success': True, 'message': f'User {username} has been {action}'})
            
    except Exception as e:
        logger.error(f"Error deactivating user: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500

@app.route('/admin/deactivate_community/<int:community_id>', methods=['POST'])
@login_required
def deactivate_community(community_id):
    """Deactivate/reactivate a community (app admin only)"""
    current_user = session.get('username')
    
    if not is_app_admin(current_user):
        return jsonify({'success': False, 'message': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Toggle community active status
            c.execute("SELECT is_active, name FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community:
                return jsonify({'success': False, 'message': 'Community not found'}), 404
            
            new_status = 0 if community['is_active'] else 1
            c.execute("UPDATE communities SET is_active = ? WHERE id = ?", (new_status, community_id))
            conn.commit()
            
            action = 'activated' if new_status else 'deactivated'
            return jsonify({'success': True, 'message': f'Community {community["name"]} has been {action}'})
            
    except Exception as e:
        logger.error(f"Error deactivating community: {e}")
        return jsonify({'success': False, 'message': str(e)}), 500
@app.route('/gym')
@login_required
def gym():
    resp = serve_react_index()
    if resp:
        return resp
    logger.warning("React build missing for /gym; redirecting to /workout_tracking")
    return redirect(url_for('workout_tracking'))

@app.route('/admin/user_statistics')
@login_required
def admin_user_statistics():
    """Admin endpoint to view user activity statistics"""
    username = session.get('username')
    
    # Check if user is admin
    if username != 'admin':
        return jsonify({'success': False, 'message': 'Unauthorized'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure required tables exist
            try:
                if USE_MYSQL:
                    c.execute("""
                        CREATE TABLE IF NOT EXISTS user_login_history (
                            id INTEGER PRIMARY KEY AUTO_INCREMENT,
                            username VARCHAR(255) NOT NULL,
                            login_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                            ip_address VARCHAR(45),
                            user_agent TEXT,
                            FOREIGN KEY (username) REFERENCES users (username)
                        )
                    """)
                    c.execute("""
                        CREATE TABLE IF NOT EXISTS community_visit_history (
                            id INTEGER PRIMARY KEY AUTO_INCREMENT,
                            username VARCHAR(191) NOT NULL,
                            community_id INTEGER NOT NULL,
                            visit_time TEXT NOT NULL,
                            FOREIGN KEY (username) REFERENCES users (username),
                            FOREIGN KEY (community_id) REFERENCES communities (id)
                        )
                    """)
                else:
                    # SQLite
                    c.execute("""
                        CREATE TABLE IF NOT EXISTS user_login_history (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            username TEXT NOT NULL,
                            login_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                            ip_address TEXT,
                            user_agent TEXT,
                            FOREIGN KEY (username) REFERENCES users (username)
                        )
                    """)
                    c.execute("""
                        CREATE TABLE IF NOT EXISTS community_visit_history (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            username TEXT NOT NULL,
                            community_id INTEGER NOT NULL,
                            visit_time TEXT NOT NULL,
                            FOREIGN KEY (username) REFERENCES users (username),
                            FOREIGN KEY (community_id) REFERENCES communities (id)
                        )
                    """)
                
                # Create indexes for both MySQL and SQLite
                try:
                    c.execute("CREATE INDEX IF NOT EXISTS idx_login_username ON user_login_history(username)")
                    c.execute("CREATE INDEX IF NOT EXISTS idx_login_time ON user_login_history(login_time)")
                    c.execute("CREATE INDEX IF NOT EXISTS idx_visit_username ON community_visit_history(username)")
                    c.execute("CREATE INDEX IF NOT EXISTS idx_visit_community ON community_visit_history(community_id)")
                    c.execute("CREATE INDEX IF NOT EXISTS idx_visit_time ON community_visit_history(visit_time)")
                except Exception:
                    pass
                conn.commit()
            except Exception as ensure_err:
                logger.warning(f"Could not ensure stats tables: {ensure_err}")
            
            # Get user statistics
            c.execute("""
                SELECT 
                    u.username,
                    u.subscription,
                    u.created_at,
                    COUNT(DISTINCT lh.id) as login_count,
                    COUNT(DISTINCT vh.id) as total_visits,
                    COUNT(DISTINCT vh.community_id) as unique_communities_visited,
                    MAX(lh.login_time) as last_login
                FROM users u
                LEFT JOIN user_login_history lh ON u.username = lh.username
                LEFT JOIN community_visit_history vh ON u.username = vh.username
                GROUP BY u.username
                ORDER BY login_count DESC, total_visits DESC
            """)
            
            user_stats = []
            for row in c.fetchall():
                user_stats.append({
                    'username': row['username'],
                    'subscription': row['subscription'],
                    'created_at': row['created_at'],
                    'login_count': row['login_count'],
                    'total_visits': row['total_visits'],
                    'unique_communities': row['unique_communities_visited'],
                    'last_login': row['last_login'] or 'Never'
                })
            
            # Get community visit details for each user
            c.execute("""
                SELECT 
                    vh.username,
                    c.name as community_name,
                    COUNT(*) as visit_count
                FROM community_visit_history vh
                JOIN communities c ON vh.community_id = c.id
                GROUP BY vh.username, c.name
                ORDER BY vh.username, visit_count DESC
            """)
            
            user_community_visits = {}
            for row in c.fetchall():
                if row['username'] not in user_community_visits:
                    user_community_visits[row['username']] = []
                user_community_visits[row['username']].append({
                    'community': row['community_name'],
                    'visits': row['visit_count']
                })
            
            return jsonify({
                'success': True,
                'user_stats': user_stats,
                'community_visits': user_community_visits
            })
            
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"Error getting user statistics: {e}")
        logger.error(f"Traceback: {error_details}")
        return jsonify({'success': False, 'message': str(e), 'traceback': error_details}), 500
@app.route('/admin/ads_overview')
@login_required
def admin_ads_overview():
    """Admin page to view all ads performance across communities"""
    username = session.get('username')
    
    # Check if user is admin
    if username != 'admin':
        flash('Access denied. Admin only.', 'error')
        return redirect(url_for('public.index'))
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all communities with their parent relationships and ads
            c.execute("""
                SELECT 
                    c.id,
                    c.name,
                    c.type,
                    c.parent_community_id,
                    pc.name as parent_name,
                    COUNT(DISTINCT ua.id) as total_ads,
                    COALESCE(SUM(ua.impressions), 0) as total_impressions,
                    COALESCE(SUM(ua.clicks), 0) as total_clicks,
                    COALESCE(SUM(CASE WHEN ua.is_active = 1 THEN 1 ELSE 0 END), 0) as active_ads
                FROM communities c
                LEFT JOIN communities pc ON c.parent_community_id = pc.id
                LEFT JOIN university_ads ua ON c.id = ua.community_id
                WHERE c.type = 'University'
                GROUP BY c.id, c.name, c.type, c.parent_community_id, pc.name
                ORDER BY 
                    CASE WHEN c.parent_community_id IS NULL THEN 0 ELSE 1 END,
                    COALESCE(pc.name, c.name),
                    c.parent_community_id IS NULL DESC,
                    c.name
            """)
            
            # Organize communities by parent groups
            parent_groups = {}
            communities_data = []
            
            for row in c.fetchall():
                ctr = 0
                if row['total_impressions'] > 0:
                    ctr = round((row['total_clicks'] / row['total_impressions']) * 100, 2)
                
                community = {
                    'id': row['id'],
                    'name': row['name'],
                    'type': row['type'],
                    'parent_id': row['parent_community_id'],
                    'parent_name': row['parent_name'],
                    'total_ads': row['total_ads'],
                    'active_ads': row['active_ads'],
                    'impressions': row['total_impressions'],
                    'clicks': row['total_clicks'],
                    'ctr': ctr
                }
                communities_data.append(community)
                
                # Organize into parent groups
                if row['parent_community_id'] is None:
                    # This is a parent community
                    if row['name'] not in parent_groups:
                        parent_groups[row['name']] = {
                            'parent': community,
                            'children': []
                        }
                    else:
                        parent_groups[row['name']]['parent'] = community
                else:
                    # This is a child community
                    parent_name = row['parent_name']
                    if parent_name not in parent_groups:
                        parent_groups[parent_name] = {
                            'parent': None,
                            'children': []
                        }
                    parent_groups[parent_name]['children'].append(community)
            
            # Get detailed ads for each community
            c.execute("""
                SELECT 
                    ua.*,
                    c.name as community_name,
                    pc.name as parent_community_name
                FROM university_ads ua
                JOIN communities c ON ua.community_id = c.id
                LEFT JOIN communities pc ON c.parent_community_id = pc.id
                ORDER BY pc.name NULLS FIRST, c.name, ua.created_at DESC
            """)
            
            all_ads = []
            for row in c.fetchall():
                ad_ctr = 0
                if row['impressions'] and row['impressions'] > 0:
                    ad_ctr = round((row['clicks'] / row['impressions']) * 100, 2)
                
                all_ads.append({
                    'id': row['id'],
                    'community_id': row['community_id'],
                    'community_name': row['community_name'],
                    'parent_community_name': row['parent_community_name'],
                    'title': row['title'],
                    'description': row['description'],
                    'price': row['price'],
                    'image_url': row['image_url'],
                    'link_url': row['link_url'],
                    'is_active': row['is_active'],
                    'impressions': row['impressions'] or 0,
                    'clicks': row['clicks'] or 0,
                    'ctr': ad_ctr,
                    'created_at': row['created_at'],
                    'created_by': row['created_by']
                })
            
            # Calculate overall stats
            total_communities = len(communities_data)
            total_ads = sum(c['total_ads'] for c in communities_data)
            total_active = sum(c['active_ads'] for c in communities_data)
            total_impressions = sum(c['impressions'] for c in communities_data)
            total_clicks = sum(c['clicks'] for c in communities_data)
            overall_ctr = 0
            if total_impressions > 0:
                overall_ctr = round((total_clicks / total_impressions) * 100, 2)
            
            return render_template('admin_ads_overview.html',
                                 communities=communities_data,
                                 parent_groups=parent_groups,
                                 all_ads=all_ads,
                                 total_communities=total_communities,
                                 total_ads=total_ads,
                                 total_active=total_active,
                                 total_impressions=total_impressions,
                                 total_clicks=total_clicks,
                                 overall_ctr=overall_ctr)
                                 
    except Exception as e:
        logger.error(f"Error loading admin ads overview: {e}")
        flash('Error loading ads overview', 'error')
        return redirect(url_for('admin'))

@app.route('/get_calendar_events')
@login_required
def get_calendar_events():
    """Get calendar events visible to the current user (invited events only)"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get current user
            username = session.get('username')
            logger.info(f"get_calendar_events called for user: {username}")
            if not username:
                return jsonify({'success': True, 'events': []})
            
            # Get calendar events where user is invited or is the creator
            ph = get_sql_placeholder()
            query = f"""
                SELECT DISTINCT ce.id, ce.username, ce.title, ce.date, 
                       COALESCE(ce.end_date, ce.date) as end_date,
                       COALESCE(ce.start_time, ce.time) as start_time,
                       ce.end_time,
                       ce.time, ce.description, ce.created_at, ce.community_id, ce.timezone
                FROM calendar_events ce
                LEFT JOIN event_invitations ei ON ce.id = ei.event_id
                WHERE ce.username = {ph} OR ei.invited_username = {ph}
                ORDER BY ce.date ASC, COALESCE(ce.start_time, ce.time) ASC
            """
            logger.info(f"Executing calendar query for username: {username}")
            c.execute(query, (username, username))
            events_raw = c.fetchall()
            logger.info(f"Found {len(events_raw)} events for user {username}")
            
            events = []
            for event in events_raw:
                event_id = event['id']
                
                # Get RSVP counts for this event
                c.execute(f"""
                    SELECT response, COUNT(*) as count
                    FROM event_rsvps
                    WHERE event_id = {ph}
                    GROUP BY response
                """, (event_id,))
                
                rsvp_counts = {'going': 0, 'maybe': 0, 'not_going': 0}
                for row in c.fetchall():
                    rsvp_counts[row['response']] = row['count']
                # Calculate no_response: total invited members - total responded
                no_response = 0
                total_invited = 0
                try:
                    # Count total invited users
                    c.execute(f"SELECT COUNT(DISTINCT invited_username) as cnt FROM event_invitations WHERE event_id={ph}", (event_id,))
                    invited_row = c.fetchone()
                    if invited_row:
                        total_invited = invited_row['cnt'] if hasattr(invited_row, 'keys') else invited_row[0]
                    else:
                        total_invited = 0
                    
                    # Add 1 for the event creator (they're always invited)
                    total_invited += 1
                    
                    # Count users who responded
                    c.execute(f"SELECT COUNT(DISTINCT username) as cnt FROM event_rsvps WHERE event_id={ph}", (event_id,))
                    responded_row = c.fetchone()
                    if responded_row:
                        responded = responded_row['cnt'] if hasattr(responded_row, 'keys') else responded_row[0]
                    else:
                        responded = 0
                    
                    # no_response = total invited - total responded
                    no_response = max(0, total_invited - responded)
                except Exception as e:
                    logger.warning(f"Error calculating no_response for event {event_id}: {e}")
                    no_response = 0
                
                rsvp_counts['no_response'] = no_response
                rsvp_counts['total_invited'] = total_invited
                
                # Get current user's RSVP if logged in
                username = session.get('username')
                user_rsvp = None
                is_invited = False
                if username:
                    c.execute(f"""
                        SELECT response FROM event_rsvps
                        WHERE event_id = {ph} AND username = {ph}
                    """, (event_id, username))
                    result = c.fetchone()
                    if result:
                        user_rsvp = result['response']
                    
                    # Check if user is invited
                    c.execute(f"""
                        SELECT 1 FROM event_invitations
                        WHERE event_id = {ph} AND invited_username = {ph}
                    """, (event_id, username))
                    is_invited = c.fetchone() is not None
                
                # Extract time portion from datetime fields (YYYY-MM-DD HH:MM:SS -> HH:MM)
                def extract_time(dt_str):
                    if not dt_str or dt_str == '0000-00-00 00:00:00':
                        return None
                    try:
                        # If it's a datetime string, extract just the time portion
                        if ' ' in str(dt_str):
                            time_part = str(dt_str).split(' ')[1]  # Get HH:MM:SS
                            return time_part[:5]  # Return just HH:MM
                        return dt_str
                    except:
                        return dt_str
                
                events.append({
                    'id': event['id'],
                    'username': event['username'],
                    'title': event['title'],
                    'date': event['date'],
                    'end_date': event['end_date'],
                    'time': event['time'],  # Keep for backward compatibility
                    'start_time': extract_time(event['start_time']),
                    'end_time': extract_time(event['end_time']),
                    'timezone': event.get('timezone') if hasattr(event, 'get') else event.get('timezone', None) if hasattr(event, 'keys') else None,
                    'description': event['description'],
                    'created_at': event['created_at'],
                    'community_id': event['community_id'],
                    'rsvp_counts': rsvp_counts,
                    'user_rsvp': user_rsvp,
                    'total_rsvps': sum(rsvp_counts.values()),
                    'is_invited': is_invited,
                    'is_creator': event['username'] == username
                })
            
            logger.info(f"Returning {len(events)} events to frontend for user {username}")
            return jsonify({'success': True, 'events': events})
            
    except Exception as e:
        logger.error(f"Error getting calendar events: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/add_calendar_event', methods=['POST'])
@login_required
def add_calendar_event():
    """Add a new calendar event with invitations"""
    try:
        username = session['username']
        title = request.form.get('title', '').strip()
        date = request.form.get('date', '').strip()
        end_date = request.form.get('end_date', '').strip()
        start_time = request.form.get('start_time', '').strip()
        end_time = request.form.get('end_time', '').strip()
        timezone = request.form.get('timezone', '').strip()
        # Fall back to 'time' field for backward compatibility
        if not start_time:
            start_time = request.form.get('time', '').strip()
        description = request.form.get('description', '').strip()
        
        # Get community_id and invited members
        community_id = request.form.get('community_id', type=int)
        invited_members = request.form.getlist('invited_members[]')
        invite_all = request.form.get('invite_all') == 'true'
        
        # Debug logging
        logger.info(f"Creating event: title={title}, date={date}, start_time='{start_time}', end_time='{end_time}', timezone='{timezone}', community_id={community_id}")
        
        # Validate required fields
        if not title or not date:
            return jsonify({'success': False, 'message': 'Title and start date are required'})
        
        # Validate date format
        try:
            from datetime import datetime
            start_dt = datetime.strptime(date, '%Y-%m-%d')
        except ValueError:
            return jsonify({'success': False, 'message': 'Invalid start date format'})
        
        # Validate end date if provided
        if end_date:
            try:
                end_dt = datetime.strptime(end_date, '%Y-%m-%d')
                if end_dt < start_dt:
                    return jsonify({'success': False, 'message': 'End date cannot be before start date'})
            except ValueError:
                return jsonify({'success': False, 'message': 'Invalid end date format'})
        
        # Validate time formats if provided (before conversion)
        if start_time:
            try:
                datetime.strptime(start_time, '%H:%M')
            except ValueError:
                return jsonify({'success': False, 'message': 'Invalid start time format'})
        
        if end_time:
            try:
                datetime.strptime(end_time, '%H:%M')
            except ValueError:
                return jsonify({'success': False, 'message': 'Invalid end time format'})
        
        # Convert empty strings to None for proper NULL storage
        end_date = end_date if end_date else None
        description = description if description else None
        timezone = timezone if timezone else None
        notification_preferences = request.form.get('notification_preferences', 'all').strip()
        
        # Convert time (HH:MM) to datetime (YYYY-MM-DD HH:MM:00) for DATETIME columns
        start_time_original = start_time
        end_time_original = end_time
        
        if start_time:
            start_time = f"{date} {start_time}:00"
        else:
            start_time = None
            
        if end_time:
            # Use end_date if provided, otherwise use start date
            time_date = end_date if end_date else date
            end_time = f"{time_date} {end_time}:00"
        else:
            end_time = None
        
        # Validate end_time is after start_time if both provided
        if start_time and end_time and end_time < start_time:
            return jsonify({'success': False, 'message': 'End time cannot be before start time'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Insert the event (keeping 'time' field for backward compatibility)
            ph = get_sql_placeholder()
            created_at_utc = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
            logger.info(f"üìÖ Creating event (UTC): created_at={created_at_utc}, start_time='{start_time}', end_time='{end_time}', end_date={end_date}, timezone={timezone}, notifications={notification_preferences}")
            c.execute(f"""
                INSERT INTO calendar_events (username, title, date, end_date, time, start_time, end_time, description, created_at, community_id, timezone, notification_preferences)
                VALUES ({ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph})
            """, (username, title, date, end_date, 
                  start_time_original,  # Keep time field as HH:MM for backward compatibility
                  start_time,           # start_time as DATETIME
                  end_time,             # end_time as DATETIME
                  description,
                  created_at_utc,       # created_at in UTC
                  community_id,
                  timezone,
                  notification_preferences))
            
            event_id = c.lastrowid
            
            # Handle invitations
            if community_id:
                invited_users = []
                
                if invite_all:
                    # Get all members of the community
                    c.execute(f"""
                        SELECT DISTINCT u.username 
                        FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE uc.community_id = {ph} AND u.username != {ph}
                    """, (community_id, username))
                    invited_users = [row['username'] for row in c.fetchall()]
                else:
                    # Use selected members
                    invited_users = invited_members
                
                # Insert invitations and create notifications
                for invited_user in invited_users:
                    try:
                        c.execute(f"""
                            INSERT INTO event_invitations (event_id, invited_username, invited_by, invited_at)
                            VALUES ({ph}, {ph}, {ph}, {ph})
                        """, (event_id, invited_user, username, datetime.now().isoformat()))
                        
                        # Create notification for the invited user
                        notification_message = f"{username} invited you to the event: {title}"
                        notification_link = f"/event/{event_id}"
                        
                        c.execute(f"""
                            INSERT INTO notifications (user_id, from_user, message, created_at, is_read, link, type, community_id)
                            VALUES ({ph}, {ph}, {ph}, {ph}, 0, {ph}, 'event_invitation', {ph})
                        """, (invited_user, username, notification_message, datetime.now().isoformat(), notification_link, community_id))
                        
                    except Exception as inv_err:
                        # Skip if already invited or other error
                        logger.warning(f"Failed to invite {invited_user}: {inv_err}")
                        pass
            
            conn.commit()
            
            return jsonify({
                'success': True, 
                'message': f'Event added successfully. {len(invited_users) if community_id else 0} members invited.',
                'event_id': event_id
            })
            
    except Exception as e:
        logger.error(f"Error adding calendar event: {str(e)}")
        return jsonify({'success': False, 'message': str(e)})

@app.route('/get_links')
@login_required
def get_links():
    """Get all links for a community or main feed"""
    try:
        username = session['username']
        community_id = request.args.get('community_id')
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            if community_id:
                # Get links for specific community
                c.execute("""
                    SELECT id, username, url, description, created_at
                    FROM useful_links
                    WHERE community_id = ?
                    ORDER BY created_at DESC
                """, (community_id,))
            else:
                # Get links for main feed (community_id is NULL)
                c.execute("""
                    SELECT id, username, url, description, created_at
                    FROM useful_links
                    WHERE community_id IS NULL
                    ORDER BY created_at DESC
                """)
            
            links_raw = c.fetchall()
            links = []
            
            for link in links_raw:
                links.append({
                    'id': link['id'],
                    'username': link['username'],
                    'url': link['url'],
                    'description': link['description'],
                    'created_at': link['created_at'],
                    'can_delete': link['username'] == username or username == 'admin'
                })
            
            # Also return docs (PDFs)
            docs = []
            try:
                if community_id:
                    c.execute("""
                        SELECT id, username, file_path, description, created_at
                        FROM useful_docs
                        WHERE community_id = ?
                        ORDER BY created_at DESC
                    """, (community_id,))
                else:
                    c.execute("""
                        SELECT id, username, file_path, description, created_at
                        FROM useful_docs
                        WHERE community_id IS NULL
                        ORDER BY created_at DESC
                    """)
                for d in c.fetchall() or []:
                    docs.append({
                        'id': d['id'] if hasattr(d,'keys') else d[0],
                        'username': d['username'] if hasattr(d,'keys') else d[1],
                        'file_path': d['file_path'] if hasattr(d,'keys') else d[2],
                        'description': d['description'] if hasattr(d,'keys') else d[3],
                        'created_at': d['created_at'] if hasattr(d,'keys') else d[4]
                    })
            except Exception as de:
                logger.warning(f"get_docs error: {de}")
            return jsonify({'success': True, 'links': links, 'docs': docs})
            
    except Exception as e:
        logger.error(f"Error getting links: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/add_link', methods=['POST'])
@login_required
def add_link():
    """Add a new useful link"""
    try:
        username = session['username']
        url = request.form.get('url', '').strip()
        description = request.form.get('description', '').strip()
        community_id = request.form.get('community_id')
        
        if not url or not description:
            return jsonify({'success': False, 'message': 'URL and description are required'})
        
        # Basic URL validation
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            c.execute("""
                INSERT INTO useful_links (community_id, username, url, description, created_at)
                VALUES (?, ?, ?, ?, ?)
            """, (community_id if community_id else None, username, url, description, 
                  datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Link added successfully'})
            
    except Exception as e:
        logger.error(f"Error adding link: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/upload_doc', methods=['POST'])
@login_required
def upload_doc():
    """Upload a PDF document for Useful Links & Docs"""
    try:
        username = session['username']
        community_id = request.form.get('community_id')
        description = (request.form.get('description') or '').strip()
        if 'file' not in request.files:
            return jsonify({'success': False, 'error': 'No file provided'})
        f = request.files['file']
        if not f or f.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'})
        # Only PDFs by extension
        from werkzeug.utils import secure_filename
        orig = secure_filename(f.filename)
        ext = orig.rsplit('.', 1)[-1].lower() if '.' in orig else ''
        if ext != 'pdf':
            return jsonify({'success': False, 'error': 'Only PDF files are allowed'})
        safe_name = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{username}.pdf"
        base_dir = os.path.dirname(os.path.abspath(__file__))
        upload_dir = os.path.join(base_dir, 'uploads', 'docs')
        os.makedirs(upload_dir, exist_ok=True)
        file_path = os.path.join(upload_dir, safe_name)
        try:
            f.save(file_path)
        except Exception as se:
            logger.error(f"upload save error: {se}")
            return jsonify({'success': False, 'error': 'Could not save file on server'})
        rel_path = f"docs/{safe_name}"
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                INSERT INTO useful_docs (community_id, username, file_path, description, created_at)
                VALUES (?, ?, ?, ?, ?)
            """, (community_id if community_id else None, username, rel_path, description, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
            conn.commit()
        return jsonify({'success': True, 'message': 'Document uploaded', 'path': f"/uploads/{rel_path}"})
    except Exception as e:
        logger.error(f"upload_doc error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/delete_doc', methods=['POST'])
@login_required
def delete_doc():
    """Delete a previously uploaded PDF document"""
    try:
        username = session.get('username')
        doc_id = request.form.get('doc_id')
        if not doc_id:
            return jsonify({'success': False, 'error': 'doc_id required'})
        with get_db_connection() as conn:
            c = conn.cursor()
            # Fetch doc owner and path
            c.execute("SELECT username, file_path FROM useful_docs WHERE id = ?", (doc_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Document not found'})
            owner = row['username'] if hasattr(row, 'keys') else row[0]
            path = row['file_path'] if hasattr(row, 'keys') else row[1]
            if username != owner and username != 'admin':
                return jsonify({'success': False, 'error': 'Forbidden'})
            # Delete DB row
            c.execute("DELETE FROM useful_docs WHERE id = ?", (doc_id,))
            conn.commit()
        # Attempt to delete file on disk
        try:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            disk_path = os.path.join(base_dir, 'uploads', path)
            if os.path.exists(disk_path):
                os.remove(disk_path)
        except Exception as fe:
            logger.warning(f"Could not remove doc file {path}: {fe}")
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"Error deleting doc: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Docs served by web server static mapping (/uploads/docs -> uploads/docs)

@app.route('/delete_link', methods=['POST'])
@login_required
def delete_link():
    """Delete a useful link"""
    try:
        username = session['username']
        link_id = request.form.get('link_id')
        
        if not link_id:
            return jsonify({'success': False, 'message': 'Link ID is required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user can delete (owner or admin)
            c.execute("SELECT username FROM useful_links WHERE id = ?", (link_id,))
            link = c.fetchone()
            
            if not link:
                return jsonify({'success': False, 'message': 'Link not found'})
            
            if link['username'] != username and username != 'admin':
                return jsonify({'success': False, 'message': 'You can only delete your own links'})
            
            # Delete the link
            c.execute("DELETE FROM useful_links WHERE id = ?", (link_id,))
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Link deleted successfully'})
            
    except Exception as e:
        logger.error(f"Error deleting link: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/edit_calendar_event', methods=['POST'])
@login_required
def edit_calendar_event():
    """Edit a calendar event"""
    try:
        username = session.get('username')
        if not username:
            return jsonify({'success': False, 'message': 'User not logged in'})
        
        # Get event details from form
        event_id = request.form.get('event_id')
        title = request.form.get('title', '').strip()
        date = request.form.get('date', '').strip()
        end_date = request.form.get('end_date', '').strip()
        start_time = request.form.get('start_time', '').strip()
        end_time = request.form.get('end_time', '').strip()
        timezone = request.form.get('timezone', '').strip()
        description = request.form.get('description', '').strip()
        
        if not all([event_id, title, date]):
            return jsonify({'success': False, 'message': 'Event ID, title, and date are required'})
        
        # Convert empty strings to None
        end_date = end_date if end_date else None
        description = description if description else None
        timezone = timezone if timezone else None
        
        # Convert time (HH:MM) to datetime (YYYY-MM-DD HH:MM:00) for DATETIME columns
        start_time_original = start_time
        if start_time:
            start_time = f"{date} {start_time}:00"
        else:
            start_time = None
            
        if end_time:
            time_date = end_date if end_date else date
            end_time = f"{time_date} {end_time}:00"
        else:
            end_time = None
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get event details and community info
            ph = get_sql_placeholder()
            c.execute(f"""
                SELECT e.username, e.community_id, c.creator_username
                FROM calendar_events e
                LEFT JOIN communities c ON e.community_id = c.id
                WHERE e.id = {ph}
            """, (event_id,))
            event = c.fetchone()
            
            if not event:
                return jsonify({'success': False, 'message': 'Event not found'})
            
            event_owner = event['username']
            community_id = event['community_id']
            community_owner = event['creator_username'] if event['creator_username'] else None
            
            # Check if user is community admin
            is_community_admin = False
            if community_id:
                c.execute(f"SELECT 1 FROM community_admins WHERE community_id = {ph} AND username = {ph}",
                         (community_id, username))
                is_community_admin = c.fetchone() is not None
            
            # Check permissions: user can edit if they're the event owner, app admin, community owner, or community admin
            can_edit = (
                event_owner == username or 
                username == 'admin' or 
                (community_owner and username == community_owner) or
                is_community_admin
            )
            
            if not can_edit:
                return jsonify({'success': False, 'message': 'You do not have permission to edit this event'})
            
            # Update the event
            c.execute(f"""
                UPDATE calendar_events 
                SET title = {ph}, date = {ph}, end_date = {ph}, start_time = {ph}, end_time = {ph}, 
                    time = {ph}, description = {ph}, timezone = {ph}
                WHERE id = {ph}
            """, (title, date, end_date, 
                  start_time, end_time,
                  start_time_original,  # Keep time field for compatibility
                  description, timezone, event_id))
            
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Event updated successfully'})
            
    except Exception as e:
        logger.error(f"Error editing calendar event: {str(e)}")
        return jsonify({'success': False, 'message': str(e)})

@app.route('/get_calendar_event/<int:event_id>')
@login_required
def get_calendar_event(event_id):
    """Get details of a specific calendar event with RSVP data"""
    try:
        username = session.get('username')
        
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            
            # Get event details with community name
            c.execute(f"""
                SELECT e.*, c.creator_username, c.name as community_name
                FROM calendar_events e
                LEFT JOIN communities c ON e.community_id = c.id
                WHERE e.id = {ph}
            """, (event_id,))
            
            event = c.fetchone()
            
            if not event:
                return jsonify({'success': False, 'message': 'Event not found'})
            
            # Get RSVP counts
            c.execute(f"""
                SELECT response, COUNT(*) as count
                FROM event_rsvps
                WHERE event_id = {ph}
                GROUP BY response
            """, (event_id,))
            
            rsvp_counts = {'going': 0, 'maybe': 0, 'not_going': 0}
            for row in c.fetchall():
                rsvp_counts[row['response']] = row['count']
            
            # Calculate no_response
            c.execute(f"SELECT COUNT(DISTINCT invited_username) as cnt FROM event_invitations WHERE event_id={ph}", (event_id,))
            invited_row = c.fetchone()
            if invited_row:
                total_invited = (invited_row['cnt'] if hasattr(invited_row, 'keys') else invited_row[0]) + 1  # +1 for creator
            else:
                total_invited = 1  # Just the creator
            
            c.execute(f"SELECT COUNT(DISTINCT username) as cnt FROM event_rsvps WHERE event_id={ph}", (event_id,))
            responded_row = c.fetchone()
            if responded_row:
                responded = responded_row['cnt'] if hasattr(responded_row, 'keys') else responded_row[0]
            else:
                responded = 0
            rsvp_counts['no_response'] = max(0, total_invited - responded)
            
            # Get current user's RSVP
            c.execute(f"""
                SELECT response FROM event_rsvps
                WHERE event_id = {ph} AND username = {ph}
            """, (event_id, username))
            user_rsvp_row = c.fetchone()
            user_rsvp = user_rsvp_row['response'] if user_rsvp_row else None
            
            # Check if user is community admin
            is_community_admin = False
            if event['community_id']:
                c.execute(f"SELECT 1 FROM community_admins WHERE community_id = {ph} AND username = {ph}",
                         (event['community_id'], username))
                is_community_admin = c.fetchone() is not None
            
            # Check if user can edit
            can_edit = (
                event['username'] == username or 
                username == 'admin' or 
                (event['creator_username'] and username == event['creator_username']) or
                is_community_admin
            )
            
            # Extract time portion from datetime
            def extract_time(dt_str):
                if not dt_str or dt_str == '0000-00-00 00:00:00':
                    return None
                try:
                    if ' ' in str(dt_str):
                        return str(dt_str).split(' ')[1][:5]  # HH:MM
                    return dt_str
                except:
                    return dt_str
            
            return jsonify({
                'success': True,
                'event': {
                    'id': event['id'],
                    'title': event['title'],
                    'date': event['date'],
                    'end_date': event['end_date'],
                    'start_time': extract_time(event['start_time']),
                    'end_time': extract_time(event['end_time']),
                    'timezone': event.get('timezone') if hasattr(event, 'get') else event.get('timezone', None) if hasattr(event, 'keys') else None,
                    'description': event['description'],
                    'username': event['username'],
                    'community_id': event['community_id'],
                    'community_name': event['community_name'],
                    'user_rsvp': user_rsvp,
                    'rsvp_counts': rsvp_counts,
                    'can_edit': can_edit
                }
            })
            
    except Exception as e:
        logger.error(f"Error getting calendar event: {str(e)}")
        return jsonify({'success': False, 'message': str(e)})
@app.route('/test_color_detection')
def test_color_detection():
    """Test page for color detection"""
    return '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Color Detection Test</title>
        <style>
            body { font-family: Arial; padding: 20px; background: #f0f0f0; }
            .container { max-width: 800px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }
            input { width: 100%; padding: 10px; margin: 10px 0; }
            button { padding: 10px 20px; background: #4CAF50; color: white; border: none; cursor: pointer; }
            #result { margin-top: 20px; padding: 20px; background: #f9f9f9; border-radius: 4px; }
            #preview { max-width: 300px; margin: 20px 0; }
            #colorBox { width: 100px; height: 100px; border: 2px solid #333; margin: 10px 0; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>Image Color Detection Test</h1>
            <input type="text" id="imageUrl" placeholder="Enter image URL" value="">
            <button onclick="testColor()">Test Color Detection</button>
            <div id="result"></div>
            <img id="preview" style="display:none;">
            <div id="colorBox" style="display:none;"></div>
        </div>
        <script>
            function testColor() {
                const url = document.getElementById('imageUrl').value;
                if (!url) {
                    alert('Please enter an image URL');
                    return;
                }
                
                // Show preview
                const preview = document.getElementById('preview');
                preview.src = url;
                preview.style.display = 'block';
                
                // Fetch color
                fetch(`/get_image_color?url=${encodeURIComponent(url)}`)
                    .then(response => response.json())
                    .then(data => {
                        console.log('Full response:', data);
                        
                        let html = '<h3>Detection Results:</h3>';
                        if (data.success) {
                            const color = data.color;
                            const rgbStr = `rgb(${color.r}, ${color.g}, ${color.b})`;
                            
                            html += `<p><strong>Detected Background Color:</strong> ${rgbStr}</p>`;
                            
                            // Show color box
                            const colorBox = document.getElementById('colorBox');
                            colorBox.style.backgroundColor = rgbStr;
                            colorBox.style.display = 'block';
                            
                            if (data.debug) {
                                html += '<h4>Debug Info:</h4>';
                                html += `<p><strong>Corner Colors:</strong><br>${data.debug.corner_colors.join('<br>')}</p>`;
                                html += `<p><strong>Top Colors Overall:</strong><br>${data.debug.top_colors.join('<br>')}</p>`;
                            }
                        } else {
                            html += '<p>Color detection failed</p>';
                        }
                        
                        document.getElementById('result').innerHTML = html;
                    })
                    .catch(error => {
                        document.getElementById('result').innerHTML = `<p>Error: ${error}</p>`;
                    });
            }
        </script>
    </body>
    </html>
    '''
@app.route('/get_image_color')
def get_image_color():
    """Extract background color from an image URL using simple border detection"""
    try:
        import requests
        from PIL import Image
        from io import BytesIO
        from collections import Counter
        
        image_url = request.args.get('url')
        if not image_url:
            return jsonify({'success': False, 'message': 'No URL provided'})
        
        try:
            # Download the image
            response = requests.get(image_url, timeout=10)
            response.raise_for_status()
            
            # Open image and convert to RGB
            img = Image.open(BytesIO(response.content)).convert('RGB')
            
            # Get dimensions
            width, height = img.size
            
            # Collect border pixels
            border_pixels = []
            
            # Top border
            for x in range(width):
                border_pixels.append(img.getpixel((x, 0)))
            
            # Bottom border
            for x in range(width):
                border_pixels.append(img.getpixel((x, height - 1)))
            
            # Left border (excluding corners to avoid double counting)
            for y in range(1, height - 1):
                border_pixels.append(img.getpixel((0, y)))
            
            # Right border (excluding corners to avoid double counting)
            for y in range(1, height - 1):
                border_pixels.append(img.getpixel((width - 1, y)))
            
            # Find the most common color in the borders
            color_counts = Counter(border_pixels)
            most_common_color = color_counts.most_common(1)[0][0]
            
            # Get top 5 colors for debugging
            top_colors = color_counts.most_common(5)
            total_border_pixels = len(border_pixels)
            
            # Log for debugging
            logger.info(f"Image URL: {image_url}")
            logger.info(f"Image size: {width}x{height}")
            logger.info(f"Background color (most common border): RGB{most_common_color}")
            logger.info(f"Top 5 border colors: {[(color, count) for color, count in top_colors]}")
            
            return jsonify({
                'success': True,
                'color': {
                    'r': most_common_color[0],
                    'g': most_common_color[1],
                    'b': most_common_color[2]
                },
                'debug': {
                    'url': image_url,
                    'detected': f"rgb({most_common_color[0]}, {most_common_color[1]}, {most_common_color[2]})",
                    'image_size': f"{width}x{height}",
                    'border_pixels_analyzed': total_border_pixels,
                    'top_border_colors': [
                        f"rgb{color} ({count} pixels, {(count/total_border_pixels)*100:.1f}%)" 
                        for color, count in top_colors
                    ],
                    'method': 'Simple border pixel detection'
                }
            })
            
        except Exception as e:
            logger.error(f"Error processing image: {str(e)}")
            # Return white as fallback
            return jsonify({
                'success': True,
                'color': {'r': 255, 'g': 255, 'b': 255}
            })
            
    except Exception as e:
        logger.error(f"Error in get_image_color: {str(e)}")
        return jsonify({
            'success': True,
            'color': {'r': 255, 'g': 255, 'b': 255}
        })

@app.route('/get_event_rsvp_details')
@login_required
def get_event_rsvp_details():
    """Get detailed RSVP information including non-responders"""
    try:
        event_id = request.args.get('event_id', type=int)
        if not event_id:
            return jsonify({'success': False, 'message': 'Event ID required'}), 400
            
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all RSVPs for the event
            c.execute("""
                SELECT r.username, r.response, u.username as display_name
                FROM event_rsvps r
                JOIN users u ON r.username = u.username
                WHERE r.event_id = ?
                ORDER BY r.response, u.username
            """, (event_id,))
            
            rsvps = c.fetchall()
            
            # Get event creator
            c.execute("SELECT username FROM calendar_events WHERE id = ?", (event_id,))
            event_row = c.fetchone()
            event_creator = event_row['username'] if event_row else None
            
            # Get all invited users
            c.execute("""
                SELECT i.invited_username, u.username as display_name
                FROM event_invitations i
                JOIN users u ON i.invited_username = u.username
                WHERE i.event_id = ?
                ORDER BY u.username
            """, (event_id,))
            
            invited_users = c.fetchall()
            
            # Add event creator to invited users if not already in the list
            if event_creator:
                invited_usernames = [u['invited_username'] for u in invited_users]
                if event_creator not in invited_usernames:
                    invited_users = list(invited_users) + [{'invited_username': event_creator, 'display_name': event_creator}]
            
            # Organize attendees by response
            attendees = {
                'going': [],
                'maybe': [],
                'not_going': [],
                'no_response': []
            }
            
            # Track who has responded
            responded_users = set()
            
            # Categorize RSVPs
            for rsvp in rsvps:
                user_info = {
                    'username': rsvp['display_name'] or rsvp['username']
                }
                attendees[rsvp['response']].append(user_info)
                responded_users.add(rsvp['username'])
            
            # Find non-responders from invited users
            for invitation in invited_users:
                if invitation['invited_username'] not in responded_users:
                    attendees['no_response'].append({
                        'username': invitation['display_name'] or invitation['invited_username']
                    })
            
            # If no specific invitations, check if it was an "invite all" event
            if not invited_users:
                c.execute("""
                    SELECT e.*, c.id as community_id
                    FROM calendar_events e
                    LEFT JOIN communities c ON e.community_id = c.id
                    WHERE e.id = ?
                """, (event_id,))
                
                event = c.fetchone()
                
                # If it's a community event, get all community members who haven't responded
                if event and event['community_id']:
                    c.execute("""
                        SELECT u.username
                        FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE uc.community_id = ?
                        AND u.username NOT IN (
                            SELECT username FROM event_rsvps WHERE event_id = ?
                        )
                        ORDER BY u.username
                    """, (event['community_id'], event_id))
                    
                    non_responders = c.fetchall()
                    for user in non_responders:
                        attendees['no_response'].append({
                            'username': user['username']
                        })
            
            return jsonify({
                'success': True,
                'attendees': attendees,
                'total_invited': len(invited_users) if invited_users else len(attendees['no_response']) + len(responded_users),
                'total_responded': len(responded_users)
            })
            
    except Exception as e:
        logger.error(f"Error getting RSVP details: {str(e)}")
        return jsonify({'success': False, 'message': str(e)}), 500
@app.route('/delete_calendar_event', methods=['POST'])
@login_required
def delete_calendar_event():
    """Delete a calendar event"""
    try:
        username = session.get('username')
        if not username:
            return jsonify({'success': False, 'message': 'User not logged in'})
            
        event_id = request.form.get('event_id', type=int)
        
        logger.info(f"Delete request from {username} for event ID: {event_id}")
        
        if not event_id:
            return jsonify({'success': False, 'message': 'Event ID is required'})
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get event details and community info
            c.execute("""
                SELECT e.username, e.community_id, c.creator_username
                FROM calendar_events e
                LEFT JOIN communities c ON e.community_id = c.id
                WHERE e.id = ?
            """, (event_id,))
            event = c.fetchone()
            
            if not event:
                logger.warning(f"Event {event_id} not found")
                return jsonify({'success': False, 'message': 'Event not found'})
            
            event_owner = event['username']
            community_id = event['community_id']
            community_owner = event['creator_username'] if event['creator_username'] else None
            
            # Check if user is community admin
            is_community_admin = False
            if community_id:
                c.execute("SELECT 1 FROM community_admins WHERE community_id = ? AND username = ?",
                         (community_id, username))
                is_community_admin = c.fetchone() is not None
            
            # Check permissions: user can delete if they're the event owner, app admin, community owner, or community admin
            can_delete = (
                event_owner == username or 
                username == 'admin' or 
                (community_owner and username == community_owner) or
                is_community_admin
            )
            
            if not can_delete:
                logger.warning(f"User {username} tried to delete event owned by {event_owner}")
                return jsonify({'success': False, 'message': 'You do not have permission to delete this event'})
            
            # Delete the event
            c.execute("DELETE FROM calendar_events WHERE id = ?", (event_id,))
            deleted_count = c.rowcount
            conn.commit()
            
            if deleted_count > 0:
                logger.info(f"Successfully deleted event {event_id}")
                return jsonify({'success': True, 'message': 'Event deleted successfully'})
            else:
                return jsonify({'success': False, 'message': 'Event could not be deleted'})
            
    except Exception as e:
        logger.error(f"Error deleting calendar event: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'message': f'Server error: {str(e)}'})

@app.route('/delete_post', methods=['POST'])
@login_required
def delete_post():
    username = session['username']
    # Temporarily disable CSRF validation
    # if not validate_csrf():
    #     return jsonify({'success': False, 'error': 'Invalid CSRF token'}), 400
    post_id = request.form.get('post_id', type=int)
    logger.debug(f"Received delete post request for {username} with post_id: {post_id}")
    if not post_id:
        return jsonify({'success': False, 'error': 'Post ID is required!'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT username, image_path, video_path, community_id FROM posts WHERE id= ?", (post_id,))
            post = c.fetchone()
            if not post or (post['username'] != username and username != 'admin'):
                return jsonify({'success': False, 'error': 'Post not found or unauthorized!'}), 403
            
            # Get community_id for cache invalidation before deleting
            post_community_id = post['community_id'] if post else None
            
            # Cancel any pending imagine jobs for this post
            try:
                ph = get_sql_placeholder()
                c.execute(f"""
                    UPDATE imagine_jobs 
                    SET status = {ph}
                    WHERE target_type = {ph} AND target_id = {ph} AND status IN ({ph}, {ph})
                """, (IMAGINE_STATUS_ERROR, 'post', post_id, IMAGINE_STATUS_PENDING, IMAGINE_STATUS_PROCESSING))
                conn.commit()
            except Exception as e:
                logger.warning(f"Could not cancel imagine jobs for post {post_id}: {e}")
            
            # Delete image file if it exists
            if post['image_path']:
                try:
                    image_file_path = os.path.join('static', post['image_path'])
                    if os.path.exists(image_file_path):
                        os.remove(image_file_path)
                except Exception as e:
                    logger.warning(f"Could not delete image file {post['image_path']}: {e}")
            # Delete video file if it exists (skip if pending)
            video_path_val = None
            try:
                video_path_val = post['video_path']
            except Exception:
                try:
                    video_path_val = post[2]
                except Exception:
                    video_path_val = None
            if video_path_val and video_path_val != 'pending':
                try:
                    video_file_path = os.path.join('static', video_path_val)
                    if os.path.exists(video_file_path):
                        os.remove(video_file_path)
                except Exception as e:
                    logger.warning(f"Could not delete video file {video_path_val}: {e}")
            
            c.execute("DELETE FROM replies WHERE post_id= ?", (post_id,))
            c.execute("DELETE FROM post_views WHERE post_id = ?", (post_id,))
            c.execute("DELETE FROM posts WHERE id= ?", (post_id,))
            conn.commit()
        
        # Invalidate community feed cache so deleted post disappears immediately
        if post_community_id:
            try:
                invalidate_community_cache(post_community_id)
                logger.info(f"Invalidated cache for community {post_community_id} after post deletion")
            except Exception as cache_err:
                logger.warning(f"Failed to invalidate cache after delete for community {post_community_id}: {cache_err}")
        
        logger.info(f"Post {post_id} deleted successfully by {username}")
        return jsonify({'success': True, 'message': 'Post deleted!'}), 200
    except Exception as e:
        logger.error(f"Error deleting post {post_id} for {username}: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500

@app.route('/edit_post', methods=['POST'])
@login_required
def edit_post():
    """Edit a post's content and/or media (owner or admin)."""
    username = session['username']
    post_id = request.form.get('post_id', type=int)
    new_content = (request.form.get('content') or '').strip()
    remove_media = request.form.get('remove_media') == 'true'
    
    if not post_id:
        return jsonify({'success': False, 'error': 'Post ID is required!'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT username, community_id, image_path, video_path FROM posts WHERE id = ?", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found!'}), 404
            owner = row['username'] if hasattr(row, 'keys') else row[0]
            post_community_id = row['community_id'] if hasattr(row, 'keys') else row[1]
            old_image_path = row['image_path'] if hasattr(row, 'keys') else row[2]
            old_video_path = row['video_path'] if hasattr(row, 'keys') else row[3]
            
            if owner != username and username != 'admin':
                return jsonify({'success': False, 'error': 'Unauthorized!'}), 403
            
            # Handle new media upload
            new_image_path = None
            new_video_path = None
            media_file = request.files.get('media')
            
            if media_file and media_file.filename:
                filename = secure_filename(media_file.filename)
                ext = os.path.splitext(filename)[1].lower()
                unique_filename = f"{uuid.uuid4().hex}{ext}"
                save_path = os.path.join(UPLOAD_FOLDER, unique_filename)
                media_file.save(save_path)
                
                if ext in ['.jpg', '.jpeg', '.png', '.gif', '.webp']:
                    new_image_path = unique_filename
                elif ext in ['.mp4', '.webm', '.mov', '.m4v', '.avi']:
                    new_video_path = unique_filename
            
            # Build update query
            updates = []
            params = []
            
            if new_content:
                updates.append("content = ?")
                params.append(new_content)
            
            if new_image_path:
                updates.append("image_path = ?")
                updates.append("video_path = NULL")
                params.append(new_image_path)
            elif new_video_path:
                updates.append("video_path = ?")
                updates.append("image_path = NULL")
                params.append(new_video_path)
            elif remove_media:
                updates.append("image_path = NULL")
                updates.append("video_path = NULL")
            
            if updates:
                params.append(post_id)
                c.execute(f"UPDATE posts SET {', '.join(updates)} WHERE id = ?", params)
                conn.commit()
        
        # Invalidate community feed cache
        if post_community_id:
            try:
                invalidate_community_cache(post_community_id)
            except Exception as cache_err:
                logger.warning(f"Failed to invalidate cache after edit for community {post_community_id}: {cache_err}")
        
        return jsonify({'success': True, 'image_path': new_image_path, 'video_path': new_video_path})
    except Exception as e:
        logger.error(f"Error editing post {post_id} by {username}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/update_audio_summary', methods=['POST'])
@login_required
def update_audio_summary():
    """Update the AI summary for an audio post (post owner or admin only)."""
    username = session['username']
    data = request.get_json()
    post_id = data.get('post_id')
    new_summary = (data.get('summary') or '').strip()
    
    if not post_id:
        return jsonify({'success': False, 'error': 'Post ID is required'}), 400
    
    if not new_summary:
        return jsonify({'success': False, 'error': 'Summary cannot be empty'}), 400
    
    try:
        conn = get_db_connection()
        c = conn.cursor()
        
        # Check if user owns the post or is admin
        c.execute("SELECT username FROM posts WHERE id = ?", (post_id,))
        row = c.fetchone()
        
        if not row:
            return jsonify({'success': False, 'error': 'Post not found'}), 404
        
        post_owner = row[0] if isinstance(row, tuple) else row['username']
        
        # Check if user is admin or post owner
        if post_owner != username and username != 'admin':
            return jsonify({'success': False, 'error': 'Not authorized to edit this summary'}), 403
        
        # Update the audio summary
        c.execute("UPDATE posts SET audio_summary = ? WHERE id = ?", (new_summary, post_id))
        conn.commit()
        
        logger.info(f"User {username} updated audio summary for post {post_id}")
        return jsonify({'success': True, 'summary': new_summary})
        
    except Exception as e:
        logger.error(f"Error updating audio summary: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
    finally:
        if conn:
            conn.close()

@app.route('/translate_summary', methods=['POST'])
@login_required
def translate_summary():
    """Translate an AI summary to a target language."""
    data = request.get_json()
    summary = (data.get('summary') or '').strip()
    target_language = (data.get('target_language') or '').strip()
    
    if not summary:
        return jsonify({'success': False, 'error': 'Summary is required'}), 400
    
    if not target_language:
        return jsonify({'success': False, 'error': 'Target language is required'}), 400
    
    # Language mapping
    language_map = {
        'pt': 'European Portuguese (Portugal)',
        'en': 'English',
        'fr': 'French',
        'de': 'German',
        'es': 'Spanish',
        'it': 'Italian',
        'zh': 'Mandarin Chinese (Simplified)'
    }
    
    target_lang_name = language_map.get(target_language)
    if not target_lang_name:
        return jsonify({'success': False, 'error': 'Invalid target language'}), 400
    
    if not OPENAI_AVAILABLE:
        return jsonify({'success': False, 'error': 'Translation service not available'}), 503
    
    if not OPENAI_API_KEY:
        return jsonify({'success': False, 'error': 'Translation service not configured'}), 503
    
    try:
        logger.info(f"Translating summary to {target_lang_name}")
        client = OpenAI(api_key=OPENAI_API_KEY)
        
        system_prompt = f"""You are a professional translator. Translate the given text to {target_lang_name}.
Rules:
- Maintain the meaning and tone of the original text
- Keep the same level of formality
- If translating to European Portuguese, use Portugal vocabulary and grammar, NOT Brazilian Portuguese
- Keep proper names unchanged
- Preserve any technical terms that don't need translation"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": f"Translate this to {target_lang_name}:\n\n{summary}"
                }
            ],
            max_tokens=200,
            temperature=0.3
        )
        
        translated = response.choices[0].message.content.strip()
        logger.info(f"Translation successful: {translated[:50]}...")
        
        return jsonify({
            'success': True,
            'translated_summary': translated,
            'target_language': target_language
        })
        
    except Exception as e:
        logger.error(f"Error translating summary: {str(e)}")
        return jsonify({'success': False, 'error': 'Translation failed'}), 500

@app.route('/admin/communities_list')
@login_required
def admin_communities_list():
    """Return communities for admin modal as JSON."""
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    try:
        out = []
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                c.execute(
                    """
                    SELECT c.id, c.name, c.type, c.creator_username,
                           COUNT(uc.user_id) as member_count, c.is_active
                    FROM communities c
                    LEFT JOIN user_communities uc ON c.id = uc.community_id
                    GROUP BY c.id, c.name, c.type, c.creator_username, c.is_active
                    ORDER BY c.name
                    """
                )
            except Exception:
                c.execute(
                    """
                    SELECT c.id, c.name, c.type, c.creator_username,
                           COUNT(uc.user_id) as member_count
                    FROM communities c
                    LEFT JOIN user_communities uc ON c.id = uc.community_id
                    GROUP BY c.id, c.name, c.type, c.creator_username
                    ORDER BY c.name
                    """
                )
            for r in c.fetchall() or []:
                out.append({
                    'id': r['id'] if hasattr(r,'keys') else r[0],
                    'name': r['name'] if hasattr(r,'keys') else r[1],
                    'type': r['type'] if hasattr(r,'keys') else r[2],
                    'creator_username': r['creator_username'] if hasattr(r,'keys') else r[3],
                    'member_count': (r['member_count'] if hasattr(r,'keys') else (r[4] if len(r) > 4 else 0)),
                    'is_active': (r['is_active'] if hasattr(r,'keys') and 'is_active' in r.keys() else (r[5] if (isinstance(r, (list,tuple)) and len(r) > 5) else 1)) in (1,'1',True)
                })
        return jsonify({'success': True, 'communities': out})
    except Exception as e:
        logger.error(f"admin_communities_list error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# === Welcome cards API ===
@app.route('/welcome_cards')
def welcome_cards():
    try:
        cards = []
        defaults = [
            'welcome/default-1.jpg',
            'welcome/default-2.jpg',
            'welcome/default-3.jpg',
        ]
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                c.execute("SELECT value FROM site_settings WHERE `key`='welcome_card_1'")
                r1 = c.fetchone()
            except Exception:
                r1 = None
            try:
                c.execute("SELECT value FROM site_settings WHERE `key`='welcome_card_2'")
                r2 = c.fetchone()
            except Exception:
                r2 = None
            try:
                c.execute("SELECT value FROM site_settings WHERE `key`='welcome_card_3'")
                r3 = c.fetchone()
            except Exception:
                r3 = None
        vals = [
            (get_scalar_result(r1, column_name='value') if r1 else None),
            (get_scalar_result(r2, column_name='value') if r2 else None),
            (get_scalar_result(r3, column_name='value') if r3 else None),
        ]
        for idx, val in enumerate(vals):
            rel = val if val else defaults[idx]
            path = os.path.join('static', rel)
            v = 0
            try: v = int(os.path.getmtime(path))
            except Exception: pass
            cards.append(f"/static/{rel}?v={v}")
        return jsonify({'success': True, 'cards': cards})
    except Exception as e:
        logger.error(f"welcome_cards error: {e}")
        return jsonify({'success': False, 'cards': []}), 500

@app.route('/admin/upload_welcome_card', methods=['POST'])
@login_required
def admin_upload_welcome_card():
    username = session.get('username')
    if not is_app_admin(username):
        return jsonify({'success': False, 'error': 'Unauthorized'}), 403
    try:
        idx = request.form.get('index') or request.args.get('index')
        try:
            idx = int(idx)
        except Exception:
            return jsonify({'success': False, 'error': 'index must be 1, 2, or 3'}), 400
        if idx not in (1,2,3):
            return jsonify({'success': False, 'error': 'index must be 1, 2, or 3'}), 400
        if 'image' not in request.files:
            return jsonify({'success': False, 'error': 'No file provided'}), 400
        f = request.files['image']
        if not f or f.filename == '':
            return jsonify({'success': False, 'error': 'No file selected'}), 400
        ext = os.path.splitext(f.filename)[1].lower()
        if ext.replace('.', '') not in ALLOWED_EXTENSIONS:
            return jsonify({'success': False, 'error': 'Invalid file type'}), 400
        os.makedirs(os.path.join('static','welcome'), exist_ok=True)
        filename = f"card-{idx}.jpg" if ext.lower() not in ('.webp',) else f"card-{idx}{ext}"
        dest = os.path.join('static','welcome', filename)
        f.save(dest)
        try:
            optimize_image(dest, max_width=1920, quality=82)
        except Exception:
            pass
        key = f"welcome_card_{idx}"
        # upsert
        with get_db_connection() as conn:
            c = conn.cursor()
            if USE_MYSQL:
                c.execute("CREATE TABLE IF NOT EXISTS site_settings (`key` VARCHAR(191) PRIMARY KEY, `value` TEXT)")
                c.execute("INSERT INTO site_settings (`key`,`value`) VALUES (%s,%s) ON DUPLICATE KEY UPDATE `value`=VALUES(`value`)", (key, f"welcome/{filename}"))
            else:
                c.execute("CREATE TABLE IF NOT EXISTS site_settings (key TEXT PRIMARY KEY, value TEXT)")
                c.execute("INSERT INTO site_settings (key,value) VALUES (?,?) ON CONFLICT(key) DO UPDATE SET value=excluded.value", (key, f"welcome/{filename}"))
            conn.commit()
        v = 0
        try: v = int(os.path.getmtime(dest))
        except Exception: pass
        return jsonify({'success': True, 'url': f"/static/welcome/{filename}?v={v}"})
    except Exception as e:
        logger.error(f"admin_upload_welcome_card error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/delete_reply', methods=['POST'])
@login_required
def delete_reply():
    username = session['username']
    # Temporarily disable CSRF validation
    # if not validate_csrf():
    #     return jsonify({'success': False, 'error': 'Invalid CSRF token'}), 400
    reply_id = request.form.get('reply_id', type=int)
    logger.debug(f"Received delete reply request for {username} with reply_id: {reply_id}")
    if not reply_id:
        return jsonify({'success': False, 'error': 'Reply ID is required!'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT username, image_path FROM replies WHERE id= ?", (reply_id,))
            reply = c.fetchone()
            if not reply or (reply['username'] != username and username != 'admin'):
                return jsonify({'success': False, 'error': 'Reply not found or unauthorized!'}), 403
            
            # Delete image file if it exists
            if reply['image_path']:
                try:
                    image_file_path = os.path.join('static', reply['image_path'])
                    if os.path.exists(image_file_path):
                        os.remove(image_file_path)
                except Exception as e:
                    logger.warning(f"Could not delete reply image file {reply['image_path']}: {e}")
            
            c.execute("DELETE FROM replies WHERE id= ?", (reply_id,))
            conn.commit()
        logger.info(f"Reply {reply_id} deleted successfully by {username}")
        return jsonify({'success': True, 'message': 'Reply deleted!'}), 200
    except Exception as e:
        logger.error(f"Error deleting reply {reply_id} for {username}: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': f'Unexpected error: {str(e)}'}), 500

@app.route('/add_reply_reaction', methods=['POST'])
@login_required
def add_reply_reaction():
    username = session['username']
    # Temporarily disable CSRF validation
    # if not validate_csrf():
    #     return jsonify({'success': False, 'error': 'Invalid CSRF token'}), 400
    reply_id = request.form.get('reply_id', type=int)
    reaction_type = request.form.get('reaction')

    if not all([reply_id, reaction_type]):
        return jsonify({'success': False, 'error': 'Missing data'}), 400

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT id, reaction_type FROM reply_reactions WHERE reply_id = ? AND username = ?", (reply_id, username))
            existing = c.fetchone()
            if existing:
                if existing['reaction_type'] == reaction_type:
                    c.execute("DELETE FROM reply_reactions WHERE id = ?", (existing['id'],))
                else:
                    c.execute("UPDATE reply_reactions SET reaction_type = ? WHERE id = ?", (reaction_type, existing['id']))
            else:
                c.execute("INSERT INTO reply_reactions (reply_id, username, reaction_type) VALUES (?, ?, ?)", (reply_id, username, reaction_type))
            conn.commit()
            new_counts, new_user_reaction = get_reply_reaction_summary(c, reply_id, username)
            return jsonify({'success': True, 'counts': new_counts, 'user_reaction': new_user_reaction})
    except Exception as e:
        logger.error(f"Error adding reply reaction: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/get_post')
@login_required
def get_post():
    username = session.get('username')
    post_id = request.args.get('post_id', type=int)
    
    if not post_id:
        return jsonify({'success': False, 'error': 'Post ID is required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Fetch the post
            c.execute("SELECT * FROM posts WHERE id = ?", (post_id,))
            post_raw = c.fetchone()
            
            if not post_raw:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            
            post = dict(post_raw)
            allow_nsfw_imagine = False
            community_id = post.get('community_id') if isinstance(post, dict) else None
            if community_id:
                try:
                    c.execute("SELECT allow_nsfw_imagine FROM communities WHERE id = ?", (community_id,))
                    allow_row = c.fetchone()
                    if allow_row is not None:
                        allow_nsfw_imagine = bool(allow_row['allow_nsfw_imagine'] if hasattr(allow_row, 'keys') else allow_row[0])
                except Exception as allow_err:
                    logger.warning(f"Failed to fetch allow_nsfw_imagine for community {community_id}: {allow_err}")
            post['allow_nsfw_imagine'] = allow_nsfw_imagine
            # Attach profile picture for post author
            try:
                c.execute("SELECT profile_picture FROM user_profiles WHERE username = ?", (post['username'],))
                pp = c.fetchone()
                post['profile_picture'] = pp['profile_picture'] if pp and 'profile_picture' in pp.keys() else None
            except Exception:
                post['profile_picture'] = None
            
            # Fetch replies for the post (top-level first)
            c.execute("SELECT * FROM replies WHERE post_id = ? ORDER BY timestamp DESC", (post_id,))
            replies_raw = [dict(row) for row in c.fetchall()]
            # Build nested tree by parent_reply_id
            children_map = {}
            for r in replies_raw:
                pid = r.get('parent_reply_id')
                children_map.setdefault(pid, []).append(r)
            def build_tree(parent_id=None):
                arr = []
                for r in children_map.get(parent_id, []):
                    r['children'] = build_tree(r['id'])
                    arr.append(r)
                return arr
            post['replies'] = build_tree(None)
            
            reaction_counts, user_reaction = get_post_reaction_summary(c, post_id, username)
            post['reactions'] = reaction_counts
            post['user_reaction'] = user_reaction
            
            # Add reaction counts for each reply and user reaction
            def hydrate_reply_metrics(reply):
                # Attach profile picture per reply
                try:
                    c.execute("SELECT profile_picture FROM user_profiles WHERE username = ?", (reply['username'],))
                    pr = c.fetchone()
                    reply['profile_picture'] = pr['profile_picture'] if pr and 'profile_picture' in pr.keys() else None
                except Exception:
                    reply['profile_picture'] = None
                counts, user_reaction = get_reply_reaction_summary(c, reply['id'], username)
                reply['reactions'] = counts
                reply['user_reaction'] = user_reaction
                for ch in reply.get('children', []):
                    hydrate_reply_metrics(ch)
            for reply in post['replies']:
                hydrate_reply_metrics(reply)

            # Fetch AI videos for carousel
            c.execute("""
                SELECT ij.result_path, ij.created_by, ij.created_at, ij.style
                FROM imagine_jobs ij
                WHERE ij.target_type = 'post'
                AND ij.target_id = ?
                AND ij.status = 'completed'
                AND ij.result_path IS NOT NULL
                ORDER BY ij.created_at ASC
            """, (post_id,))
            ai_videos_raw = c.fetchall()
            post['ai_videos'] = [
                {
                    'video_path': row['result_path'],
                    'generated_by': row['created_by'],
                    'created_at': row['created_at'],
                    'style': row['style']
                }
                for row in ai_videos_raw
            ]

            return jsonify({'success': True, 'post': post})
            
    except Exception as e:
        logger.error(f"Error fetching post {post_id}: {str(e)}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

# Community Routes
@app.route('/communities')
@login_required
def communities():
    """Communities page now redirects to React dashboard for all users"""
    # Redirect all users to premium dashboard (React app)
    return redirect('/premium_dashboard')

@app.route('/api/test_sub_permissions', methods=['POST'])
@login_required  
def test_sub_permissions():
    """Test endpoint to verify sub-community creation permissions"""
    username = session.get('username')
    data = request.get_json() or {}
    parent_id = data.get('parent_id')
    
    result = {
        'username': username,
        'is_app_admin': is_app_admin(username),
        'checks': []
    }
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check user info
            c.execute("SELECT email_verified, subscription FROM users WHERE username=?", (username,))
            user_info = c.fetchone()
            if user_info:
                result['email_verified'] = bool(user_info['email_verified'] if hasattr(user_info, 'keys') else user_info[0])
                result['subscription'] = user_info['subscription'] if hasattr(user_info, 'keys') else user_info[1]
            
            # Check parent community
            if parent_id:
                placeholder = get_sql_placeholder()
                c.execute(f"SELECT id, name, type, creator_username FROM communities WHERE id = {placeholder}", (parent_id,))
                parent = c.fetchone()
                if parent:
                    result['parent'] = {
                        'id': parent['id'] if hasattr(parent, 'keys') else parent[0],
                        'name': parent['name'] if hasattr(parent, 'keys') else parent[1],
                        'type': parent['type'] if hasattr(parent, 'keys') else parent[2],
                        'creator': parent['creator_username'] if hasattr(parent, 'keys') else parent[3]
                    }
                    
                    # Check user's role
                    c.execute(f"""
                        SELECT role FROM user_communities
                        WHERE user_id = (SELECT id FROM users WHERE username = {placeholder})
                        AND community_id = {placeholder}
                    """, (username, parent_id))
                    role_row = c.fetchone()
                    result['role_in_parent'] = role_row['role'] if (role_row and hasattr(role_row, 'keys')) else (role_row[0] if role_row else None)
        
        result['can_create'] = (
            result.get('is_app_admin') or
            (result.get('parent', {}).get('creator') == username) or
            (result.get('role_in_parent') == 'admin')
        )
        
        return jsonify({'success': True, 'data': result})
    except Exception as e:
        logger.error(f"Test permissions error: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/create_community', methods=['POST'])
@login_required
def create_community():
    """Create a new community"""
    try:
        username = session.get('username')
        logger.info(f"=== CREATE COMMUNITY REQUEST from {username} ===")
        
        # Log all form data for debugging
        logger.info(f"Form data: {dict(request.form)}")
        
        is_app_admin_user = is_app_admin(username)
        subscription_value = 'free'
        is_premium_user = False
        is_free_creator = False
        is_business_admin_creating_sub = False
        requested_type = request.form.get('type')
        raw_parent_value = request.form.get('parent_community_id', None)

        def normalize_parent_value(value):
            if value is None:
                return None
            if isinstance(value, str):
                cleaned = value.strip()
            else:
                cleaned = str(value).strip()
            if cleaned.lower() in ('', 'none', 'null', 'undefined'):
                return None
            return cleaned

        parent_community_id_check = normalize_parent_value(raw_parent_value)
        
        # Enforce verified email
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT email_verified FROM users WHERE username=?", (username,))
            row = c.fetchone()
            verified = False
            if row is not None:
                verified = bool(row['email_verified'] if hasattr(row, 'keys') else row[0])
            if not verified:
                return jsonify({'success': False, 'error': 'please verify your email'}), 403
            # Enforce subscription: only premium users (or admin) can create communities
            # Exception: Business community admins can create sub-communities without premium
            try:
                c.execute("SELECT subscription FROM users WHERE username=?", (username,))
                sub_row = c.fetchone()
                subscription = (sub_row['subscription'] if hasattr(sub_row,'keys') else (sub_row[0] if sub_row else 'free'))
            except Exception:
                subscription = 'free'
            subscription_value = normalize_subscription(subscription)
            is_premium_user = subscription_value == 'premium'
            
            # Check if this is a Business sub-community creation by a parent admin
            community_type_check = (requested_type or '').strip().lower()
            
            if parent_community_id_check is not None and community_type_check == 'business':
                # Check if user is admin of parent Business community (using same connection/cursor)
                try:
                    placeholder_check = get_sql_placeholder()
                    c.execute(f"SELECT type, creator_username FROM communities WHERE id = {placeholder_check}", (parent_community_id_check,))
                    parent_check = c.fetchone()
                    if parent_check:
                        parent_type_check = parent_check['type'] if hasattr(parent_check, 'keys') else parent_check[0]
                        parent_creator_check = parent_check['creator_username'] if hasattr(parent_check, 'keys') else parent_check[1]
                        
                        if parent_type_check.lower() == 'business':
                            # Check if owner
                            if username == parent_creator_check:
                                is_business_admin_creating_sub = True
                            else:
                                # Check if admin
                                c.execute(f"""
                                    SELECT role FROM user_communities
                                    WHERE user_id = (SELECT id FROM users WHERE username = {placeholder_check})
                                    AND community_id = {placeholder_check}
                                """, (username, parent_community_id_check))
                                role_check = c.fetchone()
                                if role_check:
                                    user_role_check = role_check['role'] if hasattr(role_check, 'keys') else role_check[0]
                                    if user_role_check == 'admin':
                                        is_business_admin_creating_sub = True
                except Exception as bypass_err:
                    logger.warning(f"Error checking Business admin bypass: {bypass_err}")
            
            raw_type = str(requested_type or '').strip().lower() or 'general'

            # Determine if user should be treated as free-plan creator
            parent_is_none = parent_community_id_check is None
            if not is_app_admin_user:
                if not is_premium_user:
                    if parent_is_none:
                        is_free_creator = True
                        raw_type = 'general'
        
        name = request.form.get('name')
        description = request.form.get('description', '')
        location = request.form.get('location', '')
        template = request.form.get('template', 'default')
        background_color = request.form.get('background_color', '#2d3839')
        text_color = request.form.get('text_color', '#ffffff')
        accent_color = request.form.get('accent_color', '#4db6ac')
        card_color = request.form.get('card_color', '#1a2526')
        parent_community_id = parent_community_id_check
        parent_community_id_value: Optional[int] = None
        if parent_community_id is not None:
            try:
                parent_community_id_value = int(str(parent_community_id))
            except (TypeError, ValueError):
                return jsonify({'success': False, 'error': 'Invalid parent community specified'}), 400
        
        if not name:
            return jsonify({'success': False, 'error': 'Name is required'}), 400
        
        # Duplicate prevention: Check if same user created a community with same name in last 60 seconds
        try:
            with get_db_connection() as conn:
                c_dup = conn.cursor()
                ph = get_sql_placeholder()
                c_dup.execute(f"""
                    SELECT id, created_at FROM communities 
                    WHERE creator_username = {ph} AND name = {ph}
                    ORDER BY id DESC LIMIT 1
                """, (username, name.strip()))
                existing = c_dup.fetchone()
                if existing:
                    existing_id = existing['id'] if hasattr(existing, 'keys') else existing[0]
                    logger.warning(f"Duplicate community prevention: User {username} already has community '{name}' (id={existing_id})")
                    return jsonify({
                        'success': True,  # Return success to prevent retry loops
                        'community_id': existing_id,
                        'message': f'Community "{name}" already exists',
                        'duplicate': True
                    })
        except Exception as dup_err:
            logger.warning(f"Error checking duplicate community: {dup_err}")
            # Continue anyway - better to risk a duplicate than block creation
        
        # Business communities can only be created by app admin (parent) or parent community admins (sub-communities)
        normalized_type = raw_type
        if normalized_type == 'business':
            if parent_community_id is not None:
                # Check if user is admin of parent Business community
                try:
                    with get_db_connection() as conn:
                        c_check = conn.cursor()
                        placeholder = get_sql_placeholder()
                        
                        # Check parent community type
                        c_check.execute(f"SELECT type, creator_username FROM communities WHERE id = {placeholder}", (parent_community_id,))
                        parent_info = c_check.fetchone()
                        if not parent_info:
                            return jsonify({'success': False, 'error': 'Parent community not found'}), 404
                        
                        parent_type = parent_info['type'] if hasattr(parent_info, 'keys') else parent_info[0]
                        parent_creator = parent_info['creator_username'] if hasattr(parent_info, 'keys') else parent_info[1]
                        
                        if parent_type.lower() != 'business':
                            return jsonify({'success': False, 'error': 'Business sub-communities can only be created under Business parent communities'}), 403
                        
                        # Check if user is owner
                        if username == parent_creator or is_app_admin(username):
                            # Owner or app admin - allowed
                            logger.info(f"Business sub-community creation allowed: {username} is owner/admin of parent {parent_community_id}")
                        else:
                            # Check if user is admin of parent community
                            logger.info(f"Checking if {username} is admin of parent community {parent_community_id}")
                            c_check.execute(f"""
                                SELECT role FROM user_communities
                                WHERE user_id = (SELECT id FROM users WHERE username = {placeholder})
                                AND community_id = {placeholder}
                            """, (username, parent_community_id))
                            user_role_row = c_check.fetchone()
                            user_role = user_role_row['role'] if (user_role_row and hasattr(user_role_row, 'keys')) else (user_role_row[0] if user_role_row else None)
                            
                            logger.info(f"User {username} role in parent {parent_community_id}: {user_role}")
                            
                            if user_role != 'admin':
                                logger.warning(f"Permission denied: {username} has role '{user_role}' (not 'admin') in parent {parent_community_id}")
                                return jsonify({'success': False, 'error': f'Only parent community admins can create Business sub-communities. Your role: {user_role}'}), 403
                            
                            logger.info(f"Business sub-community creation allowed: {username} is admin of parent {parent_community_id}")
                except Exception as e:
                    logger.error(f"Error checking parent community permissions: {e}")
                    return jsonify({'success': False, 'error': f'Permission check failed: {str(e)}'}), 500
            else:
                # Creating parent Business community - only app admin
                if not is_app_admin(username):
                    return jsonify({'success': False, 'error': 'Only app admin can create Business communities'}), 403
        
        # Generate a dummy join_code to satisfy database UNIQUE constraint
        # (Not used for joining anymore, but column still exists)
        import random
        import string
        join_code = ''.join(random.choices(string.ascii_uppercase + string.digits, k=6))
        
        # Handle background image
        background_path = None
        if 'background_file' in request.files:
            file = request.files['background_file']
            if file.filename != '':
                background_path = save_uploaded_file(file, 'community_backgrounds')
                if not background_path:
                    return jsonify({'success': False, 'error': 'Invalid background image file type. Allowed: png, jpg, jpeg, gif, webp'}), 400
        
        # Use URL if no file uploaded
        if not background_path:
            background_url = request.form.get('background_url', '').strip()
            if background_url:
                background_path = background_url
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Apply free-plan community limits before creation
            parent_id_int = parent_community_id_value
            if is_free_creator:
                if parent_id_int is None:
                    if USE_MYSQL:
                        c.execute("""
                            SELECT COUNT(*) FROM communities 
                            WHERE creator_username = %s AND (parent_community_id IS NULL OR parent_community_id = '')
                        """, (username,))
                    else:
                        c.execute("""
                            SELECT COUNT(*) FROM communities 
                            WHERE creator_username = ? AND (parent_community_id IS NULL OR parent_community_id = '')
                        """, (username,))
                    parent_count = get_scalar_result(c.fetchone(), column_index=0) or 0
                    try:
                        parent_count = int(parent_count)
                    except Exception:
                        parent_count = 0
                    if parent_count >= 2:
                        return jsonify({'success': False, 'error': 'Free plan allows up to 2 parent communities. Upgrade to create more communities.'}), 403
                else:
                    parent_info = get_community_basic(c, parent_id_int)
                    if not parent_info:
                        return jsonify({'success': False, 'error': 'Parent community not found'}), 404
                    ancestors = get_community_ancestors(c, parent_id_int)
                    depth = len(ancestors)
                    top_info = ancestors[-1] if ancestors else parent_info
                    top_creator = top_info.get('creator_username')
                    if top_creator != username:
                        return jsonify({'success': False, 'error': 'Free plan sub-communities must be created under your own parent communities.'}), 403
                    is_free_creator = True
                    if depth > 2:
                        return jsonify({'success': False, 'error': 'Free plan communities support only one nested level.'}), 403
                    child_placeholder = get_sql_placeholder()
                    if parent_info.get('parent_community_id') is None:
                        c.execute(f"SELECT COUNT(*) FROM communities WHERE parent_community_id = {child_placeholder}", (parent_id_int,))
                        child_count = get_scalar_result(c.fetchone(), column_index=0) or 0
                        try:
                            child_count = int(child_count)
                        except Exception:
                            child_count = 0
                        if child_count >= 3:
                            return jsonify({'success': False, 'error': 'Free plan parent communities can have up to 3 sub-communities.'}), 403
                    else:
                        c.execute(f"SELECT COUNT(*) FROM communities WHERE parent_community_id = {child_placeholder}", (parent_id_int,))
                        nested_count = get_scalar_result(c.fetchone(), column_index=0) or 0
                        try:
                            nested_count = int(nested_count)
                        except Exception:
                            nested_count = 0
                        if nested_count >= 1:
                            return jsonify({'success': False, 'error': 'Free plan sub-communities can have only one nested community.'}), 403

            # If creating a sub-community, enforce premium-only for creators as well
            # (Already enforced above for community creation, but keep guard explicit)
            placeholders = ', '.join([get_sql_placeholder()] * 14)
            c.execute(f"""
                INSERT INTO communities (name, type, creator_username, join_code, created_at, description, location, background_path, template, background_color, text_color, accent_color, card_color, parent_community_id)
                VALUES ({placeholders})
            """, (name, normalized_type, username, join_code, datetime.now().strftime('%m.%d.%y %H:%M'), description, location, background_path, template, background_color, text_color, accent_color, card_color, parent_id_int))
            
            community_id = c.lastrowid
            
            # Get user's ID and add creator as owner
            c.execute(f"SELECT id FROM users WHERE username = {get_sql_placeholder()}", (username,))
            user_row = c.fetchone()
            if user_row:
                user_id = user_row[0] if not hasattr(user_row, 'keys') else user_row['id']
                try:
                    add_user_to_community(c, user_id, community_id, role='owner')
                except CommunityMembershipLimitError as limit_err:
                    conn.rollback()
                    return jsonify({'success': False, 'error': str(limit_err)}), 403
            
            # Ensure admin is also a member of every community
            c.execute("SELECT id FROM users WHERE username = 'admin'")
            admin_row = c.fetchone()
            if admin_row:
                admin_id = admin_row['id'] if hasattr(admin_row, 'keys') else admin_row[0]
                c.execute(f"SELECT 1 FROM user_communities WHERE user_id={get_sql_placeholder()} AND community_id={get_sql_placeholder()}", (admin_id, community_id))
                if not c.fetchone():
                    try:
                        add_user_to_community(c, admin_id, community_id, role=None)
                    except CommunityMembershipLimitError as limit_err:
                        conn.rollback()
                        return jsonify({'success': False, 'error': str(limit_err)}), 403
            
            conn.commit()
            
            # Invalidate dashboard cache so new community appears immediately
            invalidate_user_cache(username)
            logger.info(f"Invalidated dashboard cache for {username} after community creation")
            
            return jsonify({
                'success': True, 
                'community_id': community_id,
                'message': f'Community "{name}" created successfully!'
            })
            
    except Exception as e:
        logger.error(f"Error creating community: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'error': f'Failed to create community: {str(e)}'}), 500
    except Exception as outer_err:
        logger.error(f"Outer error in create_community: {outer_err}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({'success': False, 'error': f'Server error: {str(outer_err)}'}), 500
@app.route('/get_available_parent_communities', methods=['GET'])
@login_required
def get_available_parent_communities():
    """Get communities that can be parent communities (excluding the current one if editing)"""
    username = session.get('username')
    current_community_id = request.args.get('current_id', type=int)
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all communities that the user has access to or created
            # Exclude the current community and its children to prevent circular references
            if current_community_id:
                c.execute("""
                    SELECT DISTINCT c.id, c.name, c.type, c.parent_community_id
                    FROM communities c
                    LEFT JOIN user_communities uc ON c.id = uc.community_id
                    LEFT JOIN users u ON uc.user_id = u.id
                    WHERE (u.username = ? OR c.creator_username = ? OR ? = 'admin')
                    AND c.id != ?
                    AND (c.parent_community_id IS NULL OR c.parent_community_id != ?)
                    ORDER BY c.name
                """, (username, username, username, current_community_id, current_community_id))
            else:
                c.execute("""
                    SELECT DISTINCT c.id, c.name, c.type, c.parent_community_id
                    FROM communities c
                    LEFT JOIN user_communities uc ON c.id = uc.community_id
                    LEFT JOIN users u ON uc.user_id = u.id
                    WHERE u.username = ? OR c.creator_username = ? OR ? = 'admin'
                    ORDER BY c.name
                """, (username, username, username))
            
            communities = []
            for row in c.fetchall():
                communities.append({
                    'id': row['id'],
                    'name': row['name'],
                    'type': row['type'],
                    'parent_community_id': row['parent_community_id']
                })
            
            return jsonify({'success': True, 'communities': communities})
            
    except Exception as e:
        logger.error(f"Error getting parent communities: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/get_user_communities_with_members', methods=['GET'])
@login_required
def get_user_communities_with_members():
    """Get user's communities with member lists"""
    username = session.get('username')
    logger.info(f"Getting communities for user: {username}")
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get user ID
            c.execute("SELECT id FROM users WHERE username = ?", (username,))
            user = c.fetchone()
            if not user:
                logger.error(f"User not found: {username}")
                return jsonify({'success': False, 'error': 'User not found'})
            
            user_id = user['id'] if hasattr(user, 'keys') else user[0]
            logger.info(f"User ID: {user_id}")
            
            # Get communities based on admin status
            if is_app_admin(username):
                # Admin sees all communities
                c.execute("""
                    SELECT c.id, c.name, c.type, c.creator_username
                    FROM communities c
                    ORDER BY c.name
                """)
            else:
                # Regular users see only their communities
                # Use correct placeholder based on database type
                placeholder = '%s' if USE_MYSQL else '?'
                c.execute(f"""
                    SELECT c.id, c.name, c.type, c.creator_username
                    FROM communities c
                    JOIN user_communities uc ON c.id = uc.community_id
                    WHERE uc.user_id = {placeholder}
                    ORDER BY c.name
                """, (user_id,))
            
            communities = c.fetchall()
            logger.info(f"Found {len(communities)} communities for user {username}")
            
            result = []
            for community in communities:
                try:
                    # Get members of each community with profile pictures
                    c.execute("""
                        SELECT u.id as id, u.username, p.profile_picture
                        FROM users u
                        JOIN user_communities uc ON u.id = uc.user_id
                        LEFT JOIN user_profiles p ON u.username = p.username
                        WHERE uc.community_id = ? AND u.username != ?
                        ORDER BY u.username
                    """, (community['id'], username))
                    
                    members = []
                    for member in c.fetchall():
                        members.append({
                            'id': member['id'],
                            'username': member['username'],
                            'profile_pic': member['profile_picture'] if member['profile_picture'] else None,
                            'online': False  # You can implement online status tracking later
                        })
                    
                    logger.info(f"Community {community['name']} has {len(members)} members")
                    
                    result.append({
                        'id': community['id'],
                        'name': community['name'],
                        'type': community['type'],
                        'is_creator': community['creator_username'] == username,
                        'members': members
                    })
                except Exception as ce:
                    logger.error(f"Error processing community {community['name'] if 'name' in community else 'unknown'}: {str(ce)}")
                    continue
            
            logger.info(f"Returning {len(result)} communities with members")
            return jsonify({'success': True, 'communities': result})
            
    except Exception as e:
        logger.error(f"Error fetching communities with members: {str(e)}")
        logger.error(f"Exception type: {type(e).__name__}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'success': False, 'error': f'Failed to fetch communities: {str(e)}'})

@app.route('/get_user_communities')
@login_required
def get_user_communities():
    """Get all communities the user is a member of"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is admin
            if is_app_admin(username):
                # Admin sees all communities
                c.execute(                    """
                    SELECT c.id, c.name, c.type, c.created_at, c.creator_username, c.is_active
                    FROM communities c
                    ORDER BY c.created_at DESC
                """)
            else:
                # Regular users see only their communities
                # Use correct placeholder based on database type
                placeholder = '%s' if USE_MYSQL else '?'
                c.execute(f"""
                    SELECT c.id, c.name, c.type, c.created_at, c.creator_username, c.is_active
                    FROM communities c
                    JOIN user_communities uc ON c.id = uc.community_id
                    JOIN users u ON uc.user_id = u.id
                    WHERE u.username = {placeholder}
                    ORDER BY c.created_at DESC
                """, (username,))
            
            communities = []
            for row in c.fetchall():
                communities.append({
                    'id': row['id'],
                    'name': row['name'],
                    'type': row['type'],
                    'created_at': row['created_at'],
                    'is_creator': row['creator_username'] == username,
                    'is_active': row['is_active'] if row['is_active'] is not None else True
                })
            
            return jsonify({'success': True, 'communities': communities})
            
    except Exception as e:
        logger.error(f"Error fetching user communities: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to fetch communities'}), 500

@app.route('/edit_community', methods=['POST'])
@login_required
def edit_community():
    """Edit a community name"""
    username = session.get('username')
    community_id = request.form.get('community_id', type=int)
    new_name = request.form.get('name', '').strip()
    
    if not community_id or not new_name:
        return jsonify({'success': False, 'error': 'Community ID and name are required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is the creator of this community
            c.execute(f"SELECT creator_username FROM communities WHERE id = {get_sql_placeholder()} ", (community_id,))
            community = c.fetchone()
            
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            if community['creator_username'] != username:
                return jsonify({'success': False, 'error': 'Only the community creator can edit the community'}), 403
            
            # Update the community name
            c.execute("UPDATE communities SET name = ? WHERE id = ?", (new_name, community_id))
            conn.commit()
            
            return jsonify({'success': True, 'message': 'Community updated successfully'})
            
    except Exception as e:
        logger.error(f"Error editing community: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to edit community'}), 500
@app.route('/update_community', methods=['POST'])
@login_required
def update_community():
    """Update community details (name, description, type, background, template, colors, parent, notifications, limits)"""
    username = session.get('username')
    community_id = request.form.get('community_id', type=int)
    name = request.form.get('name', '').strip()
    description = request.form.get('description', '').strip()
    community_type = request.form.get('type', '').strip()
    template = request.form.get('template', 'dark')
    background_color = request.form.get('background_color', '#2d3839')
    card_color = request.form.get('card_color', '#1a2526')
    accent_color = request.form.get('accent_color', '#4db6ac')
    text_color = request.form.get('text_color', '#ffffff')
    parent_community_id = request.form.get('parent_community_id', None)
    notify_raw = (request.form.get('notify_on_new_member') or '').strip().lower()
    notify_on_new_member = 1 if notify_raw in ('true','1','on','yes') else 0
    allow_nsfw_raw = (request.form.get('allow_nsfw_imagine') or '').strip().lower()
    allow_nsfw_imagine = 1 if allow_nsfw_raw in ('true', '1', 'on', 'yes') else 0
    max_members = request.form.get('max_members', type=int)
    
    if not community_id or not name:
        return jsonify({'success': False, 'error': 'Community ID and name are required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure notify_on_new_member and max_members columns exist (production safety)
            try:
                if 'USE_MYSQL' in globals() and USE_MYSQL:
                    c.execute("SHOW COLUMNS FROM communities LIKE 'notify_on_new_member'")
                    if not c.fetchone():
                        c.execute("ALTER TABLE communities ADD COLUMN notify_on_new_member TINYINT(1) DEFAULT 0")
                        conn.commit()
                    c.execute("SHOW COLUMNS FROM communities LIKE 'max_members'")
                    if not c.fetchone():
                        c.execute("ALTER TABLE communities ADD COLUMN max_members INT NULL")
                        conn.commit()
                    c.execute("SHOW COLUMNS FROM communities LIKE 'allow_nsfw_imagine'")
                    if not c.fetchone():
                        c.execute("ALTER TABLE communities ADD COLUMN allow_nsfw_imagine TINYINT(1) DEFAULT 0")
                        conn.commit()
                else:
                    c.execute("PRAGMA table_info(communities)")
                    cols = [row[1] if isinstance(row, (list, tuple)) else row['name'] for row in c.fetchall()]
                    if 'notify_on_new_member' not in cols:
                        c.execute("ALTER TABLE communities ADD COLUMN notify_on_new_member INTEGER DEFAULT 0")
                        conn.commit()
                    if 'max_members' not in cols:
                        c.execute("ALTER TABLE communities ADD COLUMN max_members INTEGER NULL")
                        conn.commit()
                    if 'allow_nsfw_imagine' not in cols:
                        c.execute("ALTER TABLE communities ADD COLUMN allow_nsfw_imagine INTEGER DEFAULT 0")
                        conn.commit()
            except Exception as mig_e:
                logger.warning(f"notify_on_new_member migration check failed: {mig_e}")

            ph = get_sql_placeholder()

            # Check if community exists and who is the owner
            c.execute(f"SELECT creator_username FROM communities WHERE id = {ph}", (community_id,))
            community = c.fetchone()
            
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            owner_username = community['creator_username'] if hasattr(community, 'keys') else community[0]
            is_owner = (owner_username == username)
            is_app_admin = (username == 'admin')
            # Allow community admins to edit general fields
            try:
                admin_ok = is_community_admin_or_owner(username, community_id)
            except Exception:
                admin_ok = False
            if not (admin_ok or is_app_admin):
                return jsonify({'success': False, 'error': 'Only community admins or owner can edit the community'}), 403
            
            # Handle background file upload or removal (restrict to owner or app admin)
            background_path = None
            remove_background = request.form.get('remove_background', '').lower() in ('true', '1', 'yes')
            
            if (is_owner or is_app_admin) and ('background_file' in request.files):
                file = request.files['background_file']
                if file and file.filename:
                    # Save the uploaded file using R2-enabled media service
                    stored_path = save_uploaded_file(
                        file,
                        subfolder='community_backgrounds',
                        allowed_extensions={'png', 'jpg', 'jpeg', 'gif', 'webp'}
                    )
                    if stored_path:
                        background_path = stored_path
            
            # Update the community details
            if remove_background and (is_owner or is_app_admin):
                # Remove the background image
                c.execute(
                    f"""
                    UPDATE communities 
                    SET name = {ph}, description = {ph}, type = {ph}, background_path = NULL, template = {ph},
                        background_color = {ph}, card_color = {ph}, accent_color = {ph}, text_color = {ph},
                        parent_community_id = {ph}, notify_on_new_member = {ph}, max_members = {ph},
                        allow_nsfw_imagine = {ph}
                    WHERE id = {ph}
                    """,
                    (
                        name, description, community_type, template,
                        background_color, card_color, accent_color, text_color,
                        (parent_community_id if parent_community_id and parent_community_id != 'none' else None),
                        notify_on_new_member,
                        (max_members if (isinstance(max_members, int) and max_members > 0) else None),
                        allow_nsfw_imagine,
                        community_id,
                    ),
                )
            elif background_path:
                c.execute(
                    f"""
                    UPDATE communities 
                    SET name = {ph}, description = {ph}, type = {ph}, background_path = {ph}, template = {ph},
                        background_color = {ph}, card_color = {ph}, accent_color = {ph}, text_color = {ph},
                        parent_community_id = {ph}, notify_on_new_member = {ph}, max_members = {ph},
                        allow_nsfw_imagine = {ph}
                    WHERE id = {ph}
                    """,
                    (
                        name, description, community_type, background_path, template,
                        background_color, card_color, accent_color, text_color,
                        (parent_community_id if parent_community_id and parent_community_id != 'none' else None),
                        notify_on_new_member,
                        (max_members if (isinstance(max_members, int) and max_members > 0) else None),
                        allow_nsfw_imagine,
                        community_id,
                    ),
                )
            else:
                c.execute(
                    f"""
                    UPDATE communities 
                    SET name = {ph}, description = {ph}, type = {ph}, template = {ph},
                        background_color = {ph}, card_color = {ph}, accent_color = {ph}, text_color = {ph},
                        parent_community_id = {ph}, notify_on_new_member = {ph}, max_members = {ph},
                        allow_nsfw_imagine = {ph}
                    WHERE id = {ph}
                    """,
                    (
                        name, description, community_type, template,
                        background_color, card_color, accent_color, text_color,
                        (parent_community_id if parent_community_id and parent_community_id != 'none' else None),
                        notify_on_new_member,
                        (max_members if (isinstance(max_members, int) and max_members > 0) else None),
                        allow_nsfw_imagine,
                        community_id,
                    ),
                )
            
            conn.commit()
            
            # Invalidate community feed cache so changes appear immediately
            try:
                invalidate_community_cache(community_id)
            except Exception as cache_err:
                logger.warning(f"Failed to invalidate cache after community update for {community_id}: {cache_err}")
            
            return jsonify({'success': True, 'message': 'Community updated successfully'})
            
    except Exception as e:
        logger.error(f"Error updating community: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to update community'}), 500

@app.route('/delete_community', methods=['POST'])
@login_required
def delete_community():
    """Delete a community and all its posts"""
    username = session.get('username')
    community_id = request.form.get('community_id', type=int)
    
    if not community_id:
        return jsonify({'success': False, 'error': 'Community ID is required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is the creator of this community
            c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            if community['creator_username'] != username:
                return jsonify({'success': False, 'error': 'Only the community creator can delete the community'}), 403

            descendant_ids = get_descendant_community_ids(c, community_id)
            placeholder = get_sql_placeholder()
            for target_id in descendant_ids:
                c.execute(f"SELECT creator_username FROM communities WHERE id = {placeholder}", (target_id,))
                owner_row = c.fetchone()
                owner_username = None
                if owner_row:
                    if hasattr(owner_row, 'keys'):
                        owner_username = owner_row.get('creator_username')
                    elif isinstance(owner_row, (list, tuple)):
                        owner_username = owner_row[0]
                if owner_username and owner_username != username:
                    return jsonify({
                        'success': False,
                        'error': 'This community has nested communities you do not own. Please contact an admin to remove them first.'
                    }), 403

            # Get all members of communities being deleted BEFORE deleting
            affected_usernames: Set[str] = set()
            for target_id in descendant_ids:
                placeholder = get_sql_placeholder()
                c.execute(f"""
                    SELECT DISTINCT u.username 
                    FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE uc.community_id = {placeholder}
                """, (target_id,))
                for row in c.fetchall():
                    uname = row['username'] if hasattr(row, 'keys') else row[0]
                    if uname:
                        affected_usernames.add(uname)
            
            deleted_ids: List[int] = []
            for target_id in descendant_ids:
                delete_community_records(c, target_id)
                deleted_ids.append(target_id)
            
            conn.commit()
            
            # Invalidate dashboard cache for ALL affected users
            for affected_user in affected_usernames:
                invalidate_user_cache(affected_user)
            logger.info(f"Invalidated dashboard cache for {len(affected_usernames)} users after community deletion: {list(affected_usernames)[:5]}...")
            
            return jsonify({'success': True, 'message': 'Community deleted successfully', 'deleted_ids': deleted_ids})
            
    except Exception as e:
        logger.error(f"Error deleting community: {str(e)}")
        return jsonify({'success': False, 'error': 'Failed to delete community'}), 500

@app.route('/migrate_parent_communities')
@login_required
def migrate_parent_communities():
    """Migrate KW28 parent community relationship"""
    username = session.get('username')
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Admin access required'}), 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Find KW28 community
            c.execute("SELECT id, name FROM communities WHERE name LIKE %s", ('%KW28%',))
            kw28_community = c.fetchone()
            
            # Find WHU/Otto community  
            c.execute("SELECT id, name FROM communities WHERE name LIKE %s OR name LIKE %s", ('%WHU%', '%Otto%'))
            whu_community = c.fetchone()
            
            if not kw28_community:
                return jsonify({'success': False, 'error': 'KW28 community not found'})
                
            if not whu_community:
                return jsonify({'success': False, 'error': 'WHU/Otto community not found'})
            
            # Set KW28's parent to WHU
            c.execute("""
                UPDATE communities 
                SET parent_community_id = %s 
                WHERE id = %s
            """, (whu_community['id'], kw28_community['id']))
            
            if c.rowcount > 0:
                conn.commit()
                
                # Get users in KW28 community for verification
                c.execute("""
                    SELECT u.username 
                    FROM users u
                    JOIN user_communities uc ON u.id = uc.user_id
                    WHERE uc.community_id = %s
                """, (kw28_community['id'],))
                users = c.fetchall()
                
                return jsonify({
                    'success': True,
                    'message': f'Successfully set {whu_community["name"]} as parent of {kw28_community["name"]}',
                    'parent_community': whu_community['name'],
                    'child_community': kw28_community['name'],
                    'affected_users': len(users),
                    'users': [u['username'] for u in users]
                })
            else:
                return jsonify({'success': False, 'error': 'No communities were updated'})
                
    except Exception as e:
        logger.error(f"Error migrating parent communities: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/fix_database_issues')
@login_required  
def fix_database_issues():
    """Fix database issues: missing tables, parent community memberships, and timestamps"""
    username = session.get('username')
    if username != 'admin':
        return jsonify({'success': False, 'error': 'Admin access required'}), 403
    
    try:
        results = []
        
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Fix 1: Ensure university_ads table exists
            try:
                c.execute("SELECT 1 FROM university_ads LIMIT 1")
                results.append("‚úÖ university_ads table exists")
            except:
                results.append("üî® Creating university_ads table...")
                c.execute('''CREATE TABLE university_ads (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    community_id INTEGER NOT NULL,
                    title TEXT NOT NULL,
                    description TEXT,
                    price TEXT NOT NULL,
                    image_url TEXT NOT NULL,
                    link_url TEXT,
                    is_active TINYINT(1) DEFAULT 1,
                    display_order INTEGER DEFAULT 0,
                    created_at TEXT NOT NULL,
                    created_by TEXT NOT NULL,
                    clicks INTEGER DEFAULT 0,
                    impressions INTEGER DEFAULT 0,
                    FOREIGN KEY (community_id) REFERENCES communities (id) ON DELETE CASCADE
                )''')
                results.append("‚úÖ university_ads table created")
            
            # Fix 2: Fix ALL post timestamps safely
            results.append("üîß Fixing ALL post timestamps...")
            
            # Get all posts and fix timestamps one by one
            c.execute("SELECT id, username FROM posts ORDER BY id ASC")
            all_posts = c.fetchall()
            
            if all_posts:
                results.append(f"Found {len(all_posts)} posts to fix")
                
                # Start from 7 days ago and increment by 10 minutes per post
                from datetime import datetime, timedelta
                base_time = datetime.now() - timedelta(days=7)
                fixed_count = 0
                
                for i, post in enumerate(all_posts):
                    try:
                        # Calculate timestamp: recent posts get recent times
                        post_time = base_time + timedelta(minutes=i * 10)
                        mysql_timestamp = post_time.strftime('%d-%m-%Y %H:%M:%S')
                        
                        c.execute("""
                            UPDATE posts 
                            SET timestamp = %s 
                            WHERE id = %s
                        """, (mysql_timestamp, post['id']))
                        
                        fixed_count += 1
                        
                        if i < 5:  # Show first 5 for verification
                            results.append(f"‚úÖ Post {post['id']} ({post['username']}): {mysql_timestamp}")
                        
                    except Exception as e:
                        results.append(f"‚ùå Failed to fix post {post['id']}: {e}")
                
                results.append(f"üìä Fixed {fixed_count} post timestamps")
            else:
                results.append("‚úÖ No posts found to fix")
            
            # Fix 3: Add child community members to parent communities
            c.execute("""
                SELECT c.id, c.name, c.parent_community_id, pc.name as parent_name
                FROM communities c
                JOIN communities pc ON c.parent_community_id = pc.id
                WHERE c.parent_community_id IS NOT NULL
            """)
            child_communities = c.fetchall()
            
            total_added = 0
            
            for child in child_communities:
                child_id = child['id']
                parent_id = child['parent_community_id']
                child_name = child['name']
                parent_name = child['parent_name']
                
                # Get members of child community who are not in parent
                c.execute("""
                    SELECT uc.user_id, u.username
                    FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE uc.community_id = %s
                    AND uc.user_id NOT IN (
                        SELECT user_id FROM user_communities 
                        WHERE community_id = %s
                    )
                """, (child_id, parent_id))
                
                members_to_add = c.fetchall()
                
                for member in members_to_add:
                    user_id = member['user_id']
                    username_member = member['username']
                    
                    try:
                        add_user_to_community(c, int(user_id), int(parent_id), role=None)
                        total_added += 1
                        results.append(f"‚úÖ Added {username_member} to {parent_name}")
                    except CommunityMembershipLimitError as limit_err:
                        results.append(f"‚ö†Ô∏è Skipped adding {username_member} to {parent_name}: {limit_err}")
                    except Exception as e:
                        results.append(f"‚ùå Failed to add {username_member}: {e}")
            
            conn.commit()
            results.append(f"üìä Total members added to parent communities: {total_added}")
            
        return jsonify({
            'success': True, 
            'message': 'Database issues fixed successfully',
            'results': results
        })
        
    except Exception as e:
        logger.error(f"Error fixing database issues: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/migrate_database')
def migrate_database():
    """Manual database migration endpoint"""
    try:
        add_missing_tables()
        return jsonify({'success': True, 'message': 'Database migration completed successfully'})
    except Exception as e:
        logger.error(f"Database migration failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/migrate_key_posts', methods=['POST'])
def migrate_key_posts():
    """Create key_posts table if it doesn't exist - no login required for setup"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Check if table exists
            if USE_MYSQL:
                c.execute("SHOW TABLES LIKE 'key_posts'")
                table_exists = c.fetchone() is not None
            else:
                c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='key_posts'")
                table_exists = c.fetchone() is not None

            if not table_exists:
                logger.info("Creating key_posts table...")
                c.execute('''CREATE TABLE IF NOT EXISTS key_posts
                             (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                              username VARCHAR(191) NOT NULL,
                              post_id INTEGER NOT NULL,
                              community_id INTEGER NOT NULL,
                              created_at TEXT NOT NULL,
                              FOREIGN KEY (post_id) REFERENCES posts(id),
                              FOREIGN KEY (username) REFERENCES users(username),
                              FOREIGN KEY (community_id) REFERENCES communities(id),
                              UNIQUE(username, post_id))''')
                conn.commit()
                logger.info("Created key_posts table successfully")
                return jsonify({'success': True, 'message': 'Key Posts table created successfully'})
            else:
                return jsonify({'success': True, 'message': 'Key Posts table already exists'})
    except Exception as e:
        logger.error(f"Error creating key_posts table: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/migrate_username_types', methods=['POST'])
def migrate_username_types():
    """Migrate username columns from TEXT to VARCHAR(191) for MySQL compatibility - no login required"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Check current username column types
            try:
                if USE_MYSQL:
                    # Check users table username type
                    c.execute("SHOW COLUMNS FROM users WHERE Field='username'")
                    users_col = c.fetchone()
                    users_username_type = users_col['Type'] if users_col else None

                    # Check messages table sender type
                    c.execute("SHOW COLUMNS FROM messages WHERE Field='sender'")
                    messages_col = c.fetchone()
                    messages_sender_type = messages_col['Type'] if messages_col else None

                    # Check if key_posts table exists
                    c.execute("SHOW TABLES LIKE 'key_posts'")
                    key_posts_exists = c.fetchone() is not None

                    logger.info(f"Current username types - Users: {users_username_type}, Messages sender: {messages_sender_type}, Key Posts exists: {key_posts_exists}")

                    needs_migration = False
                    if users_username_type and 'text' in users_username_type.lower():
                        needs_migration = True
                        logger.info("Found TEXT username in users table, migration needed")

                    if messages_sender_type and 'text' in messages_sender_type.lower():
                        needs_migration = True
                        logger.info("Found TEXT username in messages table, migration needed")

                    if needs_migration:
                        logger.info("Starting username column migration...")

                        # Step 1: Drop key_posts table if it exists (we'll recreate it)
                        if key_posts_exists:
                            logger.info("Dropping existing key_posts table...")
                            c.execute("DROP TABLE key_posts")
                            logger.info("key_posts table dropped")

                        # Step 2: Drop foreign key constraints temporarily
                        logger.info("Dropping foreign key constraints...")
                        try:
                            c.execute("ALTER TABLE messages DROP FOREIGN KEY messages_ibfk_1")
                        except:
                            logger.info("messages_ibfk_1 constraint not found or already dropped")

                        try:
                            c.execute("ALTER TABLE messages DROP FOREIGN KEY messages_ibfk_2")
                        except:
                            logger.info("messages_ibfk_2 constraint not found or already dropped")

                        try:
                            c.execute("ALTER TABLE password_reset_tokens DROP FOREIGN KEY password_reset_tokens_ibfk_1")
                        except:
                            logger.info("password_reset_tokens_ibfk_1 constraint not found or already dropped")

                        # Step 3: Alter username columns to VARCHAR(191)
                        logger.info("Altering username columns to VARCHAR(191)...")

                        # Alter users table
                        if users_username_type and 'text' in users_username_type.lower():
                            c.execute("ALTER TABLE users MODIFY COLUMN username VARCHAR(191) NOT NULL")

                        # Alter messages table
                        if messages_sender_type and 'text' in messages_sender_type.lower():
                            c.execute("ALTER TABLE messages MODIFY COLUMN sender VARCHAR(191) NOT NULL")
                            c.execute("ALTER TABLE messages MODIFY COLUMN receiver VARCHAR(191) NOT NULL")

                        # Alter other tables
                        c.execute("ALTER TABLE api_usage MODIFY COLUMN username VARCHAR(191)")
                        c.execute("ALTER TABLE saved_data MODIFY COLUMN username VARCHAR(191)")
                        c.execute("ALTER TABLE push_subscriptions MODIFY COLUMN username VARCHAR(191) NOT NULL")
                        c.execute("ALTER TABLE remember_tokens MODIFY COLUMN username VARCHAR(191) NOT NULL")
                        c.execute("ALTER TABLE password_reset_tokens MODIFY COLUMN username VARCHAR(191) NOT NULL")

                        # Step 4: Recreate foreign key constraints
                        logger.info("Recreating foreign key constraints...")
                        c.execute("ALTER TABLE messages ADD CONSTRAINT messages_ibfk_1 FOREIGN KEY (sender) REFERENCES users(username)")
                        c.execute("ALTER TABLE messages ADD CONSTRAINT messages_ibfk_2 FOREIGN KEY (receiver) REFERENCES users(username)")
                        c.execute("ALTER TABLE password_reset_tokens ADD CONSTRAINT password_reset_tokens_ibfk_1 FOREIGN KEY (username) REFERENCES users(username)")

                        # Step 5: Recreate key_posts table
                        logger.info("Recreating key_posts table...")
                        c.execute('''CREATE TABLE key_posts
                                     (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                      username VARCHAR(191) NOT NULL,
                                      post_id INTEGER NOT NULL,
                                      community_id INTEGER NOT NULL,
                                      created_at TEXT NOT NULL,
                                      FOREIGN KEY (post_id) REFERENCES posts(id),
                                      FOREIGN KEY (username) REFERENCES users(username),
                                      FOREIGN KEY (community_id) REFERENCES communities(id),
                                      UNIQUE(username, post_id))''')

                        conn.commit()
                        logger.info("Username column migration completed successfully")
                        return jsonify({'success': True, 'message': 'Username columns migrated and key_posts table recreated successfully'})

                    else:
                        # Check if we need to create key_posts table
                        if not key_posts_exists:
                            logger.info("Creating key_posts table...")
                            c.execute('''CREATE TABLE key_posts
                                         (id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                          username VARCHAR(191) NOT NULL,
                                          post_id INTEGER NOT NULL,
                                          community_id INTEGER NOT NULL,
                                          created_at TEXT NOT NULL,
                                          FOREIGN KEY (post_id) REFERENCES posts(id),
                                          FOREIGN KEY (username) REFERENCES users(username),
                                          FOREIGN KEY (community_id) REFERENCES communities(id),
                                          UNIQUE(username, post_id))''')
                            conn.commit()
                            logger.info("key_posts table created successfully")
                            return jsonify({'success': True, 'message': 'Key Posts table created successfully'})

                        return jsonify({'success': True, 'message': 'All username columns are already VARCHAR(191) and tables are properly configured'})

                else:
                    logger.info("Using SQLite - no migration needed for username types")
                    # For SQLite, just create key_posts table if it doesn't exist
                    c.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='key_posts'")
                    if not c.fetchone():
                        logger.info("Creating key_posts table for SQLite...")
                        c.execute('''CREATE TABLE key_posts
                                     (id INTEGER PRIMARY KEY AUTOINCREMENT,
                                      username VARCHAR(191) NOT NULL,
                                      post_id INTEGER NOT NULL,
                                      community_id INTEGER NOT NULL,
                                      created_at TEXT NOT NULL,
                                      FOREIGN KEY (post_id) REFERENCES posts(id),
                                      FOREIGN KEY (username) REFERENCES users(username),
                                      FOREIGN KEY (community_id) REFERENCES communities(id),
                                      UNIQUE(username, post_id))''')
                        conn.commit()
                        logger.info("key_posts table created successfully")
                        return jsonify({'success': True, 'message': 'Key Posts table created for SQLite'})

                    return jsonify({'success': True, 'message': 'Key Posts table already exists in SQLite'})

            except Exception as inner_e:
                logger.error(f"Error during username migration: {inner_e}")
                return jsonify({'success': False, 'error': str(inner_e)})

    except Exception as e:
        logger.error(f"Error in username migration: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/debug_community/<int:community_id>')
@login_required
def debug_community(community_id):
    """Debug route to check community data"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get community info
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'})
            
            community_dict = dict(community)
            logger.info(f"Debug community {community_id}: {community_dict}")
            
            return jsonify({
                'success': True,
                'community': community_dict,
                'community_id_type': type(community_dict.get('id')),
                'community_id_value': community_dict.get('id')
            })
    except Exception as e:
        logger.error(f"Error in debug_community: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/debug_posts')
@login_required
def debug_posts():
    """Debug route to check posts in database"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check posts table structure
            c.execute("SHOW COLUMNS FROM posts")
            columns = c.fetchall()
            logger.info("Posts table structure:")
            for col in columns:
                logger.info(f"  {col['Field']}: {col['Type']}")
            
            # Get all posts
            c.execute("SELECT id, username, content, community_id FROM posts ORDER BY id DESC LIMIT 10")
            posts = c.fetchall()
            logger.info(f"Recent posts in database:")
            for post in posts:
                logger.info(f"  Post {post['id']}: {post['username']} - {post['content'][:50]}... (community_id: {post['community_id']})")
            
            return jsonify({
                'success': True,
                'posts': [dict(post) for post in posts],
                'columns': [dict(col) for col in columns]
            })
    except Exception as e:
        logger.error(f"Error in debug_posts: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/invitation/verify', methods=['GET'])
def verify_invitation():
    """Verify invitation token and return invitation details"""
    token = request.args.get('token', '').strip()
    
    if not token:
        return jsonify({'success': False, 'error': 'Token required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT ci.id, ci.community_id, ci.invited_email, ci.used,
                       c.name as community_name, ci.invited_by_username
                FROM community_invitations ci
                JOIN communities c ON ci.community_id = c.id
                WHERE ci.token = ?
            """, (token,))
            
            invitation = c.fetchone()
            
            if not invitation:
                return jsonify({'success': False, 'error': 'Invalid invitation'}), 404
            
            used = invitation['used'] if hasattr(invitation, 'keys') else invitation[3]
            if used:
                return jsonify({'success': False, 'error': 'Invitation already used'}), 400
            
            return jsonify({
                'success': True,
                'email': invitation['invited_email'] if hasattr(invitation, 'keys') else invitation[2],
                'community_name': invitation['community_name'] if hasattr(invitation, 'keys') else invitation[4],
                'invited_by': invitation['invited_by_username'] if hasattr(invitation, 'keys') else invitation[5],
                'community_id': invitation['community_id'] if hasattr(invitation, 'keys') else invitation[1],
            })
            
    except Exception as e:
        logger.error(f"Error verifying invitation: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/api/community/invite_link', methods=['POST'])
@login_required
def generate_invite_link():
    """Generate an invitation link for QR code sharing (admin only)"""
    username = session.get('username')
    data = request.get_json() or {}
    
    community_id = data.get('community_id')
    
    if not community_id:
        return jsonify({'success': False, 'error': 'Community ID required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is admin of this community
            c.execute("SELECT id FROM users WHERE username = ?", (username,))
            user_row = c.fetchone()
            if not user_row:
                return jsonify({'success': False, 'error': 'User not found'}), 404
            user_id = user_row['id'] if hasattr(user_row, 'keys') else user_row[0]
            
            c.execute("""
                SELECT c.name, c.creator_username, uc.role
                FROM communities c
                LEFT JOIN user_communities uc ON c.id = uc.community_id AND uc.user_id = ?
                WHERE c.id = ?
            """, (user_id, community_id))
            
            community = c.fetchone()
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            community_name = community['name'] if hasattr(community, 'keys') else community[0]
            creator = community['creator_username'] if hasattr(community, 'keys') else community[1]
            role = community['role'] if hasattr(community, 'keys') else community[2]
            
            # Check if user is admin or creator
            is_admin = (username == creator) or (role == 'admin')
            if not is_admin:
                return jsonify({'success': False, 'error': 'Only community admins can generate invite links'}), 403
            
            # Generate unique token (use generic email for QR code invites)
            import secrets
            token = secrets.token_urlsafe(32)
            
            include_nested_ids = normalize_id_list(data.get('include_nested_ids', []))
            raw_parent_payload = data.get('include_parent_ids', None)
            include_parent_ids = None if raw_parent_payload is None else normalize_id_list(raw_parent_payload)
            parent_ids_to_join = include_parent_ids if include_parent_ids is not None else get_parent_chain_ids(c, community_id)
            
            # Store invitation with placeholder email
            c.execute("""
                INSERT INTO community_invitations (community_id, invited_email, invited_by_username, token, include_nested_ids, include_parent_ids)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                community_id,
                f'qr-invite-{token[:8]}@placeholder.local',
                username,
                token,
                json.dumps(include_nested_ids),
                json.dumps(parent_ids_to_join)
            ))
            conn.commit()
            
            # Generate invitation URL (to login page for both existing and new users)
            base_url = PUBLIC_BASE_URL or request.host_url.rstrip('/')
            invite_url = f"{base_url}/login?invite={token}"
            
            return jsonify({
                'success': True, 
                'invite_url': invite_url,
                'community_name': community_name
            })
            
    except Exception as e:
        logger.error(f"Error generating invite link: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': 'Server error'}), 500

def notify_community_new_member(community_id, new_username, conn):
    """Send notifications to all community members when a new member joins (if enabled)"""
    try:
        c = conn.cursor()
        
        # Check if community has notify_on_new_member enabled
        c.execute(f"SELECT name, notify_on_new_member FROM communities WHERE id = {get_sql_placeholder()}", (community_id,))
        comm_row = c.fetchone()
        if not comm_row:
            return
        
        community_name = comm_row['name'] if hasattr(comm_row, 'keys') else comm_row[0]
        should_notify = comm_row['notify_on_new_member'] if hasattr(comm_row, 'keys') else comm_row[1]
        
        if not should_notify:
            logger.info(f"Notifications disabled for community {community_id}, skipping new member notification")
            return
        
        # Get all existing members of the community (excluding the new joiner)
        c.execute(f"""
            SELECT DISTINCT u.username
            FROM user_communities uc
            JOIN users u ON uc.user_id = u.id
            WHERE uc.community_id = {get_sql_placeholder()} AND u.username != {get_sql_placeholder()}
        """, (community_id, new_username))
        
        existing_members = c.fetchall()
        
        # Send notification to each existing member
        notif_ph = ', '.join([get_sql_placeholder()] * 6)
        for member in existing_members:
            member_username = member['username'] if hasattr(member, 'keys') else member[0]
            try:
                c.execute(f"""
                    INSERT INTO notifications (user_id, from_user, type, community_id, message, link)
                    VALUES ({notif_ph})
                """, (
                    member_username,
                    new_username,
                    'new_member',
                    community_id,
                    f'{new_username} just joined "{community_name}". Say hi! üëã',
                    f'/community_feed/{community_id}'
                ))
            except Exception as member_notify_err:
                logger.warning(f"Failed to notify {member_username} about new member: {member_notify_err}")
        
        logger.info(f"Sent new member notifications to {len(existing_members)} members in {community_name}")
        
    except Exception as e:
        logger.error(f"Error sending new member notifications: {e}", exc_info=True)


@app.route('/api/join_with_invite', methods=['POST'])
@login_required
def join_with_invite():
    """Join a community using an invitation token (for existing users)"""
    username = session.get('username')
    data = request.get_json() or {}
    invite_token = data.get('invite_token', '').strip()
    
    if not invite_token:
        return jsonify({'success': False, 'error': 'Invitation token required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get user ID and email
            c.execute("SELECT id, email FROM users WHERE username = ?", (username,))
            user_row = c.fetchone()
            if not user_row:
                return jsonify({'success': False, 'error': 'User not found'}), 404
            user_id = user_row['id'] if hasattr(user_row, 'keys') else user_row[0]
            user_email = user_row['email'] if hasattr(user_row, 'keys') else user_row[1]
            
            # Get invitation with invited email
            c.execute("""
                SELECT ci.id, ci.community_id, ci.used, ci.invited_email, c.name as community_name,
                       ci.include_nested_ids, ci.include_parent_ids
                FROM community_invitations ci
                JOIN communities c ON ci.community_id = c.id
                WHERE ci.token = ?
            """, (invite_token,))
            
            invitation = c.fetchone()
            if not invitation:
                return jsonify({'success': False, 'error': 'Invalid invitation'}), 404
            
            invitation_id = invitation['id'] if hasattr(invitation, 'keys') else invitation[0]
            community_id = invitation['community_id'] if hasattr(invitation, 'keys') else invitation[1]
            used = invitation['used'] if hasattr(invitation, 'keys') else invitation[2]
            invited_email = invitation['invited_email'] if hasattr(invitation, 'keys') else invitation[3]
            community_name = invitation['community_name'] if hasattr(invitation, 'keys') else invitation[4]
            raw_nested_values = invitation['include_nested_ids'] if hasattr(invitation, 'keys') else (invitation[5] if len(invitation) > 5 else None)
            raw_parent_values = invitation['include_parent_ids'] if hasattr(invitation, 'keys') else (invitation[6] if len(invitation) > 6 else None)
            
            if used:
                return jsonify({'success': False, 'error': 'Invitation already used'}), 400
            
            # Security check: verify the logged-in user's email matches the invited email
            # Skip check for QR code invitations (placeholder emails)
            is_qr_invite = invited_email and invited_email.startswith('qr-invite-') and invited_email.endswith('@placeholder.local')
            if not is_qr_invite:
                if user_email.lower() != invited_email.lower():
                    return jsonify({'success': False, 'error': 'This invitation was sent to a different email address'}), 403
            
            # Check if already a member
            c.execute("SELECT 1 FROM user_communities WHERE user_id = ? AND community_id = ?", 
                     (user_id, community_id))
            if c.fetchone():
                return jsonify({'success': False, 'error': 'You are already a member of this community'}), 400
            
            nested_ids = normalize_id_list(raw_nested_values) if raw_nested_values else []
            parent_ids_to_join = normalize_id_list(raw_parent_values) if raw_parent_values is not None else get_parent_chain_ids(c, community_id)

            communities_to_join: List[int] = []
            seen: Set[int] = set()

            def add_community(target_id: Optional[int]):
                if not target_id:
                    return
                if target_id not in seen:
                    seen.add(target_id)
                    communities_to_join.append(target_id)

            add_community(community_id)
            for pid in parent_ids_to_join:
                add_community(pid)
            for nid in nested_ids:
                add_community(nid)
                for ancestor_id in get_parent_chain_ids(c, nid):
                    add_community(ancestor_id)

            # Join all communities (primary + selected extras)
            for comm_id in communities_to_join:
                # Check if already a member
                c.execute("SELECT 1 FROM user_communities WHERE user_id = ? AND community_id = ?", (user_id, comm_id))
                if not c.fetchone():
                    try:
                        add_user_to_community(c, user_id, int(comm_id), role='member')
                    except CommunityMembershipLimitError as limit_err:
                        conn.rollback()
                        return jsonify({'success': False, 'error': str(limit_err)}), 403
            
            # Mark invitation as used
            c.execute("""
                UPDATE community_invitations 
                SET used = 1, used_at = ?
                WHERE id = ?
            """, (datetime.now().isoformat(), invitation_id))
            
            # Send notifications to community admins/owners
            notify_community_new_member(community_id, username, conn)
            
            conn.commit()
            
            # Invalidate dashboard cache so new community appears immediately
            invalidate_user_cache(username)
            logger.info(f"Invalidated dashboard cache for {username} after joining via invite")
            
            return jsonify({
                'success': True, 
                'community_id': community_id,
                'community_name': community_name,
                'message': f'Successfully joined {community_name}'
            })
            
    except Exception as e:
        logger.error(f"Error joining with invite: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/invite_info', methods=['POST'])
@login_required
def get_invite_info():
    """Get information about an invitation token (without joining)"""
    data = request.get_json() or {}
    invite_token = data.get('invite_token', '').strip()
    
    if not invite_token:
        return jsonify({'success': False, 'error': 'Invitation token required'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get invitation info
            c.execute("""
                SELECT ci.community_id, c.name as community_name, ci.used
                FROM community_invitations ci
                JOIN communities c ON ci.community_id = c.id
                WHERE ci.token = ?
            """, (invite_token,))
            
            invitation = c.fetchone()
            if not invitation:
                return jsonify({'success': False, 'error': 'Invalid invitation'}), 404
            
            community_id = invitation['community_id'] if hasattr(invitation, 'keys') else invitation[0]
            community_name = invitation['community_name'] if hasattr(invitation, 'keys') else invitation[1]
            
            return jsonify({
                'success': True,
                'community_id': community_id,
                'community_name': community_name
            })
            
    except Exception as e:
        logger.error(f"Error getting invite info: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community/invite', methods=['POST'])
@login_required
def invite_to_community():
    """Send email invitation to join a community (admin only)"""
    username = session.get('username')
    data = request.get_json() or {}
    
    community_id = data.get('community_id')
    invited_email = data.get('email', '').strip().lower()
    
    if not community_id or not invited_email:
        return jsonify({'success': False, 'error': 'Community ID and email are required'}), 400
    
    # Validate email format
    import re
    email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    if not re.match(email_pattern, invited_email):
        return jsonify({'success': False, 'error': 'Invalid email format'}), 400
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Check if user is admin of this community
            # First get user_id
            c.execute("SELECT id FROM users WHERE username = ?", (username,))
            user_row = c.fetchone()
            if not user_row:
                return jsonify({'success': False, 'error': 'User not found'}), 404
            user_id = user_row['id'] if hasattr(user_row, 'keys') else user_row[0]
            
            c.execute("""
                SELECT c.name, c.creator_username, uc.role
                FROM communities c
                LEFT JOIN user_communities uc ON c.id = uc.community_id AND uc.user_id = ?
                WHERE c.id = ?
            """, (user_id, community_id))
            
            community = c.fetchone()
            if not community:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            community_name = community['name'] if hasattr(community, 'keys') else community[0]
            creator = community['creator_username'] if hasattr(community, 'keys') else community[1]
            role = community['role'] if hasattr(community, 'keys') else community[2]
            
            # Check if user is admin or creator
            is_admin = (username == creator) or (role == 'admin')
            if not is_admin:
                return jsonify({'success': False, 'error': 'Only community admins can send invitations'}), 403
            
            # Extract nested/parent selections from payload
            include_nested_ids = normalize_id_list(data.get('include_nested_ids', []))
            raw_parent_payload = data.get('include_parent_ids', None)
            include_parent_ids = None if raw_parent_payload is None else normalize_id_list(raw_parent_payload)

            # Check if user already exists
            c.execute("SELECT id, username FROM users WHERE email = ?", (invited_email,))
            existing_user = c.fetchone()
            
            if existing_user:
                # User exists - add them directly to the community
                existing_user_id = existing_user['id'] if hasattr(existing_user, 'keys') else existing_user[0]
                existing_username = existing_user['username'] if hasattr(existing_user, 'keys') else existing_user[1]
                
                # Check if already a member
                c.execute("SELECT 1 FROM user_communities WHERE community_id = ? AND user_id = ?", 
                         (community_id, existing_user_id))
                if c.fetchone():
                    return jsonify({'success': False, 'error': 'User is already a member of this community'}), 400
                
                # Determine parent communities to include
                parent_ids_to_join = include_parent_ids if include_parent_ids is not None else get_parent_chain_ids(c, community_id)

                # Build complete membership list (primary, selected parents, nested + their ancestors)
                communities_to_join: List[int] = []
                seen: Set[int] = set()

                def add_community(target_id: Optional[int]):
                    if not target_id:
                        return
                    if target_id not in seen:
                        seen.add(target_id)
                        communities_to_join.append(target_id)

                add_community(community_id)
                for pid in parent_ids_to_join:
                    add_community(pid)
                for nid in include_nested_ids:
                    add_community(nid)
                    for ancestor_id in get_parent_chain_ids(c, nid):
                        add_community(ancestor_id)

                # Join all communities (primary + selected extras)
                for comm_id in communities_to_join:
                    # Check if already a member
                    c.execute("SELECT 1 FROM user_communities WHERE user_id = ? AND community_id = ?", (existing_user_id, comm_id))
                    if not c.fetchone():
                        try:
                            add_user_to_community(c, existing_user_id, int(comm_id), role='member')
                        except CommunityMembershipLimitError as limit_err:
                            conn.rollback()
                            return jsonify({'success': False, 'error': str(limit_err)}), 403
                
                conn.commit()
                
                nested_names = fetch_community_names(c, include_nested_ids)
                nested_html_section = ""
                nested_text_section = ""
                if nested_names:
                    nested_items = ''.join(f"<li style='margin-bottom: 6px;'>{name}</li>" for name in nested_names)
                    nested_html_section = (
                        "<div style=\"margin: 24px 0; padding: 18px; background-color: rgba(77, 182, 172, 0.08); "
                        "border: 1px solid rgba(77, 182, 172, 0.35); border-radius: 12px;\">"
                        "<div style=\"font-size: 13px; text-transform: uppercase; letter-spacing: 0.08em; "
                        "color: #4db6ac; margin-bottom: 10px;\">You're also joining</div>"
                        f"<ul style=\"margin: 0; padding-left: 20px; color: #d0d0d0; font-size: 14px; line-height: 1.55;\">{nested_items}</ul>"
                        "</div>"
                    )
                    nested_text_section = "\nYou're also joining:\n" + ''.join(f"- {name}\n" for name in nested_names)

                # Send notification email (not signup invitation)
                html = f"""
                <!DOCTYPE html>
                <html>
                <head>
                    <meta charset="UTF-8">
                    <meta name="viewport" content="width=device-width, initial-scale=1.0">
                </head>
                <body style="margin: 0; padding: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; background-color: #000000;">
                    <table width="100%" cellpadding="0" cellspacing="0" style="background-color: #000000;">
                        <tr>
                            <td align="center" style="padding: 40px 20px;">
                                <table width="600" cellpadding="0" cellspacing="0" style="background-color: #1a1a1a; border-radius: 12px; overflow: hidden; max-width: 100%;">
                                    <tr>
                                        <td style="background: linear-gradient(135deg, #4db6ac 0%, #26a69a 100%); padding: 30px; text-align: center;">
                                            <h1 style="margin: 0; color: #000000; font-size: 28px; font-weight: 700;">
                                                You've Been Added!
                                            </h1>
                                        </td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 40px 30px; color: #ffffff;">
                                            <p style="margin: 0 0 20px 0; font-size: 16px; line-height: 1.6;">
                                                <strong>{username}</strong> has added you to <strong style="color: #4db6ac;">{community_name}</strong> on C.Point.
                                            </p>
                                             {nested_html_section}
                                             <p style="margin: 0 0 30px 0; font-size: 16px; line-height: 1.6; color: #b0b0b0;">
                                                You can now access this community and start connecting with other members.
                                            </p>
                                            <table width="100%" cellpadding="0" cellspacing="0">
                                                <tr>
                                                    <td align="center" style="padding: 10px 0;">
                                                        <a href="https://www.c-point.co/login" style="display: inline-block; padding: 16px 40px; background-color: #4db6ac; color: #000000; text-decoration: none; font-weight: 600; font-size: 16px; border-radius: 8px;">
                                                            Go to C.Point
                                                        </a>
                                                    </td>
                                                </tr>
                                            </table>
                                        </td>
                                    </tr>
                                    <tr>
                                        <td style="padding: 20px 30px; border-top: 1px solid #2a2a2a; text-align: center;">
                                            <p style="margin: 0; font-size: 12px; color: #808080;">
                                                ¬© 2025 C.Point. All rights reserved.
                                            </p>
                                        </td>
                                    </tr>
                                </table>
                            </td>
                        </tr>
                    </table>
                </body>
                </html>
                """
                
                text = f"""
You've Been Added to {community_name}

  {username} has added you to {community_name} on C.Point.{nested_text_section}
 
You can now access this community and start connecting with other members.

Go to C.Point: https://www.c-point.co/login

¬© 2025 C.Point. All rights reserved.
                """
                
                # Send notification email
                success = _send_email_via_resend(
                    to_email=invited_email,
                    subject=f"You've been added to {community_name} on C.Point",
                    html=html,
                    text=text
                )
                
                if not success:
                    return jsonify({'success': False, 'error': 'Failed to send notification email'}), 500
                
                return jsonify({'success': True, 'message': f'User added to {community_name} and notified'})
            
            else:
                # User doesn't exist - send signup invitation
                # Clean up any old unused invitations for this email (from deleted accounts)
                c.execute("""
                    DELETE FROM community_invitations 
                    WHERE community_id = ? AND invited_email = ? AND used = 0
                """, (community_id, invited_email))
                conn.commit()
                
                # Generate unique token
                import secrets
                token = secrets.token_urlsafe(32)
                
                parent_ids_to_join = include_parent_ids if include_parent_ids is not None else get_parent_chain_ids(c, community_id)
                nested_names = fetch_community_names(c, include_nested_ids)
                nested_html_section = ""
                nested_text_section = ""
                if nested_names:
                    nested_items = ''.join(f"<li style='margin-bottom: 6px;'>{name}</li>" for name in nested_names)
                    nested_html_section = (
                        "<div style=\"margin: 24px 0; padding: 18px; background-color: rgba(77, 182, 172, 0.08); "
                        "border: 1px solid rgba(77, 182, 172, 0.35); border-radius: 12px;\">"
                        "<div style=\"font-size: 13px; text-transform: uppercase; letter-spacing: 0.08em; "
                        "color: #4db6ac; margin-bottom: 10px;\">You'll also join</div>"
                        f"<ul style=\"margin: 0; padding-left: 20px; color: #d0d0d0; font-size: 14px; line-height: 1.55;\">{nested_items}</ul>"
                        "</div>"
                    )
                    nested_text_section = "\nYou'll also join:\n" + ''.join(f"- {name}\n" for name in nested_names)
                
                # Store invitation
                c.execute("""
                    INSERT INTO community_invitations (community_id, invited_email, invited_by_username, token, include_nested_ids, include_parent_ids)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (community_id, invited_email, username, token, json.dumps(include_nested_ids), json.dumps(parent_ids_to_join)))
                conn.commit()
                
                # Send invitation email with signup link
                # Use current domain or configured base URL
                base_url = PUBLIC_BASE_URL or request.host_url.rstrip('/')
                invite_url = f"{base_url}/signup?invite={token}"
            
            html = f"""
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
            </head>
            <body style="margin: 0; padding: 0; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif; background-color: #000000;">
                <table width="100%" cellpadding="0" cellspacing="0" style="background-color: #000000;">
                    <tr>
                        <td align="center" style="padding: 40px 20px;">
                            <table width="600" cellpadding="0" cellspacing="0" style="background-color: #1a1a1a; border-radius: 12px; overflow: hidden; max-width: 100%;">
                                <!-- Header -->
                                <tr>
                                    <td style="background: linear-gradient(135deg, #4db6ac 0%, #26a69a 100%); padding: 30px; text-align: center;">
                                        <h1 style="margin: 0; color: #000000; font-size: 28px; font-weight: 700;">
                                            Welcome to C.Point
                                        </h1>
                                    </td>
                                </tr>
                                
                                <!-- Body -->
                                <tr>
                                    <td style="padding: 40px 30px; color: #ffffff;">
                                        <p style="margin: 0 0 20px 0; font-size: 16px; line-height: 1.6;">
                                            You have been invited to join <strong style="color: #4db6ac;">{community_name}</strong> by <strong>{username}</strong>.
                                        </p>
                                        
                                        {nested_html_section}
                                        <p style="margin: 0 0 30px 0; font-size: 16px; line-height: 1.6; color: #b0b0b0;">
                                            C.Point is a community network where you can connect, share ideas, and engage in meaningful conversations.
                                        </p>
                                        
                                        <!-- Button -->
                                        <table width="100%" cellpadding="0" cellspacing="0">
                                            <tr>
                                                <td align="center" style="padding: 10px 0;">
                                                    <a href="{invite_url}" style="display: inline-block; padding: 16px 40px; background-color: #4db6ac; color: #000000; text-decoration: none; font-weight: 600; font-size: 16px; border-radius: 8px;">
                                                        Join {community_name}
                                                    </a>
                                                </td>
                                            </tr>
                                        </table>
                                        
                                        <p style="margin: 30px 0 0 0; font-size: 14px; line-height: 1.6; color: #808080;">
                                            If the button doesn't work, copy and paste this link into your browser:
                                        </p>
                                        <p style="margin: 10px 0 0 0; font-size: 13px; word-break: break-all; color: #4db6ac;">
                                            {invite_url}
                                        </p>
                                    </td>
                                </tr>
                                
                                <!-- Footer -->
                                <tr>
                                    <td style="padding: 20px 30px; border-top: 1px solid #2a2a2a; text-align: center;">
                                        <p style="margin: 0; font-size: 12px; color: #808080;">
                                            This invitation was sent by {username} from C.Point
                                        </p>
                                        <p style="margin: 10px 0 0 0; font-size: 12px; color: #606060;">
                                            ¬© 2025 C.Point. All rights reserved.
                                        </p>
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                </table>
            </body>
            </html>
            """
            
            text = f"""
Welcome to C.Point

  You have been invited to join {community_name} by {username}.{nested_text_section}
 
C.Point is a community network where you can connect, share ideas, and engage in meaningful conversations.

Click here to join: {invite_url}

Or copy and paste this link into your browser: {invite_url}

This invitation was sent by {username} from C.Point.
            """
            
            # Send email
            success = _send_email_via_resend(
                to_email=invited_email,
                subject=f"You're invited to join {community_name} on C.Point",
                html=html,
                text=text
            )
            
            if not success:
                return jsonify({'success': False, 'error': 'Failed to send invitation email'}), 500
            
            return jsonify({'success': True, 'message': 'Invitation sent successfully'})
            
    except Exception as e:
        logger.error(f"Error sending invitation: {str(e)}", exc_info=True)
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/leave_community', methods=['POST'])
@login_required
def leave_community():
    """Leave a community"""
    username = session.get('username')
    community_id = request.form.get('community_id')
    
    if not community_id:
        return jsonify({'success': False, 'error': 'Community ID is required'})
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get user ID
            c.execute("SELECT id FROM users WHERE username = ?", (username,))
            user = c.fetchone()
            if not user:
                return jsonify({'success': False, 'error': 'User not found'})
            
            user_id = user['id']
            
            # Check if user is a member
            c.execute("""
                SELECT id FROM user_communities 
                WHERE user_id = ? AND community_id = ?
            """, (user_id, community_id))
            
            membership = c.fetchone()
            if not membership:
                return jsonify({'success': False, 'error': 'You are not a member of this community'})
            
            # Check if user is the creator (creators cannot leave their own community)
            c.execute("SELECT creator_username FROM communities WHERE id = ?", (community_id,))
            community = c.fetchone()
            if community and community['creator_username'] == username:
                return jsonify({'success': False, 'error': 'Community creators cannot leave their own community. Delete the community instead.'})
            
            # Remove user from community
            c.execute("""
                DELETE FROM user_communities 
                WHERE user_id = ? AND community_id = ?
            """, (user_id, community_id))
            
            conn.commit()
            
            # Invalidate dashboard cache so left community disappears immediately
            invalidate_user_cache(username)
            logger.info(f"Invalidated dashboard cache for {username} after leaving community")
            
        return jsonify({'success': True, 'message': 'Successfully left the community'})
        
    except Exception as e:
        logger.error(f"Error leaving community: {str(e)}")
        return jsonify({'success': False, 'error': 'An error occurred while leaving the community'})

@app.route('/community_feed/<int:community_id>')
@login_required
def community_feed(community_id):
    """Community feed - redirect to React version for all devices"""
    return redirect(f'/community_feed_react/{community_id}')

# Old community_feed code removed - now using React version
def _old_community_feed_removed(community_id):
    """This function is disabled - kept for reference only"""
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Track community visit
            try:
                c.execute("""
                    INSERT INTO community_visit_history (username, community_id, visit_time)
                    VALUES (?, ?, ?)
                """, (username, community_id, datetime.now().isoformat()))
                conn.commit()
            except Exception as e:
                logger.error(f"Error tracking community visit: {e}")
            
            # Get community info
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community_row = c.fetchone()
            if not community_row:
                logger.error(f"Community with id {community_id} not found")
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            
            community = dict(community_row)
            
            # Check if community is deactivated
            if not community.get('is_active', True):
                # Allow admin to override with a parameter
                admin_override = request.args.get('admin_override') == 'true'
                if username != 'admin' or not admin_override:
                    # Show the deactivated notification page
                    return render_template('community_deactivated.html', 
                                         community=community, 
                                         username=username)
            
            # Get parent community info if it exists
            parent_community = None
            if community.get('parent_community_id'):
                c.execute("SELECT id, name, type FROM communities WHERE id = ?", (community['parent_community_id'],))
                parent_row = c.fetchone()
                if parent_row:
                    parent_community = dict(parent_row)
            
            # Get posts for this community
            c.execute("""
                SELECT * FROM posts 
                WHERE community_id = ? 
                ORDER BY id DESC
            """, (community_id,))
            posts_raw = c.fetchall()
            posts = [dict(row) for row in posts_raw]
            
            # Add reactions and replies to each post
            for post in posts:
                # Initialize reactions
                post['reactions'] = {}
                post['replies'] = []
                post['user_reaction'] = None
                
                # Fetch reactions for each post
                c.execute("""
                    SELECT reaction_type, COUNT(*) as count
                    FROM reactions
                    WHERE post_id = ?
                    GROUP BY reaction_type
                """, (post['id'],))
                reactions_raw = c.fetchall()
                post['reactions'] = {r['reaction_type']: r['count'] for r in reactions_raw}

                # Get the current logged-in user's reaction to this post
                c.execute("SELECT reaction_type FROM reactions WHERE post_id = ? AND username = ?", (post['id'], username))
                user_reaction_raw = c.fetchone()
                post['user_reaction'] = user_reaction_raw['reaction_type'] if user_reaction_raw else None

                # Fetch poll data for this post
                c.execute("SELECT * FROM polls WHERE post_id = ? AND is_active = 1", (post['id'],))
                poll_raw = c.fetchone()
                if poll_raw:
                    poll = dict(poll_raw)
                    # Fetch poll options
                    c.execute("SELECT * FROM poll_options WHERE poll_id = ? ORDER BY id", (poll['id'],))
                    options_raw = c.fetchall()
                    poll['options'] = [dict(option) for option in options_raw]
                    
                    # Get user's vote
                    c.execute("SELECT option_id FROM poll_votes WHERE poll_id = ? AND username = ?", (poll['id'], username))
                    user_vote_raw = c.fetchone()
                    poll['user_vote'] = user_vote_raw['option_id'] if user_vote_raw else None
                    
                    # Calculate total votes
                    total_votes = sum(option['votes'] for option in poll['options'])
                    poll['total_votes'] = total_votes
                    
                    post['poll'] = poll
                else:
                    post['poll'] = None

                # Fetch replies for each post
                # Do not include replies payload in feed list for performance; fetch on-demand on post detail
                post['replies'] = []
            
            # Get unread notification count (safely handle if table doesn't exist)
            unread_notifications = 0
            try:
                c.execute("""
                    SELECT COUNT(*) as count 
                    FROM notifications 
                    WHERE user_id = ? AND is_read = 0
                """, (username,))
                result = c.fetchone()
                if result:
                    unread_notifications = result['count']
            except Exception as e:
                logger.debug(f"Notifications table not available or error: {e}")
                unread_notifications = 0
            
            # Get unread message count
            unread_messages = 0
            try:
                c.execute("""
                    SELECT COUNT(DISTINCT sender) as count 
                    FROM messages 
                    WHERE receiver = ? AND is_read = 0
                """, (username,))
                result = c.fetchone()
                if result:
                    unread_messages = result['count']
            except Exception as e:
                logger.debug(f"Messages query error: {e}")
                unread_messages = 0
            
            # Check if user is a community admin
            is_community_admin_user = is_community_admin(username, community_id)
            
            return render_template('community_feed.html', 
                                posts=posts, 
                                community=community,
                                parent_community=parent_community,
                                username=username,
                                unread_notifications=unread_notifications,
                                unread_messages=unread_messages,
                                is_community_admin=is_community_admin_user)
            
    except Exception as e:
        logger.error(f"Error loading community feed: {str(e)}")
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        return jsonify({'success': False, 'error': f'Failed to load community feed: {str(e)}'}), 500



@app.errorhandler(500)
def internal_server_error(e):
    logger.error(f"Internal server error: {str(e)}")
    return render_template('error.html', error="An internal server error occurred. Please try again later."), 500

@app.errorhandler(404)
def not_found_error(e):
    logger.error(f"404 Not Found error: {str(e)}")
    return render_template('error.html', error="Page not found. Please check the URL or return to the homepage."), 404

# Add this after the existing routes, before the error handlers

# Uploads served by web server static mapping (/uploads -> static/uploads)

@app.route('/community_feed_smart/<int:community_id>')
@login_required
def community_feed_smart(community_id):
    """Serve HTML on desktop and React on mobile based on User-Agent."""
    try:
        ua = request.headers.get('User-Agent', '')
        is_mobile = any(k in ua for k in ['Mobi', 'Android', 'iPhone', 'iPad'])
        if is_mobile:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            dist_dir = os.path.join(base_dir, 'client', 'dist')
            return send_from_directory(dist_dir, 'index.html')
        # Fallback to HTML feed
        return redirect(url_for('community_feed', community_id=community_id))
    except Exception as e:
        logger.error(f"Error in community_feed_smart: {e}")
        abort(500)

# Fallback route for serving uploaded images if web server mapping is missing
@app.route('/uploads/<path:filename>')
def serve_uploads(filename):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        static_root = os.path.join(base_dir, 'static')
        static_uploads = os.path.join(static_root, 'uploads')
        legacy_root = os.path.join(base_dir, 'uploads')
        # Prefer the configured absolute uploads path
        configured_uploads = app.config.get('UPLOAD_FOLDER', static_uploads)

        normalized = filename
        if normalized.startswith('uploads/'):
            normalized = normalized.split('uploads/', 1)[1]
        basename = os.path.basename(normalized)

        candidates = [
            os.path.join(configured_uploads, filename),          # configured uploads/<original>
            os.path.join(configured_uploads, normalized),        # configured uploads/<stripped>
            os.path.join(configured_uploads, basename),          # configured uploads/<basename>
            os.path.join(static_uploads, filename),              # static/uploads/<original>
            os.path.join(static_uploads, normalized),            # static/uploads/<stripped>
            os.path.join(static_uploads, basename),              # static/uploads/<basename>
            os.path.join(static_root, filename),                 # static/<original>
            os.path.join(static_root, normalized),               # static/<stripped>
            os.path.join(static_root, basename),                 # static/<basename>
            os.path.join(static_root, 'message_photos', basename),      # static/message_photos/<basename>
            os.path.join(static_uploads, 'message_photos', basename),   # static/uploads/message_photos/<basename>
            os.path.join(legacy_root, filename),                 # uploads/<original>
            os.path.join(legacy_root, normalized),               # uploads/<stripped>
            os.path.join(legacy_root, basename),                 # uploads/<basename>
        ]

        tried = []
        for path in candidates:
            tried.append(path)
            try:
                if os.path.exists(path):
                    # Determine directory and relative filename for send_from_directory
                    dirpath = os.path.dirname(path)
                    relname = os.path.basename(path)
                    resp = send_from_directory(dirpath, relname)
                    try:
                        # Revert to original caching but with shorter time for audio
                        audio_extensions = ['.mp3', '.wav', '.ogg', '.m4a', '.webm', '.mp4', '.aac', '.3gp', '.3g2']
                        is_audio = any(relname.lower().endswith(ext) for ext in audio_extensions)

                        if is_audio:
                            # Audio files: short cache to help with Safari issues
                            resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour cache
                        else:
                            # Keep original caching for other files
                            resp.headers['Cache-Control'] = 'public, max-age=86400'
                    except Exception:
                        pass
                    return resp
            except Exception:
                continue

        missing_key = (filename or '').lower()
        if missing_key not in MISSING_UPLOAD_CACHE:
            logger.error(f"serve_uploads not found after fallbacks: {filename} | tried: {tried}")
            MISSING_UPLOAD_CACHE.append(missing_key)
        # Return a lightweight placeholder based on requested extension
        try:
            _, ext = os.path.splitext(basename.lower())
            transparent_pixel = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\nIDATx\x9cc\x00\x00\x00\x02\x00\x01\xe5\'\xde\xfc\x00\x00\x00\x00IEND\xaeB`\x82'
            audio_extensions = ('.mp3', '.wav', '.ogg', '.m4a', '.webm', '.mp4', '.aac', '.3gp', '.3g2')
            video_extensions = ('.mp4', '.webm', '.mov', '.mkv', '.avi')
            document_extensions = ('.pdf', '.doc', '.docx', '.ppt', '.pptx', '.xls', '.xlsx', '.txt')

            if ext in audio_extensions or ext in video_extensions:
                resp = Response(status=204)
                resp.headers['Cache-Control'] = 'public, max-age=3600'
                resp.headers['X-Missing-Upload'] = 'media'
                return resp

            if ext in document_extensions:
                resp = Response('', mimetype='text/plain')
                resp.headers['Cache-Control'] = 'public, max-age=3600'
                resp.headers['X-Missing-Upload'] = 'document'
                return resp

            resp = Response(transparent_pixel, mimetype='image/png')
            try:
                resp.headers['Cache-Control'] = 'public, max-age=300'
            except Exception:
                pass
            return resp
        except Exception:
            abort(404)
    except Exception as e:
        logger.error(f"serve_uploads error for {filename}: {e}")
        abort(404)
@app.route('/api/community_feed/<int:community_id>')
@login_required
def api_community_feed(community_id):
    """JSON API for community feed data (posts, polls, replies, reactions)."""
    username = session.get('username')
    cache_key = community_feed_user_cache_key(community_id, username or '')
    if cache_key:
        cached_response = cache.get(cache_key)
        if cached_response:
            return jsonify(cached_response)
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Community info
            c.execute("SELECT * FROM communities WHERE id = ?", (community_id,))
            community_row = c.fetchone()
            if not community_row:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            community = dict(community_row)
            community['allow_nsfw_imagine'] = bool(community.get('allow_nsfw_imagine')) if community.get('allow_nsfw_imagine') is not None else False

            # Parent community (optional) and root parent ID
            parent_community = None
            root_parent_id = None
            if community.get('parent_community_id'):
                c.execute("SELECT id, name, type FROM communities WHERE id = ?", (community['parent_community_id'],))
                parent_row = c.fetchone()
                if parent_row:
                    parent_community = dict(parent_row)
                
                # Find the root parent (top-level community with no parent)
                ancestors = get_community_ancestors(c, community_id)
                if ancestors:
                    # The last ancestor is the root (or self if no parent)
                    root = ancestors[-1]
                    root_parent_id = root.get('id') if root.get('parent_community_id') is None else None
                    # If root still has a parent, traverse up to find true root
                    if root_parent_id is None:
                        for anc in reversed(ancestors):
                            if anc.get('parent_community_id') is None:
                                root_parent_id = anc.get('id')
                                break
            else:
                # This community is already a root
                root_parent_id = community_id

            # Current user's profile picture
            try:
                c.execute("SELECT display_name, profile_picture FROM user_profiles WHERE username = ?", (username,))
                cupp = c.fetchone()
                current_user_profile_picture = cupp['profile_picture'] if cupp and 'profile_picture' in cupp.keys() else None
                current_user_display_name = cupp['display_name'] if cupp and 'display_name' in cupp.keys() and cupp['display_name'] else username
            except Exception:
                current_user_profile_picture = None
                current_user_display_name = username

            # Enforce membership to view this community
            # Allow: app admin, community creator, direct members, or admins of parent/ancestor communities
            try:
                if username != 'admin' and username != community.get('creator_username'):
                    # Check if direct member
                    c.execute("""
                        SELECT 1 FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE u.username = ? AND uc.community_id = ?
                        LIMIT 1
                    """, (username, community_id))
                    is_member = c.fetchone() is not None
                    
                    if not is_member:
                        # Not a direct member - check if admin of any ancestor community
                        has_ancestor_access = False
                        current_parent = community.get('parent_community_id')
                        
                        while current_parent:
                            # Check if user is admin or owner of this ancestor
                            c.execute("""
                                SELECT uc.role, c.creator_username
                                FROM user_communities uc
                                JOIN communities c ON uc.community_id = c.id
                                JOIN users u ON uc.user_id = u.id
                                WHERE u.username = ? AND c.id = ?
                            """, (username, current_parent))
                            ancestor_membership = c.fetchone()
                            
                            if ancestor_membership:
                                role = ancestor_membership['role'] if hasattr(ancestor_membership, 'keys') else ancestor_membership[0]
                                creator = ancestor_membership['creator_username'] if hasattr(ancestor_membership, 'keys') else ancestor_membership[1]
                                
                                if role in ('admin', 'owner') or username == creator:
                                    has_ancestor_access = True
                                    break
                            
                            # Move to next ancestor
                            c.execute("SELECT parent_community_id FROM communities WHERE id = ?", (current_parent,))
                            parent_row = c.fetchone()
                            current_parent = parent_row['parent_community_id'] if (parent_row and hasattr(parent_row, 'keys')) else (parent_row[0] if parent_row else None)
                        
                        if not has_ancestor_access:
                            return jsonify({'success': False, 'error': 'Forbidden'}), 403
            except Exception as me:
                logger.error(f"membership check failed on api_community_feed: {me}")
                return jsonify({'success': False, 'error': 'Access check failed'}), 500

            # Track visit as an activity (counts towards DAU/MAU)
            try:
                c.execute(
                    "INSERT INTO community_visit_history (username, community_id, visit_time) VALUES (?, ?, ?)",
                    (username, community_id, datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
                )
                conn.commit()
            except Exception:
                pass

            # Posts - OPTIMIZED with batch queries to avoid N+1 problem
            # Limit initial posts returned to reduce payload; clients can paginate if needed
            # Exclude posts with pending videos (talking avatar still generating)
            c.execute(
                """
                SELECT * FROM posts 
                WHERE community_id = ? 
                AND (video_path IS NULL OR video_path != 'pending')
                ORDER BY id DESC
                LIMIT 100
                """,
                (community_id,)
            )
            posts_raw = c.fetchall()
            posts = [dict(row) for row in posts_raw]
            post_ids = [post['id'] for post in posts]
            
            if not post_ids:
                # No posts - return early with empty list
                posts = []
            else:
                placeholders = ','.join([get_sql_placeholder()] * len(post_ids))
                
                # BATCH 1: Get all author usernames and fetch profile pictures in one query
                author_usernames = list(set(p['username'] for p in posts))
                if author_usernames:
                    author_placeholders = ','.join([get_sql_placeholder()] * len(author_usernames))
                    c.execute(f"SELECT username, profile_picture FROM user_profiles WHERE username IN ({author_placeholders})", tuple(author_usernames))
                    profile_pics = {row['username']: row['profile_picture'] for row in c.fetchall()}
                else:
                    profile_pics = {}
                
                # BATCH 2: Get all view counts in one query
                view_counts: Dict[int, int] = {}
                try:
                    params = list(post_ids) + ['admin']
                    c.execute(
                        f"SELECT post_id, COUNT(*) as cnt FROM post_views WHERE post_id IN ({placeholders}) AND LOWER(username) <> LOWER({get_sql_placeholder()}) GROUP BY post_id",
                        tuple(params),
                    )
                    for row in c.fetchall() or []:
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        cnt = row['cnt'] if hasattr(row, 'keys') else (row[1] if len(row) > 1 else 0)
                        view_counts[int(pid)] = int(cnt or 0)
                except Exception as e:
                    logger.warning(f"Failed to fetch post view counts: {e}")
                
                # BATCH 3: Get user viewed posts in one query
                user_viewed: Set[int] = set()
                try:
                    params = list(post_ids) + [username]
                    c.execute(f"SELECT post_id FROM post_views WHERE post_id IN ({placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                    for row in c.fetchall() or []:
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        user_viewed.add(int(pid))
                except Exception as e:
                    logger.warning(f"Failed to fetch user viewed posts: {e}")
                
                # BATCH 4: Get all reactions for all posts in one query
                post_reactions: Dict[int, Dict[str, int]] = {pid: {} for pid in post_ids}
                try:
                    c.execute(f"SELECT post_id, reaction_type, COUNT(*) as count FROM reactions WHERE post_id IN ({placeholders}) GROUP BY post_id, reaction_type", tuple(post_ids))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                        cnt = row['count'] if hasattr(row, 'keys') else row[2]
                        if pid in post_reactions:
                            post_reactions[pid][rtype] = cnt
                except Exception as e:
                    logger.warning(f"Failed to batch fetch reactions: {e}")
                
                # BATCH 5: Get user's reactions for all posts in one query
                user_reactions: Dict[int, str] = {}
                try:
                    params = list(post_ids) + [username]
                    c.execute(f"SELECT post_id, reaction_type FROM reactions WHERE post_id IN ({placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                        user_reactions[pid] = rtype
                except Exception as e:
                    logger.warning(f"Failed to batch fetch user reactions: {e}")
                
                # BATCH 6: Get user starred posts in one query
                user_starred: Set[int] = set()
                try:
                    params = list(post_ids) + [username]
                    c.execute(f"SELECT post_id FROM key_posts WHERE post_id IN ({placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        user_starred.add(pid)
                except Exception:
                    pass
                
                # BATCH 7: Get community starred posts in one query
                community_starred: Set[int] = set()
                try:
                    params = list(post_ids) + [community_id]
                    c.execute(f"SELECT post_id FROM community_key_posts WHERE post_id IN ({placeholders}) AND community_id = {get_sql_placeholder()}", tuple(params))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        community_starred.add(pid)
                except Exception:
                    pass
                
                # BATCH 8: Get all active polls for all posts in one query
                polls_by_post: Dict[int, dict] = {}
                try:
                    c.execute(f"SELECT * FROM polls WHERE post_id IN ({placeholders}) AND is_active = 1", tuple(post_ids))
                    for row in c.fetchall():
                        poll = dict(row)
                        polls_by_post[poll['post_id']] = poll
                except Exception:
                    pass
                
                # BATCH 9: Get all poll options for all polls
                if polls_by_post:
                    poll_ids = [p['id'] for p in polls_by_post.values()]
                    poll_placeholders = ','.join([get_sql_placeholder()] * len(poll_ids))
                    options_by_poll: Dict[int, list] = {pid: [] for pid in poll_ids}
                    try:
                        c.execute(f"SELECT * FROM poll_options WHERE poll_id IN ({poll_placeholders}) ORDER BY id", tuple(poll_ids))
                        for row in c.fetchall():
                            opt = dict(row)
                            if 'text' not in opt:
                                opt['text'] = opt.get('option_text', '')
                            if 'votes' not in opt:
                                opt['votes'] = 0
                            options_by_poll[opt['poll_id']].append(opt)
                    except Exception:
                        pass
                    
                    # BATCH 10: Get user votes for all polls
                    user_poll_votes: Dict[int, Set[int]] = {pid: set() for pid in poll_ids}
                    try:
                        params = list(poll_ids) + [username]
                        c.execute(f"SELECT poll_id, option_id FROM poll_votes WHERE poll_id IN ({poll_placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                        for row in c.fetchall():
                            poll_id = row['poll_id'] if hasattr(row, 'keys') else row[0]
                            opt_id = row['option_id'] if hasattr(row, 'keys') else row[1]
                            if poll_id in user_poll_votes:
                                user_poll_votes[poll_id].add(opt_id)
                    except Exception:
                        pass
                    
                    # Assemble polls with options
                    for post_id, poll in polls_by_post.items():
                        poll['options'] = options_by_poll.get(poll['id'], [])
                        voted_ids = user_poll_votes.get(poll['id'], set())
                        for opt in poll['options']:
                            opt['user_voted'] = opt['id'] in voted_ids
                        poll['user_vote'] = next(iter(voted_ids)) if voted_ids else None
                        poll['total_votes'] = sum(int(opt.get('votes', 0) or 0) for opt in poll['options'])
                
                # BATCH 11: Get all replies for all posts in one query
                replies_by_post: Dict[int, list] = {pid: [] for pid in post_ids}
                all_reply_ids: list = []
                reply_authors: Set[str] = set()
                try:
                    c.execute(f"SELECT * FROM replies WHERE post_id IN ({placeholders}) ORDER BY timestamp DESC", tuple(post_ids))
                    for row in c.fetchall():
                        reply = dict(row)
                        replies_by_post[reply['post_id']].append(reply)
                        all_reply_ids.append(reply['id'])
                        reply_authors.add(reply['username'])
                except Exception:
                    pass
                
                # BATCH 12: Get profile pictures for reply authors
                reply_profile_pics: Dict[str, str] = {}
                if reply_authors:
                    reply_author_list = list(reply_authors)
                    reply_author_placeholders = ','.join([get_sql_placeholder()] * len(reply_author_list))
                    try:
                        c.execute(f"SELECT username, profile_picture FROM user_profiles WHERE username IN ({reply_author_placeholders})", tuple(reply_author_list))
                        for row in c.fetchall():
                            reply_profile_pics[row['username']] = row['profile_picture']
                    except Exception:
                        pass
                
                # BATCH 13: Get all reply reactions
                reply_reactions: Dict[int, Dict[str, int]] = {rid: {} for rid in all_reply_ids}
                if all_reply_ids:
                    reply_placeholders = ','.join([get_sql_placeholder()] * len(all_reply_ids))
                    try:
                        c.execute(f"SELECT reply_id, reaction_type, COUNT(*) as count FROM reply_reactions WHERE reply_id IN ({reply_placeholders}) GROUP BY reply_id, reaction_type", tuple(all_reply_ids))
                        for row in c.fetchall():
                            rid = row['reply_id'] if hasattr(row, 'keys') else row[0]
                            rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                            cnt = row['count'] if hasattr(row, 'keys') else row[2]
                            if rid in reply_reactions:
                                reply_reactions[rid][rtype] = cnt
                    except Exception:
                        pass
                
                # BATCH 14: Get user's reply reactions
                user_reply_reactions: Dict[int, str] = {}
                if all_reply_ids:
                    try:
                        params = list(all_reply_ids) + [username]
                        c.execute(f"SELECT reply_id, reaction_type FROM reply_reactions WHERE reply_id IN ({reply_placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                        for row in c.fetchall():
                            rid = row['reply_id'] if hasattr(row, 'keys') else row[0]
                            rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                            user_reply_reactions[rid] = rtype
                    except Exception:
                        pass
                
                # Now enrich posts with all the batched data (no more individual queries!)
                for post in posts:
                    post_id = post['id']
                    
                    # Timestamp formatting
                    try:
                        raw_ts = (post.get('timestamp') or post.get('created_at') or '').strip()
                        if raw_ts and not raw_ts.startswith('0000-00-00'):
                            from datetime import datetime as _dt
                            dt = None
                            try:
                                dt = _dt.strptime(raw_ts[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                            except Exception:
                                for fmt in ('%d-%m-%Y %H:%M:%S','%d-%m-%Y %H:%M','%Y-%m-%d %H:%M','%m.%d.%y %H:%M','%Y-%m-%d','%Y-%m-%dT%H:%M:%S'):
                                    try:
                                        dt = _dt.strptime(raw_ts.replace('T',' '), fmt)
                                        break
                                    except Exception:
                                        continue
                            post['display_timestamp'] = dt.strftime('%Y-%m-%d %H:%M:%S') if dt else raw_ts[:19].replace('T',' ')
                        else:
                            post['display_timestamp'] = ''
                    except Exception:
                        post['display_timestamp'] = ''
                    
                    # Use batched data instead of individual queries
                    post['profile_picture'] = profile_pics.get(post['username'])
                    post['reactions'] = post_reactions.get(post_id, {})
                    post['user_reaction'] = user_reactions.get(post_id)
                    post['is_starred'] = post_id in user_starred
                    post['is_community_starred'] = post_id in community_starred
                    post['view_count'] = view_counts.get(post_id, 0)
                    post['has_viewed'] = post_id in user_viewed
                    post['poll'] = polls_by_post.get(post_id)
                    
                    # Enrich replies with batched data
                    post_replies = replies_by_post.get(post_id, [])
                    for reply in post_replies:
                        reply['profile_picture'] = reply_profile_pics.get(reply['username'])
                        reply['reactions'] = reply_reactions.get(reply['id'], {})
                        reply['user_reaction'] = user_reply_reactions.get(reply['id'])
                    post['replies'] = post_replies

            response_payload = {
                'success': True,
                'community': community,
                'parent_community': parent_community,
                'root_parent_id': root_parent_id,
                'username': username,
                'is_community_admin': is_community_admin(username, community_id),
                'current_user_profile_picture': current_user_profile_picture,
                'current_user_display_name': current_user_display_name,
                'posts': posts,
            }
            if cache_key:
                try:
                    cache.set(cache_key, response_payload, COMMUNITY_CACHE_TTL)
                except Exception:
                    pass
            return jsonify(response_payload)
    except Exception as e:
        logger.error(f"Error in api_community_feed for {community_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/api/post_view', methods=['POST'])
@login_required
def api_post_view():
    username = session.get('username')
    try:
        payload = request.get_json(silent=True) or {}
    except Exception:
        payload = {}
    post_id = payload.get('post_id')
    if not post_id:
        post_id = request.form.get('post_id', type=int)
    try:
        post_id = int(post_id)
    except Exception:
        return jsonify({'success': False, 'error': 'post_id required'}), 400

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT community_id, username FROM posts WHERE id = ?", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            community_id = row['community_id'] if hasattr(row, 'keys') else row[0]
            post_owner = row['username'] if hasattr(row, 'keys') else row[1]
            if community_id:
                if username not in ('admin', post_owner):
                    placeholder = get_sql_placeholder()
                    c.execute(f"""
                        SELECT 1 FROM user_communities uc
                        JOIN users u ON uc.user_id = u.id
                        WHERE u.username = {placeholder} AND uc.community_id = {placeholder}
                        LIMIT 1
                    """, (username, community_id))
                    if not c.fetchone():
                        return jsonify({'success': False, 'error': 'Forbidden'}), 403
            try:
                view_count = upsert_post_view(c, post_id, username)
                conn.commit()
            except Exception as view_err:
                logger.warning(f"Failed to record post view for {post_id}: {view_err}")
                view_count = None
            try:
                if community_id:
                    invalidate_community_cache(community_id)
            except Exception as e:
                logger.warning(f"Failed to invalidate cache for community {community_id}: {e}")
            return jsonify({'success': True, 'view_count': int(view_count or 0), 'post_id': post_id})
    except Exception as e:
        logger.error(f"Error saving post view for {post_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/api/community_stories/<int:community_id>')
@login_required
def api_community_stories(community_id: int):
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            ph = get_sql_placeholder()
            c.execute(
                f"SELECT id, name, creator_username, parent_community_id FROM communities WHERE id = {ph}",
                (community_id,),
            )
            community_row = c.fetchone()
            if not community_row:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            community_name = (
                community_row["name"]
                if hasattr(community_row, "keys")
                else (community_row[1] if len(community_row) > 1 else None)
            )
            creator_username = (
                community_row["creator_username"]
                if hasattr(community_row, "keys")
                else (community_row[2] if len(community_row) > 2 else None)
            )
            if not user_has_story_access(c, username, community_id, creator_username):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403

            now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
            c.execute(
                f"""
                SELECT cs.id, cs.community_id, cs.username, cs.media_path, cs.media_type,
                       cs.caption, cs.duration_seconds, cs.status, cs.created_at,
                       cs.expires_at, cs.view_count, cs.last_viewed_at, up.profile_picture,
                       cs.text_overlays, cs.location_data
                FROM community_stories cs
                LEFT JOIN user_profiles up ON up.username = cs.username
                WHERE cs.community_id = {ph}
                  AND cs.status = 'active'
                  AND cs.expires_at > {ph}
                ORDER BY cs.created_at DESC
                LIMIT 200
                """,
                (community_id, now_str),
            )
            rows = c.fetchall() or []
            story_ids = []
            for row in rows:
                if hasattr(row, "keys"):
                    story_ids.append(row.get("id"))
                else:
                    story_ids.append(row[0] if row else None)
            story_ids = [int(sid) for sid in story_ids if sid]

            viewed_ids: Set[int] = set()
            if story_ids:
                placeholders = ",".join([ph] * len(story_ids))
                params = list(story_ids) + [username]
                c.execute(
                    f"""
                    SELECT story_id FROM community_story_views
                    WHERE story_id IN ({placeholders}) AND LOWER(username) = LOWER({ph})
                    """,
                    tuple(params),
                )
                viewed_rows = c.fetchall() or []
                for vr in viewed_rows:
                    if hasattr(vr, "keys"):
                        viewed_ids.add(int(vr.get("story_id")))
                    else:
                        viewed_ids.add(int(vr[0]))

            reaction_counts, user_reactions = fetch_story_reaction_maps(c, story_ids, username)

            def _coerce_timestamp(value):
                if not value:
                    return None
                if isinstance(value, datetime):
                    return value.isoformat()
                return str(value)

            def _public_url(raw_path):
                if not raw_path:
                    return None
                # If already a full URL (CDN), return as-is
                if str(raw_path).startswith(('http://', 'https://')):
                    return raw_path
                norm = normalize_upload_reference(raw_path)
                return get_public_upload_url(norm) if norm else None

            groups_map: Dict[str, Dict[str, Any]] = {}
            stories_payload: List[Dict[str, Any]] = []
            for row in rows:
                if hasattr(row, "keys"):
                    story_id = row.get("id")
                    author = row.get("username")
                    media_path = row.get("media_path")
                    media_type = row.get("media_type")
                    caption = row.get("caption")
                    duration_seconds = row.get("duration_seconds")
                    created_at = row.get("created_at")
                    expires_at = row.get("expires_at")
                    view_count = row.get("view_count")
                    profile_picture = row.get("profile_picture")
                    text_overlays_raw = row.get("text_overlays")
                    location_data_raw = row.get("location_data")
                else:
                    story_id = row[0]
                    author = row[2] if len(row) > 2 else None
                    media_path = row[3] if len(row) > 3 else None
                    media_type = row[4] if len(row) > 4 else None
                    caption = row[5] if len(row) > 5 else None
                    duration_seconds = row[6] if len(row) > 6 else None
                    created_at = row[8] if len(row) > 8 else None
                    expires_at = row[9] if len(row) > 9 else None
                    view_count = row[10] if len(row) > 10 else 0
                    profile_picture = row[12] if len(row) > 12 else None
                    text_overlays_raw = row[13] if len(row) > 13 else None
                    location_data_raw = row[14] if len(row) > 14 else None
                if not story_id or not author:
                    continue
                story_id = int(story_id)
                has_viewed = story_id in viewed_ids
                
                # Parse JSON fields
                text_overlays = None
                if text_overlays_raw:
                    try:
                        text_overlays = json.loads(text_overlays_raw) if isinstance(text_overlays_raw, str) else text_overlays_raw
                    except Exception:
                        pass
                location_data = None
                if location_data_raw:
                    try:
                        location_data = json.loads(location_data_raw) if isinstance(location_data_raw, str) else location_data_raw
                    except Exception:
                        pass
                
                story_payload = {
                    'id': story_id,
                    'community_id': community_id,
                    'username': author,
                    'media_type': media_type or 'image',
                    'media_path': media_path,
                    'media_url': _public_url(media_path),
                    'caption': caption,
                    'duration_seconds': duration_seconds,
                    'created_at': _coerce_timestamp(created_at),
                    'expires_at': _coerce_timestamp(expires_at),
                    'view_count': int(view_count or 0),
                    'has_viewed': has_viewed,
                    'profile_picture': _public_url(profile_picture),
                    'reactions': reaction_counts.get(story_id, {}),
                    'user_reaction': user_reactions.get(story_id),
                    'text_overlays': text_overlays,
                    'location_data': location_data,
                }
                stories_payload.append(story_payload)
                group = groups_map.setdefault(
                    author,
                    {
                        'username': author,
                        'profile_picture': story_payload['profile_picture'],
                        'stories': [],
                        'has_unseen': False,
                    },
                )
                group['stories'].append(story_payload)
                if not has_viewed:
                    group['has_unseen'] = True

            groups = list(groups_map.values())
            groups.sort(
                key=lambda g: g['stories'][0]['created_at'] if g['stories'] else '',
                reverse=True,
            )
            return jsonify({
                'success': True,
                'community': {
                    'id': community_id,
                    'name': community_name,
                },
                'has_new': any(not story['has_viewed'] for story in stories_payload),
                'groups': groups,
                'stories': stories_payload,
            })
    except Exception as e:
        logger.error(f"Error loading community stories for {community_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_stories', methods=['POST'])
@login_required
def create_community_story():
    username = session.get('username')
    community_id = request.form.get('community_id', type=int)
    if not community_id:
        return jsonify({'success': False, 'error': 'community_id required'}), 400
    
    # Support multiple file uploads - check for 'media' (single) and 'media[]' (multiple)
    media_files = request.files.getlist('media') or request.files.getlist('media[]')
    single_media = request.files.get('media')
    if single_media and single_media.filename and not media_files:
        media_files = [single_media]
    
    if not media_files or all(not f.filename for f in media_files):
        return jsonify({'success': False, 'error': 'Media file(s) required'}), 400
    
    # Filter out empty files
    media_files = [f for f in media_files if f and f.filename]
    if not media_files:
        return jsonify({'success': False, 'error': 'Media file(s) required'}), 400
    
    # Parse shared metadata (caption, text_overlays, location_data)
    caption = (request.form.get('caption') or '').strip()
    if caption and len(caption) > STORY_MAX_CAPTION_LENGTH:
        caption = caption[:STORY_MAX_CAPTION_LENGTH]
    
    # Text overlays: JSON array of {text, x, y, fontSize, color, fontFamily, rotation}
    text_overlays_raw = request.form.get('text_overlays', '')
    text_overlays = None
    if text_overlays_raw:
        try:
            text_overlays = json.loads(text_overlays_raw)
            if not isinstance(text_overlays, list):
                text_overlays = None
        except Exception:
            text_overlays = None
    
    # Location data: JSON object {name, x, y}
    location_data_raw = request.form.get('location_data', '')
    location_data = None
    if location_data_raw:
        try:
            location_data = json.loads(location_data_raw)
            if not isinstance(location_data, dict):
                location_data = None
        except Exception:
            location_data = None
    
    # Per-file metadata (optional, JSON array matching files order)
    per_file_meta_raw = request.form.get('per_file_metadata', '')
    per_file_meta = []
    if per_file_meta_raw:
        try:
            per_file_meta = json.loads(per_file_meta_raw)
            if not isinstance(per_file_meta, list):
                per_file_meta = []
        except Exception:
            per_file_meta = []
    
    duration_seconds = request.form.get('duration_seconds', type=int)
    if isinstance(duration_seconds, int) and duration_seconds < 0:
        duration_seconds = None
    
    created_stories = []
    base_created_at = datetime.utcnow()
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            
            # Ensure new columns exist
            try:
                if USE_MYSQL:
                    c.execute("ALTER TABLE community_stories ADD COLUMN text_overlays JSON")
                else:
                    c.execute("ALTER TABLE community_stories ADD COLUMN text_overlays TEXT")
            except Exception:
                pass
            try:
                if USE_MYSQL:
                    c.execute("ALTER TABLE community_stories ADD COLUMN location_data JSON")
                else:
                    c.execute("ALTER TABLE community_stories ADD COLUMN location_data TEXT")
            except Exception:
                pass
            
            ph = get_sql_placeholder()
            c.execute(
                f"SELECT creator_username FROM communities WHERE id = {ph}",
                (community_id,),
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            creator_username = (
                row["creator_username"]
                if hasattr(row, "keys")
                else (row[0] if row else None)
            )
            if not user_has_story_access(c, username, community_id, creator_username):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            
            # Process each file
            for idx, media_file in enumerate(media_files):
                ext = os.path.splitext(media_file.filename)[1].lower().lstrip('.')
                if ext not in STORY_ALLOWED_EXTENSIONS:
                    continue  # Skip unsupported files
                
                media_type = 'image' if ext in STORY_IMAGE_EXTENSIONS else 'video'
                
                stored_path = save_uploaded_file(
                    media_file,
                    subfolder='community_stories',
                    allowed_extensions=STORY_ALLOWED_EXTENSIONS,
                )
                if not stored_path:
                    continue  # Skip files that fail to save
                
                # Get per-file metadata if provided
                file_caption = caption
                file_text_overlays = text_overlays
                file_location_data = location_data
                file_duration = duration_seconds
                
                if idx < len(per_file_meta) and isinstance(per_file_meta[idx], dict):
                    meta = per_file_meta[idx]
                    if 'caption' in meta:
                        file_caption = str(meta['caption'])[:STORY_MAX_CAPTION_LENGTH]
                    if 'text_overlays' in meta and isinstance(meta['text_overlays'], list):
                        file_text_overlays = meta['text_overlays']
                    if 'location_data' in meta and isinstance(meta['location_data'], dict):
                        file_location_data = meta['location_data']
                    if 'duration_seconds' in meta:
                        try:
                            file_duration = int(meta['duration_seconds'])
                        except Exception:
                            pass
                
                # Stagger created_at slightly for each file to maintain order
                created_at = base_created_at + timedelta(milliseconds=idx * 100)
                expires_at = created_at + timedelta(hours=STORY_DEFAULT_LIFESPAN_HOURS)
                
                # Serialize JSON fields
                text_overlays_str = json.dumps(file_text_overlays) if file_text_overlays else None
                location_data_str = json.dumps(file_location_data) if file_location_data else None
                
                c.execute(
                    f"""
                    INSERT INTO community_stories
                    (community_id, username, media_path, media_type, caption, duration_seconds, status, created_at, expires_at, text_overlays, location_data)
                    VALUES ({ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph}, {ph})
                    """,
                    (
                        community_id,
                        username,
                        stored_path,
                        media_type,
                        file_caption if file_caption else None,
                        file_duration,
                        'active',
                        created_at.strftime('%Y-%m-%d %H:%M:%S'),
                        expires_at.strftime('%Y-%m-%d %H:%M:%S'),
                        text_overlays_str,
                        location_data_str,
                    ),
                )
                story_id = getattr(c, 'lastrowid', None)
                
                created_stories.append({
                    'id': story_id,
                    'community_id': community_id,
                    'username': username,
                    'media_type': media_type,
                    'media_path': stored_path,
                    'media_url': get_public_upload_url(normalize_upload_reference(stored_path)),
                    'caption': file_caption,
                    'text_overlays': file_text_overlays,
                    'location_data': file_location_data,
                    'duration_seconds': file_duration,
                    'created_at': created_at.isoformat(),
                    'expires_at': expires_at.isoformat(),
                    'view_count': 0,
                    'has_viewed': True,
                })
            
            conn.commit()
        
        if not created_stories:
            return jsonify({'success': False, 'error': 'No valid media files were uploaded'}), 400
        
        logger.info(f"Successfully created {len(created_stories)} stories for community {community_id}")
        invalidate_community_cache(community_id)
        
        # Send notifications to community members (matching post notification pattern)
        logger.info(f"Starting story notification process for community {community_id}")
        try:
            with get_db_connection() as conn:
                c = conn.cursor()
                
                # Get all members of the community (excluding author)
                logger.info(f"Story posted by {username} in community {community_id}")
                c.execute(
                    """
                    SELECT DISTINCT u.username
                    FROM users u
                    JOIN user_communities uc ON u.id = uc.user_id
                    WHERE uc.community_id = ? AND u.username != ?
                    """,
                    (community_id, username)
                )
                members = [row['username'] if hasattr(row, 'keys') else row[0] for row in c.fetchall()]
                logger.info(f"Sending story notifications to {len(members)} members: {members}")

                # Resolve community name for nicer message
                community_name = None
                try:
                    c.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
                    r = c.fetchone()
                    if r:
                        community_name = r['name'] if hasattr(r, 'keys') else r[0]
                except Exception:
                    pass

                story_count = len(created_stories)
                notif_message = (
                    f"{username} shared {story_count} new {'story' if story_count == 1 else 'stories'}" 
                    + (f" in {community_name}" if community_name else "")
                )
                notif_link = f"/community_feed_react/{community_id}"
                first_story_id = created_stories[0]['id'] if created_stories else None
                logger.info(f"Story notification message: {notif_message}")

                for member in members:
                    logger.info(f"Attempting to notify member: {member}")
                    # In-app notification row (dedupe by unique key if present)
                    try:
                        if USE_MYSQL:
                            c.execute(
                                """
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                                VALUES (?, ?, 'new_story', ?, ?, ?, NOW(), 0, ?)
                                ON DUPLICATE KEY UPDATE
                                  created_at = NOW(),
                                  message = VALUES(message),
                                  is_read = 0,
                                  link = VALUES(link)
                                """,
                                (member, username, first_story_id, community_id, notif_message, notif_link),
                            )
                        else:
                            c.execute(
                                """
                                INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read, link)
                                VALUES (?, ?, 'new_story', ?, ?, ?, datetime('now'), 0, ?)
                                ON CONFLICT(user_id, from_user, type, post_id, community_id)
                                DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                                """,
                                (member, username, first_story_id, community_id, notif_message, notif_link),
                            )
                        conn.commit()
                    except Exception as ne:
                        logger.warning(f"Story notification db error for {member}: {ne}")

                    # Push notification (non-blocking)
                    try:
                        send_push_to_user(
                            member,
                            {
                                'title': f'New story in {community_name}' if community_name else 'New story',
                                'body': notif_message,
                                'url': notif_link,
                                'tag': f"community-story-{community_id}",
                            },
                        )
                    except Exception as pe:
                        logger.warning(f"Push notify story error for {member}: {pe}")
        except Exception as notify_err:
            logger.warning(f"Story notification block error: {notify_err}")
        
        # Return single story for backwards compatibility, plus array of all
        return jsonify({
            'success': True,
            'story': created_stories[0] if created_stories else None,
            'stories': created_stories,
            'count': len(created_stories),
        })
    except Exception as e:
        logger.error(f"Error creating community story for community {community_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_stories/view', methods=['POST'])
@login_required
def api_mark_story_view():
    username = session.get('username')
    try:
        payload = request.get_json(silent=True) or {}
    except Exception:
        payload = {}
    story_id = payload.get('story_id') or request.form.get('story_id')
    try:
        story_id = int(story_id)
    except Exception:
        return jsonify({'success': False, 'error': 'story_id required'}), 400

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            ph = get_sql_placeholder()
            c.execute(
                f"""
                SELECT cs.id, cs.community_id, c.creator_username
                FROM community_stories cs
                JOIN communities c ON c.id = cs.community_id
                WHERE cs.id = {ph}
                """,
                (story_id,),
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Story not found'}), 404
            community_id = row["community_id"] if hasattr(row, "keys") else row[1]
            creator_username = row["creator_username"] if hasattr(row, "keys") else row[2]
            if not user_has_story_access(c, username, community_id, creator_username):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            view_count = record_story_view(c, story_id, username)
            conn.commit()
            return jsonify({'success': True, 'story_id': story_id, 'view_count': view_count})
    except Exception as e:
        logger.error(f"Error recording view for story {story_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_stories/<int:story_id>/viewers', methods=['GET'])
@login_required
def api_get_story_viewers(story_id: int):
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            ph = get_sql_placeholder()
            c.execute(
                f"""
                SELECT cs.community_id, c.creator_username
                FROM community_stories cs
                JOIN communities c ON c.id = cs.community_id
                WHERE cs.id = {ph}
                """,
                (story_id,),
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Story not found'}), 404
            community_id = row["community_id"] if hasattr(row, "keys") else row[0]
            creator_username = row["creator_username"] if hasattr(row, "keys") else (row[1] if len(row) > 1 else None)
            if not user_has_story_access(c, username, community_id, creator_username):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403

            c.execute(
                f"""
                SELECT csv.username, csv.viewed_at, up.profile_picture
                FROM community_story_views csv
                LEFT JOIN user_profiles up ON up.username = csv.username
                WHERE csv.story_id = {ph}
                ORDER BY csv.viewed_at DESC
                LIMIT 500
                """,
                (story_id,),
            )
            rows = c.fetchall() or []
            viewers: List[Dict[str, Any]] = []
            for viewer in rows:
                viewer_username = viewer["username"] if hasattr(viewer, "keys") else viewer[0]
                viewed_at = viewer["viewed_at"] if hasattr(viewer, "keys") else (viewer[1] if len(viewer) > 1 else None)
                profile_pic = viewer["profile_picture"] if hasattr(viewer, "keys") else (viewer[2] if len(viewer) > 2 else None)
                viewers.append(
                    {
                        'username': viewer_username,
                        'profile_picture': get_public_upload_url(normalize_upload_reference(profile_pic)) if profile_pic else None,
                        'viewed_at': viewed_at,
                    }
                )
            return jsonify({'success': True, 'story_id': story_id, 'viewers': viewers})
    except Exception as e:
        logger.error(f"Error fetching viewers for story {story_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_stories/<int:story_id>', methods=['DELETE'])
@login_required
def delete_community_story(story_id: int):
    """Delete a community story. Only the story owner or community admin can delete."""
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            ph = get_sql_placeholder()
            
            # Get story info
            c.execute(
                f"""
                SELECT cs.id, cs.username as story_owner, cs.community_id, c.creator_username
                FROM community_stories cs
                JOIN communities c ON c.id = cs.community_id
                WHERE cs.id = {ph}
                """,
                (story_id,),
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Story not found'}), 404
            
            story_owner = row["story_owner"] if hasattr(row, "keys") else row[1]
            community_id = row["community_id"] if hasattr(row, "keys") else row[2]
            community_creator = row["creator_username"] if hasattr(row, "keys") else row[3]
            
            # Check permission: must be story owner, community creator, or admin
            is_story_owner = username.lower() == story_owner.lower()
            is_community_creator = username.lower() == (community_creator or '').lower()
            is_app_admin = username.lower() == 'admin'
            
            if not (is_story_owner or is_community_creator or is_app_admin):
                return jsonify({'success': False, 'error': 'You can only delete your own stories'}), 403
            
            # Delete story views first (foreign key constraint)
            c.execute(f"DELETE FROM community_story_views WHERE story_id = {ph}", (story_id,))
            
            # Delete the story
            c.execute(f"DELETE FROM community_stories WHERE id = {ph}", (story_id,))
            conn.commit()
            
            logger.info(f"Story {story_id} deleted by {username}")
            return jsonify({'success': True, 'message': 'Story deleted'})
            
    except Exception as e:
        logger.error(f"Error deleting story {story_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_stories/react', methods=['POST'])
@login_required
def api_story_reaction():
    username = session.get('username')
    try:
        payload = request.get_json(silent=True) or {}
    except Exception:
        payload = {}
    story_id = payload.get('story_id') or request.form.get('story_id')
    reaction = payload.get('reaction')
    try:
        story_id = int(story_id)
    except Exception:
        return jsonify({'success': False, 'error': 'story_id required'}), 400

    normalized_reaction = normalize_story_reaction(reaction) if reaction else None
    if reaction and not normalized_reaction:
        return jsonify({'success': False, 'error': 'Invalid reaction'}), 400

    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ensure_story_tables(c)
            ph = get_sql_placeholder()
            c.execute(
                f"""
                SELECT cs.community_id, c.creator_username
                FROM community_stories cs
                JOIN communities c ON c.id = cs.community_id
                WHERE cs.id = {ph}
                """,
                (story_id,),
            )
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Story not found'}), 404
            community_id = row["community_id"] if hasattr(row, "keys") else row[0]
            creator_username = row["creator_username"] if hasattr(row, "keys") else (row[1] if len(row) > 1 else None)
            if not user_has_story_access(c, username, community_id, creator_username):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403

            now_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
            c.execute(
                f"""
                SELECT reaction FROM community_story_reactions
                WHERE story_id = {ph} AND LOWER(username) = LOWER({ph})
                """,
                (story_id, username),
            )
            existing_row = c.fetchone()
            existing_reaction = (
                existing_row["reaction"]
                if hasattr(existing_row, "keys")
                else (existing_row[0] if existing_row else None)
            )

            if not normalized_reaction:
                if existing_reaction:
                    c.execute(
                        f"DELETE FROM community_story_reactions WHERE story_id = {ph} AND LOWER(username) = LOWER({ph})",
                        (story_id, username),
                    )
            else:
                if existing_reaction and existing_reaction == normalized_reaction:
                    c.execute(
                        f"DELETE FROM community_story_reactions WHERE story_id = {ph} AND LOWER(username) = LOWER({ph})",
                        (story_id, username),
                    )
                else:
                    if USE_MYSQL:
                        c.execute(
                            """
                            INSERT INTO community_story_reactions (story_id, username, reaction, created_at)
                            VALUES (%s, %s, %s, %s)
                            ON DUPLICATE KEY UPDATE reaction = VALUES(reaction), created_at = VALUES(created_at)
                            """,
                            (story_id, username, normalized_reaction, now_str),
                        )
                    else:
                        c.execute(
                            """
                            INSERT INTO community_story_reactions (story_id, username, reaction, created_at)
                            VALUES (?, ?, ?, ?)
                            ON CONFLICT(story_id, username)
                            DO UPDATE SET reaction = excluded.reaction, created_at = excluded.created_at
                            """,
                            (story_id, username, normalized_reaction, now_str),
                        )

            conn.commit()
            reaction_counts, user_reactions = fetch_story_reaction_maps(c, [story_id], username)
            return jsonify(
                {
                    'success': True,
                    'story_id': story_id,
                    'reactions': reaction_counts.get(story_id, {}),
                    'user_reaction': user_reactions.get(story_id),
                }
            )
    except Exception as e:
        logger.error(f"Error reacting to story {story_id}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500


@app.route('/api/community_member_suggest')
@login_required
def api_community_member_suggest():
    try:
        q = (request.args.get('q') or '').strip()
        community_id = request.args.get('community_id', type=int)
        post_id = request.args.get('post_id', type=int)
        reply_id = request.args.get('reply_id', type=int)
        with get_db_connection() as conn:
            c = conn.cursor()
            # Derive community_id from post_id or reply_id if not provided
            if not community_id:
                try:
                    if post_id:
                        c.execute("SELECT community_id FROM posts WHERE id = ?", (post_id,))
                        row = c.fetchone()
                        if row:
                            community_id = row['community_id'] if hasattr(row, 'keys') else row[0]
                    elif reply_id:
                        c.execute("SELECT community_id FROM replies WHERE id = ?", (reply_id,))
                        row = c.fetchone()
                        if row:
                            community_id = row['community_id'] if hasattr(row, 'keys') else row[0]
                except Exception as de:
                    logger.warning(f"suggest: could not derive community_id (post_id={post_id}, reply_id={reply_id}): {de}")

            # Require at least 1 char and a resolved community_id
            if not community_id or len(q) < 1:
                return jsonify({'success': True, 'members': []})
            ph = get_sql_placeholder()
            # Only members of this community
            c.execute(f"""
                SELECT u.username,
                       COALESCE(p.display_name, u.username) AS display_name,
                       p.profile_picture
                FROM users u
                JOIN user_communities uc ON u.id = uc.user_id
                LEFT JOIN user_profiles p ON p.username = u.username
                WHERE uc.community_id = {ph}
                  AND (u.username LIKE {ph} OR p.display_name LIKE {ph})
                ORDER BY u.username
                LIMIT 10
            """, (community_id, f"%{q}%", f"%{q}%"))
            rows = c.fetchall() or []
            members = []
            for r in rows:
                if hasattr(r,'keys'):
                    members.append({ 'username': r['username'], 'display_name': r['display_name'], 'avatar': r.get('profile_picture') })
                else:
                    members.append({ 'username': r[0], 'display_name': r[1], 'avatar': r[2] if len(r) > 2 else None })
            return jsonify({'success': True, 'members': members})
    except Exception as e:
        logger.error(f"api_community_member_suggest error: {e}")
        return jsonify({'success': False, 'members': []}), 500

# Toggle key post (star/unstar)
@app.route('/api/toggle_key_post', methods=['POST'])
@login_required
def api_toggle_key_post():
    try:
        username = session.get('username')
        post_id = request.form.get('post_id', type=int)
        if not post_id:
            return jsonify({'success': False, 'error': 'post_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            # Determine community_id from post
            c.execute("SELECT community_id FROM posts WHERE id = ?", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            community_id = row['community_id'] if hasattr(row, 'keys') else row[0]
            if community_id is None:
                # Only allow starring community posts to scope Key Posts
                community_id = -1
            # Toggle
            c.execute("SELECT id FROM key_posts WHERE username = ? AND post_id = ?", (username, post_id))
            existing = c.fetchone()
            if existing:
                c.execute("DELETE FROM key_posts WHERE username = ? AND post_id = ?", (username, post_id))
                conn.commit()
                return jsonify({'success': True, 'starred': False})
            else:
                now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                c.execute("INSERT INTO key_posts (username, post_id, community_id, created_at) VALUES (?, ?, ?, ?)", (str(username), post_id, community_id, now))
                conn.commit()
                return jsonify({'success': True, 'starred': True})
    except Exception as e:
        logger.error(f"toggle key post error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# Toggle community key post (admin/owner only)
@app.route('/api/toggle_community_key_post', methods=['POST'])
@login_required
def api_toggle_community_key_post():
    try:
        username = session.get('username')
        post_id = request.form.get('post_id', type=int)
        if not post_id:
            return jsonify({'success': False, 'error': 'post_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            # Determine community_id from post
            c.execute("SELECT community_id FROM posts WHERE id = ?", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            community_id = row['community_id'] if hasattr(row, 'keys') else row[0]
            if not community_id:
                return jsonify({'success': False, 'error': 'Not a community post'}), 400
            # Check permission (owner or community admin or app admin)
            if not (is_app_admin(username) or is_community_owner(username, community_id) or is_community_admin(username, community_id)):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            # Toggle in community_key_posts
            c.execute("SELECT id FROM community_key_posts WHERE community_id = ? AND post_id = ?", (community_id, post_id))
            existing = c.fetchone()
            if existing:
                c.execute("DELETE FROM community_key_posts WHERE community_id = ? AND post_id = ?", (community_id, post_id))
                conn.commit()
                return jsonify({'success': True, 'starred': False})
            else:
                now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                c.execute("INSERT INTO community_key_posts (community_id, post_id, created_at) VALUES (?, ?, ?)", (community_id, post_id, now))
                conn.commit()
                return jsonify({'success': True, 'starred': True})
    except Exception as e:
        logger.error(f"toggle community key post error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# List community key posts for a community (admin/yellow stars)
@app.route('/api/community_key_posts', methods=['GET'])
@login_required
def api_community_key_posts():
    try:
        community_id = request.args.get('community_id', type=int)
        if not community_id:
            return jsonify({'success': False, 'error': 'community_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            # Get post ids
            c.execute("SELECT post_id FROM community_key_posts WHERE community_id = ? ORDER BY id DESC", (community_id,))
            rows = c.fetchall() or []
            post_ids = [(r['post_id'] if hasattr(r, 'keys') else r[0]) for r in rows]
            if not post_ids:
                return jsonify({'success': True, 'posts': []})
            placeholders = ",".join(["?"] * len(post_ids))
            c.execute(f"SELECT * FROM posts WHERE id IN ({placeholders}) ORDER BY id DESC", tuple(post_ids))
            posts = [dict(r) for r in (c.fetchall() or [])]
            # Enrich minimal fields similar to api_key_posts
            # We will reuse current user's username for user_reaction enrichment
            cur_user = session.get('username')
            for post in posts:
                pid = post['id']
                try:
                    c.execute("SELECT profile_picture FROM user_profiles WHERE username = ?", (post['username'],))
                    pp = c.fetchone()
                    post['profile_picture'] = pp['profile_picture'] if pp and 'profile_picture' in pp.keys() else None
                except Exception:
                    post['profile_picture'] = None
                c.execute("SELECT reaction_type, COUNT(*) as count FROM reactions WHERE post_id = ? GROUP BY reaction_type", (pid,))
                post['reactions'] = {row['reaction_type']: row['count'] for row in (c.fetchall() or [])}
                c.execute("SELECT reaction_type FROM reactions WHERE post_id = ? AND username = ?", (pid, cur_user))
                ur = c.fetchone()
                post['user_reaction'] = ur['reaction_type'] if ur else None
                post['is_starred'] = True  # community list implies highlighted
            return jsonify({'success': True, 'posts': posts})
    except Exception as e:
        logger.error(f"community key posts error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# List current user's key posts for a community
@app.route('/api/key_posts', methods=['GET'])
@login_required
def api_key_posts():
    try:
        username = session.get('username')
        community_id = request.args.get('community_id', type=int)
        if not community_id:
            return jsonify({'success': False, 'error': 'community_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            # Get starred post ids for this user/community
            c.execute("SELECT post_id FROM key_posts WHERE username = ? AND community_id = ? ORDER BY id DESC", (username, community_id))
            rows = c.fetchall() or []
            post_ids = [ (r['post_id'] if hasattr(r, 'keys') else r[0]) for r in rows ]
            if not post_ids:
                return jsonify({'success': True, 'posts': []})
            placeholders = ",".join(["?"] * len(post_ids))
            c.execute(f"SELECT * FROM posts WHERE id IN ({placeholders}) ORDER BY id DESC", tuple(post_ids))
            posts = [dict(r) for r in (c.fetchall() or [])]
            for post in posts:
                pid = post['id']
                # Author picture
                try:
                    c.execute("SELECT profile_picture FROM user_profiles WHERE username = ?", (post['username'],))
                    pp = c.fetchone()
                    post['profile_picture'] = pp['profile_picture'] if pp and 'profile_picture' in pp.keys() else None
                except Exception:
                    post['profile_picture'] = None
                # Reactions
                c.execute("SELECT reaction_type, COUNT(*) as count FROM reactions WHERE post_id = ? GROUP BY reaction_type", (pid,))
                post['reactions'] = {row['reaction_type']: row['count'] for row in (c.fetchall() or [])}
                c.execute("SELECT reaction_type FROM reactions WHERE post_id = ? AND username = ?", (pid, username))
                ur = c.fetchone()
                post['user_reaction'] = ur['reaction_type'] if ur else None
                post['is_starred'] = True
            return jsonify({'success': True, 'posts': posts})
    except Exception as e:
        logger.error(f"key posts error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# Product Development APIs
@app.route('/api/product_posts', methods=['GET'])
@login_required
def api_product_posts():
    section = request.args.get('section', 'updates').lower()
    if section not in ('updates','feedback'):
        section = 'updates'
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT id, username, content, created_at FROM product_posts WHERE section={ph} ORDER BY id DESC LIMIT 100", (section,))
            posts = c.fetchall() or []
            post_ids = [ (p['id'] if hasattr(p,'keys') else p[0]) for p in posts ]
            replies_map = {}
            if post_ids:
                placeholders = ','.join([get_sql_placeholder()]*len(post_ids))
                c.execute(f"SELECT id, post_id, username, content, created_at FROM product_replies WHERE post_id IN ({placeholders}) ORDER BY id DESC", tuple(post_ids))
                for r in c.fetchall() or []:
                    pid = r['post_id'] if hasattr(r,'keys') else r[1]
                    replies_map.setdefault(pid, []).append({
                        'id': r['id'] if hasattr(r,'keys') else r[0],
                        'username': r['username'] if hasattr(r,'keys') else r[2],
                        'content': r['content'] if hasattr(r,'keys') else r[3],
                        'created_at': r['created_at'] if hasattr(r,'keys') else r[4],
                    })
            out = []
            for p in posts:
                pid = p['id'] if hasattr(p,'keys') else p[0]
                out.append({
                    'id': pid,
                    'username': p['username'] if hasattr(p,'keys') else p[1],
                    'content': p['content'] if hasattr(p,'keys') else p[2],
                    'created_at': p['created_at'] if hasattr(p,'keys') else p[3],
                    'replies': replies_map.get(pid, [])
                })
            return jsonify({'success': True, 'posts': out})
    except Exception as e:
        logger.error(f"product posts error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_post', methods=['POST'])
@login_required
def api_create_product_post():
    username = session.get('username')
    section = (request.form.get('section') or '').lower()
    content = (request.form.get('content') or '').strip()
    if section not in ('updates','feedback'):
        return jsonify({'success': False, 'error': 'invalid section'}), 400
    if not content:
        return jsonify({'success': False, 'error': 'content required'}), 400
    # Only Admin/Paulo can post to updates
    if section == 'updates' and username not in ('admin','Paulo','paulo'):
        return jsonify({'success': False, 'error': 'Forbidden'}), 403
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ph = get_sql_placeholder()
            c.execute(f"INSERT INTO product_posts (username, section, content, created_at) VALUES ({ph},{ph},{ph},{ph})", (username, section, content, now))
            pid = c.lastrowid
            conn.commit()
            return jsonify({'success': True, 'post': {'id': pid, 'username': username, 'content': content, 'created_at': now, 'replies': []}})
    except Exception as e:
        logger.error(f"create product post error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_reply', methods=['POST'])
@login_required
def api_create_product_reply():
    username = session.get('username')
    post_id = request.form.get('post_id', type=int)
    content = (request.form.get('content') or '').strip()
    if not post_id or not content:
        return jsonify({'success': False, 'error': 'post_id and content required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ph = get_sql_placeholder()
            c.execute(f"INSERT INTO product_replies (post_id, username, content, created_at) VALUES ({ph},{ph},{ph},{ph})", (post_id, username, content, now))
            rid = c.lastrowid
            conn.commit()
            return jsonify({'success': True, 'reply': {'id': rid, 'post_id': post_id, 'username': username, 'content': content, 'created_at': now}})
    except Exception as e:
        logger.error(f"create product reply error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_post_edit', methods=['POST'])
@login_required
def api_edit_product_post():
    try:
        username = session.get('username')
        post_id = request.form.get('post_id', type=int)
        content = (request.form.get('content') or '').strip()
        if not post_id or not content:
            return jsonify({'success': False, 'error': 'post_id and content required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM product_posts WHERE id={ph}", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            owner = row['username'] if hasattr(row,'keys') else row[0]
            # Restrict edits to Admin/Paulo only (owners cannot edit unless they are admin/Paulo)
            if (username or '').lower() not in ('admin','paulo'):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            c.execute(f"UPDATE product_posts SET content={ph} WHERE id={ph}", (content, post_id))
            conn.commit()
            return jsonify({'success': True, 'post': {'id': post_id, 'content': content }})
    except Exception as e:
        logger.error(f"edit product post error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_post_delete', methods=['POST'])
@login_required
def api_delete_product_post():
    try:
        username = session.get('username')
        post_id = request.form.get('post_id', type=int)
        if not post_id:
            return jsonify({'success': False, 'error': 'post_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM product_posts WHERE id={ph}", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            owner = row['username'] if hasattr(row,'keys') else row[0]
            # Restrict deletes to Admin/Paulo only (owners cannot delete unless they are admin/Paulo)
            if (username or '').lower() not in ('admin','paulo'):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            # Delete post (replies should cascade if FK set; otherwise explicit delete)
            try:
                c.execute(f"DELETE FROM product_posts WHERE id={ph}", (post_id,))
            except Exception:
                # Fallback: delete replies then post
                c.execute(f"DELETE FROM product_replies WHERE post_id={ph}", (post_id,))
                c.execute(f"DELETE FROM product_posts WHERE id={ph}", (post_id,))
            conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"delete product post error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_reply_edit', methods=['POST'])
@login_required
def api_edit_product_reply():
    try:
        username = session.get('username')
        reply_id = request.form.get('reply_id', type=int)
        content = (request.form.get('content') or '').strip()
        if not reply_id or not content:
            return jsonify({'success': False, 'error': 'reply_id and content required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM product_replies WHERE id={ph}", (reply_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Reply not found'}), 404
            owner = row['username'] if hasattr(row,'keys') else row[0]
            # Restrict edits to Admin/Paulo only
            if (username or '').lower() not in ('admin','paulo'):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            c.execute(f"UPDATE product_replies SET content={ph} WHERE id={ph}", (content, reply_id))
            conn.commit()
            return jsonify({'success': True, 'reply': {'id': reply_id, 'content': content }})
    except Exception as e:
        logger.error(f"edit product reply error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_reply_delete', methods=['POST'])
@login_required
def api_delete_product_reply():
    try:
        username = session.get('username')
        reply_id = request.form.get('reply_id', type=int)
        if not reply_id:
            return jsonify({'success': False, 'error': 'reply_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT username FROM product_replies WHERE id={ph}", (reply_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Reply not found'}), 404
            owner = row['username'] if hasattr(row,'keys') else row[0]
            # Restrict deletes to Admin/Paulo only
            if (username or '').lower() not in ('admin','paulo'):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            c.execute(f"DELETE FROM product_replies WHERE id={ph}", (reply_id,))
            conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"delete product reply error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_polls', methods=['GET'])
@login_required
def api_product_polls():
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT id, username, question, options_json, created_at, closed, allow_multiple FROM product_polls ORDER BY id DESC LIMIT 100")
            polls = []
            for r in c.fetchall() or []:
                poll = {
                    'id': r['id'] if hasattr(r,'keys') else r[0],
                    'username': r['username'] if hasattr(r,'keys') else r[1],
                    'question': r['question'] if hasattr(r,'keys') else r[2],
                    'options': json.loads(r['options_json'] if hasattr(r,'keys') else r[3] or '[]'),
                    'created_at': r['created_at'] if hasattr(r,'keys') else r[4],
                    'closed': (r['closed'] if hasattr(r,'keys') else r[5]) in (1, '1', True),
                    'allow_multiple': (r['allow_multiple'] if hasattr(r,'keys') else r[6]) in (1,'1',True)
                }
                # Vote counts per option
                try:
                    with get_db_connection() as conn2:
                        c2 = conn2.cursor()
                        c2.execute("SELECT option_index, COUNT(*) as cnt FROM product_poll_votes WHERE poll_id=? GROUP BY option_index", (poll['id'],))
                        counts_map = { (row['option_index'] if hasattr(row,'keys') else row[0]): (row['cnt'] if hasattr(row,'keys') else row[1]) for row in (c2.fetchall() or []) }
                        poll['option_counts'] = [int(counts_map.get(i, 0)) for i in range(len(poll['options']))]
                except Exception:
                    poll['option_counts'] = [0]*len(poll['options'])
                polls.append(poll)
            return jsonify({'success': True, 'polls': polls})
    except Exception as e:
        logger.error(f"product polls error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_poll', methods=['POST'])
@login_required
def api_create_product_poll():
    username = session.get('username')
    if (username or '').lower() not in ('admin','paulo'):
        return jsonify({'success': False, 'error': 'Forbidden'}), 403
    question = (request.form.get('question') or '').strip()
    raw_options = request.form.getlist('options') or []
    options = [o.strip() for o in raw_options if o and o.strip()]
    if not question or len(options) < 2:
        return jsonify({'success': False, 'error': 'Question and at least 2 options required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            allow_multiple = 1 if (request.form.get('allow_multiple') in ('1','true','on','yes')) else 0
            notify_all = 1 if (request.form.get('notify_all') in ('1','true','on','yes')) else 0
            c.execute("INSERT INTO product_polls (username, question, options_json, created_at, allow_multiple) VALUES (?,?,?,?,?)",
                      (username, question, json.dumps(options), now, allow_multiple))
            poll_id = c.lastrowid
            conn.commit()
        try:
            # Send notification to all users with push subscription
            if notify_all:
                with get_db_connection() as conn2:
                    c2 = conn2.cursor()
                    c2.execute("SELECT DISTINCT username FROM push_subscriptions")
                    for row in c2.fetchall() or []:
                        u = row['username'] if hasattr(row,'keys') else row[0]
                        send_push_to_user(u, {
                            'title': 'New Product Poll',
                            'body': question,
                            'url': f"{CANONICAL_SCHEME}://{CANONICAL_HOST}/product_development"
                        })
        except Exception as ne:
            logger.warning(f"poll notify error: {ne}")
        return jsonify({'success': True, 'poll': { 'id': poll_id, 'username': username, 'question': question, 'options': options, 'created_at': now, 'closed': False, 'allow_multiple': bool(allow_multiple), 'option_counts': [0]*len(options) }})
    except Exception as e:
        logger.error(f"create product poll error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_poll_vote', methods=['POST'])
@login_required
def api_product_poll_vote():
    username = session.get('username')
    poll_id = request.form.get('poll_id', type=int)
    option_index = request.form.get('option_index', type=int)
    if poll_id is None or option_index is None:
        return jsonify({'success': False, 'error': 'poll_id and option_index required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            # Ensure poll exists and option index is valid
            c.execute("SELECT options_json, closed, allow_multiple FROM product_polls WHERE id=?", (poll_id,))
            prow = c.fetchone()
            if not prow:
                return jsonify({'success': False, 'error': 'Poll not found'}), 404
            opts = json.loads(prow['options_json'] if hasattr(prow,'keys') else prow[0] or '[]')
            closed = (prow['closed'] if hasattr(prow,'keys') else prow[1]) in (1, '1', True)
            allow_multiple = (prow['allow_multiple'] if hasattr(prow,'keys') else prow[2]) in (1,'1',True)
            if closed:
                return jsonify({'success': False, 'error': 'Poll is closed'}), 400
            if option_index < 0 or option_index >= len(opts):
                return jsonify({'success': False, 'error': 'Invalid option'}), 400
            if allow_multiple:
                # One vote per option per user (unique on poll_id, username, option_index)
                try:
                    c.execute("INSERT INTO product_poll_votes (poll_id, username, option_index, created_at) VALUES (?, ?, ?, ?)", (poll_id, username, option_index, now))
                except Exception:
                    # Already voted on this option, ignore
                    pass
            else:
                # Single choice: ensure only one record for user per poll
                try:
                    c.execute("DELETE FROM product_poll_votes WHERE poll_id=? AND username=?", (poll_id, username))
                    c.execute("INSERT INTO product_poll_votes (poll_id, username, option_index, created_at) VALUES (?, ?, ?, ?)", (poll_id, username, option_index, now))
                except Exception:
                    c.execute("UPDATE product_poll_votes SET option_index=?, created_at=? WHERE poll_id=? AND username=?", (option_index, now, poll_id, username))
            conn.commit()
            # Return fresh counts
            c.execute("SELECT option_index, COUNT(*) as cnt FROM product_poll_votes WHERE poll_id=? GROUP BY option_index", (poll_id,))
            counts_map = { (row['option_index'] if hasattr(row,'keys') else row[0]): (row['cnt'] if hasattr(row,'keys') else row[1]) for row in (c.fetchall() or []) }
            counts = [int(counts_map.get(i, 0)) for i in range(len(opts))]
            return jsonify({'success': True, 'option_counts': counts})
    except Exception as e:
        logger.error(f"poll vote error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_poll_close', methods=['POST'])
@login_required
def api_product_poll_close():
    username = (session.get('username') or '').lower()
    if username not in ('admin','paulo'):
        return jsonify({'success': False, 'error': 'Forbidden'}), 403
    poll_id = request.form.get('poll_id', type=int)
    if not poll_id:
        return jsonify({'success': False, 'error': 'poll_id required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("UPDATE product_polls SET closed=1 WHERE id=?", (poll_id,))
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"poll close error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/product_poll_delete', methods=['POST'])
@login_required
def api_product_poll_delete():
    username = (session.get('username') or '').lower()
    if username not in ('admin','paulo'):
        return jsonify({'success': False, 'error': 'Forbidden'}), 403
    poll_id = request.form.get('poll_id', type=int)
    if not poll_id:
        return jsonify({'success': False, 'error': 'poll_id required'}), 400
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("DELETE FROM product_polls WHERE id=?", (poll_id,))
            conn.commit()
        return jsonify({'success': True})
    except Exception as e:
        logger.error(f"poll delete error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

# Edit reply content
@app.route('/edit_reply', methods=['POST'])
@login_required
def edit_reply():
    username = session.get('username')
    try:
        reply_id = request.form.get('reply_id', type=int)
        new_content = (request.form.get('content') or '').strip()
        if not reply_id:
            return jsonify({'success': False, 'error': 'reply_id required'}), 400
        if new_content == '':
            return jsonify({'success': False, 'error': 'content required'}), 400

        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            # Verify ownership or admin
            c.execute(f"SELECT username FROM replies WHERE id={ph}", (reply_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Reply not found'}), 404
            owner = row['username'] if hasattr(row, 'keys') else row[0]
            if username != owner and username != 'admin':
                return jsonify({'success': False, 'error': 'Forbidden'}), 403

            # Update content
            c.execute(f"UPDATE replies SET content={ph} WHERE id={ph}", (new_content, reply_id))
            conn.commit()

            # Return minimal updated reply
            return jsonify({'success': True, 'reply': {'id': reply_id, 'content': new_content}})
    except Exception as e:
        logger.error(f"Error editing reply {username}: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500
def api_home_timeline():
    """Aggregate timeline across all communities the user belongs to for the last 48 hours."""
    username = session.get('username')
    logger.info(f"api_home_timeline called for user: {username}")
    try:
        with get_db_connection() as conn:
            c = conn.cursor()

            # Current user profile
            try:
                c.execute("SELECT display_name, profile_picture FROM user_profiles WHERE username = ?", (username,))
                cupp = c.fetchone()
                current_user_profile_picture = cupp['profile_picture'] if cupp and 'profile_picture' in cupp.keys() else None
                current_user_display_name = cupp['display_name'] if cupp and 'display_name' in cupp.keys() and cupp['display_name'] else username
            except Exception:
                current_user_profile_picture = None
                current_user_display_name = username

            # Get community ids for the user
            c.execute("""
                SELECT c.id, c.name
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = ?
            """, (username,))
            rows = c.fetchall()
            community_ids = [row['id'] for row in rows]
            id_to_name = {row['id']: row['name'] for row in rows}

            community_allow_map: Dict[str, bool] = {}
            if community_ids:
                try:
                    placeholders = ', '.join([get_sql_placeholder() for _ in community_ids])
                    query = f"SELECT id, allow_nsfw_imagine FROM communities WHERE id IN ({placeholders})"
                    c.execute(query, tuple(community_ids))
                    fetched = c.fetchall() or []
                    for row in fetched:
                        cid = row['id'] if hasattr(row, 'keys') else row[0]
                        val = row['allow_nsfw_imagine'] if hasattr(row, 'keys') else (row[1] if len(row) > 1 else 0)
                        community_allow_map[str(cid)] = bool(val)
                except Exception as allow_err:
                    logger.warning(f"Failed to load allow_nsfw_imagine for communities: {allow_err}")

            if not community_ids:
                return jsonify({
                    'success': True,
                    'username': username,
                    'current_user_profile_picture': current_user_profile_picture,
                    'current_user_display_name': current_user_display_name,
                    'posts': [],
                    'settings': {'allow_nsfw_imagine': False},
                    'community_allow_map': {}
                })

            # Strict: only posts from communities the user directly belongs to
            # Get posts ordered by ID (most recent first), then filter by timestamp in Python
            from datetime import datetime, timedelta
            now = datetime.utcnow()  # Use UTC - posts are stored with datetime.utcnow()
            forty_eight = timedelta(hours=48)
            
            ph = get_sql_placeholder()
            c.execute(
                f"""
                SELECT DISTINCT p.*
                FROM posts p
                JOIN user_communities uc ON uc.community_id = p.community_id
                JOIN users u ON u.id = uc.user_id
                WHERE u.username = {ph}
                ORDER BY p.id DESC
                LIMIT 200
                """,
                (username,),
            )
            rows = [dict(row) for row in c.fetchall()]
            
            # Debug log
            logger.info(f"Home timeline: fetched {len(rows)} posts for user {username}")
            if rows:
                logger.info(f"First post timestamp: {rows[0].get('timestamp')}, id: {rows[0].get('id')}")
                logger.info(f"Last post timestamp: {rows[-1].get('timestamp')}, id: {rows[-1].get('id')}")
            
            # Robust timestamp parsing - matches community feed approach
            def parse_ts(raw):
                if not raw:
                    return None
                # Handle case where MySQL returns datetime object directly
                if isinstance(raw, datetime):
                    return raw
                s = str(raw).strip()
                if not s or s.startswith('0000-00-00'):
                    return None
                # Normalize: replace T with space, take first 19 chars
                s_normalized = s[:19].replace('T', ' ')
                # Try primary format first (same as community feed)
                try:
                    return datetime.strptime(s_normalized, '%Y-%m-%d %H:%M:%S')
                except Exception:
                    pass
                # Try other formats
                for fmt in ('%d-%m-%Y %H:%M:%S', '%d-%m-%Y %H:%M', '%Y-%m-%d %H:%M', '%m.%d.%y %H:%M', '%Y-%m-%d', '%m/%d/%y %I:%M %p'):
                    try:
                        return datetime.strptime(s.replace('T', ' '), fmt)
                    except Exception:
                        continue
                # Try epoch timestamps
                try:
                    if s.isdigit():
                        n = int(s)
                        if n < 1e12:
                            return datetime.utcfromtimestamp(n)
                        else:
                            return datetime.utcfromtimestamp(n / 1000)
                except Exception:
                    pass
                # Final fallback: fromisoformat
                try:
                    return datetime.fromisoformat(s_normalized)
                except Exception:
                    return None
            
            # Filter posts from last 48 hours
            posts = []
            cutoff = now - forty_eight
            logger.info(f"Home timeline filter: now={now}, cutoff={cutoff}")
            
            for r in rows:
                # Check both timestamp and created_at (same as community feed)
                ts_raw = r.get('timestamp') or r.get('created_at') or ''
                dt = parse_ts(ts_raw)
                if dt is None:
                    logger.warning(f"Could not parse timestamp '{ts_raw}' (type={type(ts_raw).__name__}) for post {r.get('id')}")
                    continue
                # Include post if its timestamp is after the cutoff (within last 48h)
                if dt >= cutoff:
                    posts.append(r)
                else:
                    # Log first few rejected posts to debug
                    if len([p for p in rows if parse_ts(str(p.get('timestamp',''))) and parse_ts(str(p.get('timestamp',''))) < cutoff]) <= 3:
                        logger.info(f"Post {r.get('id')} rejected: dt={dt} < cutoff={cutoff}")
            
            logger.info(f"Home timeline: {len(posts)} posts after 48h filter (from {len(rows)} fetched)")

            # OPTIMIZED: Batch queries to avoid N+1 problem
            post_ids = [p['id'] for p in posts]
            
            if post_ids:
                placeholders = ','.join([get_sql_placeholder()] * len(post_ids))
                
                # BATCH 1: Get all author profile pictures
                author_usernames = list(set(p['username'] for p in posts))
                profile_pics = {}
                if author_usernames:
                    author_ph = ','.join([get_sql_placeholder()] * len(author_usernames))
                    c.execute(f"SELECT username, profile_picture FROM user_profiles WHERE username IN ({author_ph})", tuple(author_usernames))
                    for row in c.fetchall():
                        profile_pics[row['username']] = row['profile_picture']
                
                # BATCH 2: Get all reactions
                post_reactions: Dict[int, Dict[str, int]] = {pid: {} for pid in post_ids}
                try:
                    c.execute(f"SELECT post_id, reaction_type, COUNT(*) as count FROM reactions WHERE post_id IN ({placeholders}) GROUP BY post_id, reaction_type", tuple(post_ids))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                        cnt = row['count'] if hasattr(row, 'keys') else row[2]
                        if pid in post_reactions:
                            post_reactions[pid][rtype] = cnt
                except Exception:
                    pass
                
                # BATCH 3: Get user's reactions
                user_reactions: Dict[int, str] = {}
                try:
                    params = list(post_ids) + [username]
                    c.execute(f"SELECT post_id, reaction_type FROM reactions WHERE post_id IN ({placeholders}) AND username = {get_sql_placeholder()}", tuple(params))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        rtype = row['reaction_type'] if hasattr(row, 'keys') else row[1]
                        user_reactions[pid] = rtype
                except Exception:
                    pass
                
                # BATCH 4: Get all polls
                polls_by_post: Dict[int, dict] = {}
                try:
                    c.execute(f"SELECT * FROM polls WHERE post_id IN ({placeholders}) AND is_active = 1", tuple(post_ids))
                    for row in c.fetchall():
                        poll = dict(row)
                        polls_by_post[poll['post_id']] = poll
                except Exception:
                    pass
                
                # BATCH 5: Get poll options and votes
                if polls_by_post:
                    poll_ids = [p['id'] for p in polls_by_post.values()]
                    poll_ph = ','.join([get_sql_placeholder()] * len(poll_ids))
                    options_by_poll: Dict[int, list] = {pid: [] for pid in poll_ids}
                    
                    # Get options with vote counts
                    try:
                        c.execute(f"SELECT * FROM poll_options WHERE poll_id IN ({poll_ph}) ORDER BY id", tuple(poll_ids))
                        for row in c.fetchall():
                            opt = dict(row)
                            opt['text'] = opt.get('option_text', '')
                            opt['votes'] = opt.get('votes', 0)
                            options_by_poll[opt['poll_id']].append(opt)
                    except Exception:
                        pass
                    
                    # Get user votes
                    user_poll_votes: Dict[int, int] = {}
                    try:
                        params = list(poll_ids) + [username]
                        c.execute(f"SELECT poll_id, option_id FROM poll_votes WHERE poll_id IN ({poll_ph}) AND username = {get_sql_placeholder()}", tuple(params))
                        for row in c.fetchall():
                            poll_id = row['poll_id'] if hasattr(row, 'keys') else row[0]
                            opt_id = row['option_id'] if hasattr(row, 'keys') else row[1]
                            user_poll_votes[poll_id] = opt_id
                    except Exception:
                        pass
                    
                    # Assemble polls
                    for post_id, poll in polls_by_post.items():
                        poll['options'] = options_by_poll.get(poll['id'], [])
                        poll['user_vote'] = user_poll_votes.get(poll['id'])
                        poll['total_votes'] = sum(int(opt.get('votes', 0) or 0) for opt in poll['options'])
                
                # BATCH 6: Get reply counts
                reply_counts: Dict[int, int] = {}
                try:
                    c.execute(f"SELECT post_id, COUNT(*) as cnt FROM replies WHERE post_id IN ({placeholders}) GROUP BY post_id", tuple(post_ids))
                    for row in c.fetchall():
                        pid = row['post_id'] if hasattr(row, 'keys') else row[0]
                        cnt = row['cnt'] if hasattr(row, 'keys') else row[1]
                        reply_counts[pid] = cnt
                except Exception:
                    pass
            
            # Helper to normalize paths
            def normalize_path(p):
                if not p:
                    return None
                p_str = str(p).strip()
                if p_str.startswith('http://') or p_str.startswith('https://'):
                    return p_str
                if p_str.startswith('/uploads') or p_str.startswith('/static'):
                    return p_str
                if p_str.startswith('uploads/') or p_str.startswith('static/'):
                    return '/' + p_str
                return f"/uploads/{p_str}"
            
            # Enrich posts with batched data (no more N+1 queries!)
            for post in posts:
                post_id = post['id']
                comm_id = post.get('community_id')
                post['community_name'] = id_to_name.get(comm_id)
                post['image_path'] = normalize_path(post.get('image_path'))
                post['video_path'] = normalize_path(post.get('video_path'))
                
                # Timestamp formatting - use YYYY-MM-DD HH:MM:SS format (same as community feed)
                # This format is parsed by frontend as UTC, allowing correct relative time display
                try:
                    raw_ts = (post.get('timestamp') or post.get('created_at') or '').strip()
                    if raw_ts and not raw_ts.startswith('0000-00-00'):
                        dt = None
                        try:
                            dt = datetime.strptime(raw_ts[:19].replace('T',' '), '%Y-%m-%d %H:%M:%S')
                        except Exception:
                            for fmt in ('%d-%m-%Y %H:%M:%S','%d-%m-%Y %H:%M','%Y-%m-%d %H:%M','%m.%d.%y %H:%M','%Y-%m-%d','%Y-%m-%dT%H:%M:%S'):
                                try:
                                    dt = datetime.strptime(raw_ts.replace('T',' '), fmt)
                                    break
                                except Exception:
                                    continue
                        post['display_timestamp'] = dt.strftime('%Y-%m-%d %H:%M:%S') if dt else raw_ts[:19].replace('T',' ')
                    else:
                        post['display_timestamp'] = ''
                except Exception:
                    post['display_timestamp'] = ''
                
                # Use batched data
                pp = profile_pics.get(post['username'])
                post['profile_picture'] = normalize_path(pp) if pp else None
                post['reactions'] = post_reactions.get(post_id, {})
                post['user_reaction'] = user_reactions.get(post_id)
                post['poll'] = polls_by_post.get(post_id)
                post['replies_count'] = reply_counts.get(post_id, 0)

            return jsonify({
                'success': True,
                'username': username,
                'current_user_profile_picture': current_user_profile_picture,
                'current_user_display_name': current_user_display_name,
                'posts': posts,
                'settings': {
                    'allow_nsfw_imagine': any(community_allow_map.values())
                },
                'community_allow_map': community_allow_map
            })
    except Exception as e:
        logger.error(f"Error in api_home_timeline: {e}")
        return jsonify({'success': False, 'error': 'Server error'}), 500

@app.route('/api/home_timeline')
@login_required
def api_home_timeline_route():
    return api_home_timeline()

@app.route('/home')
@login_required
def react_home_timeline_page():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        return send_from_directory(dist_dir, 'index.html')
    except Exception as e:
        logger.error(f"Error serving React home timeline: {str(e)}")
        abort(500)
@app.route('/community_feed_react/<int:community_id>')
@login_required
def community_feed_react(community_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React community feed: {str(e)}")
        abort(500)

@app.route('/community/<int:community_id>/calendar_react')
@login_required
def community_calendar_react(community_id):
    try:
        ua = request.headers.get('User-Agent', '')
        is_mobile = any(k in ua for k in ['Mobi', 'Android', 'iPhone', 'iPad'])
        if is_mobile:
            base_dir = os.path.dirname(os.path.abspath(__file__))
            dist_dir = os.path.join(base_dir, 'client', 'dist')
            return send_from_directory(dist_dir, 'index.html')
        # Desktop: fall back to existing HTML calendar if available
        return redirect(f"/community/{community_id}/calendar")
    except Exception as e:
        logger.error(f"Error serving React community calendar: {str(e)}")
        abort(500)


@app.route('/community/<int:community_id>/tasks_react')
@login_required
def community_tasks_react(community_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React community tasks: {str(e)}")
        abort(500)

@app.route('/community/<int:community_id>/polls_react')
@login_required
def community_polls_react(community_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React community polls: {str(e)}")
        abort(500)

@app.route('/post/<int:post_id>')
@login_required
def react_post_detail(post_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React post detail: {str(e)}")
        abort(500)

@app.route('/community/<int:community_id>/members')
@login_required
def react_members_page(community_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        resp = send_from_directory(dist_dir, 'index.html')
        try:
            resp.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            resp.headers['Pragma'] = 'no-cache'
            resp.headers['Expires'] = '0'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"Error serving React community members page: {str(e)}")
        abort(500)
@app.route('/.well-known/apple-app-site-association')
def apple_app_site_association():
    """Serve Apple App Site Association file for Universal Links"""
    try:
        response = send_from_directory('static/.well-known', 'apple-app-site-association')
        response.headers['Content-Type'] = 'application/json'
        response.headers['Cache-Control'] = 'public, max-age=3600'
        return response
    except Exception as e:
        logger.error(f"Error serving AASA file: {str(e)}")
        return jsonify({
            "applinks": {
                "apps": [],
                "details": []
            }
        }), 200

@app.route('/static/uploads/<path:filename>')
def static_uploaded_file(filename):
    """Alternative route for static uploads with caching"""
    try:
        logger.info(f"Static image request: {filename}")
        response = send_from_directory('static/uploads', filename)
        
        # Set cache headers - shorter cache for audio files
        audio_extensions = ['.mp3', '.wav', '.ogg', '.m4a', '.webm', '.mp4', '.aac', '.3gp', '.3g2']
        is_audio = any(filename.lower().endswith(ext) for ext in audio_extensions)

        if is_audio:
            response.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour for audio
        else:
            response.headers['Cache-Control'] = f'public, max-age={IMAGE_CACHE_TTL}'
        
        return response
    except Exception as e:
        logger.error(f"Error serving static image {filename}: {str(e)}")
        return "Error serving image", 500

# NOTE: Old uploads compatibility route removed to avoid overriding the main /uploads handler

# PWA/static helpers to avoid web server mapping issues
@app.route('/manifest.webmanifest')
def serve_manifest():
    try:
        resp = send_from_directory('static', 'manifest.webmanifest')
        try:
            resp.headers['Cache-Control'] = 'public, max-age=3600'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"serve_manifest error: {e}")
        abort(404)

@app.route('/favicon.svg')
def serve_favicon():
    try:
        return send_from_directory('static', 'favicon.svg')
    except Exception as e:
        logger.error(f"serve_favicon error: {e}")
        abort(404)

@app.route('/icons/<path:filename>')
def serve_icons(filename):
    try:
        resp = send_from_directory('static/icons', filename)
        try:
            resp.headers['Cache-Control'] = 'public, max-age=86400'
        except Exception:
            pass
        return resp
    except Exception as e:
        logger.error(f"serve_icons error for {filename}: {e}")
        abort(404)

# --- Diagnostics: image path checks ---
@app.route('/api/debug_image_paths')
@login_required
def api_debug_image_paths():
    """Inspect recent posts for a community and report image paths and file existence, plus user avatars.
    Usage: /api/debug_image_paths?community_id=123&limit=20
    """
    try:
        from datetime import datetime as _dt
        community_id = request.args.get('community_id', type=int)
        limit = request.args.get('limit', default=20, type=int)
        if not community_id:
            return jsonify({'success': False, 'error': 'community_id required'}), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT id, username, image_path, timestamp
                FROM posts
                WHERE community_id = ?
                ORDER BY id DESC
                LIMIT ?
            """, (community_id, limit))
            rows = c.fetchall() or []
            # Gather profile pictures for listed users
            usernames = list({(r['username'] if hasattr(r,'keys') else r[1]) for r in rows})
            avatars = {}
            try:
                if usernames:
                    placeholders = ",".join([get_sql_placeholder()]*len(usernames))
                    c.execute(f"SELECT username, profile_picture FROM user_profiles WHERE username IN ({placeholders})", tuple(usernames))
                    for ar in c.fetchall() or []:
                        u = ar['username'] if hasattr(ar,'keys') else ar[0]
                        avatars[u] = (ar['profile_picture'] if hasattr(ar,'keys') else ar[1]) or None
            except Exception:
                pass
        base_dir = os.path.dirname(os.path.abspath(__file__))
        static_uploads = os.path.join(base_dir, 'static', 'uploads')
        root_uploads = os.path.join(base_dir, 'uploads')
        def check_exists(p: str):
            try:
                s = (p or '').strip()
                if not s:
                    return {'given': p, 'exists': False, 'tried': []}
                tried = []
                if s.startswith('http'):
                    return {'given': p, 'exists': True, 'tried': ['http (skipped check)']}
                # Build candidates mirroring client logic
                cands = []
                if s.startswith('/uploads'):
                    cands.append(os.path.join(static_uploads, s.split('/uploads/',1)[1]))
                    cands.append(os.path.join(root_uploads, s.split('/uploads/',1)[1]))
                elif s.startswith('uploads/'):
                    cands.append(os.path.join(static_uploads, s.split('uploads/',1)[1]))
                    cands.append(os.path.join(root_uploads, s.split('uploads/',1)[1]))
                elif s.startswith('/static/'):
                    cands.append(os.path.join(base_dir, s.lstrip('/')))
                elif s.startswith('static/'):
                    cands.append(os.path.join(base_dir, s))
                else:
                    # bare filename
                    cands.append(os.path.join(static_uploads, s))
                    cands.append(os.path.join(base_dir, 'static', s))
                    cands.append(os.path.join(root_uploads, s))
                for fp in cands:
                    tried.append(fp)
                    if os.path.exists(fp):
                        return {'given': p, 'exists': True, 'path': fp, 'tried': tried}
                return {'given': p, 'exists': False, 'tried': tried}
            except Exception as e:
                return {'given': p, 'exists': False, 'error': str(e)}
        out = []
        for r in rows:
            pid = r['id'] if hasattr(r,'keys') else r[0]
            uname = r['username'] if hasattr(r,'keys') else r[1]
            img = r['image_path'] if hasattr(r,'keys') else r[2]
            ts = r['timestamp'] if hasattr(r,'keys') else r[3]
            out.append({
                'post_id': pid,
                'username': uname,
                'timestamp': ts,
                'image_path': img,
                'image_check': check_exists(str(img) if img is not None else ''),
                'avatar': avatars.get(uname),
                'avatar_check': check_exists(str(avatars.get(uname) or ''))
            })
        return jsonify({'success': True, 'community_id': community_id, 'count': len(out), 'items': out})
    except Exception as e:
        logger.error(f"debug_image_paths error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/static/community_backgrounds/<path:filename>')
def community_background_file(filename):
    """Serve community background images"""
    try:
        logger.info(f"Community background request: {filename}")
        # Check if file exists
        import os
        # Check in uploads folder first (where files are actually saved)
        upload_path = os.path.join(app.config['UPLOAD_FOLDER'], 'community_backgrounds', filename)
        static_path = os.path.join('static', 'community_backgrounds', filename)
        
        if os.path.exists(upload_path):
            response = send_from_directory(os.path.join(app.config['UPLOAD_FOLDER'], 'community_backgrounds'), filename)
            response.headers['Cache-Control'] = 'public, max-age=7200'  # 2 hours
            response.headers['ETag'] = f'"{filename}"'
            return response
        elif os.path.exists(static_path):
            response = send_from_directory('static/community_backgrounds', filename)
            response.headers['Cache-Control'] = 'public, max-age=7200'  # 2 hours
            response.headers['ETag'] = f'"{filename}"'
            return response
        else:
            logger.warning(f"Community background file not found in uploads or static: {filename}")
            # Return a transparent 1x1 pixel instead of 404
            from flask import Response
            transparent_pixel = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\nIDATx\x9cc\x00\x00\x00\x02\x00\x01\xe5\x27\xde\xfc\x00\x00\x00\x00IEND\xaeB`\x82'
            return Response(transparent_pixel, mimetype='image/png')
    except Exception as e:
        logger.error(f"Error serving community background {filename}: {str(e)}")
        return "Error serving image", 500

@app.route('/your_sports')
@login_required
def your_sports():
    username = session.get('username')
    
    # Check if user belongs to a gym community
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT c.type FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = ? AND c.type = 'gym'
                LIMIT 1
            """, (username,))
            gym_membership = c.fetchone()
            
            if not gym_membership:
                # User doesn't belong to a gym community
                ua = request.headers.get('User-Agent', '')
                is_mobile = any(k in ua for k in ['Mobi', 'Android', 'iPhone', 'iPad'])
                if is_mobile:
                    return redirect(url_for('premium_dashboard'))
                return render_template('error.html', 
                                     error_title='Access Restricted',
                                     error_message='You must be a member of a gym community to access Your Sports.',
                                     username=username)
    except Exception as e:
        logger.error(f"Error checking gym membership for {username}: {str(e)}")
        # On error, allow access (fail open)
        pass
    
    try:
        resp = serve_react_index()
        if resp:
            return resp
        logger.warning("React build missing for /your_sports; redirecting to premium dashboard")
        return redirect(url_for('premium_dashboard'))
    except Exception as e:
        logger.error(f"Error serving /your_sports for {username}: {e}")
        return redirect(url_for('premium_dashboard'))

@app.route('/api/check_gym_membership')
@login_required
def check_gym_membership():
    """Check if user belongs to a gym community"""
    username = session.get('username')
    logger.info(f"check_gym_membership called for user: {username}")
    
    # Special access for Paulo (case-insensitive)
    if username and username.lower() == 'paulo':
        logger.info(f"Paulo detected, granting gym access")
        return jsonify({
            'hasGymAccess': True,
            'username': username,
            'special_access': True
        })
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT c.type FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = ? AND c.type = 'gym'
                LIMIT 1
            """, (username,))
            gym_membership = c.fetchone()
            
            return jsonify({
                'hasGymAccess': bool(gym_membership),
                'username': username
            })
    except Exception as e:
        logger.error(f"Error checking gym membership for {username}: {str(e)}")
        return jsonify({'hasGymAccess': False, 'error': str(e)}), 500

@app.route('/api/simple_test')
@login_required
def simple_community_test():
    """Super simple test to see what communities exist"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get ALL parent communities
            c.execute("""
                SELECT id, name, type
                FROM communities
                WHERE parent_community_id IS NULL
                ORDER BY name
            """)
            all_parents = c.fetchall()
            
            return jsonify({
                'success': True,
                'username': username,
                'total_parent_communities': len(all_parents),
                'parent_communities': [
                    {'id': c.get('id'), 'name': c.get('name'), 'type': c.get('type')}
                    for c in all_parents
                ]
            })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/dashboard_communities_test')
@login_required
def dashboard_communities_test():
    """Test endpoint to show what communities should appear on dashboard"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # First, get ALL communities to understand the structure
            c.execute("""
                SELECT id, name, type, parent_community_id
                FROM communities
                ORDER BY CASE WHEN parent_community_id IS NULL THEN 0 ELSE 1 END, name
            """)
            all_communities = c.fetchall()
            
            # Get user's memberships
            placeholder = get_sql_placeholder()
            c.execute(f"""
                SELECT c.id, c.name, c.type, c.parent_community_id
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {placeholder}
                ORDER BY c.name
            """, (username,))
            user_communities = c.fetchall()
            
            # Determine what should show on dashboard
            dashboard_communities = []
            seen_parents = set()
            
            for comm in user_communities:
                comm_id = comm.get('id')
                parent_id = comm.get('parent_community_id')
                
                if parent_id is None:
                    # This is a standalone/parent community - show it
                    if comm_id not in seen_parents:
                        dashboard_communities.append({
                            'id': comm_id,
                            'name': comm.get('name'),
                            'type': comm.get('type'),
                            'reason': 'Standalone community (no parent)'
                        })
                        seen_parents.add(comm_id)
                else:
                    # This is a child community - show its parent
                    if parent_id not in seen_parents:
                        # Find parent details
                        parent = next((c for c in all_communities if c.get('id') == parent_id), None)
                        if parent:
                            dashboard_communities.append({
                                'id': parent_id,
                                'name': parent.get('name'),
                                'type': parent.get('type'),
                                'reason': f"Parent of {comm.get('name')}"
                            })
                            seen_parents.add(parent_id)
            
            return jsonify({
                'success': True,
                'username': username,
                'all_communities_count': len(all_communities),
                'user_communities_count': len(user_communities),
                'dashboard_should_show': dashboard_communities,
                'dashboard_count': len(dashboard_communities),
                'all_communities': [
                    {
                        'id': c.get('id'),
                        'name': c.get('name'),
                        'type': c.get('type'),
                        'parent_id': c.get('parent_community_id')
                    } for c in all_communities
                ],
                'user_communities': [
                    {
                        'id': c.get('id'),
                        'name': c.get('name'),
                        'type': c.get('type'),
                        'parent_id': c.get('parent_community_id')
                    } for c in user_communities
                ]
            })
            
    except Exception as e:
        logger.error(f"Dashboard communities test error: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/all_communities_debug')
@login_required
def get_all_communities_debug():
    """Debug endpoint to see ALL communities and user memberships"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get ALL communities in the database
            c.execute("""
                SELECT id, name, type, parent_community_id
                FROM communities
                ORDER BY name
            """)
            all_communities = c.fetchall()
            
            # Get user's direct community memberships
            placeholder = get_sql_placeholder()
            c.execute(f"""
                SELECT c.id, c.name, c.type, c.parent_community_id
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {placeholder}
                ORDER BY c.name
            """, (username,))
            user_communities = c.fetchall()
            
            return jsonify({
                'success': True,
                'username': username,
                'all_communities_in_db': [
                    {
                        'id': c.get('id'),
                        'name': c.get('name'),
                        'type': c.get('type'),
                        'parent_id': c.get('parent_community_id')
                    } for c in all_communities
                ],
                'user_direct_memberships': [
                    {
                        'id': c.get('id'),
                        'name': c.get('name'),
                        'type': c.get('type'),
                        'parent_id': c.get('parent_community_id')
                    } for c in user_communities
                ]
            })
    except Exception as e:
        logger.error(f"Debug all communities error: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500
@app.route('/api/user_parent_community')
@login_required
def get_user_parent_community():
    """Get communities to display on dashboard - SIMPLIFIED"""
    username = session.get('username')
    logger.info(f"Getting dashboard communities for user: {username}")
    cache_key = user_parent_dashboard_cache_key(username)
    if cache_key:
        cached = cache.get(cache_key)
        if cached:
            return jsonify(cached)
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Simple approach: Just get all parent communities (those without parent_community_id)
            # Admins see all, regular users see only theirs
            placeholder = get_sql_placeholder()

            # Determine admin using application logic to avoid DB column dependency
            is_admin = is_app_admin(username)
            logger.info(f"User {username} is_admin: {is_admin}")

            if is_admin:
                # Admin: return ALL top-level parent communities
                c.execute("""
                    SELECT id, name, type
                    FROM communities
                    WHERE parent_community_id IS NULL
                    ORDER BY name
                """)
                parent_rows = c.fetchall()
                logger.info("Admin: fetched all top-level parent communities")
                communities_list = []
                for row in parent_rows:
                    if hasattr(row, 'keys'):
                        communities_list.append({'id': row['id'], 'name': row['name'], 'type': row['type']})
                    else:
                        communities_list.append({'id': row[0], 'name': row[1], 'type': row[2]})
            else:
                # User: gather communities by membership OR creator OR admin role (run separately for robust cross-DB behavior)
                # 1) Memberships via user_communities
                c.execute(f"SELECT id FROM users WHERE username = {placeholder}", (username,))
                user_row = c.fetchone()
                user_id = user_row['id'] if hasattr(user_row, 'keys') else (user_row[0] if user_row else None)
                if not user_id:
                    logger.warning(f"Dashboard: user_id not found for {username}")
                community_ids = set()
                if user_id:
                    c.execute(f"SELECT community_id FROM user_communities WHERE user_id = {placeholder}", (user_id,))
                    uc_rows = c.fetchall()
                    for r in uc_rows:
                        cid = r['community_id'] if hasattr(r, 'keys') else (r[0] if len(r) > 0 else None)
                        if cid:
                            community_ids.add(cid)
                    logger.info(f"Dashboard: membership communities for {username}: {len(uc_rows)} rows, {len(community_ids)} unique IDs")

                # 2) Communities created by user
                c.execute(f"SELECT id FROM communities WHERE creator_username = {placeholder}", (username,))
                created_rows = c.fetchall()
                for r in created_rows:
                    cid = r['id'] if hasattr(r, 'keys') else (r[0] if len(r) > 0 else None)
                    if cid:
                        community_ids.add(cid)
                logger.info(f"Dashboard: created communities for {username}: {len(created_rows)} rows, total IDs now {len(community_ids)}")

                # 3) Communities where user is admin
                c.execute(f"SELECT community_id FROM community_admins WHERE username = {placeholder}", (username,))
                admin_rows = c.fetchall()
                for r in admin_rows:
                    cid = r['community_id'] if hasattr(r, 'keys') else (r[0] if len(r) > 0 else None)
                    if cid:
                        community_ids.add(cid)
                logger.info(f"Dashboard: admin communities for {username}: {len(admin_rows)} rows, total IDs now {len(community_ids)}")

                if not community_ids:
                    logger.info(f"Dashboard: no direct communities found for {username}")

                # Fetch full rows for these community IDs
                member_rows = []
                if community_ids:
                    # Build placeholder list safely
                    ph = get_sql_placeholder()
                    placeholders = ','.join([ph for _ in community_ids])
                    c.execute(f"SELECT id, name, type, parent_community_id FROM communities WHERE id IN ({placeholders})", tuple(community_ids))
                    member_rows = c.fetchall()
                logger.info(f"Dashboard: resolved {len(member_rows)} community rows for {username}")

                # Helper to fetch a community by id
                def fetch_comm(comm_id):
                    ph = get_sql_placeholder()
                    c.execute(f"SELECT id, name, type, parent_community_id FROM communities WHERE id = {ph}", (comm_id,))
                    return c.fetchone()

                top_parents = {}
                for row in member_rows:
                    if hasattr(row, 'keys'):
                        current_id = row['id']
                        parent_id = row['parent_community_id']
                        current_name = row['name']
                        current_type = row['type']
                    else:
                        current_id = row[0]
                        parent_id = row[3]
                        current_name = row[1]
                        current_type = row[2]

                    seen_chain = set()
                    top_name = current_name
                    top_type = current_type
                    # Walk up parent chain until root
                    while parent_id is not None and parent_id not in seen_chain:
                        seen_chain.add(parent_id)
                        parent_row = fetch_comm(parent_id)
                        if not parent_row:
                            break
                        if hasattr(parent_row, 'keys'):
                            current_id = parent_row['id']
                            parent_id = parent_row['parent_community_id']
                            top_name = parent_row['name']
                            top_type = parent_row['type']
                        else:
                            current_id = parent_row[0]
                            parent_id = parent_row[3]
                            top_name = parent_row[1]
                            top_type = parent_row[2]

                    # current_id now points to the top-most parent (or original if no parent)
                    if current_id not in top_parents:
                        top_parents[current_id] = {
                            'id': current_id,
                            'name': top_name,
                            'type': top_type
                        }

                communities_list = list(top_parents.values())
                communities_list.sort(key=lambda x: (x.get('name') or '').lower())

                # Ensure Gym community appears for users with gym access (e.g., Paulo)
                try:
                    has_gym_access = (username and username.lower() == 'paulo')
                    if not has_gym_access:
                        ph = get_sql_placeholder()
                        c.execute(f"""
                            SELECT 1
                            FROM communities c
                            JOIN user_communities uc ON c.id = uc.community_id
                            JOIN users u ON uc.user_id = u.id
                            WHERE u.username = {ph} AND c.type = 'gym'
                            LIMIT 1
                        """, (username,))
                        has_gym_access = c.fetchone() is not None

                    if has_gym_access:
                        # Add any gym communities by climbing to their top-level parent
                        c.execute("""
                            SELECT id, name, type, parent_community_id
                            FROM communities
                            WHERE LOWER(type) = 'gym'
                        """)
                        gym_rows = c.fetchall()
                        seen_ids = {item['id'] if hasattr(item, 'keys') else item[0] for item in communities_list}
                        added = 0
                        for row in gym_rows:
                            if hasattr(row, 'keys'):
                                cid, name, gtype, parent_id = row['id'], row['name'], row['type'], row['parent_community_id']
                            else:
                                cid, name, gtype, parent_id = row[0], row[1], row[2], row[3]

                            # climb to top parent
                            top_id, top_name, top_type = cid, name, gtype
                            visited = set()
                            while parent_id is not None and parent_id not in visited:
                                visited.add(parent_id)
                                ph = get_sql_placeholder()
                                c.execute(f"SELECT id, name, type, parent_community_id FROM communities WHERE id = {ph}", (parent_id,))
                                prow = c.fetchone()
                                if not prow:
                                    break
                                if hasattr(prow, 'keys'):
                                    top_id, top_name, top_type = prow['id'], prow['name'], prow['type']
                                    parent_id = prow['parent_community_id']
                                else:
                                    top_id, top_name, top_type = prow[0], prow[1], prow[2]
                                    parent_id = prow[3]

                            if top_id not in seen_ids:
                                communities_list.append({'id': top_id, 'name': top_name, 'type': top_type})
                                seen_ids.add(top_id)
                                added += 1
                        if added:
                            logger.info(f"Dashboard: added {added} gym parent communities for {username}")
                except Exception as gym_err:
                    logger.warning(f"Dashboard: failed to ensure gym community for {username}: {gym_err}")
                try:
                    logger.info(f"Dashboard: top-level parent communities for {username} -> {len(communities_list)} items: " + 
                                ", ".join([f"{c.get('id')}:{c.get('name')}" for c in communities_list]))
                except Exception:
                    pass
            
            logger.info(f"Returning {len(communities_list)} communities for dashboard")
            
            response_payload = {
                'success': True,
                'communities': communities_list,
                'parentCommunity': communities_list[0] if communities_list else None  # Keep backward compatibility
            }
            if cache_key:
                try:
                    cache.set(cache_key, response_payload, COMMUNITY_CACHE_TTL)
                except Exception:
                    pass
            return jsonify(response_payload)
                
    except Exception as e:
        logger.error(f"Error getting parent community for {username}: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/user_communities_hierarchical')
@login_required
def get_user_communities_hierarchical():
    """Get user's communities organized in parent-child hierarchy"""
    username = session.get('username')
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            placeholder = '%s' if USE_MYSQL else '?'
            
            # Check if user is admin
            if is_app_admin(username):
                # Admin sees all communities
                c.execute("""
                    SELECT DISTINCT 
                        c.id,
                        c.name,
                        c.type,
                        c.parent_community_id,
                        c.creator_username,
                        pc.name as parent_name
                    FROM communities c
                    LEFT JOIN communities pc ON c.parent_community_id = pc.id
                    ORDER BY 
                        CASE WHEN c.parent_community_id IS NULL THEN 0 ELSE 1 END,
                        COALESCE(pc.name, c.name),
                        c.name
                """)
            else:
                # Get communities user is directly a member of
                c.execute(f"""
                    SELECT DISTINCT 
                        c.id,
                        c.name,
                        c.type,
                        c.parent_community_id,
                        c.creator_username,
                        pc.name as parent_name,
                        uc.role
                    FROM communities c
                    JOIN user_communities uc ON c.id = uc.community_id
                    JOIN users u ON uc.user_id = u.id
                    LEFT JOIN communities pc ON c.parent_community_id = pc.id
                    WHERE u.username = {placeholder}
                    ORDER BY 
                        CASE WHEN c.parent_community_id IS NULL THEN 0 ELSE 1 END,
                        COALESCE(pc.name, c.name),
                        c.name
                """, (username,))
                
                user_communities = c.fetchall()
                
                # Find communities where user is owner or admin (can see descendants)
                admin_community_ids = []
                for comm in user_communities:
                    comm_id = comm['id'] if hasattr(comm, 'keys') else comm[0]
                    creator = comm['creator_username'] if hasattr(comm, 'keys') else comm[4]
                    role = comm['role'] if hasattr(comm, 'keys') else comm[6]
                    
                    # If user is owner or admin of this community, they can see all descendants
                    if username == creator or role == 'admin' or role == 'owner':
                        admin_community_ids.append(comm_id)
                
                # Start with communities user is a member of
                all_accessible_ids = set()
                for comm in user_communities:
                    all_accessible_ids.add(comm['id'] if hasattr(comm, 'keys') else comm[0])
                
                # Add ALL descendant communities where user is admin/owner
                if admin_community_ids:
                    # Get all communities
                    c.execute("""
                        SELECT id, name, type, parent_community_id, creator_username
                        FROM communities
                    """)
                    all_comms = c.fetchall()
                    
                    # Recursively get all descendants
                    def get_all_descendants(comm_id, all_comms_list):
                        descendants = []
                        for comm in all_comms_list:
                            parent_id = comm['parent_community_id'] if hasattr(comm, 'keys') else comm[3]
                            if parent_id == comm_id:
                                child_id = comm['id'] if hasattr(comm, 'keys') else comm[0]
                                descendants.append(child_id)
                                # Recursively get this child's descendants
                                descendants.extend(get_all_descendants(child_id, all_comms_list))
                        return descendants
                    
                    # For each admin community, get ALL its descendants
                    for admin_id in admin_community_ids:
                        descendants = get_all_descendants(admin_id, all_comms)
                        all_accessible_ids.update(descendants)
                
                # Get full details of accessible communities
                if all_accessible_ids:
                    id_list = ','.join([str(x) for x in all_accessible_ids])
                    c.execute(f"""
                        SELECT DISTINCT 
                            c.id,
                            c.name,
                            c.type,
                            c.parent_community_id,
                            c.creator_username,
                            pc.name as parent_name
                        FROM communities c
                        LEFT JOIN communities pc ON c.parent_community_id = pc.id
                        WHERE c.id IN ({id_list})
                        ORDER BY 
                            CASE WHEN c.parent_community_id IS NULL THEN 0 ELSE 1 END,
                            COALESCE(pc.name, c.name),
                            c.name
                    """)
                else:
                    return jsonify({'success': True, 'communities': []})
            
            communities = c.fetchall()
            
            # Organize into N-level hierarchy
            all_communities_dict = {}
            already_added_as_child = set()  # Track which communities are already children to prevent duplicates
            
            # First pass: create all community objects
            for community in communities:
                community_data = {
                    'id': community['id'],
                    'name': community['name'],
                    'type': community['type'],
                    'parent_community_id': community['parent_community_id'],
                    'creator_username': community.get('creator_username') if hasattr(community, 'get') else community['creator_username'],
                    'children': []
                }
                all_communities_dict[community['id']] = community_data
            
            # Second pass: build hierarchy - only add each community as a child once
            for comm_id, comm_data in list(all_communities_dict.items()):
                parent_id = comm_data['parent_community_id']
                if parent_id and parent_id in all_communities_dict:
                    # Parent exists in our dict, add this as a child
                    # Check if this child is not already in the parent's children list (prevent duplicates)
                    parent_children_ids = [ch['id'] for ch in all_communities_dict[parent_id]['children']]
                    if comm_id not in parent_children_ids and comm_id not in already_added_as_child:
                        all_communities_dict[parent_id]['children'].append(comm_data)
                        already_added_as_child.add(comm_id)
            
            # Find root communities
            parent_communities = {}
            for comm_id, comm_data in all_communities_dict.items():
                if not comm_data['parent_community_id']:
                    # This is a root community
                    parent_communities[comm_id] = comm_data
                elif comm_data['parent_community_id'] not in all_communities_dict:
                    # Edge case: User owns a sub-community but doesn't have access to parent
                    # Get parent info and create a placeholder parent
                    placeholder_parent = '%s' if USE_MYSQL else '?'
                    c.execute(f"SELECT id, name, type, creator_username FROM communities WHERE id = {placeholder_parent}", (comm_data['parent_community_id'],))
                    parent_info = c.fetchone()
                    if parent_info:
                        parent_id = parent_info['id'] if hasattr(parent_info, 'keys') else parent_info[0]
                        if parent_id not in parent_communities:
                            parent_data = {
                                'id': parent_id,
                                'name': parent_info['name'] if hasattr(parent_info, 'keys') else parent_info[1],
                                'type': parent_info['type'] if hasattr(parent_info, 'keys') else parent_info[2],
                                'creator_username': parent_info.get('creator_username') if hasattr(parent_info, 'get') else (parent_info['creator_username'] if hasattr(parent_info, 'keys') else parent_info[3]),
                                'parent_community_id': None,
                                'children': [],
                                'is_parent_only': True  # User is not directly member of parent
                            }
                            # Add this sub-community as a child only if not already added
                            if comm_id not in already_added_as_child:
                                parent_data['children'].append(comm_data)
                                already_added_as_child.add(comm_id)
                            parent_communities[parent_id] = parent_data
            
            # Convert to list and validate no circular references
            result = list(parent_communities.values())
            
            # Safety check: ensure no community appears multiple times in the tree
            def validate_no_duplicates(communities, seen_ids=None):
                if seen_ids is None:
                    seen_ids = set()
                for comm in communities:
                    if comm['id'] in seen_ids:
                        logger.warning(f"Duplicate community detected in hierarchy: {comm['id']} - {comm['name']}")
                        return False
                    seen_ids.add(comm['id'])
                    if comm.get('children'):
                        if not validate_no_duplicates(comm['children'], seen_ids):
                            return False
                return True
            
            if not validate_no_duplicates(result):
                logger.error(f"Circular reference detected in hierarchy for user {username}")
                # Fallback: just return flat list without hierarchy
                return jsonify({
                    'success': True,
                    'communities': [{'id': c['id'], 'name': c['name'], 'type': c['type'], 'children': []} 
                                   for c in all_communities_dict.values()]
                })
            
            return jsonify({
                'success': True,
                'communities': result
            })
                
    except Exception as e:
        logger.error(f"Error getting hierarchical communities for {username}: {str(e)}")
        return jsonify({'success': False, 'error': str(e)}), 500

# ----------------------
# Groups (horizontal) APIs
# ----------------------

@app.route('/api/groups/create_legacy_disabled', methods=['POST'], endpoint='api_groups_create_legacy')
@login_required
def api_groups_create_legacy():
    """Create a group under a specific community/sub-community. Admins/owners only."""
    username = session.get('username')
    community_id_raw = request.form.get('community_id', '').strip()
    name = request.form.get('name', '').strip()
    approval_required_raw = request.form.get('approval_required', '0').strip()
    try:
        community_id = int(community_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community_id'})
    if not name:
        return jsonify({'success': False, 'error': 'Group name is required'})
    approval_required = approval_required_raw in ('1', 'true', 'True', 'yes', 'on')
    try:
        # Treat community owner, admins, and app admin as authorized. Also allow the community's creator via user_communities role=admin fallback.
        if not has_community_management_permission(username, community_id):
            return jsonify({'success': False, 'error': 'Not authorized'}), 403
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure community exists
            c.execute("SELECT id FROM communities WHERE id = ?", (community_id,))
            if not c.fetchone():
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            # Insert group
            if USE_MYSQL:
                c.execute("""
                    INSERT INTO `groups` (community_id, name, approval_required, created_by)
                    VALUES (%s, %s, %s, %s)
                """, (community_id, name, 1 if approval_required else 0, username))
                gid = c.lastrowid
            else:
                c.execute("""
                    INSERT INTO groups (community_id, name, approval_required, created_by, created_at)
                    VALUES (?, ?, ?, ?, ?)
                """, (community_id, name, 1 if approval_required else 0, username, datetime.now().isoformat()))
                gid = c.lastrowid
            conn.commit()
            return jsonify({'success': True, 'group_id': int(gid)})
    except Exception as e:
        logger.error(f"api_groups_create error: {e}")
        return jsonify({'success': False, 'error': 'Failed to create group'})


@app.route('/api/groups_legacy_disabled', methods=['GET'], endpoint='api_groups_list_legacy')
@login_required
def api_groups_list_legacy():
    """List groups for a community. If include_ancestors=1, includes parent chain."""
    username = session.get('username')
    community_id_raw = request.args.get('community_id', '').strip()
    include_ancestors = request.args.get('include_ancestors', '0') in ('1', 'true', 'True', 'yes')
    try:
        community_id = int(community_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            placeholder = get_sql_placeholder()
            # Determine parent for ancestor inclusion and membership checks
            c.execute(f"SELECT parent_community_id FROM communities WHERE id = {placeholder}", (community_id,))
            row = c.fetchone()
            parent_id = (row['parent_community_id'] if hasattr(row, 'keys') else row[0]) if row else None

            def is_member(comm_id: int) -> bool:
                try:
                    c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={placeholder} AND uc.community_id={placeholder}", (username, comm_id))
                    return c.fetchone() is not None
                except Exception:
                    return False

            # User must be member of the community or its parent
            if not (is_member(community_id) or (parent_id and is_member(parent_id))):
                return jsonify({'success': False, 'error': 'Not a member'}), 403

            community_ids = [community_id]
            if include_ancestors and parent_id:
                community_ids.append(parent_id)

            out = []
            for cid in community_ids:
                c.execute("SELECT id, name, approval_required FROM groups WHERE community_id = ? ORDER BY name", (cid,))
                groups = c.fetchall() or []
                for g in groups:
                    gid = g['id'] if hasattr(g, 'keys') else g[0]
                    c.execute("SELECT status FROM group_members WHERE group_id=? AND username=?", (gid, username))
                    gm = c.fetchone()
                    status = gm['status'] if hasattr(gm, 'keys') else (gm[0] if gm else None)
                    out.append({
                        'id': gid,
                        'name': g['name'] if hasattr(g, 'keys') else g[1],
                        'approval_required': bool(g['approval_required'] if hasattr(g, 'keys') else g[2]),
                        'membership_status': status or None,
                        'community_id': cid,
                    })
            return jsonify({'success': True, 'groups': out})
    except Exception as e:
        logger.error(f"api_groups_list error: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/groups/join_legacy_disabled', methods=['POST'], endpoint='api_groups_join_legacy')
@login_required
def api_groups_join_legacy():
    username = session.get('username')
    group_id = request.form.get('group_id', '').strip()
    try:
        group_id_int = int(group_id)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Find group community and approval flag
            c.execute("SELECT community_id, approval_required FROM groups WHERE id=?", (group_id_int,))
            g = c.fetchone()
            if not g:
                return jsonify({'success': False, 'error': 'Group not found'})
            community_id = g['community_id'] if hasattr(g, 'keys') else g[0]
            approval_required = bool(g['approval_required'] if hasattr(g, 'keys') else g[1])

            # Check membership in community or its parent
            placeholder = get_sql_placeholder()
            def is_member(comm_id: int) -> bool:
                try:
                    c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={placeholder} AND uc.community_id={placeholder}", (username, comm_id))
                    return c.fetchone() is not None
                except Exception:
                    return False
            c.execute(f"SELECT parent_community_id FROM communities WHERE id={placeholder}", (community_id,))
            row = c.fetchone()
            parent_id = (row['parent_community_id'] if hasattr(row, 'keys') else row[0]) if row else None
            if not (is_member(community_id) or (parent_id and is_member(parent_id))):
                return jsonify({'success': False, 'error': 'Not a member of the related community'}), 403

            status = 'pending' if approval_required else 'member'
            try:
                c.execute("INSERT INTO group_members (group_id, username, status) VALUES (?, ?, ?)", (group_id_int, username, status))
            except Exception:
                # If exists, update to member if previously pending
                c.execute("UPDATE group_members SET status=? WHERE group_id=? AND username=?", (status, group_id_int, username))
            if not USE_MYSQL:
                conn.commit()
            return jsonify({'success': True, 'status': status})
    except Exception as e:
        logger.error(f"api_groups_join error: {e}")
        return jsonify({'success': False, 'error': str(e)})


@app.route('/api/groups/available_count_legacy_disabled', methods=['GET'], endpoint='api_groups_available_count_legacy')
@login_required
def api_groups_available_count_legacy():
    username = session.get('username')
    community_id = request.args.get('community_id', '').strip()
    try:
        community_id_int = int(community_id)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Count groups for community and its parents that user can join and is not a member/pending
            # Collect candidate community ids: self + parent
            placeholder = get_sql_placeholder()
            candidate_ids = [community_id_int]
            try:
                c.execute(f"SELECT parent_community_id FROM communities WHERE id={placeholder}", (community_id_int,))
                row = c.fetchone()
                pid = (row['parent_community_id'] if hasattr(row, 'keys') else row[0]) if row else None
                if pid:
                    candidate_ids.append(pid)
            except Exception:
                pass
            # Build query
            total = 0
            for cid in candidate_ids:
                c.execute("SELECT id FROM groups WHERE community_id=?", (cid,))
                groups = c.fetchall() or []
                for g in groups:
                    gid = g['id'] if hasattr(g, 'keys') else g[0]
                    c.execute("SELECT status FROM group_members WHERE group_id=? AND username=?", (gid, username))
                    if c.fetchone():
                        continue
                    total += 1
            return jsonify({'success': True, 'count': total})
    except Exception as e:
        logger.error(f"api_groups_available_count error: {e}")
        return jsonify({'success': False, 'error': str(e)})

# ---------------------- Groups (primary endpoints) ----------------------
@app.route('/api/groups/create', methods=['POST'])
@login_required
def api_groups_create():
    """Create a group under a specific community/sub-community.
    Only the global app admin and Paulo can create groups.
    """
    username = session.get('username')
    community_id_raw = request.form.get('community_id', '').strip()
    name = request.form.get('name', '').strip()
    approval_required_raw = request.form.get('approval_required', '0').strip()
    try:
        community_id = int(community_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community_id'})
    if not name:
        return jsonify({'success': False, 'error': 'Group name is required'})
    approval_required = approval_required_raw in ('1', 'true', 'True', 'yes', 'on')
    try:
        # Restrict creators to app admin or Paulo only
        allowed_creators = { 'admin', 'paulo' }
        if not (username and username.lower() in allowed_creators):
            return jsonify({'success': False, 'error': 'Only admin or Paulo can create groups'}), 403
        with get_db_connection() as conn:
            c = conn.cursor()
            # Ensure community exists
            c.execute("SELECT id, creator_username, parent_community_id FROM communities WHERE id = ?", (community_id,))
            community_row = c.fetchone()
            if not community_row:
                return jsonify({'success': False, 'error': 'Community not found'}), 404
            community_parent_id = community_row['parent_community_id'] if hasattr(community_row, 'keys') else community_row[2]
            ancestors = get_community_ancestors(c, community_id)
            top_info = ancestors[-1] if ancestors else get_community_basic(c, community_id)
            top_creator = top_info.get('creator_username') if top_info else None
            if community_parent_id:
                subscription_value = fetch_user_subscription(c, top_creator) if top_creator else ''
                if top_creator and top_creator.lower() != 'admin' and is_free_subscription(subscription_value):
                    return jsonify({'success': False, 'error': 'Groups for free plan communities are only available at the parent community level.'}), 403
            # Insert group
            if USE_MYSQL:
                c.execute("""
                    INSERT INTO `groups` (community_id, name, approval_required, created_by)
                    VALUES (%s, %s, %s, %s)
                """, (community_id, name, 1 if approval_required else 0, username))
                gid = c.lastrowid
            else:
                c.execute("""
                    INSERT INTO groups (community_id, name, approval_required, created_by, created_at)
                    VALUES (?, ?, ?, ?, ?)
                """, (community_id, name, 1 if approval_required else 0, username, datetime.now().isoformat()))
                gid = c.lastrowid
            conn.commit()
            return jsonify({'success': True, 'group_id': int(gid)})
    except Exception as e:
        logger.error(f"api_groups_create error: {e}")
        return jsonify({'success': False, 'error': 'Failed to create group'})

@app.route('/api/groups', methods=['GET'])
@login_required
def api_groups_list():
    """List groups for a community. If include_ancestors=1, includes parent chain."""
    username = session.get('username')
    community_id_raw = request.args.get('community_id', '').strip()
    include_ancestors = request.args.get('include_ancestors', '0') in ('1', 'true', 'True', 'yes')
    try:
        community_id = int(community_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Verify membership in the community
            ph = get_sql_placeholder()
            c.execute(f"""
                SELECT 1 FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {ph} AND uc.community_id = {ph}
            """, (username, community_id))
            member_direct = bool(c.fetchone())
            if not member_direct:
                # If include_ancestors is requested, also allow if user is member of parent
                if not include_ancestors:
                    return jsonify({'success': False, 'error': 'Not a member'}), 403
            # Build eligible ids
            eligible_ids = set([community_id])
            if include_ancestors:
                try:
                    c.execute(f"SELECT parent_community_id FROM communities WHERE id = {ph}", (community_id,))
                    rowp = c.fetchone()
                    pid = rowp['parent_community_id'] if rowp else None
                    if pid:
                        eligible_ids.add(pid)
                except Exception:
                    pass
            placeholders = ','.join([get_sql_placeholder()]*len(eligible_ids)) if eligible_ids else 'NULL'
            params = tuple(eligible_ids)
            # Fetch groups and membership status
            groups_table = '`groups`' if USE_MYSQL else 'groups'
            group_members_table = '`group_members`' if USE_MYSQL else 'group_members'
            c.execute(f"""
                SELECT g.id, g.name, g.community_id, g.approval_required, g.created_by,
                       COALESCE(gm.status, '') AS membership_status
                FROM {groups_table} g
                LEFT JOIN {group_members_table} gm ON gm.group_id = g.id AND gm.username = {ph}
                WHERE g.community_id IN ({placeholders})
                ORDER BY g.name
            """, (username, *params) if eligible_ids else (username,))
            rows = c.fetchall()
            groups = []
            for r in rows:
                item = {
                    'id': r['id'],
                    'name': r['name'],
                    'community_id': r['community_id'],
                    'approval_required': bool(r['approval_required']),
                    'membership_status': r['membership_status'] or None,
                    'can_delete': bool((r['created_by'] if hasattr(r, 'keys') else None) == username or is_app_admin(username)),
                }
                groups.append(item)
            return jsonify({'success': True, 'groups': groups, 'member': bool(member_direct)})
    except Exception as e:
        logger.error(f"api_groups_list error: {e}")
        return jsonify({'success': False, 'error': 'Failed to list groups'})

@app.route('/api/groups/join', methods=['POST'])
@login_required
def api_groups_join():
    """Join a group. If approval_required, status=pending; else member."""
    username = session.get('username')
    gid_raw = request.form.get('group_id', '').strip()
    try:
        group_id = int(gid_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            # Fetch group and owning community
            c.execute(f"SELECT id, community_id, approval_required FROM {'`groups`' if USE_MYSQL else 'groups'} WHERE id = ?", (group_id,))
            g = c.fetchone()
            if not g:
                return jsonify({'success': False, 'error': 'Group not found'}), 404
            community_id = g['community_id']
            approval_required = bool(g['approval_required'])
            # Verify membership in owning community (direct)
            c.execute(f"""
                SELECT 1 FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = {ph} AND uc.community_id = {ph}
            """, (username, community_id))
            if not c.fetchone():
                # Also allow if user is member of parent (in case they weren't auto-added)
                c.execute("SELECT parent_community_id FROM communities WHERE id = ?", (community_id,))
                rowp = c.fetchone()
                pid = rowp['parent_community_id'] if rowp else None
                if not pid:
                    return jsonify({'success': False, 'error': 'Not a member of this community'}), 403
                c.execute(f"""
                    SELECT 1 FROM user_communities uc
                    JOIN users u ON uc.user_id = u.id
                    WHERE u.username = {ph} AND uc.community_id = {ph}
                """, (username, pid))
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'Not a member of this community'}), 403
            # Insert/Update membership
            status = 'pending' if approval_required else 'member'
            if USE_MYSQL:
                try:
                    c.execute("""
                        INSERT INTO group_members (group_id, username, status)
                        VALUES (%s, %s, %s)
                        ON DUPLICATE KEY UPDATE status = VALUES(status)
                    """, (group_id, username, status))
                except Exception:
                    # Fallback if ON DUPLICATE not available
                    c.execute("SELECT id,status FROM group_members WHERE group_id=%s AND username=%s", (group_id, username))
                    row = c.fetchone()
                    if row:
                        c.execute("UPDATE group_members SET status=%s WHERE id=%s", (status, row['id']))
                    else:
                        c.execute("INSERT INTO group_members (group_id, username, status) VALUES (%s, %s, %s)", (group_id, username, status))
            else:
                try:
                    c.execute("INSERT OR REPLACE INTO group_members (group_id, username, status, created_at) VALUES (?, ?, ?, ?)", (group_id, username, status, datetime.now().isoformat()))
                except Exception:
                    # Fallback without REPLACE
                    c.execute("SELECT id FROM group_members WHERE group_id=? AND username=?", (group_id, username))
                    r = c.fetchone()
                    if r:
                        c.execute("UPDATE group_members SET status=? WHERE id=?", (status, r['id']))
                    else:
                        c.execute("INSERT INTO group_members (group_id, username, status, created_at) VALUES (?, ?, ?, ?)", (group_id, username, status, datetime.now().isoformat()))
            conn.commit()
            return jsonify({'success': True, 'status': status})
    except Exception as e:
        logger.error(f"api_groups_join error: {e}")
        return jsonify({'success': False, 'error': 'Failed to join group'})

# Leave a group (member can leave)
@app.route('/api/groups/leave', methods=['POST'])
@login_required
def api_groups_leave():
    username = session.get('username')
    gid_raw = request.form.get('group_id', '').strip()
    try:
        group_id = int(gid_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Verify group exists
            c.execute(f"SELECT id FROM {'`groups`' if USE_MYSQL else 'groups'} WHERE id = {get_sql_placeholder()}", (group_id,))
            if not c.fetchone():
                return jsonify({'success': False, 'error': 'Group not found'}), 404
            # Delete membership if present
            c.execute(f"DELETE FROM {'`group_members`' if USE_MYSQL else 'group_members'} WHERE group_id = {get_sql_placeholder()} AND username = {get_sql_placeholder()}", (group_id, username))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True, 'left': True})
    except Exception as e:
        logger.error(f"api_groups_leave error: {e}")
        return jsonify({'success': False, 'error': 'Failed to leave group'})

# Delete a group (group owner or app admin only)
@app.route('/api/groups/delete', methods=['POST'])
@login_required
def api_groups_delete():
    username = session.get('username')
    gid_raw = request.form.get('group_id', '').strip()
    try:
        group_id = int(gid_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute(f"SELECT id, created_by FROM {'`groups`' if USE_MYSQL else 'groups'} WHERE id = {get_sql_placeholder()}", (group_id,))
            g = c.fetchone()
            if not g:
                return jsonify({'success': False, 'error': 'Group not found'}), 404
            created_by = g['created_by'] if hasattr(g, 'keys') else g[1]
            if not (username == created_by or is_app_admin(username)):
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            c.execute(f"DELETE FROM {'`groups`' if USE_MYSQL else 'groups'} WHERE id = {get_sql_placeholder()}", (group_id,))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_groups_delete error: {e}")
        return jsonify({'success': False, 'error': 'Failed to delete group'})

@app.route('/api/groups/available_count', methods=['GET'])
@login_required
def api_groups_available_count():
    """Return count of groups available to join for a given community, including parent."""
    username = session.get('username')
    community_id_raw = request.args.get('community_id', '').strip()
    try:
        community_id = int(community_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid community_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            eligible = set([community_id])
            try:
                c.execute("SELECT parent_community_id FROM communities WHERE id = ?", (community_id,))
                rowp = c.fetchone()
                pid = rowp['parent_community_id'] if rowp else None
                if pid:
                    eligible.add(pid)
            except Exception:
                pass
            if not eligible:
                return jsonify({'success': True, 'count': 0})
            placeholders = ','.join([get_sql_placeholder()]*len(eligible))
            groups_table = '`groups`' if USE_MYSQL else 'groups'
            group_members_table = '`group_members`' if USE_MYSQL else 'group_members'
            c.execute(f"""
                SELECT COUNT(*) AS cnt
                FROM {groups_table} g
                WHERE g.community_id IN ({placeholders})
                  AND NOT EXISTS (
                      SELECT 1 FROM {group_members_table} gm
                      WHERE gm.group_id = g.id AND gm.username = {get_sql_placeholder()}
                  )
            """, (*eligible, username))
            rowc = c.fetchone()
            count = int(rowc['cnt'] if rowc else 0)
            return jsonify({'success': True, 'count': count})
    except Exception as e:
        logger.error(f"api_groups_available_count error: {e}")
        return jsonify({'success': False, 'error': 'Failed to compute count'})

@app.route('/api/groups/my', methods=['GET'])
@login_required
def api_groups_my():
    """List user's group memberships across communities with status."""
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                SELECT g.id as group_id, g.name, g.community_id, gm.status
                FROM group_members gm
                JOIN groups g ON gm.group_id = g.id
                WHERE gm.username = ?
                ORDER BY g.community_id, g.name
            """, (username,))
            rows = c.fetchall()
            items = [
                {
                    'group_id': r['group_id'],
                    'name': r['name'],
                    'community_id': r['community_id'],
                    'status': r['status']
                } for r in rows
            ]
            return jsonify({'success': True, 'groups': items})
    except Exception as e:
        logger.error(f"api_groups_my error: {e}")
        return jsonify({'success': False, 'error': 'Failed to load memberships'})

# Group feed API: returns posts scoped to group membership
@app.route('/api/group_feed')
@login_required
def api_group_feed():
    username = session.get('username')
    try:
        group_id = int(request.args.get('group_id', '0'))
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Load group and owning community
            c.execute(f"SELECT g.id, g.name, g.community_id, g.created_by FROM {'`groups`' if USE_MYSQL else 'groups'} g WHERE g.id = {get_sql_placeholder()}", (group_id,))
            g = c.fetchone()
            if not g:
                return jsonify({'success': False, 'error': 'Group not found'}), 404
            community_id = g['community_id'] if hasattr(g, 'keys') else g[2]
            group_name = g['name'] if hasattr(g, 'keys') else g[1]
            group_owner = g['created_by'] if hasattr(g, 'keys') else (g[3] if len(g) > 3 else None)
            # Community meta
            c.execute("SELECT name, type FROM communities WHERE id = ?", (community_id,))
            cm = c.fetchone() or {}
            community_name = cm['name'] if hasattr(cm, 'keys') else (cm[0] if cm else None)
            community_type = cm['type'] if hasattr(cm, 'keys') else (cm[1] if cm else None)

            # Verify user is member of community (or parent)
            ph = get_sql_placeholder()
            c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={ph} AND uc.community_id={ph}", (username, community_id))
            if not c.fetchone():
                # allow if member of parent
                c.execute("SELECT parent_community_id FROM communities WHERE id=?", (community_id,))
                row = c.fetchone()
                pid = (row['parent_community_id'] if hasattr(row, 'keys') else row[0]) if row else None
                if not pid:
                    return jsonify({'success': False, 'error': 'Not a member'}), 403
                c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={ph} AND uc.community_id={ph}", (username, pid))
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'Not a member'}), 403

            # Permission baseline for group managers
            is_manager = (
                is_app_admin(username)
                or is_community_owner(username, community_id)
                or is_community_admin(username, community_id)
                or (group_owner is not None and username == group_owner)
            )

            # Load latest group posts
            c.execute(f"""
                SELECT gp.id, gp.username, gp.content, gp.image_path, gp.created_at,
                       up.profile_picture
                FROM {'`group_posts`' if USE_MYSQL else 'group_posts'} gp
                LEFT JOIN user_profiles up ON up.username = gp.username
                WHERE gp.group_id = {get_sql_placeholder()}
                ORDER BY gp.id DESC
                LIMIT 50
            """, (group_id,))
            rows = c.fetchall() or []
            posts = []
            for r in rows:
                pid = r['id'] if hasattr(r, 'keys') else r[0]
                uname = r['username'] if hasattr(r, 'keys') else r[1]
                # Reactions
                c.execute(f"SELECT reaction, COUNT(*) as c FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id = {get_sql_placeholder()} GROUP BY reaction", (pid,))
                rx = c.fetchall() or []
                reactions = { (row['reaction'] if hasattr(row, 'keys') else row[0]): (row['c'] if hasattr(row, 'keys') else row[1]) for row in rx }
                c.execute(f"SELECT reaction FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id = {get_sql_placeholder()} AND username = {get_sql_placeholder()}", (pid, username))
                urr = c.fetchone()
                user_reaction = urr['reaction'] if hasattr(urr, 'keys') else (urr[0] if urr else None)
                # Replies (latest 25)
                c.execute(f"""
                    SELECT gr.id, gr.username, gr.content, gr.image_path, gr.created_at,
                           up.profile_picture
                    FROM {'`group_replies`' if USE_MYSQL else 'group_replies'} gr
                    LEFT JOIN user_profiles up ON up.username = gr.username
                    WHERE gr.group_post_id = {get_sql_placeholder()}
                    ORDER BY gr.id DESC
                    LIMIT 25
                """, (pid,))
                rep_rows = c.fetchall() or []
                replies = []
                for rr in rep_rows:
                    rid = rr['id'] if hasattr(rr, 'keys') else rr[0]
                    c.execute(f"SELECT reaction, COUNT(*) as c FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id = {get_sql_placeholder()} GROUP BY reaction", (rid,))
                    rrx = c.fetchall() or []
                    rreactions = { (row['reaction'] if hasattr(row, 'keys') else row[0]): (row['c'] if hasattr(row, 'keys') else row[1]) for row in rrx }
                    c.execute(f"SELECT reaction FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id = {get_sql_placeholder()} AND username = {get_sql_placeholder()}", (rid, username))
                    rur = c.fetchone()
                    reply_user_reaction = rur['reaction'] if hasattr(rur, 'keys') else (rur[0] if rur else None)
                    replies.append({
                        'id': rid,
                        'username': rr['username'] if hasattr(rr, 'keys') else rr[1],
                        'content': rr['content'] if hasattr(rr, 'keys') else rr[2],
                        'image_path': rr['image_path'] if hasattr(rr, 'keys') else rr[3],
                        'timestamp': rr['created_at'] if hasattr(rr, 'keys') else rr[4],
                        'profile_picture': rr['profile_picture'] if hasattr(rr, 'keys') else rr[5],
                        'reactions': rreactions,
                        'user_reaction': reply_user_reaction,
                    })
                can_manage = bool(is_manager or (uname == username))
                posts.append({
                    'id': pid,
                    'username': uname,
                    'content': r['content'] if hasattr(r, 'keys') else r[2],
                    'image_path': r['image_path'] if hasattr(r, 'keys') else r[3],
                    'timestamp': r['created_at'] if hasattr(r, 'keys') else r[4],
                    'reactions': reactions,
                    'user_reaction': user_reaction,
                    'profile_picture': r['profile_picture'] if hasattr(r, 'keys') else r[5],
                    'replies': replies,
                    'can_edit': can_manage,
                    'can_delete': can_manage,
                })
            return jsonify({'success': True, 'group': { 'id': group_id, 'name': group_name }, 'community': { 'id': community_id, 'name': community_name, 'type': community_type }, 'posts': posts})
    except Exception as e:
        logger.error(f"api_group_feed error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Single group post API
@app.route('/api/group_post')
@login_required
def api_group_post():
    username = session.get('username')
    try:
        post_id = int(request.args.get('post_id', '0'))
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid post_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Load post and group/community
            c.execute(f"""
                SELECT gp.id, gp.group_id, gp.username, gp.content, gp.image_path, gp.created_at,
                       g.name as group_name, g.community_id, g.created_by
                FROM {'`group_posts`' if USE_MYSQL else 'group_posts'} gp
                JOIN {'`groups`' if USE_MYSQL else 'groups'} g ON g.id = gp.group_id
                WHERE gp.id = {get_sql_placeholder()}
            """, (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            group_id = row['group_id'] if hasattr(row, 'keys') else row[1]
            community_id = row['community_id'] if hasattr(row, 'keys') else row[7]
            group_owner = row['created_by'] if hasattr(row, 'keys') else (row[8] if len(row) > 8 else None)

            # Membership check
            ph = get_sql_placeholder()
            c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={ph} AND uc.community_id={ph}", (username, community_id))
            if not c.fetchone():
                c.execute("SELECT parent_community_id FROM communities WHERE id=?", (community_id,))
                r = c.fetchone(); pid = r['parent_community_id'] if hasattr(r, 'keys') else (r[0] if r else None)
                if not pid:
                    return jsonify({'success': False, 'error': 'Not a member'}), 403
                c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={ph} AND uc.community_id={ph}", (username, pid))
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'Not a member'}), 403

            # Build post
            pid = row['id'] if hasattr(row, 'keys') else row[0]
            uname = row['username'] if hasattr(row, 'keys') else row[2]
            content = row['content'] if hasattr(row, 'keys') else row[3]
            image_path = row['image_path'] if hasattr(row, 'keys') else row[4]
            created_at = row['created_at'] if hasattr(row, 'keys') else row[5]
            group_name = row['group_name'] if hasattr(row, 'keys') else row[6]

            is_manager = (
                is_app_admin(username)
                or is_community_owner(username, community_id)
                or is_community_admin(username, community_id)
                or (group_owner is not None and username == group_owner)
            )

            # Reactions
            c.execute(f"SELECT reaction, COUNT(*) as c FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id = {get_sql_placeholder()} GROUP BY reaction", (pid,))
            rx = c.fetchall() or []
            reactions = { (r2['reaction'] if hasattr(r2, 'keys') else r2[0]): (r2['c'] if hasattr(r2, 'keys') else r2[1]) for r2 in rx }
            c.execute(f"SELECT reaction FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id = {get_sql_placeholder()} AND username = {get_sql_placeholder()}", (pid, username))
            urr = c.fetchone(); user_reaction = urr['reaction'] if hasattr(urr, 'keys') else (urr[0] if urr else None)

            # Replies
            c.execute(f"""
                SELECT gr.id, gr.username, gr.content, gr.image_path, gr.created_at, up.profile_picture
                FROM {'`group_replies`' if USE_MYSQL else 'group_replies'} gr
                LEFT JOIN user_profiles up ON up.username = gr.username
                WHERE gr.group_post_id = {get_sql_placeholder()}
                ORDER BY gr.id DESC
                LIMIT 100
            """, (pid,))
            rep_rows = c.fetchall() or []
            replies = []
            for rr in rep_rows:
                rid = rr['id'] if hasattr(rr, 'keys') else rr[0]
                c.execute(f"SELECT reaction, COUNT(*) as c FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id = {get_sql_placeholder()} GROUP BY reaction", (rid,))
                rrx = c.fetchall() or []
                rreactions = { (r3['reaction'] if hasattr(r3, 'keys') else r3[0]): (r3['c'] if hasattr(r3, 'keys') else r3[1]) for r3 in rrx }
                c.execute(f"SELECT reaction FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id = {get_sql_placeholder()} AND username = {get_sql_placeholder()}", (rid, username))
                rur = c.fetchone(); reply_user_reaction = rur['reaction'] if hasattr(rur, 'keys') else (rur[0] if rur else None)
                replies.append({
                    'id': rid,
                    'username': rr['username'] if hasattr(rr, 'keys') else rr[1],
                    'content': rr['content'] if hasattr(rr, 'keys') else rr[2],
                    'image_path': rr['image_path'] if hasattr(rr, 'keys') else rr[3],
                    'timestamp': rr['created_at'] if hasattr(rr, 'keys') else rr[4],
                    'profile_picture': rr['profile_picture'] if hasattr(rr, 'keys') else rr[5],
                    'reactions': rreactions,
                    'user_reaction': reply_user_reaction,
                })
            post = {
                'id': pid,
                'username': uname,
                'content': content,
                'image_path': image_path,
                'timestamp': created_at,
                'reactions': reactions,
                'user_reaction': user_reaction,
                'replies': replies,
                'can_edit': bool(is_manager or (uname == username)),
                'can_delete': bool(is_manager or (uname == username)),
            }
            allow_nsfw_imagine = False
            if community_id:
                try:
                    c.execute("SELECT allow_nsfw_imagine FROM communities WHERE id = ?", (community_id,))
                    allow_row = c.fetchone()
                    if allow_row is not None:
                        allow_nsfw_imagine = bool(allow_row['allow_nsfw_imagine'] if hasattr(allow_row, 'keys') else allow_row[0])
                except Exception as allow_err:
                    logger.warning(f"Failed to fetch allow_nsfw_imagine for community {community_id}: {allow_err}")
            post['allow_nsfw_imagine'] = allow_nsfw_imagine
            return jsonify({'success': True, 'post': post, 'group': { 'id': group_id, 'name': group_name }, 'community_id': community_id})
    except Exception as e:
        logger.error(f"api_group_post error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})
# Create group post
@app.route('/api/group_posts', methods=['POST'])
@login_required
def api_group_posts_create():
    username = session.get('username')
    group_id_raw = request.form.get('group_id', '').strip()
    content = (request.form.get('content', '') or '').strip()
    dedupe_token = (request.form.get('dedupe_token') or '').strip()
    try:
        group_id = int(group_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_id'})
    if not content and 'image' not in request.files:
        return jsonify({'success': False, 'error': 'Content or image is required'})
    # Check membership
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT 1 FROM group_members WHERE group_id={ph} AND username={ph}", (group_id, username))
            if not c.fetchone():
                # Also allow community-level members
                c.execute(f"SELECT community_id FROM {'`groups`' if USE_MYSQL else 'groups'} WHERE id={ph}", (group_id,))
                gr = c.fetchone(); comm_id = gr['community_id'] if hasattr(gr, 'keys') else (gr[0] if gr else None)
                if not comm_id:
                    return jsonify({'success': False, 'error': 'Group not found'}), 404
                c.execute(f"SELECT 1 FROM user_communities uc JOIN users u ON uc.user_id=u.id WHERE u.username={ph} AND uc.community_id={ph}", (username, comm_id))
                if not c.fetchone():
                    return jsonify({'success': False, 'error': 'Not a member'}), 403
            # Save file if any
            image_path = None
            if 'image' in request.files and request.files['image'].filename:
                image_path = save_uploaded_file(request.files['image'])
            # Dedupe (best effort)
            if dedupe_token:
                try:
                    c.execute("CREATE TABLE IF NOT EXISTS recent_group_post_tokens (token TEXT, username TEXT, created_at TEXT)")
                    c.execute("DELETE FROM recent_group_post_tokens WHERE created_at < ?", (datetime.now() - timedelta(seconds=60),))
                    c.execute("SELECT 1 FROM recent_group_post_tokens WHERE token=? AND username=?", (dedupe_token, username))
                    if c.fetchone():
                        return jsonify({'success': True, 'deduped': True})
                    c.execute("INSERT INTO recent_group_post_tokens (token, username, created_at) VALUES (?, ?, ?)", (dedupe_token, username, datetime.now().isoformat()))
                except Exception:
                    pass
            # Insert
            c.execute(f"INSERT INTO {'`group_posts`' if USE_MYSQL else 'group_posts'} (group_id, username, content, image_path, created_at) VALUES ({ph}, {ph}, {ph}, {ph}, {ph})",
                      (group_id, username, content, image_path, datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_group_posts_create error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Toggle reaction on group post
@app.route('/api/group_posts/react', methods=['POST'])
@login_required
def api_group_posts_react():
    username = session.get('username')
    post_id_raw = request.form.get('post_id', '').strip()
    reaction = (request.form.get('reaction', '') or '').strip()
    try:
        post_id = int(post_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid post_id'})
    if not reaction:
        return jsonify({'success': False, 'error': 'reaction required'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Insert/Toggle
            try:
                c.execute(f"INSERT INTO {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} (group_post_id, username, reaction) VALUES ({get_sql_placeholder()}, {get_sql_placeholder()}, {get_sql_placeholder()})",
                          (post_id, username, reaction))
            except Exception:
                # If exists, toggle to the same reaction (remove if same, set if different)
                c.execute(f"SELECT reaction FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (post_id, username))
                row = c.fetchone()
                if row:
                    prev = row['reaction'] if hasattr(row, 'keys') else row[0]
                    if prev == reaction:
                        c.execute(f"DELETE FROM {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} WHERE group_post_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (post_id, username))
                        if not USE_MYSQL: conn.commit()
                        return jsonify({'success': True, 'user_reaction': None})
                    else:
                        c.execute(f"UPDATE {'`group_post_reactions`' if USE_MYSQL else 'group_post_reactions'} SET reaction={get_sql_placeholder()} WHERE group_post_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (reaction, post_id, username))
                        if not USE_MYSQL: conn.commit()
                        return jsonify({'success': True, 'user_reaction': reaction})
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True, 'user_reaction': reaction})
    except Exception as e:
        logger.error(f"api_group_posts_react error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Edit group post
@app.route('/api/group_posts/edit', methods=['POST'])
@login_required
def api_group_posts_edit():
    username = session.get('username')
    post_id_raw = request.form.get('post_id', '').strip()
    content = (request.form.get('content') or '').strip()
    try:
        post_id = int(post_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid post_id'})
    if not content and 'image' not in request.files:
        return jsonify({'success': False, 'error': 'Nothing to update'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Load post and group
            ph = get_sql_placeholder()
            c.execute(f"SELECT gp.username, gp.group_id, g.community_id, g.created_by FROM {'`group_posts`' if USE_MYSQL else 'group_posts'} gp JOIN {'`groups`' if USE_MYSQL else 'groups'} g ON g.id=gp.group_id WHERE gp.id={ph}", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            author = row['username'] if hasattr(row, 'keys') else row[0]
            group_id = row['group_id'] if hasattr(row, 'keys') else row[1]
            community_id = row['community_id'] if hasattr(row, 'keys') else row[2]
            group_owner = row['created_by'] if hasattr(row, 'keys') else row[3]

            allowed = (
                username == author
                or is_app_admin(username)
                or is_community_owner(username, community_id)
                or is_community_admin(username, community_id)
                or (username == group_owner)
            )
            if not allowed:
                return jsonify({'success': False, 'error': 'Forbidden'}), 403

            image_path = None
            if 'image' in request.files and request.files['image'].filename:
                image_path = save_uploaded_file(request.files['image'])

            # Build update
            if image_path is not None:
                c.execute(f"UPDATE {'`group_posts`' if USE_MYSQL else 'group_posts'} SET content={ph}, image_path={ph} WHERE id={ph}", (content, image_path, post_id))
            else:
                c.execute(f"UPDATE {'`group_posts`' if USE_MYSQL else 'group_posts'} SET content={ph} WHERE id={ph}", (content, post_id))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_group_posts_edit error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Delete group post
@app.route('/api/group_posts/delete', methods=['POST'])
@login_required
def api_group_posts_delete():
    username = session.get('username')
    post_id_raw = request.form.get('post_id', '').strip()
    try:
        post_id = int(post_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid post_id'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            ph = get_sql_placeholder()
            c.execute(f"SELECT gp.username, gp.group_id, g.community_id, g.created_by FROM {'`group_posts`' if USE_MYSQL else 'group_posts'} gp JOIN {'`groups`' if USE_MYSQL else 'groups'} g ON g.id=gp.group_id WHERE gp.id={ph}", (post_id,))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Post not found'}), 404
            author = row['username'] if hasattr(row, 'keys') else row[0]
            community_id = row['community_id'] if hasattr(row, 'keys') else row[2]
            group_owner = row['created_by'] if hasattr(row, 'keys') else row[3]
            allowed = (
                username == author
                or is_app_admin(username)
                or is_community_owner(username, community_id)
                or is_community_admin(username, community_id)
                or (username == group_owner)
            )
            if not allowed:
                return jsonify({'success': False, 'error': 'Forbidden'}), 403
            c.execute(f"DELETE FROM {'`group_posts`' if USE_MYSQL else 'group_posts'} WHERE id={ph}", (post_id,))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_group_posts_delete error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Create group reply
@app.route('/api/group_replies', methods=['POST'])
@login_required
def api_group_replies_create():
    username = session.get('username')
    post_id_raw = request.form.get('group_post_id', '').strip()
    parent_id_raw = request.form.get('parent_reply_id', '').strip()
    content = (request.form.get('content', '') or '').strip()
    try:
        post_id = int(post_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid group_post_id'})
    parent_id = None
    if parent_id_raw:
        try: parent_id = int(parent_id_raw)
        except Exception: parent_id = None
    if not content and 'image' not in request.files:
        return jsonify({'success': False, 'error': 'Content or image is required'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            image_path = None
            if 'image' in request.files and request.files['image'].filename:
                image_path = save_uploaded_file(request.files['image'])
            c.execute(f"INSERT INTO {'`group_replies`' if USE_MYSQL else 'group_replies'} (group_post_id, parent_reply_id, username, content, image_path, created_at) VALUES ({get_sql_placeholder()},{get_sql_placeholder()},{get_sql_placeholder()},{get_sql_placeholder()},{get_sql_placeholder()},{get_sql_placeholder()})",
                      (post_id, parent_id, username, content, image_path, datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')))
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        logger.error(f"api_group_replies_create error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Toggle reaction on group reply
@app.route('/api/group_replies/react', methods=['POST'])
@login_required
def api_group_replies_react():
    username = session.get('username')
    reply_id_raw = request.form.get('reply_id', '').strip()
    reaction = (request.form.get('reaction', '') or '').strip()
    try:
        reply_id = int(reply_id_raw)
    except Exception:
        return jsonify({'success': False, 'error': 'Invalid reply_id'})
    if not reaction:
        return jsonify({'success': False, 'error': 'reaction required'})
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            try:
                c.execute(f"INSERT INTO {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} (group_reply_id, username, reaction) VALUES ({get_sql_placeholder()},{get_sql_placeholder()},{get_sql_placeholder()})",
                          (reply_id, username, reaction))
            except Exception:
                c.execute(f"SELECT reaction FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (reply_id, username))
                row = c.fetchone()
                if row:
                    prev = row['reaction'] if hasattr(row, 'keys') else row[0]
                    if prev == reaction:
                        c.execute(f"DELETE FROM {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} WHERE group_reply_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (reply_id, username))
                        if not USE_MYSQL: conn.commit()
                        return jsonify({'success': True, 'user_reaction': None})
                    else:
                        c.execute(f"UPDATE {'`group_reply_reactions`' if USE_MYSQL else 'group_reply_reactions'} SET reaction={get_sql_placeholder()} WHERE group_reply_id={get_sql_placeholder()} AND username={get_sql_placeholder()}", (reaction, reply_id, username))
                        if not USE_MYSQL: conn.commit()
                        return jsonify({'success': True, 'user_reaction': reaction})
            if not USE_MYSQL: conn.commit()
            return jsonify({'success': True, 'user_reaction': reaction})
    except Exception as e:
        logger.error(f"api_group_replies_react error: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

# Serve React app for group feed route
@app.route('/group_feed_react/<int:group_id>')
@login_required
def group_feed_react(group_id):
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        return send_from_directory(dist_dir, 'index.html')
    except Exception as e:
        logger.error(f"Error serving group feed react: {str(e)}")
        abort(500)

@app.route('/gym_react')
@login_required
def gym_react():
    return gym()

@app.route('/crossfit')
@login_required
def crossfit():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        return send_from_directory(dist_dir, 'index.html')
    except Exception as e:
        logger.error(f"Error serving /crossfit: {str(e)}")
        abort(500)

@app.route('/crossfit_react')
@login_required
def crossfit_react():
    try:
        base_dir = os.path.dirname(os.path.abspath(__file__))
        dist_dir = os.path.join(base_dir, 'client', 'dist')
        index_path = os.path.join(dist_dir, 'index.html')
        if os.path.exists(index_path):
            return send_from_directory(dist_dir, 'index.html')
        logger.warning("React build missing for /crossfit_react; redirecting to /crossfit")
        return redirect(url_for('crossfit'))
    except Exception as e:
        logger.error(f"Error serving React CrossfitExact: {str(e)}")
        abort(500)

@app.route('/cf_add_entry', methods=['POST'])
@login_required
def cf_add_entry():
    try:
        username = session.get('username')
        entry_type = request.form.get('type', '').strip().lower()
        name = request.form.get('name', '').strip()
        weight = request.form.get('weight', '').strip()
        reps = request.form.get('reps', '').strip()
        score = request.form.get('score', '').strip()
        date = request.form.get('date', '').strip()

        # Basic validation
        if not entry_type or not name or not date:
            return jsonify({'success': False, 'error': 'Type, name and date are required'})

        with get_db_connection() as conn:
            c = conn.cursor()

            c.execute('''
                CREATE TABLE IF NOT EXISTS crossfit_entries (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    username VARCHAR(191) NOT NULL,
                    type TEXT NOT NULL,
                    name TEXT NOT NULL,
                    weight REAL,
                    reps INTEGER,
                    score TEXT,
                    score_numeric REAL,
                    created_at TEXT NOT NULL
                )
            ''')

        # Helper to parse time strings like HH:MM:SS or MM:SS
        def parse_time_to_seconds(value: str):
            try:
                parts = value.split(':')
                parts = [int(p) for p in parts]
                if len(parts) == 3:
                    return parts[0]*3600 + parts[1]*60 + parts[2]
                if len(parts) == 2:
                    return parts[0]*60 + parts[1]
            except Exception:
                pass
            try:
                # Fallback if numeric like 315.5 (seconds)
                return float(value)
            except Exception:
                return None

        score_numeric = None
        weight_val = float(weight) if weight not in (None, '',) else None
        reps_val = int(reps) if reps not in (None, '',) else None
        if entry_type == 'wod':
            # Prefer explicit score_numeric, else parse score string
            if score:
                score_numeric = parse_time_to_seconds(score)

            c.execute('''
                INSERT INTO crossfit_entries (username, type, name, weight, reps, score, score_numeric, created_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (username, entry_type, name, weight_val, reps_val, score if score else None, score_numeric, date))

            conn.commit()
            return jsonify({'success': True})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/sync_gym_to_crossfit', methods=['POST'])
@login_required
def sync_gym_to_crossfit():
    try:
        username = session.get('username')
        with get_db_connection() as conn:
            c = conn.cursor()
            # Find overlapping exercise names
            overlapping = {'Back Squat','Front Squat','Overhead Squat','Deadlift','Clean','Jerk','Clean & Jerk','Snatch','Bench Press','Push Press','Thruster','Overhead Press'}
            # Get all user gym sets for overlapping exercises
            c.execute('''
                SELECT e.name, es.weight, es.reps, es.created_at
                FROM exercises e
                JOIN exercise_sets es ON e.id = es.exercise_id
                WHERE e.username = ? AND e.name IN ({})
            '''.format(','.join('?'*len(overlapping))), (username, *overlapping))
            rows = c.fetchall()

            c.execute('''CREATE TABLE IF NOT EXISTS crossfit_entries (
                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                username VARCHAR(191) NOT NULL,
                type TEXT NOT NULL,
                name TEXT NOT NULL,
                weight REAL,
                reps INTEGER,
                score TEXT,
                score_numeric REAL,
                created_at TEXT NOT NULL
            )''')

            # Insert any missing entries
            for r in rows:
                name, weight, reps, created_at = r
                c.execute('''INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                             VALUES (?, 'lift', ?, ?, ?, ?)''', (username, name, weight, reps, created_at))

            conn.commit()
        return jsonify({'success': True, 'synced': len(rows)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/cf_compare_item_in_box', methods=['GET'])
@login_required
def cf_compare_item_in_box():
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        item_type = request.args.get('item_type', 'lift').strip().lower()
        item_name = request.args.get('item_name', '').strip()
        if not community_id or not item_type or not item_name:
            return jsonify({'success': False, 'error': 'Missing parameters'})
        with get_db_connection() as conn:
            c = conn.cursor()

            # Community users
            c.execute(
                '''
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
                ''',
                (community_id,)
            )
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # Helper to parse time strings
            def parse_time_to_seconds(value: str):
                try:
                    parts = value.split(':')
                    parts = [int(p) for p in parts]
                    if len(parts) == 3:
                        return parts[0]*3600 + parts[1]*60 + parts[2]
                    if len(parts) == 2:
                        return parts[0]*60 + parts[1]
                except Exception:
                    pass
                try:
                    return float(value)
                except Exception:
                    return None

            values = []
            user_value = None

            if item_type == 'lift':
                for user in users:
                    c.execute(
                        '''
                        SELECT MAX(weight) as val
                        FROM crossfit_entries
                        WHERE username = ? AND type = 'lift' AND name = ?
                        ''',
                        (user, item_name)
                    )
                    row = c.fetchone()
                    val = row['val'] if row and row['val'] is not None else 0
                    values.append(val)
                    if user == username:
                        user_value = val
                valid = [v for v in values if v and v > 0]
                avg = round(sum(valid)/len(valid), 1) if valid else 0
                top = round(max(valid), 1) if valid else 0
                percentile = 0
                if valid and user_value and user_value > 0:
                    less_or_equal = sum(1 for v in valid if v <= user_value)
                    percentile = round((less_or_equal / len(valid)) * 100)
                unit = 'kg'
                lower_is_better = False
            else:  # wod
                for user in users:
                    c.execute(
                        '''
                        SELECT score, score_numeric
                        FROM crossfit_entries
                        WHERE username = ? AND type = 'wod' AND name = ?
                        ''',
                        (user, item_name)
                    )
                    rows = c.fetchall()
                    best = None
                    for r in rows:
                        n = r['score_numeric'] if r['score_numeric'] is not None else (parse_time_to_seconds(r['score']) if r['score'] else None)
                        if n is None:
                            continue
                        if best is None or n < best:
                            best = n
                    val = best if best is not None else 0
                    values.append(val)
                    if user == username:
                        user_value = val
                valid = [v for v in values if v and v > 0]
                avg = round(sum(valid)/len(valid), 1) if valid else 0
                top = round(min(valid), 1) if valid else 0  # best (fastest) time
                percentile = 0
                if valid and user_value and user_value > 0:
                    greater_or_equal = sum(1 for v in valid if v >= user_value)  # lower is better
                    percentile = round((greater_or_equal / len(valid)) * 100)
                unit = 'sec'
                lower_is_better = True

            data = {
                'labels': ['You'],
                'avgValues': [avg],
                'userValues': [user_value or 0],
                'unit': unit,
                'lowerIsBetter': lower_is_better,
            }

            if item_type == 'lift':
                summary = f"Your max for {item_name}: {user_value or 0} {unit}. Box avg: {avg} {unit}. Percentile: {percentile}% ‚Ä¢ Top: {top} {unit}"
            else:
                def fmt_seconds(s):
                    try:
                        s = int(round(s))
                        m = s // 60
                        sec = s % 60
                        return f"{m}:{sec:02d}"
                    except Exception:
                        return str(s)
                summary = f"Your best time for {item_name}: {fmt_seconds(user_value or 0)}. Box avg: {fmt_seconds(avg)}. Percentile: {percentile}% ‚Ä¢ Top: {fmt_seconds(top)}"

            return jsonify({'success': True, 'data': data, 'summary': summary, 'percentile': percentile, 'community_max': top})
    except Exception as e:
        logger.error(f"Error in CF comparison endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/workout_generator')
@login_required
def workout_generator():
    username = session.get('username')
    logger.info(f"Redirecting {username} from legacy workout generator to workout_tracking React page")
    return redirect(url_for('workout_tracking'))

@app.route('/workout_tracking')
@login_required
def workout_tracking():
    username = session.get('username')
    try:
        resp = serve_react_index()
        if resp:
            return resp
        logger.error("React build missing while serving /workout_tracking; returning error response")
        return ("React build missing", 503)
    except Exception as e:
        logger.error(f"Error in workout_tracking smart route: {e}")
        resp = serve_react_index()
        if resp:
            return resp
        return ("React build missing", 503)

# ===== WORKOUT TRACKING ROUTES =====

@app.route('/add_exercise', methods=['POST'])
@login_required
def add_exercise():
    try:
        username = session.get('username')
        name = request.form.get('name')
        muscle_group = request.form.get('muscle_group', 'Other')
        # Normalize new group values
        if muscle_group.lower() == 'glutes':
            muscle_group = 'Glutes'
        weight = request.form.get('weight')
        reps = request.form.get('reps')
        date = request.form.get('date')
        
        if not name:
            return jsonify({'success': False, 'error': 'Exercise name is required'})
        
        if not all([weight, reps, date]):
            return jsonify({'success': False, 'error': 'Weight, reps, and date are required'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if exercise already exists for this user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE username = ? AND name = ? AND muscle_group = ?
        ''', (username, name, muscle_group))
        
        if cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise already exists'})
        
        # Create tables if they don't exist
        if USE_MYSQL:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS exercises (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    muscle_group TEXT NOT NULL
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS exercise_sets (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    exercise_id INTEGER NOT NULL,
                    weight REAL NOT NULL,
                    reps INTEGER NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workouts (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workout_exercises (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    workout_id INTEGER NOT NULL,
                    exercise_id INTEGER NOT NULL,
                    sets INTEGER DEFAULT 0,
                    reps INTEGER DEFAULT 0,
                    weight REAL DEFAULT 0,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (workout_id) REFERENCES workouts (id) ON DELETE CASCADE,
                    FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                )
            ''')
        else:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS exercises (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    muscle_group TEXT NOT NULL DEFAULT "Other"
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS exercise_sets (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    exercise_id INTEGER NOT NULL,
                    weight REAL NOT NULL,
                    reps INTEGER NOT NULL,
                    created_at TEXT DEFAULT (datetime('now')),
                    FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workouts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT DEFAULT (datetime('now'))
                )
            ''')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workout_exercises (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    workout_id INTEGER NOT NULL,
                    exercise_id INTEGER NOT NULL,
                    sets INTEGER DEFAULT 0,
                    reps INTEGER DEFAULT 0,
                    weight REAL DEFAULT 0,
                    created_at TEXT DEFAULT (datetime('now')),
                    FOREIGN KEY (workout_id) REFERENCES workouts (id) ON DELETE CASCADE,
                    FOREIGN KEY (exercise_id) REFERENCES exercises (id) ON DELETE CASCADE
                )
            ''')
        
        # Insert the exercise
        if USE_MYSQL:
            cursor.execute('''
                INSERT INTO exercises (username, name, muscle_group)
                VALUES (%s, %s, %s)
            ''', (username, name, muscle_group))
        else:
            cursor.execute('''
                INSERT INTO exercises (username, name, muscle_group)
                VALUES (?, ?, ?)
            ''', (username, name, muscle_group))
        
        exercise_id = cursor.lastrowid
        # Insert the initial weight entry
        if USE_MYSQL:
            cursor.execute('''
                INSERT INTO exercise_sets (exercise_id, weight, reps, created_at)
                VALUES (%s, %s, %s, %s)
            ''', (exercise_id, weight, reps, date))
        else:
            cursor.execute('''
                INSERT INTO exercise_sets (exercise_id, weight, reps, created_at)
                VALUES (?, ?, ?, ?)
            ''', (exercise_id, weight, reps, date))
        
        # Cross-sync initial entry to crossfit_entries for overlapping lift names
        try:
            overlapping = {'Back Squat','Front Squat','Overhead Squat','Deadlift','Clean','Jerk','Clean & Jerk','Snatch','Bench Press','Push Press','Thruster','Overhead Press'}
            if name in overlapping:
                if USE_MYSQL:
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS crossfit_entries (
                            id INTEGER PRIMARY KEY AUTO_INCREMENT,
                            username VARCHAR(191) NOT NULL,
                            type TEXT NOT NULL,
                            name TEXT NOT NULL,
                            weight REAL,
                            reps INTEGER,
                            score TEXT,
                            score_numeric REAL,
                            created_at TEXT NOT NULL
                        )
                    ''')
                    cursor.execute('''
                        INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                        VALUES (%s, 'lift', %s, %s, %s, %s)
                    ''', (username, name, float(weight), int(reps), date))
                else:
                    cursor.execute('''
                        CREATE TABLE IF NOT EXISTS crossfit_entries (
                            id INTEGER PRIMARY KEY AUTOINCREMENT,
                            username VARCHAR(191) NOT NULL,
                            type TEXT NOT NULL,
                            name TEXT NOT NULL,
                            weight REAL,
                            reps INTEGER,
                            score TEXT,
                            score_numeric REAL,
                            created_at TEXT NOT NULL
                        )
                    ''')
                    cursor.execute('''
                        INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                        VALUES (?, 'lift', ?, ?, ?, ?)
                    ''', (username, name, float(weight), int(reps), date))
        except Exception as _e:
            pass
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/get_workout_exercises', methods=['GET'])
@login_required
def get_workout_exercises():
    try:
        username = session.get('username')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Get exercises with data from both exercise_sets (Exercise Management) and workout_exercises (Workouts)
        cursor.execute('''
            SELECT e.id, e.name, e.muscle_group,
                   COALESCE(es.weight, we.weight) as set_weight,
                   COALESCE(es.reps, we.reps) as set_reps,
                   COALESCE(es.created_at, we.created_at) as created_at,
                   CASE WHEN es.id IS NOT NULL THEN 'exercise_management' ELSE 'workout' END as source
            FROM exercises e
            LEFT JOIN exercise_sets es ON e.id = es.exercise_id
            LEFT JOIN workout_exercises we ON e.id = we.exercise_id
            WHERE e.username = ?
            ORDER BY e.muscle_group, e.name, COALESCE(es.created_at, we.created_at) DESC
        ''', (username,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({'success': True, 'exercises': []})
        
        # Group exercises by muscle group
        exercises = []
        current_exercise = None
        
        for row in rows:
            exercise_id = get_scalar_result(row, 0, 'id')
            exercise_name = get_scalar_result(row, 1, 'name')
            muscle_group = get_scalar_result(row, 2, 'muscle_group')
            
            # If this is a new exercise
            if not current_exercise or current_exercise['id'] != exercise_id:
                current_exercise = {
                    'id': exercise_id,
                    'name': exercise_name,
                    'muscle_group': muscle_group,
                    'sets_data': []
                }
                exercises.append(current_exercise)
            
            # Add set data if it exists (from either Exercise Management or Workouts)
            set_weight = get_scalar_result(row, 3, 'set_weight')
            set_reps = get_scalar_result(row, 4, 'set_reps')
            created_at = get_scalar_result(row, 5, 'created_at')
            source = get_scalar_result(row, 6, 'source')
            if set_weight:  # If there's weight data
                current_exercise['sets_data'].append({
                    'weight': set_weight,
                    'reps': set_reps,
                    'created_at': created_at,
                    'source': source  # 'exercise_management' or 'workout'
                })
        
        return jsonify({'success': True, 'exercises': exercises})
        
    except Exception as e:
        logger.error(f"Error in get_workout_exercises: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/edit_exercise', methods=['POST'])
@login_required
def edit_exercise():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        name = request.form.get('name')
        muscle_group = request.form.get('muscle_group', '').strip()
        
        if not exercise_id:
            return jsonify({'success': False, 'error': 'Exercise ID is required'})
        if not name and not muscle_group:
            return jsonify({'success': False, 'error': 'Nothing to update'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Normalize and validate muscle group if provided
        if muscle_group:
            normalized_group = muscle_group.capitalize()
            allowed_groups = {'Chest','Back','Shoulders','Biceps','Triceps','Legs','Core','Glutes','Other'}
            if normalized_group not in allowed_groups:
                normalized_group = 'Other'
        
        if name and muscle_group:
            cursor.execute('''
                UPDATE exercises 
                SET name = ?, muscle_group = ?
                WHERE id = ? AND username = ?
            ''', (name, normalized_group, exercise_id, username))
        elif name:
            cursor.execute('''
                UPDATE exercises 
                SET name = ?
                WHERE id = ? AND username = ?
            ''', (name, exercise_id, username))
        elif muscle_group:
            cursor.execute('''
                UPDATE exercises 
                SET muscle_group = ?
                WHERE id = ? AND username = ?
            ''', (normalized_group, exercise_id, username))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
    except Exception as e:
        try:
            conn.close()
        except Exception:
            pass
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_exercise', methods=['POST'])
@login_required
def delete_exercise():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        if not exercise_id:
            return jsonify({'success': False, 'error': 'Exercise ID is required'})

        conn = get_db_connection()
        cursor = conn.cursor()

        # Verify the exercise belongs to the current user
        if USE_MYSQL:
            cursor.execute('SELECT id FROM exercises WHERE id = %s AND username = %s', (exercise_id, username))
        else:
            cursor.execute('SELECT id FROM exercises WHERE id = ? AND username = ?', (exercise_id, username))
        row = cursor.fetchone()
        if not row:
            try:
                conn.close()
            except Exception:
                pass
            return jsonify({'success': False, 'error': 'Exercise not found'})

        # Delete dependent rows explicitly to be robust across SQLite/MySQL
        if USE_MYSQL:
            cursor.execute('DELETE FROM workout_exercises WHERE exercise_id = %s', (exercise_id,))
            cursor.execute('DELETE FROM exercise_sets WHERE exercise_id = %s', (exercise_id,))
            cursor.execute('DELETE FROM exercises WHERE id = %s AND username = %s', (exercise_id, username))
        else:
            cursor.execute('DELETE FROM workout_exercises WHERE exercise_id = ?', (exercise_id,))
            cursor.execute('DELETE FROM exercise_sets WHERE exercise_id = ?', (exercise_id,))
            cursor.execute('DELETE FROM exercises WHERE id = ? AND username = ?', (exercise_id, username))

        conn.commit()
        conn.close()
        return jsonify({'success': True})
    except Exception as e:
        try:
            conn.close()
        except Exception:
            pass
        return jsonify({'success': False, 'error': str(e)})
@app.route('/compare_exercise_in_community', methods=['GET'])
@login_required
def compare_exercise_in_community():
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        exercise_id = int(request.args.get('exercise_id', '0'))
        if not community_id or not exercise_id:
            return jsonify({'success': False, 'error': 'Missing parameters'})

        with get_db_connection() as conn:
            c = conn.cursor()
            # Get all usernames in the community
            c.execute("""
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
            """, (community_id,))
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # For each user, compute their max weight for the selected exercise name
            # First get the exercise name for the requesting user
            c.execute("SELECT name FROM exercises WHERE id = ? AND username = ?", (exercise_id, username))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Exercise not found for user'})
            exercise_name = row['name']

            community_max_weights = []
            user_max = 0
            for user in users:
                c.execute("SELECT id FROM exercises WHERE username = ? AND name = ?", (user, exercise_name))
                ex_row = c.fetchone()
                if not ex_row:
                    continue
                ex_id = ex_row['id']
                c.execute("SELECT MAX(weight) as mw FROM exercise_sets WHERE exercise_id = ?", (ex_id,))
                mw_row = c.fetchone()
                max_w = mw_row['mw'] if mw_row and mw_row['mw'] is not None else 0
                community_max_weights.append(max_w)
                if user == username:
                    user_max = max_w

            if not community_max_weights:
                return jsonify({'success': False, 'error': 'No comparable data'})

            # Compute community average and max excluding zeros
            valid = [w for w in community_max_weights if w and w > 0]
            avg = round(sum(valid) / len(valid), 1) if valid else 0
            community_max = round(max(valid), 1) if valid else 0

            # Percentile of user's max within community distribution (<= user_max)
            percentile = 0
            if valid and user_max and user_max > 0:
                less_or_equal = sum(1 for w in valid if w <= user_max)
                percentile = round((less_or_equal / len(valid)) * 100)

            data = {
                'labels': ['You'],
                'avgMaxWeights': [avg],
                'userMaxWeights': [user_max]
            }
            summary = (
                f"Your max for {exercise_name}: {user_max or 0} kg. "
                f"Community avg: {avg} kg. "
                f"Percentile: {percentile}% ‚Ä¢ Top: {community_max} kg"
            )
            return jsonify({'success': True, 'data': data, 'summary': summary, 'percentile': percentile, 'community_max': community_max})
    except Exception as e:
        logger.error(f"Error in comparison endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/leaderboard_exercise_in_community', methods=['GET'])
@login_required
def leaderboard_exercise_in_community():
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        exercise_id = int(request.args.get('exercise_id', '0'))
        if not community_id or not exercise_id:
            return jsonify({'success': False, 'error': 'Missing parameters'})

        with get_db_connection() as conn:
            c = conn.cursor()
            # Community users
            c.execute("""
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
            """, (community_id,))
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # Get exercise name for requesting user
            c.execute("SELECT name FROM exercises WHERE id = ? AND username = ?", (exercise_id, username))
            row = c.fetchone()
            if not row:
                return jsonify({'success': False, 'error': 'Exercise not found for user'})
            exercise_name = row['name']

            # Compute each user's max for that exercise name
            leaderboard = []
            for user in users:
                c.execute("SELECT id FROM exercises WHERE username = ? AND name = ?", (user, exercise_name))
                ex_row = c.fetchone()
                if not ex_row:
                    continue
                ex_id = ex_row['id']
                c.execute("SELECT MAX(weight) as mw FROM exercise_sets WHERE exercise_id = ?", (ex_id,))
                mw_row = c.fetchone()
                max_w = mw_row['mw'] if mw_row and mw_row['mw'] is not None else 0
                leaderboard.append({ 'username': user, 'max': float(max_w) })

            # Sort descending by max
            leaderboard.sort(key=lambda x: x['max'], reverse=True)
            return jsonify({ 'success': True, 'exercise_name': exercise_name, 'entries': leaderboard })
    except Exception as e:
        logger.error(f"Error in leaderboard endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/compare_overview_in_community', methods=['GET'])
@login_required
def compare_overview_in_community():
    """Overview across all of the user's exercises: user max, community average, percentile."""
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        if not community_id:
            return jsonify({'success': False, 'error': 'Missing community_id'})

        with get_db_connection() as conn:
            c = conn.cursor()

            # Community users
            c.execute(
                """
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
                """,
                (community_id,)
            )
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # User's exercises (include muscle group for grouping in UI)
            c.execute("SELECT id, name, muscle_group FROM exercises WHERE username = ?", (username,))
            user_exercises = c.fetchall()

            overview = []
            for ex in user_exercises:
                ex_id = ex['id']
                ex_name = ex['name']
                ex_group = ex['muscle_group'] or 'Other'

                # User max for this exercise
                c.execute("SELECT MAX(weight) as mw FROM exercise_sets WHERE exercise_id = ?", (ex_id,))
                mw_row = c.fetchone()
                user_max = mw_row['mw'] if mw_row and mw_row['mw'] is not None else 0

                # Community maxima for the same-named exercise
                maxima = []
                for user in users:
                    c.execute("SELECT id FROM exercises WHERE username = ? AND name = ?", (user, ex_name))
                    ex_row = c.fetchone()
                    if not ex_row:
                        continue
                    c.execute("SELECT MAX(weight) as mw FROM exercise_sets WHERE exercise_id = ?", (ex_row['id'],))
                    r = c.fetchone()
                    max_w = r['mw'] if r and r['mw'] is not None else 0
                    if max_w and max_w > 0:
                        maxima.append(max_w)

                community_avg = round(sum(maxima) / len(maxima), 1) if maxima else 0
                community_top = round(max(maxima), 1) if maxima else 0

                # Percentile calculation of user's max among community maxima
                percentile = 0
                if maxima and user_max and user_max > 0:
                    less_or_equal = sum(1 for w in maxima if w <= user_max)
                    percentile = round((less_or_equal / len(maxima)) * 100)

                overview.append({
                    'exercise_id': ex_id,
                    'name': ex_name,
                    'muscle_group': ex_group,
                    'user_max': float(user_max or 0),
                    'community_avg': float(community_avg or 0),
                    'community_max': float(community_top or 0),
                    'percentile': int(percentile)
                })

            return jsonify({'success': True, 'overview': overview})
    except Exception as e:
        logger.error(f"Error in comparison overview endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})
@app.route('/compare_attendance_in_community', methods=['GET'])
@login_required
def compare_attendance_in_community():
    """Compare number of workouts attended in a period vs community average and percentile."""
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        period_days = int(request.args.get('period_days', '30'))
        if not community_id:
            return jsonify({'success': False, 'error': 'Missing community_id'})

        with get_db_connection() as conn:
            c = conn.cursor()

            # Get all usernames in the community
            c.execute(
                """
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
                """,
                (community_id,)
            )
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # Attendance counts per user in given period
            attendance = []
            user_attendance = 0
            for user in users:
                c.execute(
                    """
                    SELECT COUNT(*) as cnt
                    FROM workouts
                    WHERE username = ? AND date >= DATE_SUB(NOW(), INTERVAL ? DAY)
                    """,
                    (user, period_days)
                )
                cnt_row = c.fetchone()
                cnt = cnt_row['cnt'] if cnt_row and cnt_row['cnt'] is not None else 0
                attendance.append(cnt)
                if user == username:
                    user_attendance = cnt

            valid = attendance  # zero is allowed for attendance
            avg = round(sum(valid) / len(valid), 1) if valid else 0
            community_max = max(valid) if valid else 0
            percentile = 0
            if valid:
                less_or_equal = sum(1 for v in valid if v <= user_attendance)
                percentile = round((less_or_equal / len(valid)) * 100)

            summary = (
                f"Attendance last {period_days}d ‚Äî You: {user_attendance}, Avg: {avg}, "
                f"Pct: {percentile}% ‚Ä¢ Top: {community_max}"
            )

            return jsonify({
                'success': True,
                'attendance': {
                    'user': int(user_attendance),
                    'avg': float(avg),
                    'percentile': int(percentile),
                    'community_max': int(community_max),
                    'period_days': int(period_days)
                },
                'summary': summary
            })
    except Exception as e:
        logger.error(f"Error in attendance comparison endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})

@app.route('/compare_improvement_in_community', methods=['GET'])
@login_required
def compare_improvement_in_community():
    """Compare percent improvement in 1RM over timeframe vs community average and percentile."""
    try:
        username = session.get('username')
        community_id = int(request.args.get('community_id', '0'))
        months = int(request.args.get('months', '3'))
        if not community_id:
            return jsonify({'success': False, 'error': 'Missing community_id'})

        with get_db_connection() as conn:
            c = conn.cursor()

            # Community users
            c.execute(
                """
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
                """,
                (community_id,)
            )
            users = [row['username'] for row in c.fetchall()]
            if not users:
                return jsonify({'success': False, 'error': 'No users in community'})

            # Helper to compute average improvement percent for a user across their exercises
            def compute_user_improvement(user_name: str) -> float:
                # Get user's exercises
                c.execute("SELECT id FROM exercises WHERE username = ?", (user_name,))
                user_exs = [r['id'] for r in c.fetchall()]
                improvements = []
                for ex_id in user_exs:
                    c.execute(
                        """
                        SELECT weight, reps, created_at
                        FROM exercise_sets
                        WHERE exercise_id = ? AND created_at >= DATE_SUB(NOW(), INTERVAL ? MONTH)
                        ORDER BY created_at ASC
                        """,
                        (ex_id, months)
                    )
                    sets = c.fetchall()
                    if not sets or len(sets) < 2:
                        continue
                    # Compute 1RM per entry
                    one_rms = [row['weight'] * (1 + row['reps'] / 30.0) for row in sets]
                    baseline = one_rms[0]
                    current = max(one_rms)
                    if baseline and baseline > 0:
                        improvements.append(((current - baseline) / baseline) * 100.0)
                if not improvements:
                    return 0.0
                return sum(improvements) / len(improvements)

            community_improvements = []
            user_improvement = 0.0
            for user in users:
                imp = compute_user_improvement(user)
                community_improvements.append(imp)
                if user == username:
                    user_improvement = imp

            valid = community_improvements
            avg = round(sum(valid) / len(valid), 1) if valid else 0.0
            community_max = round(max(valid), 1) if valid else 0.0
            percentile = 0
            if valid:
                less_or_equal = sum(1 for v in valid if v <= user_improvement)
                percentile = round((less_or_equal / len(valid)) * 100)

            summary = (
                f"Improvement last {months}m ‚Äî You: {round(user_improvement,1)}%, Avg: {avg}%, "
                f"Pct: {percentile}% ‚Ä¢ Top: {community_max}%"
            )

            return jsonify({
                'success': True,
                'improvement': {
                    'user': round(user_improvement, 1),
                    'avg': float(avg),
                    'percentile': int(percentile),
                    'community_max': float(community_max),
                    'months': int(months)
                },
                'summary': summary
            })
    except Exception as e:
        logger.error(f"Error in improvement comparison endpoint: {e}")
        return jsonify({'success': False, 'error': 'Server error'})
 

@app.route('/log_weight_set', methods=['POST'])
@login_required
def log_weight_set():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        weight = request.form.get('weight')
        reps = request.form.get('reps')
        date = request.form.get('date')
        
        if not all([exercise_id, weight, reps, date]):
            return jsonify({'success': False, 'error': 'All fields are required'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify the exercise belongs to the user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE id = ? AND username = ?
        ''', (exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        # Add the set with the specified date
        # Normalize date for MySQL: accept 'YYYY-MM-DD' or ISO; also handle RFC 2822 strings
        date_str = date
        try:
            if date and isinstance(date, str):
                if date.endswith('GMT') or ',' in date:
                    # RFC 2822 (e.g., Wed, 03 Sep 2025 00:00:00 GMT)
                    dt = parsedate_to_datetime(date)
                    date_str = dt.strftime('%Y-%m-%d %H:%M:%S')
                elif len(date) == 10 and date[4] == '-' and date[7] == '-':
                    date_str = f"{date} 00:00:00"
                elif 'T' in date and len(date) >= 19:
                    date_str = date.replace('T', ' ')[:19]
        except Exception:
            pass

        cursor.execute('''
            INSERT INTO exercise_sets (exercise_id, weight, reps, created_at)
            VALUES (?, ?, ?, ?)
        ''', (exercise_id, weight, reps, date_str))

        # Cross-sync to crossfit_entries for overlapping lift names
        try:
            # Fetch exercise name
            cursor.execute('SELECT name FROM exercises WHERE id=?', (exercise_id,))
            row = cursor.fetchone()
            if row:
                ex_name = row[0] if isinstance(row, tuple) else row[0]
                # Only sync for known overlapping lifts
                overlapping = {'Back Squat','Front Squat','Overhead Squat','Deadlift','Clean','Jerk','Clean & Jerk','Snatch','Bench Press','Push Press','Thruster','Overhead Press'}
                if ex_name in overlapping:
                    # Use MySQL-compatible DDL if needed
                    if USE_MYSQL:
                        cursor.execute('''
                            CREATE TABLE IF NOT EXISTS crossfit_entries (
                                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                                username VARCHAR(191) NOT NULL,
                                type TEXT NOT NULL,
                                name TEXT NOT NULL,
                                weight REAL,
                                reps INTEGER,
                                score TEXT,
                                score_numeric REAL,
                                created_at TEXT NOT NULL
                            )
                        ''')
                        cursor.execute('''
                            INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                            VALUES (?, 'lift', ?, ?, ?, ?)
                        ''', (username, ex_name, float(weight), int(reps), date))
                    else:
                        cursor.execute('''
                            CREATE TABLE IF NOT EXISTS crossfit_entries (
                                id INTEGER PRIMARY KEY AUTOINCREMENT,
                                username VARCHAR(191) NOT NULL,
                                type TEXT NOT NULL,
                                name TEXT NOT NULL,
                                weight REAL,
                                reps INTEGER,
                                score TEXT,
                                score_numeric REAL,
                                created_at TEXT NOT NULL
                            )
                        ''')
                        cursor.execute('''
                            INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                            VALUES (?, 'lift', ?, ?, ?, ?)
                        ''', (username, ex_name, float(weight), int(reps), date))
        except Exception as _e:
            pass
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        logger.error(f"Error logging weight: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/edit_set', methods=['POST'])
@login_required
def edit_set():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        set_id = request.form.get('set_id')
        weight = request.form.get('weight')
        
        if not all([exercise_id, set_id, weight]):
            return jsonify({'success': False, 'error': 'All fields are required'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify the exercise belongs to the user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE id = ? AND username = ?
        ''', (exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        # Update the set
        cursor.execute('''
            UPDATE exercise_sets 
            SET weight = ?
            WHERE id = ? AND exercise_id = ?
        ''', (weight, set_id, exercise_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_set', methods=['POST'])
@login_required
def delete_set():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        set_id = request.form.get('set_id')
        
        if not all([exercise_id, set_id]):
            return jsonify({'success': False, 'error': 'Exercise ID and set ID are required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Verify the exercise belongs to the user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE id = ? AND username = ?
        ''', (exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        # Delete the set
        cursor.execute('''
            DELETE FROM exercise_sets 
            WHERE id = ? AND exercise_id = ?
        ''', (set_id, exercise_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_weight_entry', methods=['POST'])
@login_required
def delete_weight_entry():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        date = request.form.get('date')
        weight = request.form.get('weight')
        reps = request.form.get('reps')
        
        if not all([exercise_id, date, weight, reps]):
            return jsonify({'success': False, 'error': 'All fields are required'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify the exercise belongs to the user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE id = ? AND username = ?
        ''', (exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        # Delete the specific weight entry
        cursor.execute('''
            DELETE FROM exercise_sets 
            WHERE exercise_id = ? AND weight = ? AND reps = ? AND created_at = ?
        ''', (exercise_id, weight, reps, date))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        if deleted_count == 0:
            return jsonify({'success': False, 'error': 'Weight entry not found'})
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

def formatDate(date_string):
    """Format date for chart labels"""
    date = datetime.strptime(date_string, '%Y-%m-%d')
    return date.strftime('%b %d')
@app.route('/get_exercise_progress', methods=['GET'])
@login_required
def get_exercise_progress():
    try:
        username = session.get('username')
        exercise_id = request.args.get('exercise_id')
        time_range = request.args.get('time_range', 'all')
        
        if not exercise_id:
            return jsonify({'success': False, 'error': 'Exercise ID is required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Build date filter
        date_filter = ""
        if time_range != 'all':
            date_filter = f"AND es.created_at >= DATE_SUB(NOW(), INTERVAL {time_range} DAY)"
        
        # Get weight entries for the exercise
        cursor.execute(f'''
            SELECT es.weight, es.reps, es.created_at
            FROM exercise_sets es
            JOIN exercises e ON es.exercise_id = e.id
            WHERE e.id = ? AND e.username = ? {date_filter}
            ORDER BY es.created_at ASC
        ''', (exercise_id, username))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({
                'success': True,
                'data': {
                    'labels': [],
                    'maxWeights': []
                }
            })
        
        # Process data for chart
        weight_data = {}
        for row in rows:
            weight, reps, date = row
            # Calculate 1RM using Epley formula
            one_rm = weight * (1 + reps / 30)
            
            if date not in weight_data:
                weight_data[date] = []
            weight_data[date].append(one_rm)
        
        # Get max 1RM for each date
        dates = sorted(weight_data.keys())
        labels = []
        max_weights = []
        
        for date in dates:
            max_1rm = max(weight_data[date])
            labels.append(formatDate(date))
            max_weights.append(round(max_1rm, 1))
        
        return jsonify({
            'success': True,
            'data': {
                'labels': labels,
                'maxWeights': max_weights
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/get_exercise_one_rm', methods=['GET'])
@login_required
def get_exercise_one_rm():
    try:
        username = session.get('username')
        exercise_id = request.args.get('exercise_id')
        
        if not exercise_id:
            return jsonify({'success': False, 'error': 'Exercise ID is required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get all weight entries for the exercise and calculate max 1RM
        cursor.execute('''
            SELECT es.weight, es.reps
            FROM exercise_sets es
            JOIN exercises e ON es.exercise_id = e.id
            WHERE e.id = ? AND e.username = ?
            ORDER BY es.created_at DESC
        ''', (exercise_id, username))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({'success': True, 'one_rm': 0})
        
        # Calculate 1RM for each entry and find the maximum
        max_one_rm = 0
        for row in rows:
            weight, reps = row
            one_rm = weight * (1 + reps / 30)  # Epley formula
            max_one_rm = max(max_one_rm, one_rm)
        
        return jsonify({'success': True, 'one_rm': round(max_one_rm, 1)})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/update_exercise_one_rm', methods=['POST'])
@login_required
def update_exercise_one_rm():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        weight = request.form.get('weight')
        reps = request.form.get('reps')
        
        if not all([exercise_id, weight, reps]):
            return jsonify({'success': False, 'error': 'All fields are required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Verify the exercise belongs to the user
        cursor.execute('''
            SELECT id FROM exercises 
            WHERE id = ? AND username = ?
        ''', (exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        # Add the new weight entry to exercise_sets
        cursor.execute('''
            INSERT INTO exercise_sets (exercise_id, weight, reps, created_at)
            VALUES (?, ?, ?, NOW())
        ''', (exercise_id, weight, reps))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/check_exercise_in_workout', methods=['GET'])
@login_required
def check_exercise_in_workout():
    try:
        username = session.get('username')
        workout_id = request.args.get('workout_id')
        exercise_id = request.args.get('exercise_id')
        
        if not all([workout_id, exercise_id]):
            return jsonify({'success': False, 'error': 'Workout ID and Exercise ID are required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Check if the exercise is already in the workout and get its details
        cursor.execute('''
            SELECT we.id, we.weight, we.sets, we.reps, e.name
            FROM workout_exercises we
            JOIN workouts w ON we.workout_id = w.id
            JOIN exercises e ON we.exercise_id = e.id
            WHERE we.workout_id = ? AND we.exercise_id = ? AND w.username = ?
        ''', (workout_id, exercise_id, username))
        
        row = cursor.fetchone()
        conn.close()
        
        if row:
            return jsonify({
                'success': True, 
                'is_duplicate': True,
                'existing_exercise': {
                    'id': row[0],
                    'weight': row[1],
                    'sets': row[2],
                    'reps': row[3],
                    'name': row[4]
                }
            })
        else:
            return jsonify({'success': True, 'is_duplicate': False})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/update_exercise_in_workout', methods=['POST'])
@login_required
def update_exercise_in_workout():
    try:
        username = session.get('username')
        workout_exercise_id = request.form.get('workout_exercise_id')
        weight = request.form.get('weight')
        sets = request.form.get('sets')
        reps = request.form.get('reps')
        
        if not all([workout_exercise_id, weight, sets, reps]):
            return jsonify({'success': False, 'error': 'All fields are required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Verify the workout exercise belongs to the user
        cursor.execute('''
            SELECT we.id 
            FROM workout_exercises we
            JOIN workouts w ON we.workout_id = w.id
            WHERE we.id = ? AND w.username = ?
        ''', (workout_exercise_id, username))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Workout exercise not found'})
        
        # Update the workout exercise
        cursor.execute('''
            UPDATE workout_exercises 
            SET weight = ?, sets = ?, reps = ?
            WHERE id = ?
        ''', (weight, sets, reps, workout_exercise_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_progress_summary', methods=['GET'])
@login_required
def get_progress_summary():
    try:
        username = session.get('username')
        exercise_id = request.args.get('exercise_id')
        time_range = request.args.get('time_range', 'all')
        
        if not exercise_id:
            return jsonify({'success': False, 'error': 'Exercise ID is required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get exercise name
        cursor.execute('SELECT name FROM exercises WHERE id = ? AND username = ?', (exercise_id, username))
        exercise = cursor.fetchone()
        if not exercise:
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        exercise_name = exercise[0]
        
        # Build date filter
        date_filter = ""
        if time_range != 'all':
            date_filter = f"AND created_at >= DATE_SUB(NOW(), INTERVAL {time_range} DAY)"
        
        # Get all weight entries for the exercise
        cursor.execute(f'''
            SELECT weight, reps, created_at
            FROM exercise_sets 
            WHERE exercise_id = ? {date_filter}
            ORDER BY created_at ASC
        ''', (exercise_id,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if not rows:
            return jsonify({
                'success': True,
                'summary': {
                    'exercise_name': exercise_name,
                    'current_1rm': 0,
                    'progress_percentage': 0,
                    'total_sets': 0
                }
            })
        
        # Calculate 1RM for each entry
        one_rms = []
        for row in rows:
            weight, reps, date = row
            one_rm = weight * (1 + reps / 30)  # Epley formula
            one_rms.append(one_rm)
        
        current_1rm = max(one_rms)
        initial_1rm = one_rms[0] if one_rms else 0
        progress_percentage = ((current_1rm - initial_1rm) / initial_1rm * 100) if initial_1rm > 0 else 0
        
        return jsonify({
            'success': True,
            'summary': {
                'exercise_name': exercise_name,
                'current_1rm': round(current_1rm, 1),
                'progress_percentage': round(progress_percentage, 1),
                'total_sets': len(rows)
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_workout_summary', methods=['GET'])
@login_required
def get_workout_summary():
    try:
        username = session.get('username')
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get total workouts
        cursor.execute('SELECT COUNT(*) FROM workouts WHERE username = ?', (username,))
        total_workouts = cursor.fetchone()[0]
        
        # Get workouts this week
        cursor.execute('''
            SELECT COUNT(*) FROM workouts 
            WHERE username = ? AND date >= DATE_SUB(NOW(), INTERVAL 7 DAY)
        ''', (username,))
        workouts_this_week = cursor.fetchone()[0]
        
        # Get total exercises in workouts
        cursor.execute('''
            SELECT COUNT(*) FROM workout_exercises we
            JOIN workouts w ON we.workout_id = w.id
            WHERE w.username = ?
        ''', (username,))
        total_exercises = cursor.fetchone()[0]
        
        conn.close()
        
        return jsonify({
            'success': True,
            'summary': {
                'total_workouts': total_workouts,
                'workouts_this_week': workouts_this_week,
                'total_exercises': total_exercises
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/share_progress', methods=['POST'])
@login_required
def share_progress():
    try:
        username = session.get('username')
        exercise_id = request.form.get('exercise_id')
        time_range = request.form.get('time_range')
        communities = request.form.getlist('communities')
        
        if not exercise_id or not communities:
            return jsonify({'success': False, 'error': 'Missing required fields'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get exercise name
        cursor.execute('SELECT name FROM exercises WHERE id = ? AND username = ?', (exercise_id, username))
        exercise = cursor.fetchone()
        if not exercise:
            return jsonify({'success': False, 'error': 'Exercise not found'})
        
        exercise_name = exercise[0]
        
        # Get progress data
        date_filter = ""
        if time_range != 'all':
            date_filter = f"AND created_at >= DATE_SUB(NOW(), INTERVAL {time_range} DAY)"
        
        cursor.execute(f'''
            SELECT weight, reps, created_at
            FROM exercise_sets 
            WHERE exercise_id = ? {date_filter}
            ORDER BY created_at ASC
        ''', (exercise_id,))
        
        rows = cursor.fetchall()
        
        if not rows:
            return jsonify({'success': False, 'error': 'No progress data found'})
        
        # Calculate summary
        one_rms = [weight * (1 + reps / 30) for weight, reps, date in rows]
        current_1rm = max(one_rms)
        initial_1rm = one_rms[0]
        progress_percentage = ((current_1rm - initial_1rm) / initial_1rm * 100) if initial_1rm > 0 else 0
        
        # Get user message and graph image if provided
        user_message = request.form.get('user_message', '').strip()
        graph_image = request.form.get('graph_image', '').strip()
        
        # Create simple post content - just the exercise name if no user message
        if user_message:
            post_content = f"{user_message}"
        else:
            post_content = f"Progress Update: {exercise_name}"
        
        # Save graph image if provided
        image_path = None
        if graph_image and graph_image.startswith('data:image'):
            try:
                # Extract base64 data
                import base64
                image_data = graph_image.split(',')[1]
                image_bytes = base64.b64decode(image_data)
                
                # Generate filename
                import os
                from datetime import datetime
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                filename = f"progress_graph_{username}_{exercise_id}_{timestamp}.png"
                filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
                
                # Save image
                with open(filepath, 'wb') as f:
                    f.write(image_bytes)
                
                image_path = f"uploads/{filename}"
                print(f"Debug: Saved graph image to {image_path}")
                
            except Exception as e:
                print(f"Debug: Error saving graph image: {e}")
                image_path = None
        
        # Share to each selected community
        for community_id in communities:
            cursor.execute('''
                INSERT INTO posts (username, community_id, content, image_path, timestamp)
                VALUES (?, ?, ?, ?, NOW())
            ''', (username, community_id, post_content, image_path))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/share_workouts', methods=['POST'])
@login_required
def share_workouts():
    try:
        username = session.get('username')
        communities = request.form.getlist('communities')
        
        if not communities:
            return jsonify({'success': False, 'error': 'No communities selected'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get workout summary
        cursor.execute('SELECT COUNT(*) FROM workouts WHERE username = ?', (username,))
        total_workouts = cursor.fetchone()[0]
        
        cursor.execute('''
            SELECT COUNT(*) FROM workouts 
            WHERE username = ? AND date >= DATE_SUB(NOW(), INTERVAL 7 DAY)
        ''', (username,))
        workouts_this_week = cursor.fetchone()[0]
        
        cursor.execute('''
            SELECT COUNT(*) FROM workout_exercises we
            JOIN workouts w ON we.workout_id = w.id
            WHERE w.username = ?
        ''', (username,))
        total_exercises = cursor.fetchone()[0]
        
        # Get user message if provided
        user_message = request.form.get('user_message', '').strip()
        
        # Create post content with proper spacing
        post_content = f"Workout Summary\n\n"
        post_content += f"Total workouts: {total_workouts}\n"
        post_content += f"This week: {workouts_this_week}\n"
        post_content += f"Total exercises: {total_exercises}"
        
        # Add user message if provided
        if user_message:
            post_content = f"{user_message}\n\n{post_content}"
        
        # Share to each selected community
        for community_id in communities:
            cursor.execute('''
                INSERT INTO posts (username, community_id, content, timestamp)
                VALUES (?, ?, ?, NOW())
            ''', (username, community_id, post_content))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_individual_workout_summary', methods=['GET'])
@login_required
def get_individual_workout_summary():
    try:
        username = session.get('username')
        workout_id = request.args.get('workout_id')
        
        if not workout_id:
            return jsonify({'success': False, 'error': 'Workout ID is required'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get workout details
        cursor.execute('''
            SELECT w.name, w.date, COUNT(we.id) as exercise_count, SUM(we.sets) as total_sets
            FROM workouts w
            LEFT JOIN workout_exercises we ON w.id = we.workout_id
            WHERE w.id = ? AND w.username = ?
            GROUP BY w.id
        ''', (workout_id, username))
        
        row = cursor.fetchone()
        conn.close()
        
        if not row:
            return jsonify({'success': False, 'error': 'Workout not found'})
        
        name, date, exercise_count, total_sets = row
        
        return jsonify({
            'success': True,
            'summary': {
                'name': name,
                'date': date,
                'exercise_count': exercise_count or 0,
                'total_sets': total_sets or 0
            }
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/share_individual_workout', methods=['POST'])
@login_required
def share_individual_workout():
    print("=== SHARE INDIVIDUAL WORKOUT DEBUG ===")
    print(f"Form data: {request.form}")
    print(f"Form keys: {list(request.form.keys())}")
    
    try:
        username = session.get('username')
        workout_id = request.form.get('workout_id')
        communities = request.form.getlist('communities')
        
        print(f"Username: {username}")
        print(f"Workout ID: {workout_id}")
        print(f"Communities: {communities}")
        
        if not workout_id:
            return jsonify({'success': False, 'error': 'Workout ID is required'})
        
        if not communities:
            return jsonify({'success': False, 'error': 'No communities selected'})
        
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Get workout details
        cursor.execute('''
            SELECT w.name, w.date, COUNT(we.id) as exercise_count, 
                   GROUP_CONCAT(e.name || ' (' || we.weight || 'kg x ' || we.sets || ' sets x ' || we.reps || ' reps)') as exercises
            FROM workouts w
            LEFT JOIN workout_exercises we ON w.id = we.workout_id
            LEFT JOIN exercises e ON we.exercise_id = e.id
            WHERE w.id = ? AND w.username = ?
            GROUP BY w.id
        ''', (workout_id, username))
        
        row = cursor.fetchone()
        if not row:
            conn.close()
            return jsonify({'success': False, 'error': 'Workout not found'})
        
        name, date, exercise_count, exercises = row
        
        print(f"Debug: Raw data from database:")
        print(f"  name = '{name}'")
        print(f"  date = '{date}'")
        print(f"  exercise_count = {exercise_count}")
        print(f"  exercises = '{exercises}'")
        
        # Get user message if provided
        user_message = request.form.get('user_message', '').strip()
        print(f"Debug: user_message = '{user_message}'")
        
        # Create post content with clean format
        # Extract just the workout name (remove any date or extra parts)
        workout_name = name
        if ' - ' in name:
            workout_name = name.split(' - ')[0]
        elif ' Push Day' in name:
            workout_name = name.split(' Push Day')[0]
        
        print(f"Debug: Original name = '{name}'")
        print(f"Debug: Cleaned workout_name = '{workout_name}'")
        
        content = f"{workout_name}\n\n"
        content += f"{date}\n"
        
        if exercises:
            exercise_list = exercises.split(',')
            for exercise in exercise_list:
                # Clean up the exercise format
                exercise_clean = exercise.strip()
                if '(' in exercise_clean:
                    exercise_name = exercise_clean.split(' (')[0].strip()
                    exercise_details = exercise_clean.split('(')[1].split(')')[0].strip()
                    content += f"{exercise_name} ({exercise_details})\n"
                else:
                    content += f"{exercise_clean}\n"
        
        # Add user message if provided
        if user_message:
            content = f"{user_message}\n\n{content}"
        
        print(f"Debug: Final workout content = '{content}'")
        print(f"Debug: Content length = {len(content)}")
        print(f"Debug: Content lines = {content.split(chr(10))}")
        
        # Share to each selected community
        for community_id in communities:
            cursor.execute('''
                INSERT INTO posts (username, community_id, content, timestamp)
                VALUES (?, ?, ?, NOW())
            ''', (username, community_id, content))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

# Workout Management Routes
@app.route('/create_workout', methods=['POST'])
def create_workout():
    print(f"Debug: create_workout called")
    print(f"Debug: session username: {session.get('username')}")
    print(f"Debug: form data: {request.form}")
    
    if 'username' not in session:
        print(f"Debug: User not logged in")
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        name = request.form.get('name')
        date = request.form.get('date')
        
        print(f"Debug: name={name}, date={date}")
        
        if not name or not date:
            print(f"Debug: Missing required fields")
            return jsonify({'success': False, 'error': 'Missing required fields'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Create workouts table if it doesn't exist
        if USE_MYSQL:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workouts (
                    id INTEGER PRIMARY KEY AUTO_INCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
        else:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS workouts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    username VARCHAR(191) NOT NULL,
                    name TEXT NOT NULL,
                    date TEXT NOT NULL,
                    created_at TEXT DEFAULT (datetime('now'))
                )
            ''')
        
        # Insert workout
        if USE_MYSQL:
            cursor.execute('''
                INSERT INTO workouts (username, name, date)
                VALUES (%s, %s, %s)
            ''', (session['username'], name, date))
        else:
            cursor.execute('''
                INSERT INTO workouts (username, name, date)
                VALUES (?, ?, ?)
            ''', (session['username'], name, date))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_workouts', methods=['GET'])
def get_workouts():
    if 'username' not in session:
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Get workouts
        cursor.execute('''
            SELECT w.id, w.name, w.date, w.created_at,
                   COUNT(we.id) as exercise_count
            FROM workouts w
            LEFT JOIN workout_exercises we ON w.id = we.workout_id
            WHERE w.username = ?
            GROUP BY w.id
            ORDER BY w.date DESC
        ''', (session['username'],))
        
        workouts = []
        for row in cursor.fetchall():
            workout = {
                'id': get_scalar_result(row, 0, 'id'),
                'name': get_scalar_result(row, 1, 'name'),
                'date': get_scalar_result(row, 2, 'date'),
                'created_at': get_scalar_result(row, 3, 'created_at'),
                'exercise_count': get_scalar_result(row, 4, 'exercise_count')
            }
            workouts.append(workout)
        
        conn.close()
        return jsonify({'success': True, 'workouts': workouts})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_workout_details', methods=['GET'])
def get_workout_details():
    if 'username' not in session:
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        workout_id = request.args.get('workout_id')
        if not workout_id:
            return jsonify({'success': False, 'error': 'Missing workout ID'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Get workout details
        cursor.execute('''
            SELECT w.id, w.name, w.date, w.created_at
            FROM workouts w
            WHERE w.id = ? AND w.username = ?
        ''', (workout_id, session['username']))
        
        workout_row = cursor.fetchone()
        if not workout_row:
            return jsonify({'success': False, 'error': 'Workout not found'})
        
        workout = {
            'id': get_scalar_result(workout_row, 0, 'id'),
            'name': get_scalar_result(workout_row, 1, 'name'),
            'date': get_scalar_result(workout_row, 2, 'date'),
            'created_at': get_scalar_result(workout_row, 3, 'created_at'),
            'exercises': []
        }
        
        # Get workout exercises
        cursor.execute('''
            SELECT we.id, we.weight, we.sets, we.reps, e.name as exercise_name, e.muscle_group
            FROM workout_exercises we
            JOIN exercises e ON we.exercise_id = e.id
            WHERE we.workout_id = ?
            ORDER BY we.id
        ''', (workout_id,))
        
        for row in cursor.fetchall():
            exercise = {
                'id': get_scalar_result(row, 0, 'id'),
                'weight': get_scalar_result(row, 1, 'weight'),
                'sets': get_scalar_result(row, 2, 'sets'),
                'reps': get_scalar_result(row, 3, 'reps'),
                'exercise_name': get_scalar_result(row, 4, 'exercise_name'),
                'muscle_group': get_scalar_result(row, 5, 'muscle_group')
            }
            workout['exercises'].append(exercise)
        
        conn.close()
        return jsonify({'success': True, 'workout': workout})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/add_exercise_to_workout', methods=['POST'])
def add_exercise_to_workout():
    if 'username' not in session:
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        workout_id = request.form.get('workout_id')
        exercise_id = request.form.get('exercise_id')
        weight = request.form.get('weight')
        sets = request.form.get('sets')
        reps = request.form.get('reps')
        
        print(f"Debug: Adding exercise to workout - workout_id: {workout_id}, exercise_id: {exercise_id}, weight: {weight}, sets: {sets}, reps: {reps}")
        
        if not all([workout_id, exercise_id, weight, sets, reps]):
            return jsonify({'success': False, 'error': 'Missing required fields'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify workout belongs to user
        if USE_MYSQL:
            cursor.execute('''
                SELECT id FROM workouts 
                WHERE id = %s AND username = %s
            ''', (workout_id, session['username']))
        else:
            cursor.execute('''
                SELECT id FROM workouts 
                WHERE id = ? AND username = ?
            ''', (workout_id, session['username']))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Workout not found'})
        
        # Add exercise to workout
        if USE_MYSQL:
            cursor.execute('''
                INSERT INTO workout_exercises (workout_id, exercise_id, weight, sets, reps)
                VALUES (%s, %s, %s, %s, %s)
            ''', (workout_id, exercise_id, weight, sets, reps))
        else:
            cursor.execute('''
                INSERT INTO workout_exercises (workout_id, exercise_id, weight, sets, reps)
                VALUES (?, ?, ?, ?, ?)
            ''', (workout_id, exercise_id, weight, sets, reps))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/remove_exercise_from_workout', methods=['POST'])
def remove_exercise_from_workout():
    if 'username' not in session:
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        workout_exercise_id = request.form.get('workout_exercise_id')
        
        if not workout_exercise_id:
            return jsonify({'success': False, 'error': 'Missing workout exercise ID'})
        
        print(f"Debug: Removing workout exercise ID: {workout_exercise_id}")
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify workout exercise belongs to user
        if USE_MYSQL:
            cursor.execute('''
                SELECT we.id FROM workout_exercises we
                JOIN workouts w ON we.workout_id = w.id
                WHERE we.id = %s AND w.username = %s
            ''', (workout_exercise_id, session['username']))
        else:
            cursor.execute('''
                SELECT we.id FROM workout_exercises we
                JOIN workouts w ON we.workout_id = w.id
                WHERE we.id = ? AND w.username = ?
            ''', (workout_exercise_id, session['username']))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Workout exercise not found'})
        
        # Remove exercise from workout
        if USE_MYSQL:
            cursor.execute('DELETE FROM workout_exercises WHERE id = %s', (workout_exercise_id,))
        else:
            cursor.execute('DELETE FROM workout_exercises WHERE id = ?', (workout_exercise_id,))
        
        print(f"Debug: Removed workout exercise ID: {workout_exercise_id}")
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/delete_workout', methods=['POST'])
def delete_workout():
    if 'username' not in session:
        return jsonify({'success': False, 'error': 'Not logged in'})
    
    try:
        workout_id = request.form.get('workout_id')
        
        if not workout_id:
            return jsonify({'success': False, 'error': 'Missing workout ID'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Verify workout belongs to user
        if USE_MYSQL:
            cursor.execute('''
                SELECT id FROM workouts 
                WHERE id = %s AND username = %s
            ''', (workout_id, session['username']))
        else:
            cursor.execute('''
                SELECT id FROM workouts 
                WHERE id = ? AND username = ?
            ''', (workout_id, session['username']))
        
        if not cursor.fetchone():
            return jsonify({'success': False, 'error': 'Workout not found'})
        
        # Delete workout exercises first (due to foreign key)
        if USE_MYSQL:
            cursor.execute('DELETE FROM workout_exercises WHERE workout_id = %s', (workout_id,))
        else:
            cursor.execute('DELETE FROM workout_exercises WHERE workout_id = ?', (workout_id,))
        
        # Delete workout
        if USE_MYSQL:
            cursor.execute('DELETE FROM workouts WHERE id = %s', (workout_id,))
        else:
            cursor.execute('DELETE FROM workouts WHERE id = ?', (workout_id,))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_user_exercises', methods=['GET'])
@login_required
def get_user_exercises():
    try:
        username = session.get('username')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Get all exercises with their weight history
        cursor.execute('''
            SELECT e.id, e.name, e.muscle_group,
                   es.weight, es.reps, es.created_at
            FROM exercises e
            LEFT JOIN exercise_sets es ON e.id = es.exercise_id
            WHERE e.username = ?
            ORDER BY e.muscle_group, e.name, es.created_at DESC
        ''', (username,))
        
        rows = cursor.fetchall()
        conn.close()
        
        # Group exercises with their weight history
        exercises = []
        current_exercise = None
        
        for row in rows:
            exercise_id = get_scalar_result(row, 0, 'id')
            exercise_name = get_scalar_result(row, 1, 'name')
            muscle_group = get_scalar_result(row, 2, 'muscle_group')
            
            # If this is a new exercise
            if not current_exercise or current_exercise['id'] != exercise_id:
                current_exercise = {
                    'id': exercise_id,
                    'name': exercise_name,
                    'muscle_group': muscle_group,
                    'weight_history': []
                }
                exercises.append(current_exercise)
            
            # Add weight data if it exists
            weight_val = get_scalar_result(row, 3, 'weight')
            reps_val = get_scalar_result(row, 4, 'reps')
            created_at_val = get_scalar_result(row, 5, 'created_at')
            if weight_val:  # If there's weight data
                current_exercise['weight_history'].append({
                    'weight': weight_val,
                    'reps': reps_val,
                    'date': created_at_val
                })
        
        print(f"Debug: Found {len(exercises)} exercises for user {username}")
        for exercise in exercises:
            print(f"Debug: Exercise '{exercise['name']}' has {len(exercise['weight_history'])} weight entries")
            if exercise['weight_history']:
                print(f"Debug: Weight entries: {exercise['weight_history']}")
        
        return jsonify({'success': True, 'exercises': exercises})
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/admin/get_user_exercises', methods=['GET'])
@login_required
def admin_get_user_exercises():
    try:
        username = session.get('username')
        if not is_app_admin(username):
            return jsonify({'success': False, 'error': 'Forbidden'}), 403
        target = request.args.get('username', '').strip()
        if not target:
            return jsonify({'success': False, 'error': 'username required'}), 400

        conn = get_db_connection()
        cursor = conn.cursor()

        # Fetch all exercises and their sets for the target user
        cursor.execute('''
            SELECT e.id, e.name, e.muscle_group, es.weight, es.reps, es.created_at
            FROM exercises e
            LEFT JOIN exercise_sets es ON e.id = es.exercise_id
            WHERE e.username = ?
            ORDER BY e.muscle_group, e.name, es.created_at DESC
        ''', (target,))

        rows = cursor.fetchall()
        conn.close()

        # Group into structured list
        exercises = []
        current = None
        for row in rows:
            ex_id = get_scalar_result(row, 0, 'id')
            ex_name = get_scalar_result(row, 1, 'name')
            ex_group = get_scalar_result(row, 2, 'muscle_group')
            weight_val = get_scalar_result(row, 3, 'weight')
            reps_val = get_scalar_result(row, 4, 'reps')
            created_at_val = get_scalar_result(row, 5, 'created_at')
            if current is None or current['id'] != ex_id:
                current = { 'id': ex_id, 'name': ex_name, 'muscle_group': ex_group, 'weight_history': [] }
                exercises.append(current)
            if weight_val is not None:
                current['weight_history'].append({ 'weight': float(weight_val), 'reps': int(reps_val or 0), 'date': created_at_val })

        return jsonify({ 'success': True, 'exercises': exercises, 'username': target })
    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) })

@app.route('/api/admin/set_parent', methods=['GET', 'POST'])
@login_required
def admin_set_parent():
    """Set a community's parent by names or ids. Admin only.
    Accepts: child_id or child_name, parent_id or parent_name (query or form)
    """
    try:
        requester = session.get('username')
        if not is_app_admin(requester):
            return jsonify({'success': False, 'error': 'Forbidden'}), 403

        # Read inputs (names or ids)
        child_id = request.values.get('child_id') or request.args.get('child_id')
        parent_id = request.values.get('parent_id') or request.args.get('parent_id')
        child_name = (request.values.get('child_name') or request.args.get('child_name') or '').strip()
        parent_name = (request.values.get('parent_name') or request.args.get('parent_name') or '').strip()

        with get_db_connection() as conn:
            c = conn.cursor()

            def resolve_comm_id(name_or_id, is_parent=False):
                # If numeric id provided, return it
                if name_or_id and str(name_or_id).isdigit():
                    return int(name_or_id)
                return None

            # Resolve parent id
            pid = resolve_comm_id(parent_id, True)
            if not pid and parent_name:
                c.execute("SELECT id FROM communities WHERE name = ?", (parent_name,))
                row = c.fetchone()
                if not row:
                    return jsonify({'success': False, 'error': f"Parent not found: {parent_name}"}), 404
                pid = row['id'] if hasattr(row, 'keys') else row[0]

            # Resolve child id
            cid = resolve_comm_id(child_id, False)
            if not cid and child_name:
                c.execute("SELECT id FROM communities WHERE name = ?", (child_name,))
                row = c.fetchone()
                if not row:
                    return jsonify({'success': False, 'error': f"Child not found: {child_name}"}), 404
                cid = row['id'] if hasattr(row, 'keys') else row[0]

            if not cid or not pid:
                return jsonify({'success': False, 'error': 'child and parent are required (by id or name)'}), 400

            # Update relationship
            c.execute("UPDATE communities SET parent_community_id = ? WHERE id = ?", (pid, cid))
            conn.commit()

            return jsonify({'success': True, 'child_id': int(cid), 'parent_id': int(pid)})
    except Exception as e:
        logger.error(f"admin_set_parent error: {e}")
        return jsonify({'success': False, 'error': 'server error'}), 500

@app.route('/api/admin/legacy_user_exercises', methods=['GET'])
@login_required
def admin_legacy_user_exercises():
    """Retrieve legacy exercise data for a user from the SQLite users.db file when current DB is MySQL."""
    try:
        requester = session.get('username')
        if not is_app_admin(requester):
            return jsonify({'success': False, 'error': 'Forbidden'}), 403
        target = request.args.get('username', '').strip()
        if not target:
            return jsonify({'success': False, 'error': 'username required'}), 400

        # Determine legacy source: if current is MySQL, read from SQLite file
        legacy_exercises = []
        try:
            db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'users.db')
            if os.path.exists(db_path):
                conn = sqlite3.connect(db_path)
                conn.row_factory = sqlite3.Row
                c = conn.cursor()
                # Gather exercises
                c.execute("SELECT id, name, muscle_group FROM exercises WHERE username = ? ORDER BY muscle_group, name", (target,))
                ex_rows = c.fetchall()
                for ex in ex_rows:
                    ex_id = ex['id']
                    item = { 'id': ex_id, 'name': ex['name'], 'muscle_group': ex['muscle_group'], 'weight_history': [] }
                    # From exercise_sets
                    c.execute("SELECT weight, reps, created_at FROM exercise_sets WHERE exercise_id = ? ORDER BY created_at DESC", (ex_id,))
                    for s in c.fetchall():
                        item['weight_history'].append({ 'weight': float(s['weight']), 'reps': int(s['reps']), 'date': s['created_at'] })
                    # Also convert workout_exercises into weight entries (if present)
                    try:
                        c.execute("SELECT weight, reps, created_at FROM workout_exercises WHERE exercise_id = ? ORDER BY created_at DESC", (ex_id,))
                        for s in c.fetchall():
                            item['weight_history'].append({ 'weight': float(s['weight'] or 0), 'reps': int(s['reps'] or 0), 'date': s['created_at'] })
                    except Exception:
                        pass
                    legacy_exercises.append(item)
                conn.close()
        except Exception as _e:
            # If legacy source not available, return empty
            pass

        return jsonify({ 'success': True, 'username': target, 'exercises': legacy_exercises, 'source': 'sqlite_users.db' })
    except Exception as e:
        return jsonify({ 'success': False, 'error': str(e) })

@app.route('/api/admin/merge_legacy_user_exercises', methods=['GET', 'POST'])
@login_required
def admin_merge_legacy_user_exercises():
    """Merge legacy exercises from SQLite users.db into current DB for a specific user (admin-only)."""
    try:
        requester = session.get('username')
        if not is_app_admin(requester):
            return jsonify({'success': False, 'error': 'Forbidden'}), 403
        # Support both POST form and GET query param
        target = (request.form.get('username') or request.args.get('username') or '').strip()
        if not target:
            return jsonify({'success': False, 'error': 'username required'}), 400

        db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'users.db')
        if not os.path.exists(db_path):
            return jsonify({'success': False, 'error': 'legacy users.db not found'}), 404

        # Read legacy data first
        legacy = []
        s_conn = sqlite3.connect(db_path)
        s_conn.row_factory = sqlite3.Row
        s = s_conn.cursor()
        s.execute("SELECT id, name, muscle_group FROM exercises WHERE username = ? ORDER BY muscle_group, name", (target,))
        ex_rows = s.fetchall()
        for ex in ex_rows:
            ex_id = ex['id']
            item = { 'name': ex['name'], 'muscle_group': ex['muscle_group'], 'sets': [] }
            s.execute("SELECT weight, reps, created_at FROM exercise_sets WHERE exercise_id = ? ORDER BY created_at", (ex_id,))
            for r in s.fetchall():
                item['sets'].append((float(r['weight']), int(r['reps']), r['created_at']))
            # Also import from workout_exercises if present
            try:
                s.execute("SELECT weight, reps, created_at FROM workout_exercises WHERE exercise_id = ? ORDER BY created_at", (ex_id,))
                for r in s.fetchall():
                    item['sets'].append((float(r['weight'] or 0), int(r['reps'] or 0), r['created_at']))
            except Exception:
                pass
            legacy.append(item)
        s_conn.close()

        # Merge into current DB
        conn = get_db_connection()
        c = conn.cursor()
        inserted_ex = 0
        inserted_sets = 0
        for ex in legacy:
            # Check if exercise exists
            if USE_MYSQL:
                c.execute("SELECT id FROM exercises WHERE username = %s AND name = %s AND muscle_group = %s", (target, ex['name'], ex['muscle_group']))
            else:
                c.execute("SELECT id FROM exercises WHERE username = ? AND name = ? AND muscle_group = ?", (target, ex['name'], ex['muscle_group']))
            row = c.fetchone()
            if row:
                ex_id = row['id'] if hasattr(row, 'keys') else row[0]
            else:
                # Insert exercise
                if USE_MYSQL:
                    c.execute("INSERT INTO exercises (username, name, muscle_group) VALUES (%s, %s, %s)", (target, ex['name'], ex['muscle_group']))
                else:
                    c.execute("INSERT INTO exercises (username, name, muscle_group) VALUES (?, ?, ?)", (target, ex['name'], ex['muscle_group']))
                inserted_ex += 1
                # Retrieve new id
                if USE_MYSQL:
                    c.execute("SELECT LAST_INSERT_ID()")
                    ex_id = list(c.fetchone().values())[0]
                else:
                    ex_id = c.lastrowid

            # Insert sets, avoid duplicates by exact match
            for (w, rps, dt) in ex['sets']:
                if USE_MYSQL:
                    c.execute("SELECT 1 FROM exercise_sets WHERE exercise_id = %s AND weight = %s AND reps = %s AND created_at = %s", (ex_id, w, rps, dt))
                else:
                    c.execute("SELECT 1 FROM exercise_sets WHERE exercise_id = ? AND weight = ? AND reps = ? AND created_at = ?", (ex_id, w, rps, dt))
                if c.fetchone():
                    continue
                if USE_MYSQL:
                    c.execute("INSERT INTO exercise_sets (exercise_id, weight, reps, created_at) VALUES (%s, %s, %s, %s)", (ex_id, w, rps, dt))
                else:
                    c.execute("INSERT INTO exercise_sets (exercise_id, weight, reps, created_at) VALUES (?, ?, ?, ?)", (ex_id, w, rps, dt))
                inserted_sets += 1

        conn.commit()
        conn.close()

        return jsonify({ 'success': True, 'merged_exercises': inserted_ex, 'merged_sets': inserted_sets, 'username': target })
    except Exception as e:
        try:
            conn.close()
        except Exception:
            pass
        return jsonify({ 'success': False, 'error': str(e) })





@app.route('/test_version')
def test_version():
    return jsonify({'version': '1755799276', 'message': 'Updated version loaded with format fix'})
@app.route('/test_database')
def test_database():
    try:
        conn = sqlite3.connect('users.db')
        cursor = conn.cursor()
        
        # Check if tables exist
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = cursor.fetchall()
        
        # Check exercises table
        cursor.execute("SELECT COUNT(*) FROM exercises")
        exercise_count = cursor.fetchone()[0]
        
        # Check workouts table
        cursor.execute("SELECT COUNT(*) FROM workouts")
        workout_count = cursor.fetchone()[0]
        
        # Check exercise_sets table
        cursor.execute("SELECT COUNT(*) FROM exercise_sets")
        sets_count = cursor.fetchone()[0]
        
        # Check communities table structure
        cursor.execute("SHOW COLUMNS FROM communities")
        community_columns = cursor.fetchall()
        
        # Check if required columns exist
        column_names = [col['Field'] for col in community_columns]
        missing_columns = []
        if 'info' not in column_names:
            missing_columns.append('info')
        if 'info_updated_at' not in column_names:
            missing_columns.append('info_updated_at')
        
        # Check community_announcements table
        announcements_count = 0
        try:
            cursor.execute("SELECT COUNT(*) FROM community_announcements")
            announcements_count = cursor.fetchone()[0]
        except:
            pass
        
        # Check community_files table
        files_count = 0
        try:
            cursor.execute("SELECT COUNT(*) FROM community_files")
            files_count = cursor.fetchone()[0]
        except:
            pass
        
        conn.close()
        
        return jsonify({
            'tables': [table[0] for table in tables],
            'exercise_count': exercise_count,
            'workout_count': workout_count,
            'sets_count': sets_count,
            'community_columns': column_names,
            'missing_columns': missing_columns,
            'needs_fix': len(missing_columns) > 0,
            'announcements_count': announcements_count,
            'files_count': files_count
        })
        
    except Exception as e:
        return jsonify({'error': str(e)})

@app.route('/fix_communities_table')
def fix_communities_table():
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if info column exists
        cursor.execute("SHOW COLUMNS FROM communities")
        columns = [col['Field'] for col in cursor.fetchall()]
        
        changes_made = []
        
        if 'info' not in columns:
            logger.info("Adding info column to communities table...")
            cursor.execute("ALTER TABLE communities ADD COLUMN info TEXT")
            changes_made.append('info column added')
        
        if 'info_updated_at' not in columns:
            logger.info("Adding info_updated_at column to communities table...")
            cursor.execute("ALTER TABLE communities ADD COLUMN info_updated_at TEXT")
            changes_made.append('info_updated_at column added')
        
        conn.commit()
        conn.close()
        
        if changes_made:
            return jsonify({'success': True, 'message': f'Database updated: {", ".join(changes_made)}'})
        else:
            return jsonify({'success': True, 'message': 'All columns already exist'})
        
    except Exception as e:
        logger.error(f"Error fixing communities table: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/test_format')
def test_format():
    # Simulate the format generation
    workout_name = "Wod v3 Push Day"
    date = "2025-08-21"
    
    # Extract clean workout name
    clean_name = workout_name
    if ' - ' in workout_name:
        clean_name = workout_name.split(' - ')[0]
    elif ' Push Day' in workout_name:
        clean_name = workout_name.split(' Push Day')[0]
    
    content = f"{clean_name}\n\n"
    content += f"{date}\n"
    content += "Hack Squat (40.0kg x 2 sets x 12 reps)\n"
    content += "Bench Press (150.0kg x 1 sets x 1 reps)\n"
    
    return jsonify({
        'original_name': workout_name,
        'clean_name': clean_name,
        'date': date,
        'final_content': content,
        'content_lines': content.split('\n')
    })

@app.route('/test_community_template')
def test_community_template():
    """Test route to check if community template renders correctly"""
    try:
        # Create a mock community object
        mock_community = {
            'id': 1,
            'name': 'Test Community',
            'type': 'Test',
            'creator_username': 'admin',
            'join_code': 'TEST123',
            'created_at': '2025-01-01',
            'description': 'Test description',
            'location': 'Test location',
            'background_path': '',
            'info': 'Test announcement\nWith multiple lines',
            'info_updated_at': '2025-01-01 12:00:00',
            'template': 'default',
            'background_color': '#2d3839',
            'text_color': '#ffffff',
            'accent_color': '#4db6ac',
            'card_color': '#1a2526'
        }
        
        # Return JSON instead of HTML template
        return jsonify({
            'success': True,
            'community': mock_community,
            'posts': [],
            'message': 'Test route - community_feed.html removed, use React version'
        })
    except Exception as e:
        import traceback
        return jsonify({
            'success': False, 
            'error': str(e), 
            'traceback': traceback.format_exc()
        })

@app.route('/simple_test', endpoint='simple_test_route')
def simple_test_route():
    """Simple test route without any decorators"""
    return jsonify({'success': True, 'message': 'Simple test route works'})
# Community Announcements Routes
@app.route('/save_community_info', methods=['POST'])
def save_community_info():
    try:
        if 'username' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'})
        
        community_id = request.form.get('community_id')
        info = request.form.get('info', '')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if user is admin or community creator
        cursor.execute('''
            SELECT creator_username FROM communities 
            WHERE id = ?
        ''', (community_id,))
        
        community = cursor.fetchone()
        if not community:
            return jsonify({'success': False, 'error': 'Community not found'})
        
        if session['username'] != community['creator_username'] and session['username'] != 'admin':
            return jsonify({'success': False, 'error': 'Unauthorized'})
        
        # Save announcement to announcements table
        cursor.execute('''
            INSERT INTO community_announcements 
            (community_id, content, created_by, created_at)
            VALUES (?, ?, ?, ?)
        ''', (community_id, info, session['username'], datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
        
        # Update community info to show latest announcement
        cursor.execute('''
            UPDATE communities 
            SET info = ?, info_updated_at = ? 
            WHERE id = ?
        ''', (info, datetime.now().strftime('%Y-%m-%d %H:%M:%S'), community_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        logger.error(f"Error saving community info: {e}")
        return jsonify({'success': False, 'error': str(e)})
@app.route('/upload_community_files', methods=['POST'])
def upload_community_files():
    try:
        if 'username' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'})
        
        community_id = request.form.get('community_id')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if user is admin or community creator
        cursor.execute('''
            SELECT creator_username FROM communities 
            WHERE id = ?
        ''', (community_id,))
        
        community = cursor.fetchone()
        if not community:
            return jsonify({'success': False, 'error': 'Community not found'})
        
        if session['username'] != community['creator_username'] and session['username'] != 'admin':
            return jsonify({'success': False, 'error': 'Unauthorized'})
        
        # Create community files directory
        community_files_dir = os.path.join('static', 'community_files', str(community_id))
        os.makedirs(community_files_dir, exist_ok=True)
        
        uploaded_files = []
        files = request.files.getlist('files')
        
        for file in files:
            if file and file.filename:
                filename = secure_filename(file.filename)
                file_path = os.path.join(community_files_dir, filename)
                file.save(file_path)
                
                # Get file description
                description = request.form.get('description', '')
                
                # Save file info to database
                cursor.execute('''
                    INSERT INTO community_files (community_id, filename, uploaded_by, upload_date, description)
                    VALUES (?, ?, ?, ?, ?)
                ''', (community_id, filename, session['username'], datetime.now().strftime('%Y-%m-%d %H:%M:%S'), description))
                
                uploaded_files.append(filename)
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True, 'files': uploaded_files})
        
    except Exception as e:
        logger.error(f"Error uploading community files: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_community_files', methods=['GET'])
def get_community_files():
    try:
        community_id = request.args.get('community_id')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT filename, uploaded_by, upload_date, description 
            FROM community_files 
            WHERE community_id = ?
            ORDER BY upload_date DESC
        ''', (community_id,))
        
        files = []
        for row in cursor.fetchall():
            files.append({
                'filename': row['filename'],
                'uploaded_by': row['uploaded_by'],
                'upload_date': row['upload_date'],
                'description': row['description'] or ''
            })
        
        conn.close()
        
        return jsonify({'success': True, 'files': files})
        
    except Exception as e:
        logger.error(f"Error getting community files: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/download_community_file/<filename>')
def download_community_file(filename):
    try:
        community_id = request.args.get('community_id')
        
        if not community_id:
            return jsonify({'success': False, 'error': 'Community ID required'})
        
        file_path = os.path.join('static', 'community_files', str(community_id), filename)
        
        if not os.path.exists(file_path):
            return jsonify({'success': False, 'error': 'File not found'})
        
        return send_from_directory(os.path.dirname(file_path), filename)
        
    except Exception as e:
        logger.error(f"Error downloading community file: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_community_file', methods=['POST'])
def delete_community_file():
    try:
        if 'username' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'})
        
        community_id = request.form.get('community_id')
        file_id = request.form.get('file_id')
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if user is admin or community creator
        cursor.execute('''
            SELECT creator_username FROM communities 
            WHERE id = ?
        ''', (community_id,))
        
        community = cursor.fetchone()
        if not community:
            return jsonify({'success': False, 'error': 'Community not found'})
        
        if session['username'] != community['creator_username'] and session['username'] != 'admin':
            return jsonify({'success': False, 'error': 'Unauthorized'})
        
        # Get file info first
        cursor.execute('''
            SELECT filename, file_path FROM community_files 
            WHERE id = ? AND community_id = ?
        ''', (file_id, community_id))
        
        file_data = cursor.fetchone()
        if not file_data:
            return jsonify({'success': False, 'error': 'File not found'})
        
        # Delete file from filesystem
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file_data['file_path'])
        if os.path.exists(file_path):
            os.remove(file_path)
        
        # Delete file record from database
        cursor.execute('''
            DELETE FROM community_files 
            WHERE id = ? AND community_id = ?
        ''', (file_id, community_id))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        logger.error(f"Error deleting community file: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/save_community_announcement', methods=['POST'])
def save_community_announcement():
    try:
        if 'username' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'})
        
        content = request.form.get('content')
        community_id_raw = request.form.get('community_id')
        
        if not content or not community_id_raw:
            return jsonify({'success': False, 'error': 'Missing required fields'})
        
        try:
            community_id = int(community_id_raw)
        except (TypeError, ValueError):
            return jsonify({'success': False, 'error': 'Invalid community ID'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Create tables if they don't exist
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS community_announcements (
                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                community_id INTEGER NOT NULL,
                content TEXT NOT NULL,
                created_by TEXT NOT NULL,
                created_at TEXT NOT NULL
            )
        ''')
        
        # Drop and recreate community_files table with correct structure
        cursor.execute("DROP TABLE IF EXISTS community_files")
        cursor.execute('''
            CREATE TABLE community_files (
                id INTEGER PRIMARY KEY AUTO_INCREMENT,
                announcement_id INTEGER NOT NULL,
                community_id INTEGER NOT NULL,
                filename TEXT NOT NULL,
                file_path TEXT NOT NULL,
                uploaded_by TEXT NOT NULL,
                uploaded_at TEXT NOT NULL,
                upload_date TEXT NOT NULL,
                FOREIGN KEY (announcement_id) REFERENCES community_announcements (id) ON DELETE CASCADE
            )
        ''')
        
        # Check if user is creator, app admin, or community admin
        cursor.execute('''
            SELECT creator_username FROM communities 
            WHERE id = ?
        ''', (community_id,))
        community = cursor.fetchone()
        if not community:
            return jsonify({'success': False, 'error': 'Community not found'})

        current_user = session['username']
        if not has_community_management_permission(current_user, community_id):
            return jsonify({'success': False, 'error': 'Unauthorized'})
        
        # Save announcement to database
        cursor.execute('''
            INSERT INTO community_announcements (community_id, content, created_by, created_at)
            VALUES (?, ?, ?, ?)
        ''', (community_id, content, session['username'], datetime.now().strftime('%Y-%m-%d')))
        
        announcement_id = cursor.lastrowid
        
        # Handle file uploads
        files = request.files.getlist('files')
        uploaded_files = []
        
        for file in files:
            if file and file.filename:
                # Create unique filename
                filename = secure_filename(file.filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                unique_filename = f"{timestamp}_{filename}"
                
                # Save file to uploads directory
                file_path = os.path.join(app.config['UPLOAD_FOLDER'], unique_filename)
                file.save(file_path)
                
                # Save file info to database
                cursor.execute('''
                    INSERT INTO community_files (announcement_id, community_id, filename, file_path, uploaded_by, uploaded_at, upload_date)
                    VALUES (?, ?, ?, ?, ?, ?, ?)
                ''', (announcement_id, community_id, filename, unique_filename, session['username'], datetime.now().strftime('%Y-%m-%d'), datetime.now().strftime('%Y-%m-%d')))
                
                uploaded_files.append({
                    'filename': filename,
                    'file_path': unique_filename
                })
        
        # Update community info to show the latest announcement
        cursor.execute('''
            UPDATE communities 
            SET info = ?, info_updated_at = ? 
            WHERE id = ?
        ''', (content, datetime.now().strftime('%Y-%m-%d'), community_id))
        
        conn.commit()

        # Notify all members of this community via Web Push and in-app notifications (best-effort)
        try:
            # Fetch community name for nicer title
            community_name = None
            try:
                cursor.execute("SELECT name FROM communities WHERE id = ?", (community_id,))
                rown = cursor.fetchone()
                community_name = (rown['name'] if hasattr(rown, 'keys') else rown[0]) if rown else None
            except Exception:
                community_name = None

            # Load all member usernames
            cursor.execute(
                """
                SELECT u.username
                FROM user_communities uc
                JOIN users u ON uc.user_id = u.id
                WHERE uc.community_id = ?
                """,
                (community_id,)
            )
            members = [r['username'] if hasattr(r, 'keys') else r[0] for r in (cursor.fetchall() or [])]
            # Trim announcement body for push body
            body_snippet = (content or '')[:120]
            for m in members:
                if not m or m == current_user:
                    continue
                # In-app notification (announcement)
                try:
                    if 'USE_MYSQL' in globals() and USE_MYSQL:
                        cursor.execute(
                            """
                            INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                            VALUES (?, ?, 'announcement', ?, ?, NOW(), 0, ?)
                            ON DUPLICATE KEY UPDATE created_at = NOW(), is_read = 0, message = VALUES(message), link = VALUES(link)
                            """,
                            (m, current_user, community_id, f"New announcement in {community_name}" if community_name else "New announcement", f"/community_feed_react/{community_id}")
                        )
                    else:
                        cursor.execute(
                            """
                            INSERT INTO notifications (user_id, from_user, type, community_id, message, created_at, is_read, link)
                            VALUES (?, ?, 'announcement', ?, ?, datetime('now'), 0, ?)
                            ON CONFLICT(user_id, from_user, type, community_id)
                            DO UPDATE SET created_at = datetime('now'), is_read = 0, message = excluded.message, link = excluded.link
                            """,
                            (m, current_user, community_id, f"New announcement in {community_name}" if community_name else "New announcement", f"/community_feed_react/{community_id}")
                        )
                except Exception as ne:
                    logger.warning(f"announcement in-app notify warn to {m}: {ne}")
                try:
                    send_push_to_user(m, {
                        'title': f"New announcement{(' in ' + community_name) if community_name else ''}",
                        'body': body_snippet,
                        'url': f"/community_feed_react/{community_id}",
                        'tag': f"community-announcement-{community_id}"
                    })
                except Exception as pe:
                    logger.warning(f"announcement push warn to {m}: {pe}")
        except Exception as ne:
            logger.warning(f"announcement notify warn: {ne}")

        conn.close()
        return jsonify({'success': True, 'files': uploaded_files})
        
    except Exception as e:
        logger.error(f"Error saving community announcement: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/get_community_announcements', methods=['GET'])
def get_community_announcements():
    try:
        community_id = request.args.get('community_id')
        logger.info(f"Getting announcements for community_id: {community_id}")
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, content, created_by, created_at 
            FROM community_announcements 
            WHERE community_id = ?
            ORDER BY created_at DESC
        ''', (community_id,))
        
        rows = cursor.fetchall()
        logger.info(f"Found {len(rows)} announcements for community {community_id}")
        
        announcements = []
        for row in rows:
            # Get files for this announcement
            cursor.execute('''
                SELECT id, filename, file_path, uploaded_by, uploaded_at
                FROM community_files 
                WHERE announcement_id = ?
                ORDER BY uploaded_at DESC
            ''', (row['id'],))
            
            files = []
            for file_row in cursor.fetchall():
                files.append({
                    'id': file_row['id'],
                    'filename': file_row['filename'],
                    'file_path': file_row['file_path'],
                    'uploaded_by': file_row['uploaded_by'],
                    'uploaded_at': file_row['uploaded_at']
                })
            
            announcements.append({
                'id': row['id'],
                'content': row['content'],
                'created_by': row['created_by'],
                'created_at': row['created_at'],
                'files': files
            })
        
        conn.close()
        
        return jsonify({'success': True, 'announcements': announcements})
        
    except Exception as e:
        logger.error(f"Error getting community announcements: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/delete_community_announcement', methods=['POST'])
def delete_community_announcement():
    try:
        if 'username' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'})
        
        announcement_id = request.form.get('announcement_id')
        community_id_raw = request.form.get('community_id')
        
        try:
            community_id = int(community_id_raw)
        except (TypeError, ValueError):
            return jsonify({'success': False, 'error': 'Invalid community ID'})
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check if user is creator, app admin, or community admin
        cursor.execute('''
            SELECT creator_username FROM communities 
            WHERE id = ?
        ''', (community_id,))
        community = cursor.fetchone()
        if not community:
            return jsonify({'success': False, 'error': 'Community not found'})

        current_user = session['username']
        if not has_community_management_permission(current_user, community_id):
            return jsonify({'success': False, 'error': 'Unauthorized'})
        
        # Delete announcement from database
        cursor.execute('''
            DELETE FROM community_announcements 
            WHERE id = ? AND community_id = ?
        ''', (announcement_id, community_id))
        
        # Update community info to show the next latest announcement
        cursor.execute('''
            SELECT content, created_at FROM community_announcements 
            WHERE community_id = ? 
            ORDER BY created_at DESC 
            LIMIT 1
        ''', (community_id,))
        
        latest = cursor.fetchone()
        if latest:
            cursor.execute('''
                UPDATE communities 
                SET info = ?, info_updated_at = ? 
                WHERE id = ?
            ''', (latest['content'], latest['created_at'], community_id))
        else:
            cursor.execute('''
                UPDATE communities 
                SET info = NULL, info_updated_at = NULL 
                WHERE id = ?
            ''', (community_id,))
        
        conn.commit()
        conn.close()
        
        return jsonify({'success': True})
        
    except Exception as e:
        logger.error(f"Error deleting community announcement: {e}")
        return jsonify({'success': False, 'error': str(e)})

@app.route('/download_announcement_file/<int:file_id>')
def download_announcement_file(file_id):
    """Download a community file"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT filename, file_path FROM community_files 
            WHERE id = ?
        ''', (file_id,))
        
        file_data = cursor.fetchone()
        logger.info(f"File data for ID {file_id}: {file_data}")
        conn.close()
        
        if not file_data:
            return "File not found", 404
        
        if not file_data['file_path']:
            return "File path not found", 404
            
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], file_data['file_path'])
        
        if not os.path.exists(file_path):
            return "File not found", 404
        
        return send_from_directory(app.config['UPLOAD_FOLDER'], file_data['file_path'], as_attachment=True, download_name=file_data['filename'])
        
    except Exception as e:
        logger.error(f"Error downloading community file: {e}")
        return "Error downloading file", 500

@app.route('/debug_table_structure')
def debug_table_structure():
    """Debug route to check table structure"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Check community_files table structure
        cursor.execute("SHOW COLUMNS FROM community_files")
        columns = cursor.fetchall()
        
        conn.close()
        
        return jsonify({
            'success': True,
            'community_files_columns': [{'name': col[1], 'type': col[2], 'notnull': col[3]} for col in columns]
        })
        
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})
@app.route('/cleanup_missing_images')
@login_required
def cleanup_missing_images():
    """Clean up database references to missing image files"""
    if session.get('username') != 'admin':
        return "Access denied", 403
    
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            
            # Get all posts with image_path
            c.execute("SELECT id, image_path FROM posts WHERE image_path IS NOT NULL AND image_path != '' AND image_path != 'None'")
            posts = c.fetchall()
            
            cleaned_count = 0
            for post in posts:
                image_path = post['image_path']
                # Clean the path
                clean_path = image_path.replace('uploads/uploads/', '').replace('uploads/', '')
                full_path = os.path.join(app.config['UPLOAD_FOLDER'], clean_path)
                
                # Check if file exists
                if not os.path.exists(full_path):
                    logger.info(f"Cleaning missing image reference: {image_path} for post {post['id']}")
                    c.execute("UPDATE posts SET image_path = NULL WHERE id = ?", (post['id'],))
                    cleaned_count += 1
            
            conn.commit()
            return jsonify({
                'success': True,
                'message': f'Cleaned {cleaned_count} missing image references',
                'cleaned_count': cleaned_count
            })
            
    except Exception as e:
        logger.error(f"Error cleaning missing images: {str(e)}")
        return jsonify({'success': False, 'error': str(e)})
@app.route('/seed_dummy_data', methods=['POST'])
@login_required
def seed_dummy_data():
    try:
        # Only allow admin to seed
        username = session.get('username')
        if username != 'admin':
            return jsonify({'success': False, 'error': 'Unauthorized'}), 403

        import random
        from datetime import datetime, timedelta

        with get_db_connection() as conn:
            c = conn.cursor()

            # Ensure crossfit_entries table exists
            c.execute('''CREATE TABLE IF NOT EXISTS crossfit_entries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                username VARCHAR(191) NOT NULL,
                type TEXT NOT NULL,
                name TEXT NOT NULL,
                weight REAL,
                reps INTEGER,
                score TEXT,
                score_numeric REAL,
                created_at TEXT NOT NULL
            )''')

            # Create or get Gym and Crossfit communities
            def get_or_create_community(name, ctype):
                c.execute('SELECT id FROM communities WHERE name=? AND type=?', (name, ctype))
                r = c.fetchone()
                if r:
                    return r['id'] if isinstance(r, sqlite3.Row) else r[0]
                join_code = generate_join_code()
                c.execute('''INSERT INTO communities (name, type, creator_username, join_code, created_at)
                             VALUES (?, ?, ?, ?, ?)''', (name, ctype, 'admin', join_code, datetime.now().strftime('%m.%d.%y %H:%M')))
                return c.lastrowid

            gym_comm_id = get_or_create_community('Demo Gym', 'gym')
            cf_comm_id = get_or_create_community('Demo Crossfit Box', 'crossfit')

            # Helper to get or create user and map to communities
            def ensure_user(u):
                c.execute('SELECT rowid FROM users WHERE username=?', (u,))
                row = c.fetchone()
                if not row:
                    c.execute('''INSERT INTO users (username, email, password, created_at)
                                 VALUES (?, ?, ?, ?)''', (u, f'{u}@example.com', '12345', datetime.now().strftime('%m.%d.%y %H:%M')))
                    c.execute('SELECT rowid FROM users WHERE username=?', (u,))
                    row = c.fetchone()
                user_id = row['rowid'] if isinstance(row, sqlite3.Row) else row[0]
                # Add to communities if not already
                for comm_id in (gym_comm_id, cf_comm_id):
                    c.execute('SELECT 1 FROM user_communities WHERE user_id=? AND community_id=?', (user_id, comm_id))
                    if not c.fetchone():
                        try:
                            add_user_to_community(c, user_id, int(comm_id), role=None)
                        except CommunityMembershipLimitError:
                            logger.warning(f"Skipping seed membership for user {u} in community {comm_id} due to free-plan member limit.")

            # Generate 20 users
            users = [f'user{i:02d}' for i in range(1, 21)]
            for u in users:
                ensure_user(u)

            # Gym seed data: a few common exercises
            gym_exercises = [
                ('Bench Press', 'Chest'),
                ('Back Squat', 'Legs'),
                ('Deadlift', 'Back'),
                ('Overhead Press', 'Shoulders')
            ]

            # Crossfit lists (subset)
            cf_lifts = ['Back Squat','Deadlift','Clean','Snatch','Thruster']
            cf_wods = ['Fran','Cindy','Helen','Grace','Isabel']

            # 6-month timeline (roughly every 7 days)
            today = datetime.now().date()
            start_date = today - timedelta(days=180)
            dates = [start_date + timedelta(days=7*i) for i in range(27)]

            # Seed gym exercises/sets
            for u in users:
                for name, group in gym_exercises:
                    # Ensure exercise row exists for user
                    c.execute('SELECT id FROM exercises WHERE username=? AND name=?', (u, name))
                    row = c.fetchone()
                    if row:
                        ex_id = row['id'] if isinstance(row, sqlite3.Row) else row[0]
                    else:
                        c.execute('INSERT INTO exercises (username, name, muscle_group) VALUES (?, ?, ?)', (u, name, group))
                        ex_id = c.lastrowid
                    # Generate progressive sets over dates
                    base = random.randint(50, 90)
                    for idx, d in enumerate(dates):
                        weight = base + int(idx * random.uniform(0.2, 0.8))
                        reps = random.choice([3,5,8])
                        c.execute('INSERT INTO exercise_sets (exercise_id, weight, reps, created_at) VALUES (?, ?, ?, ?)', (ex_id, weight, reps, d.isoformat()))

            # Seed crossfit lifts and WODs
            def time_str(seconds):
                m = seconds // 60; s = seconds % 60
                return f"{int(m)}:{int(s):02d}"

            for u in users:
                # Lifts
                for name in cf_lifts:
                    base = random.randint(40, 100)
                    for idx, d in enumerate(dates):
                        w = base + int(idx * random.uniform(0.3, 1.0))
                        reps = random.choice([1,3,5])
                        c.execute('''INSERT INTO crossfit_entries (username, type, name, weight, reps, created_at)
                                     VALUES (?, 'lift', ?, ?, ?, ?)''', (u, name, w, reps, d.isoformat()))
                # WODs (lower is better)
                for name in cf_wods:
                    base = random.randint(300, 1200)  # seconds
                    for idx, d in enumerate(dates):
                        seconds = max(120, int(base - idx * random.uniform(1.0, 4.0)))
                        score = time_str(seconds)
                        c.execute('''INSERT INTO crossfit_entries (username, type, name, score, score_numeric, created_at)
                                     VALUES (?, 'wod', ?, ?, ?, ?)''', (u, name, score, seconds, d.isoformat()))

            conn.commit()

        return jsonify({'success': True, 'users_created': len(users), 'dates': len(dates)})
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)})

@app.route('/api/get_user_id_by_username', methods=['POST'])
@login_required
def api_get_user_id_by_username():
    try:
        username = request.form.get('username','').strip()
        if not username:
            return jsonify({ 'success': False, 'error': 'username required' }), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT id FROM users WHERE username=?", (username,))
            row = c.fetchone()
            if not row:
                return jsonify({ 'success': False, 'error': 'user not found' }), 404
            user_id = row['id'] if hasattr(row, 'keys') else row[0]
            return jsonify({ 'success': True, 'user_id': user_id })
    except Exception as e:
        logger.error(f"Error resolving user id: {e}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500

@app.route('/api/get_user_profile_brief', methods=['GET'])
@login_required
def api_get_user_profile_brief():
    """Return brief profile info for a given username: display_name and profile_picture (relative path)"""
    try:
        username = request.args.get('username','').strip()
        if not username:
            return jsonify({ 'success': False, 'error': 'username required' }), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT display_name, profile_picture FROM user_profiles WHERE username=?", (username,))
            row = c.fetchone()
            display_name = None
            profile_picture = None
            if row:
                try:
                    display_name = row['display_name'] if hasattr(row, 'keys') and 'display_name' in row.keys() else row[0]
                    profile_picture = row['profile_picture'] if hasattr(row, 'keys') and 'profile_picture' in row.keys() else row[1]
                except Exception:
                    pass
        return jsonify({ 'success': True, 'username': username, 'display_name': display_name or username, 'profile_picture': profile_picture })
    except Exception as e:
        logger.error(f"Error in api_get_user_profile_brief: {e}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500

# --- Typing status APIs ---
@app.route('/api/typing', methods=['POST'])
@login_required
@handle_broken_pipe
def api_set_typing():
    try:
        me = session['username']
        data = request.get_json(force=True, silent=True) or {}
        peer = (data.get('peer') or '').strip()
        is_typing = 1 if data.get('is_typing') else 0
        if not peer:
            return jsonify({ 'success': False, 'error': 'peer required' }), 400
        now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("""
                INSERT INTO typing_status (user, peer, is_typing, updated_at)
                VALUES (?, ?, ?, ?)
                ON DUPLICATE KEY UPDATE is_typing=VALUES(is_typing), updated_at=VALUES(updated_at)
            """, (me, peer, is_typing, now))
            conn.commit()
        return jsonify({ 'success': True })
    except Exception as e:
        logger.error(f"typing set error: {e}")
        return jsonify({ 'success': False }), 500

@app.route('/api/typing', methods=['GET'])
@login_required
@handle_broken_pipe
def api_get_typing():
    try:
        me = session['username']
        peer = (request.args.get('peer') or '').strip()
        if not peer:
            return jsonify({ 'success': False, 'error': 'peer required' }), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT is_typing, updated_at FROM typing_status WHERE user=? AND peer=?", (peer, me))
            row = c.fetchone()
        if not row:
            return jsonify({ 'success': True, 'is_typing': False })
        is_typing, updated_at = (row['is_typing'], row['updated_at']) if hasattr(row, 'keys') else (row[0], row[1])
        try:
            last = datetime.fromisoformat(updated_at) if 'T' in updated_at else datetime.strptime(updated_at, '%Y-%m-%d %H:%M:%S')
            fresh = (datetime.now() - last).total_seconds() <= TYPING_TTL_SECONDS
        except Exception:
            fresh = False
        return jsonify({ 'success': True, 'is_typing': bool(is_typing) and fresh })
    except Exception as e:
        logger.error(f"typing get error: {e}")
        return jsonify({ 'success': False, 'is_typing': False }), 500

# Web Push: expose public VAPID key
@app.route('/api/push/public_key')
@login_required
def api_push_public_key():
    if not VAPID_PUBLIC_KEY:
        return jsonify({ 'publicKey': '' })
    return jsonify({ 'publicKey': VAPID_PUBLIC_KEY })

# Save a browser subscription
@app.route('/api/push/subscribe', methods=['POST'])
@login_required
def api_push_subscribe():
    try:
        sub = request.get_json(force=True, silent=True) or {}
        endpoint = sub.get('endpoint')
        keys = sub.get('keys') or {}
        p256dh = keys.get('p256dh')
        authk = keys.get('auth')
        if not endpoint:
            return jsonify({ 'success': False, 'error': 'invalid subscription' }), 400
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("REPLACE INTO push_subscriptions (username, endpoint, p256dh, auth) VALUES (?,?,?,?)",
                      (session['username'], endpoint, p256dh, authk))
            conn.commit()
        return jsonify({ 'success': True })
    except Exception as e:
        logger.error(f"push subscribe error: {e}")
        return jsonify({ 'success': False }), 500

@app.route('/api/push/status')
@login_required
def api_push_status():
    """Return whether the current user has an active push subscription stored."""
    try:
        username = session.get('username')
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT COUNT(1) FROM push_subscriptions WHERE username=?", (username,))
            row = c.fetchone()
            count = row[0] if row and not hasattr(row, 'keys') else (row['COUNT(1)'] if row else 0)
        return jsonify({ 'success': True, 'hasSubscription': (count or 0) > 0 })
    except Exception as e:
        logger.error(f"push status error: {e}")
        return jsonify({ 'success': False, 'hasSubscription': False }), 500


def _set_native_push_cookie(response, install_id: str):
    """Attach/update the native push install cookie on the response."""
    try:
        response.set_cookie(
            'native_push_install_id',
            install_id,
            max_age=60 * 60 * 24 * 365,
            secure=app.config.get('SESSION_COOKIE_SECURE', False),
            httponly=False,
            samesite='Lax',
        )
    except Exception:
        pass


@app.route('/api/native_push/register', methods=['POST'])
def api_native_push_register():
    """Register or refresh a native (APNs) token. Works before or after login."""
    try:
        data = request.get_json(force=True, silent=True) or {}
    except Exception:
        data = {}

    token = (data.get('token') or '').strip()
    if not token:
        return jsonify({ 'success': False, 'error': 'token required' }), 400

    install_id = request.cookies.get('native_push_install_id') or secrets.token_urlsafe(24)
    platform = (data.get('platform') or 'ios').lower()
    environment = (data.get('environment') or DEFAULT_APNS_ENVIRONMENT).lower()
    bundle_id = (data.get('bundle_id') or '').strip() or None
    device_name = (data.get('device_name') or '').strip() or None
    username = session.get('username')

    try:
        register_native_push_token(
            token=token,
            username=username,
            install_id=install_id,
            platform=platform,
            environment=environment,
            bundle_id=bundle_id,
            device_name=device_name,
        )
        if username:
            associate_install_tokens_with_user(install_id, username)
        resp = jsonify({ 'success': True, 'install_id': install_id, 'linked': bool(username) })
        _set_native_push_cookie(resp, install_id)
        return resp
    except ValueError:
        return jsonify({ 'success': False, 'error': 'token required' }), 400
    except Exception as exc:
        app.logger.error(f"native push register error: {exc}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500


@app.route('/api/native_push/claim', methods=['POST'])
@login_required
def api_native_push_claim():
    """Associate any anonymous native tokens on this device with the logged-in user."""
    try:
        data = request.get_json(force=True, silent=True) or {}
    except Exception:
        data = {}
    install_id = (data.get('install_id') or '').strip() or request.cookies.get('native_push_install_id')
    if not install_id:
        return jsonify({ 'success': False, 'error': 'missing install id' }), 400
    username = session.get('username')
    try:
        updated = associate_install_tokens_with_user(install_id, username)
        resp = jsonify({ 'success': True, 'updated': updated })
        _set_native_push_cookie(resp, install_id)
        return resp
    except Exception as exc:
        app.logger.error(f"native push claim error: {exc}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500


@app.route('/api/native_push/unregister', methods=['POST'])
def api_native_push_unregister():
    """Remove a native push token (e.g., on logout or uninstall)."""
    try:
        data = request.get_json(force=True, silent=True) or {}
    except Exception:
        data = {}
    token = (data.get('token') or '').strip()
    if not token:
        return jsonify({ 'success': False, 'error': 'token required' }), 400
    try:
        unregister_native_push_token(session.get('username'), token)
        return jsonify({ 'success': True })
    except Exception as exc:
        app.logger.error(f"native push unregister error: {exc}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500


@app.route('/api/active_chat', methods=['POST'])
@login_required
@handle_broken_pipe
def api_active_chat():
    """Record that the current user is actively viewing a chat with peer. Used to suppress push notifications."""
    try:
        me = session.get('username')
        data = request.get_json(force=True, silent=True) or {}
        peer = (data.get('peer') or '').strip()
        if not peer:
            return jsonify({ 'success': False, 'error': 'peer required' }), 400
        now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        with get_db_connection() as conn:
            c = conn.cursor()
            if USE_MYSQL:
                c.execute("""
                    INSERT INTO active_chat_status (user, peer, updated_at)
                    VALUES (?, ?, NOW())
                    ON DUPLICATE KEY UPDATE updated_at=NOW()
                """, (me, peer))
            else:
                c.execute("""
                    INSERT INTO active_chat_status (user, peer, updated_at)
                    VALUES (?, ?, ?)
                    ON CONFLICT(user, peer) DO UPDATE SET updated_at=excluded.updated_at
                """, (me, peer, now))
            conn.commit()
        return jsonify({ 'success': True })
    except Exception as e:
        logger.error(f"active chat set error: {e}")
        return jsonify({ 'success': False }), 500

def _collect_mentions(text: str) -> list:
    """Return lowercased usernames mentioned with @, avoiding emails and words."""
    try:
        import re as _re
        # Negative lookbehind to ensure @ is not preceded by a word character (avoids emails)
        pattern = _re.compile(r"(?<!\w)@([A-Za-z0-9_]{1,30})")
        return list({ m.group(1).lower() for m in pattern.finditer(text or '') })
    except Exception:
        return []

def process_mentions_for_post(post_id: int, author_username: str):
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            c.execute("SELECT content, community_id FROM posts WHERE id = ?", (post_id,))
            row = c.fetchone()
            if not row:
                return
            content = row['content'] if hasattr(row, 'keys') else row[0]
            community_id = row['community_id'] if hasattr(row, 'keys') else row[1]
            mentions = _collect_mentions(content)
            if not mentions:
                return
            try:
                logger.info(f"mentions-post: post_id={post_id} author={author_username} found={mentions}")
            except Exception:
                pass
            members_map = {}
            if community_id:
                c.execute("SELECT u.username FROM users u JOIN user_communities uc ON u.id=uc.user_id WHERE uc.community_id=?", (community_id,))
                for r in c.fetchall() or []:
                    uname = r['username'] if hasattr(r,'keys') else r[0]
                    members_map[uname.lower()] = uname
            current_lower = (author_username or '').lower()
            allowed = [u for u in mentions if (u != current_lower) and (not community_id or u in members_map)]
            try:
                logger.info(f"mentions-post: allowed={allowed} members={list(members_map.keys())[:5]}...")
            except Exception:
                pass
            # Fallback: if allowed empty but mentions exist, notify valid platform users (ignoring community)
            if not allowed and mentions:
                try:
                    # Resolve to canonical usernames that exist on the platform
                    resolved: list[str] = []
                    for m in mentions:
                        if m == current_lower:
                            continue
                        c.execute("SELECT username FROM users WHERE LOWER(username)=? LIMIT 1", (m,))
                        rr = c.fetchone()
                        if rr:
                            resolved.append(rr['username'] if hasattr(rr,'keys') else rr[0])
                    if resolved:
                        logger.info(f"mentions-post: fallback notifying={resolved}")
                        for target in resolved:
                            try:
                                if USE_MYSQL:
                                    c.execute("""
                                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                                        VALUES (?, ?, 'mention_post', ?, ?, ?, NOW(), 0)
                                        ON DUPLICATE KEY UPDATE created_at = NOW(), is_read = 0, message = VALUES(message)
                                    """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a post"))
                                else:
                                    now_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    c.execute("""
                                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                                        VALUES (?, ?, 'mention_post', ?, ?, ?, ?, 0)
                                    """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a post", now_ts))
                                conn.commit()
                                try:
                                    send_push_to_user(target, {
                                        'title': 'You were mentioned',
                                        'body': f"{author_username} mentioned you in a post",
                                        'url': f"/post/{post_id}",
                                        'tag': f"mention-post-{post_id}-{target}"
                                    })
                                except Exception as pe:
                                    logger.warning(f"push mention post fallback warn: {pe}")
                            except Exception as ne:
                                logger.warning(f"mention post fallback insert warn to {target}: {ne}")
                except Exception as fe:
                    logger.warning(f"mentions-post fallback error: {fe}")
            for target_lower in allowed:
                target = members_map.get(target_lower, target_lower)
                try:
                    if USE_MYSQL:
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                            VALUES (?, ?, 'mention_post', ?, ?, ?, NOW(), 0)
                            ON DUPLICATE KEY UPDATE created_at = NOW(), is_read = 0, message = VALUES(message)
                        """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a post"))
                    else:
                        now_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                            VALUES (?, ?, 'mention_post', ?, ?, ?, ?, 0)
                        """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a post", now_ts))
                    conn.commit()
                    try:
                        send_push_to_user(target, {
                            'title': 'You were mentioned',
                            'body': f"{author_username} mentioned you in a post",
                            'url': f"/post/{post_id}",
                            'tag': f"mention-post-{post_id}-{target}"
                        })
                    except Exception as pe:
                        logger.warning(f"push mention post helper warn: {pe}")
                except Exception as ne:
                    logger.warning(f"mention post helper insert warn to {target}: {ne}")
    except Exception as e:
        logger.warning(f"process_mentions_for_post error: {e}")

def process_mentions_for_reply(post_id: int, author_username: str, community_id: int|None, reply_id: int|None = None):
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Get exact reply content if reply_id provided, else most recent by this author/post
            if reply_id:
                c.execute("SELECT content FROM replies WHERE id=? LIMIT 1", (reply_id,))
            else:
                c.execute("""
                    SELECT content FROM replies
                    WHERE post_id=? AND username=?
                    ORDER BY id DESC
                    LIMIT 1
                """, (post_id, author_username))
            row = c.fetchone()
            if not row:
                return
            content = row['content'] if hasattr(row, 'keys') else row[0]
            mentions = _collect_mentions(content)
            if not mentions:
                return
            try:
                logger.info(f"mentions-reply: post_id={post_id} reply_id={reply_id} author={author_username} found={mentions}")
            except Exception:
                pass
            members_map = {}
            if community_id:
                c.execute("SELECT u.username FROM users u JOIN user_communities uc ON u.id=uc.user_id WHERE uc.community_id=?", (community_id,))
                for r in c.fetchall() or []:
                    uname = r['username'] if hasattr(r,'keys') else r[0]
                    members_map[uname.lower()] = uname
            current_lower = (author_username or '').lower()
            allowed = [u for u in mentions if (u != current_lower) and (not community_id or u in members_map)]
            try:
                logger.info(f"mentions-reply: allowed={allowed} members={list(members_map.keys())[:5]}...")
            except Exception:
                pass
            # Fallback: if allowed empty but mentions exist, notify valid platform users (ignoring community)
            if not allowed and mentions:
                try:
                    resolved: list[str] = []
                    for m in mentions:
                        if m == current_lower:
                            continue
                        c.execute("SELECT username FROM users WHERE LOWER(username)=? LIMIT 1", (m,))
                        rr = c.fetchone()
                        if rr:
                            resolved.append(rr['username'] if hasattr(rr,'keys') else rr[0])
                    if resolved:
                        logger.info(f"mentions-reply: fallback notifying={resolved}")
                        for target in resolved:
                            try:
                                if USE_MYSQL:
                                    c.execute("""
                                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                                        VALUES (?, ?, 'mention_reply', ?, ?, ?, NOW(), 0)
                                        ON DUPLICATE KEY UPDATE created_at = NOW(), is_read = 0, message = VALUES(message)
                                    """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a reply"))
                                else:
                                    now_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    c.execute("""
                                        INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                                        VALUES (?, ?, 'mention_reply', ?, ?, ?, ?, 0)
                                    """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a reply", now_ts))
                                conn.commit()
                                try:
                                    send_push_to_user(target, {
                                        'title': 'You were mentioned',
                                        'body': f"{author_username} mentioned you in a reply",
                                        'url': f"/post/{post_id}",
                                        'tag': f"mention-reply-{post_id}-{target}"
                                    })
                                except Exception as pe:
                                    logger.warning(f"push mention reply fallback warn: {pe}")
                            except Exception as ne:
                                logger.warning(f"mention reply fallback insert warn to {target}: {ne}")
                except Exception as fe:
                    logger.warning(f"mentions-reply fallback error: {fe}")
            for target_lower in allowed:
                target = members_map.get(target_lower, target_lower)
                try:
                    if USE_MYSQL:
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                            VALUES (?, ?, 'mention_reply', ?, ?, ?, NOW(), 0)
                            ON DUPLICATE KEY UPDATE created_at = NOW(), is_read = 0, message = VALUES(message)
                        """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a reply"))
                    else:
                        now_ts = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        c.execute("""
                            INSERT INTO notifications (user_id, from_user, type, post_id, community_id, message, created_at, is_read)
                            VALUES (?, ?, 'mention_reply', ?, ?, ?, ?, 0)
                        """, (target, author_username, post_id, community_id, f"{author_username} mentioned you in a reply", now_ts))
                    conn.commit()
                    try:
                        send_push_to_user(target, {
                            'title': 'You were mentioned',
                            'body': f"{author_username} mentioned you in a reply",
                            'url': f"/post/{post_id}",
                            'tag': f"mention-reply-{post_id}-{target}"
                        })
                    except Exception as pe:
                        logger.warning(f"push mention reply helper warn: {pe}")
                except Exception as ne:
                    logger.warning(f"mention reply helper insert warn to {target}: {ne}")
    except Exception as e:
        logger.warning(f"process_mentions_for_reply error: {e}")

@app.route('/api/push/test', methods=['POST'])
@login_required
def api_push_test():
    """Send a test push notification to the current user."""
    try:
        if not VAPID_PUBLIC_KEY or not VAPID_PRIVATE_KEY:
            return jsonify({ 'success': False, 'error': 'VAPID keys not configured on server' }), 400
        username = session.get('username')
        data = request.get_json(silent=True) or {}
        title = data.get('title') or 'Test notification'
        body = data.get('body') or 'If you see this, push works.'
        url = data.get('url') or '/'
        send_push_to_user(username, { 'title': title, 'body': body, 'url': url })
        return jsonify({ 'success': True })
    except Exception as e:
        logger.error(f"push test error: {e}")
        return jsonify({ 'success': False, 'error': 'failed to send' }), 500

@app.route('/get_active_chat_counts')
@login_required
def get_active_chat_counts():
    """Return number of distinct chat partners per community for the current user."""
    username = session.get('username')
    try:
        with get_db_connection() as conn:
            c = conn.cursor()
            # Map usernames to id for joins
            c.execute("SELECT id FROM users WHERE username=?", (username,))
            me = c.fetchone()
            if not me:
                return jsonify({ 'success': False, 'error': 'user not found' }), 404
            # Communities the user belongs to
            c.execute("""
                SELECT c.id, c.name
                FROM communities c
                JOIN user_communities uc ON c.id = uc.community_id
                JOIN users u ON uc.user_id = u.id
                WHERE u.username = ?
            """, (username,))
            comms = [dict(row) for row in c.fetchall()]
            results = []
            for comm in comms:
                # Distinct partners in this community: any user who shares this community and has message with me
                c.execute("""
                    SELECT DISTINCT m.sender as user
                    FROM messages m
                    WHERE m.receiver = ?
                    UNION
                    SELECT DISTINCT m.receiver as user
                    FROM messages m
                    WHERE m.sender = ?
                """, (username, username))
                partners = {row['user'] for row in c.fetchall()}
                if not partners:
                    results.append({ 'community_id': comm['id'], 'community_name': comm['name'], 'active_chats': 0 })
                    continue
                placeholders = ",".join(["?"]*len(partners))
                params = list(partners)
                # Intersect with community members
                c.execute(f"""
                    SELECT COUNT(DISTINCT u.username) as cnt
                    FROM users u
                    JOIN user_communities uc ON u.id = uc.user_id
                    WHERE uc.community_id = ? AND u.username IN ({placeholders}) AND u.username != ?
                """, [comm['id'], *params, username])
                row = c.fetchone()
                cnt = row['cnt'] if isinstance(row, dict) else (row[0] if row else 0)
                results.append({ 'community_id': comm['id'], 'community_name': comm['name'], 'active_chats': cnt or 0 })
            return jsonify({ 'success': True, 'counts': results })
    except Exception as e:
        logger.error(f"Error in get_active_chat_counts: {e}")
        return jsonify({ 'success': False, 'error': 'server error' }), 500

# Register encryption endpoints for E2E encryption
try:
    register_encryption_endpoints(app, get_db_connection, logger)
except Exception as e:
    logger.error(f"Failed to register encryption endpoints: {e}")

try:
    register_signal_endpoints(app, get_db_connection, logger)
except Exception as e:
    logger.error(f"Failed to register signal endpoints: {e}")

if __name__ == '__main__':
    app.run(debug=False, host='0.0.0.0', port=8080)
